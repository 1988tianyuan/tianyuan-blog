{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/1547708979007.png","path":"images/1547708979007.png","modified":0,"renderable":0},{"_id":"source/images/1547709525963.png","path":"images/1547709525963.png","modified":0,"renderable":0},{"_id":"source/images/1547709651604.png","path":"images/1547709651604.png","modified":0,"renderable":0},{"_id":"source/images/1547712156480.png","path":"images/1547712156480.png","modified":0,"renderable":0},{"_id":"source/images/1547710015291.png","path":"images/1547710015291.png","modified":0,"renderable":0},{"_id":"source/images/1547712312524.png","path":"images/1547712312524.png","modified":0,"renderable":0},{"_id":"source/images/1547713322805.png","path":"images/1547713322805.png","modified":0,"renderable":0},{"_id":"source/images/1559481447073.png","path":"images/1559481447073.png","modified":0,"renderable":0},{"_id":"source/images/1547713402558.png","path":"images/1547713402558.png","modified":0,"renderable":0},{"_id":"source/images/1547712873168.png","path":"images/1547712873168.png","modified":0,"renderable":0},{"_id":"source/images/1547792452619.png","path":"images/1547792452619.png","modified":0,"renderable":0},{"_id":"source/images/3pc-1.png","path":"images/3pc-1.png","modified":0,"renderable":0},{"_id":"source/images/1559482380158.png","path":"images/1559482380158.png","modified":0,"renderable":0},{"_id":"source/images/3pc-2.png","path":"images/3pc-2.png","modified":0,"renderable":0},{"_id":"source/images/3pc-3.png","path":"images/3pc-3.png","modified":0,"renderable":0},{"_id":"source/images/image.png","path":"images/image.png","modified":0,"renderable":0},{"_id":"source/images/nagle.jpg","path":"images/nagle.jpg","modified":0,"renderable":0},{"_id":"source/images/pasted-1.png","path":"images/pasted-1.png","modified":0,"renderable":0},{"_id":"source/images/pasted-19.png","path":"images/pasted-19.png","modified":0,"renderable":0},{"_id":"source/images/pasted-2.png","path":"images/pasted-2.png","modified":0,"renderable":0},{"_id":"source/images/pasted-20.png","path":"images/pasted-20.png","modified":0,"renderable":0},{"_id":"source/images/pasted-24.png","path":"images/pasted-24.png","modified":0,"renderable":0},{"_id":"source/images/pasted-25.png","path":"images/pasted-25.png","modified":0,"renderable":0},{"_id":"source/images/pasted-29.png","path":"images/pasted-29.png","modified":0,"renderable":0},{"_id":"source/images/pasted-3.png","path":"images/pasted-3.png","modified":0,"renderable":0},{"_id":"source/images/pasted-4.png","path":"images/pasted-4.png","modified":0,"renderable":0},{"_id":"source/images/pasted-5.png","path":"images/pasted-5.png","modified":0,"renderable":0},{"_id":"source/images/pasted-9.png","path":"images/pasted-9.png","modified":0,"renderable":0},{"_id":"source/images/pasted-7.png","path":"images/pasted-7.png","modified":0,"renderable":0},{"_id":"source/images/pasted-6.png","path":"images/pasted-6.png","modified":0,"renderable":0},{"_id":"source/images/pasted-8.png","path":"images/pasted-8.png","modified":0,"renderable":0},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"source/images/1559568139040.png","path":"images/1559568139040.png","modified":0,"renderable":0},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"source/images/pasted-16.png","path":"images/pasted-16.png","modified":0,"renderable":0},{"_id":"source/images/pasted-18.png","path":"images/pasted-18.png","modified":0,"renderable":0},{"_id":"source/images/1548985987329.png","path":"images/1548985987329.png","modified":0,"renderable":0},{"_id":"source/images/kafka.png","path":"images/kafka.png","modified":0,"renderable":0},{"_id":"source/images/pasted-22.png","path":"images/pasted-22.png","modified":0,"renderable":0},{"_id":"source/images/pasted-21.png","path":"images/pasted-21.png","modified":0,"renderable":0},{"_id":"source/images/pasted-23.png","path":"images/pasted-23.png","modified":0,"renderable":0},{"_id":"source/images/pasted-26.png","path":"images/pasted-26.png","modified":0,"renderable":0},{"_id":"source/images/pasted-28.png","path":"images/pasted-28.png","modified":0,"renderable":0},{"_id":"source/images/pasted-10.png","path":"images/pasted-10.png","modified":0,"renderable":0},{"_id":"source/images/pasted-13.png","path":"images/pasted-13.png","modified":0,"renderable":0},{"_id":"source/images/pasted-15.png","path":"images/pasted-15.png","modified":0,"renderable":0},{"_id":"source/images/pasted-11.png","path":"images/pasted-11.png","modified":0,"renderable":0},{"_id":"source/images/pasted-27.png","path":"images/pasted-27.png","modified":0,"renderable":0},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/next-boot.js","path":"js/src/next-boot.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"source/images/pasted-17.png","path":"images/pasted-17.png","modified":0,"renderable":0},{"_id":"source/images/pasted-14.png","path":"images/pasted-14.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"source/images/pasted-0.png","path":"images/pasted-0.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/muse.js","path":"js/src/schemes/muse.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"source/images/pasted-12.png","path":"images/pasted-12.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"source/images/pasted-30.png","path":"images/pasted-30.png","modified":0,"renderable":0},{"_id":"source/images/avatar.jpg","path":"images/avatar.jpg","modified":0,"renderable":0}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1622430393236},{"_id":"themes/next/.eslintrc.json","hash":"cc5f297f0322672fe3f684f823bc4659e4a54c41","modified":1622430393236},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1622430393236},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1622430393236},{"_id":"themes/next/.all-contributorsrc","hash":"14a716cd05a63d8473053914d67c0f2392b58c37","modified":1622430393236},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1622430393236},{"_id":"themes/next/README.md","hash":"be1aee74c5b82a1255d7159cc218dc1ada055e3e","modified":1622430393236},{"_id":"themes/next/LICENSE.md","hash":"18144d8ed58c75af66cb419d54f3f63374cd5c5b","modified":1622430393236},{"_id":"themes/next/.travis.yml","hash":"3d1dc928c4a97933e64379cfde749dedf62f252c","modified":1622430393236},{"_id":"themes/next/bower.json","hash":"1be57277396806031619b0f625cbeba0224a7cb5","modified":1622430393237},{"_id":"themes/next/package.json","hash":"f3b4ef65214cec9c37acd10ef080526fb1ea14bb","modified":1622430393268},{"_id":"themes/next/_config.yml","hash":"4f367b8a93634fb1a3957f8872be395f492ebab1","modified":1553089548520},{"_id":"themes/next/crowdin.yml","hash":"e026078448c77dcdd9ef50256bb6635a8f83dca6","modified":1622430393237},{"_id":"themes/next/gulpfile.coffee","hash":"48d2f9fa88a4210308fc41cc7d3f6d53989f71b7","modified":1622430393243},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"141e989844d0b5ae2e09fb162a280715afb39b0d","modified":1622430393238},{"_id":"themes/next/docs/DATA-FILES.md","hash":"8e1962dd3e1b700169b3ae5bba43992f100651ce","modified":1622430393239},{"_id":"themes/next/docs/AUTHORS.md","hash":"7b24be2891167bdedb9284a682c2344ec63e50b5","modified":1622430393238},{"_id":"themes/next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1622430393238},{"_id":"themes/next/docs/INSTALLATION.md","hash":"2bbdd6c1751b2b42ce9b9335da420c6026a483e9","modified":1622430393239},{"_id":"themes/next/docs/LICENSE.txt","hash":"368bf2c29d70f27d8726dd914f1b3211cae4bbab","modified":1622430393239},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"212a36d57495990b5f56e46ca8dce1d76c199660","modified":1622430393239},{"_id":"themes/next/languages/default.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1553009877224},{"_id":"themes/next/languages/de.yml","hash":"9e524b2bdfb848504b93a51c5650e76bba5fa9e0","modified":1622430393243},{"_id":"themes/next/languages/en.yml","hash":"c540c3a0d7db2d4239293c8783881962640b6c34","modified":1622430393244},{"_id":"themes/next/languages/it.yml","hash":"b30ff77ad8044e3b021a3b09187cd377dc789fd2","modified":1622430393244},{"_id":"themes/next/languages/ja.yml","hash":"1dc35e436da6214cdb3c2ff44bc4a06d0be5b9a0","modified":1622430393245},{"_id":"themes/next/languages/ko.yml","hash":"20bfaa7600d35235996c18e5c13dcef89c119626","modified":1622430393245},{"_id":"themes/next/languages/nl.yml","hash":"1c44b3cb2f817808607f3bf6ef47f58ce7599995","modified":1622430393245},{"_id":"themes/next/languages/pt-BR.yml","hash":"08b913a5cf4cc160083069cb4dfb2d66eecd1218","modified":1622430393245},{"_id":"themes/next/languages/fr.yml","hash":"d37a5d82b499a2f082fe9bbf3ad9f11b36b6b837","modified":1622430393244},{"_id":"themes/next/languages/id.yml","hash":"1c4868837f5109f1df863b04fe627352c31d404b","modified":1622430393244},{"_id":"themes/next/docs/MATH.md","hash":"e6023505dcccaef0b856102543585a13fc6af0b1","modified":1622430393239},{"_id":"themes/next/languages/pt.yml","hash":"8ddac820e2c17b484b56c0da8881e142b10e221b","modified":1622430393245},{"_id":"themes/next/languages/tr.yml","hash":"c5f0c20743b1dd52ccb256050b1397d023e6bcd9","modified":1622430393246},{"_id":"themes/next/languages/ru.yml","hash":"db0644e738d2306ac38567aa183ca3e859a3980f","modified":1622430393246},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"ad57c168d12ba01cf144a1ea0627b2ffd1847d3e","modified":1622430393240},{"_id":"themes/next/languages/uk.yml","hash":"1eb59e581568da9a81d6e20541b4ada5fc1c55c0","modified":1622430393246},{"_id":"themes/next/languages/vi.yml","hash":"ba7aff8f88e03f69a0acf7f1b90ee03e077ee88e","modified":1622430393246},{"_id":"themes/next/languages/zh-TW.yml","hash":"6e6d2cd8f4244cb1b349b94904cb4770935acefd","modified":1622430393247},{"_id":"themes/next/layout/_layout.swig","hash":"74701fcf2303d59400587436ab4c244e04df7ad9","modified":1622430393248},{"_id":"themes/next/languages/zh-CN.yml","hash":"fbbf3a0b664ae8e927c700b0a813692b94345156","modified":1622430393247},{"_id":"themes/next/languages/zh-HK.yml","hash":"7903b96912c605e630fb695534012501b2fad805","modified":1622430393247},{"_id":"themes/next/layout/post.swig","hash":"f74929fd792541916eb25c2addfb35431be071ba","modified":1622430393268},{"_id":"themes/next/layout/index.swig","hash":"c2a3896c64e96790edc10426ef586b6186a87f46","modified":1622430393268},{"_id":"themes/next/scripts/merge-configs.js","hash":"33afe97284d34542015d358a720823feeebef120","modified":1622430393269},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1622430393269},{"_id":"themes/next/layout/archive.swig","hash":"7e8f3a41a68e912f2b2aaba905d314306ccaf794","modified":1622430393268},{"_id":"themes/next/layout/tag.swig","hash":"a6be69a90924c9d2f4d90fb4867234859bd2c2e9","modified":1622430393268},{"_id":"themes/next/layout/schedule.swig","hash":"3268dd3d90d8b0e142cfa1a2ebb23355baeda148","modified":1622430393268},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1622430393296},{"_id":"themes/next/layout/category.swig","hash":"dda0e6b2139decaf5e865d22ec9d45fdb615a703","modified":1622430393268},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1622430393296},{"_id":"themes/next/layout/page.swig","hash":"d8a6cbf6f611c5d68d5da430cb6dc7010ff2c7e0","modified":1622430393268},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1622430393297},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553009878370},{"_id":"source/tags/index.md","hash":"e976c6eec426e52279846bad1d63f5054d68e91f","modified":1622430393235},{"_id":"source/_discarded/hello-world.md","hash":"1bc59add6d8c31c631b78469bb080a8ccc245527","modified":1622430393193},{"_id":"source/_discarded/TCP连接-Nagle-和-Cork.md","hash":"303cbad65a7743da9c89d263f6801a765a3abc02","modified":1622430393193},{"_id":"source/_discarded/kafka学习笔记（1）——-kafka基本特点以及与其他mq的对比.md","hash":"993bf9e83118333a915b44b3156512d6e80f4564","modified":1622430393193},{"_id":"source/_discarded/kafka学习笔记（1）——-kafka基本特点以及与其他mq的对比-1.md","hash":"dd2c4f336961d53d8a72cb6b252b445c686dc9d2","modified":1622430393193},{"_id":"source/_discarded/如何理解3PC协议.md","hash":"72c5b28ed06ba9257a4b8170bcd693edf12044b2","modified":1553783684959},{"_id":"source/categories/index.md","hash":"198eaab2175017d9c804237cff5b78b5cd6692ab","modified":1622430393203},{"_id":"source/_discarded/如何理解3PC协议-1.md","hash":"708bbec1dd46994e9c4f518d1787a59d5e2b9923","modified":1553783688544},{"_id":"source/images/1547708979007.png","hash":"b1f7b5b6eae6bb711a2b3c5ee408dd349aa55b0d","modified":1553002258501},{"_id":"source/images/1547709525963.png","hash":"72399a2f28c89b498f86a7f3f203fe4a43986ad3","modified":1553002258503},{"_id":"source/images/1547709651604.png","hash":"c67398544bde7838d68d71dac601c928c951d2ce","modified":1553002258505},{"_id":"source/images/1547712156480.png","hash":"89344a6a67e8861d9836f07dcf908c77af0cf84e","modified":1553002258507},{"_id":"source/images/1547710015291.png","hash":"4ba0af0e179bce338f32ffba3f74afdf2a005854","modified":1553002258506},{"_id":"source/_drafts/《深入理解计算机系统》读书笔记——Chapter-12-2.md","hash":"0048097b4a714c50ece6ba73a92970207bd63b44","modified":1577280593172},{"_id":"source/images/1547712312524.png","hash":"aa8dfb6a7b289029dd52d0987ee1568fce82d2a9","modified":1553002258509},{"_id":"source/_discarded/new.md","hash":"7e5b5986ef9702c7797eacc465b823c54a5b9a05","modified":1622430393193},{"_id":"source/images/1547713322805.png","hash":"fbe70104ed5347dde7c3d8ad72507b861899a2e5","modified":1553002258510},{"_id":"source/images/1559481447073.png","hash":"0176c9c1fb16b3b8e24276bb3723145d04210b50","modified":1559481447112},{"_id":"source/images/1547713402558.png","hash":"7960d279b99e8de04f1e25e0f2277bf97946fa86","modified":1553002258511},{"_id":"source/images/1547712873168.png","hash":"33b16eb035ee2ead7cd58b8ac4096e60b110782d","modified":1553002258510},{"_id":"source/images/1547792452619.png","hash":"e7f78be7f846f465a499b8e7ff18411e2131bed3","modified":1553002258513},{"_id":"source/images/3pc-1.png","hash":"2a669a25d9a86d1fecc415fc7d205970859224c6","modified":1553784562039},{"_id":"source/images/1559482380158.png","hash":"e2fd45ae2ce12c0aa776d80dae26bd1fe537d51f","modified":1559482380170},{"_id":"source/images/3pc-2.png","hash":"b915bd357a110aeb91a0de036dfea4f58702aebb","modified":1553784592209},{"_id":"source/images/3pc-3.png","hash":"88209d7105c0fcf9423c190bbbd46aceb31c7a8b","modified":1553784611370},{"_id":"source/images/image.png","hash":"a0b536df2acad1d7501fc10b38041c572ee47467","modified":1562937403604},{"_id":"source/images/nagle.jpg","hash":"b09937be89b4c34a9181559560bd6611a7b3c13c","modified":1553002258767},{"_id":"source/images/pasted-1.png","hash":"064386e353e32ae73f96d3eb521a6c4b6f544d7e","modified":1553002258770},{"_id":"source/images/pasted-19.png","hash":"40a4a3f5d3640959c626bf6ec784f70d1f6ca664","modified":1553002258831},{"_id":"source/images/pasted-2.png","hash":"3cbd3c0ba47836fc06b6106571d61fc330b7b2c5","modified":1553002258832},{"_id":"source/images/pasted-20.png","hash":"26999d9aa4326ff104df1358ddddaa6ebad37a0c","modified":1553002258834},{"_id":"source/images/pasted-24.png","hash":"12a8dfa52e3e5d8b5136cddba2a375d6f62603f8","modified":1553002258840},{"_id":"source/images/pasted-25.png","hash":"c83e737c7eb02596ccbcd8ea86fa7c7239a3d895","modified":1553002258841},{"_id":"source/images/pasted-29.png","hash":"6c223870fbc0bccfebd680bda7947f42d407ec8d","modified":1553002258848},{"_id":"source/images/pasted-3.png","hash":"9e6c97f86ff66b84de59238342d8706dbafb298f","modified":1553002258849},{"_id":"source/images/pasted-4.png","hash":"62d15792f2440d8d299adc67f7a6b784f28e6be3","modified":1553002258850},{"_id":"source/images/pasted-5.png","hash":"07b43af19dec0c3d0265b8abd5bbc6f5000f1241","modified":1553002258851},{"_id":"source/images/pasted-9.png","hash":"be2a4c8f18d02d1fba519d45b0ea6929478db084","modified":1553002258855},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"d6d20f60f77a76c77f8e65d0c9adbd79d0274557","modified":1622430393240},{"_id":"source/images/pasted-7.png","hash":"711e78431f2b6051041e84b847475ab06a19046e","modified":1553002258853},{"_id":"source/images/pasted-6.png","hash":"91ff11cc5e36ea28f55cb7e59a10d8cbc1adbdd8","modified":1553002258852},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"b1dd18d9b890b21718883ea1832e7e02a773104a","modified":1622430393241},{"_id":"source/images/pasted-8.png","hash":"ce4ba3d666934f7eed61512e6b24dc5db58fb672","modified":1553002258854},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"6c5d69e94961c793da156217ecf1179e868d7ba1","modified":1622430393240},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"6855402e2ef59aae307e8bd2a990647d3a605eb8","modified":1622430393241},{"_id":"themes/next/docs/ru/README.md","hash":"0430806eebb5a773f53a3d1cc0af8bb12f6334f9","modified":1622430393241},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"b218e30df4126b6adc87684775ac4c86ea7f7958","modified":1622430393241},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"f3eec572a7d83542e2710a7404082014aaa1a5e7","modified":1622430393242},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"58c1f95903e959142c34ada6bae15e15c5aea29e","modified":1622430393241},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"5da70d7fa0c988a66a469b9795d33d471a4a4433","modified":1622430393243},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"b19a6e0ae96eb7c756fb5b1ba03934c7f9cbb3c3","modified":1622430393242},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"b76ccbc658024e86639cfa5f8a3817647fc8d651","modified":1622430393242},{"_id":"themes/next/docs/zh-CN/README.md","hash":"30fe3217b7605b27b0411cf1b32d53124ec82c2e","modified":1622430393243},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"115ffbde2b3ce01ef1f8c2b3833e6f6794650132","modified":1622430393242},{"_id":"source/_posts/Netty概览-1.md","hash":"ab2b8729c405b53a4b0641e64fc8f816383eb170","modified":1622430393195},{"_id":"source/_posts/Netty-NioEventLoop的reactor线程模型.md","hash":"efefad492c12ccdfc2cde32dd4e4be217596a13f","modified":1622430393195},{"_id":"source/_posts/Apahce-Nifi学习-——-何为Nifi.md","hash":"b85c44bc7255f66823c346a9a1a811f8c047f2e0","modified":1564408304833},{"_id":"source/_posts/Netty概览.md","hash":"f41cf1fc8e409afaa29631da06e972baeda87340","modified":1622430393196},{"_id":"source/_posts/Nginx-root和alias路径映射.md","hash":"96254823a53fb07e893786c7971f4fb24e2114fd","modified":1622430393196},{"_id":"source/_posts/Reactor-Kafka（1）.md","hash":"fae69ec78148ba082a2e2a772a54238bb83329dd","modified":1622430393196},{"_id":"source/_posts/TCP连接-Nagle-和-Cork-1.md","hash":"a93979724dbb16d570480aa96588498a602fc25a","modified":1622430393196},{"_id":"source/_posts/Kubernetes学习-——-如何将自己的应用部署为k8s-service.md","hash":"c9cb4a3417a184c8f080109f73f83c3bd0eb153b","modified":1562937407820},{"_id":"source/_posts/Vim编辑器.md","hash":"532691b5e7fb9b9c3d847f473ff012d5f99af93f","modified":1622430393196},{"_id":"source/_posts/Yarn初探.md","hash":"deebf3a5f07362c81c956b8c7e54eefcd58437fd","modified":1557069391806},{"_id":"source/_posts/Yarn任务调度机制探析.md","hash":"da33b76b8fa1050cd3d30e5d0d3c6fda7b4ba151","modified":1559653415249},{"_id":"source/_posts/ElasticSearch分布式原理探究-——-节点和分片.md","hash":"d77c3c89e7465664b8d01ebd5e52b2ca7b45d6ee","modified":1590325200618},{"_id":"source/_posts/ElasticSearch启动配置注意事项.md","hash":"6468ff126d3a7b8bd46946c227f274d8ef1f0a39","modified":1590325349579},{"_id":"source/_posts/java线程池源码分析--submit-的过程.md","hash":"baf4abb7cc139e58719ca02d14e1b42c41a2b4ad","modified":1622430393197},{"_id":"source/_posts/kafka学习笔记（1）——-kafka基本特点以及与其他mq的对比-2.md","hash":"28ee51fcce12a2d79e879fb9e0140a8286714dfb","modified":1622430393197},{"_id":"source/_posts/kafka学习笔记（2）——-生产者-producer.md","hash":"21940356f759be3875e9ab6da00507171b7db6ee","modified":1622430393198},{"_id":"source/_posts/java线程池源码分析--shutdown, shutdownNow, awaitTermination.md","hash":"d4db5a47cf62ab8973beafc0afdfc900dd2e77f2","modified":1622430393197},{"_id":"source/_posts/mongodb索引类型.md","hash":"290434e803322b49e0bf192ddd70e6665f341ffb","modified":1622430393198},{"_id":"source/_posts/kafka学习笔记（4）——-深入集群.md","hash":"a57bc8d1724b307c00ceabe39764890a571a5160","modified":1622430393198},{"_id":"source/_posts/kafka学习笔记（3）——-消费者-consumer.md","hash":"d99e40627f759a9240ac4f134eabc273ad397bb3","modified":1622430393198},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-11-1.md","hash":"6be8d95ee1f50f6db2736ea371141fcb6cf1bf16","modified":1622430393199},{"_id":"source/_posts/netty-ByteBuf浅析.md","hash":"65a70701b7e7eeb82e3b598e1da3fde9941abffc","modified":1622430393198},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-10.md","hash":"69756bedb4bea86ab5978a4281ed132ed5fc5fc5","modified":1622430393199},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-11-2.md","hash":"ecb92948cda43f1dba3cb7299e00487bf9078eda","modified":1622430393199},{"_id":"source/_posts/vue学习笔记-——-用vue-cli搭建spa工程.md","hash":"6a5d1621895a34e7b887c108a35b638b4b19025d","modified":1622430393198},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-3-2.md","hash":"0323d577d4ed7aa3cf7fa2d7dced7dbe7595c3e8","modified":1570434519948},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-2-2.md","hash":"0f41a93d37ab3e02f35c103d168ff6d0c7885db9","modified":1622430393199},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-1.md","hash":"481b296dec4c325ffb907325a859e3e1a101f18a","modified":1567297654524},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-3.md","hash":"4a61ab81adaf947c85cc6024a35787fda34b5628","modified":1569925504176},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-3-3.md","hash":"3a52f4aefb1c64c59c1bd1d7fb19ec654449d3ff","modified":1570852257954},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-7-2.md","hash":"d8005a5b5814627a2fbc6862373d12e430982f2c","modified":1622430393201},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-7-1.md","hash":"3d74ad914217e7d27eba12891bfeb382f196c0ee","modified":1622430393201},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-9-2.md","hash":"589153589d6cf73b6345d9a8eb8af0b14677f987","modified":1622430393201},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-6.md","hash":"0464bcc18dd58c38b4181dfbc6307c455f5ea143","modified":1622430393200},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-2.md","hash":"a45ebaabb8636687f9e8552042290560bc4a7360","modified":1568817618350},{"_id":"source/_posts/何为RestTemplate.md","hash":"850f88a81f0e47c38c3cb44adaa11f80b17275e7","modified":1622430393202},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-8.md","hash":"2121f33f2ef08fea726cf7572f281579be5541e7","modified":1622430393201},{"_id":"source/_posts/《深入理解计算机系统》读书笔记——Chapter-12-1.md","hash":"f26b7331178020d618ecf55d6fcec4767c23ea08","modified":1576385319684},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1622430393248},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1622430393248},{"_id":"source/_posts/自定义类加载器实践.md","hash":"45a476227d3d8cc514b5567da59a0d08fe62ffb4","modified":1556028748231},{"_id":"themes/next/layout/_custom/head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1622430393248},{"_id":"source/_posts/如何理解3PC协议-1.md","hash":"c01ec74b3950f9da75e91fa340a67bd4bc7e7e32","modified":1553784622624},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"480d93619479dcfcbec6906803bb38b2dfbeae53","modified":1622430393250},{"_id":"themes/next/layout/_partials/comments.swig","hash":"5352f96f4544c1520babf1cec7b44ddf2f8057b3","modified":1622430393250},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"89b0a0e64637bf5b0cfea0a23642df3d95eedfa4","modified":1622430393249},{"_id":"themes/next/layout/_partials/footer.swig","hash":"07f88421bda86d9d5ff32d130b1cb1196b99a326","modified":1622430393250},{"_id":"themes/next/layout/_partials/github-banner.swig","hash":"818deb840c91f7ebe8ff558840ca3c1612a3f1fe","modified":1622430393250},{"_id":"source/_posts/对于Map-Reduce并行度的理解.md","hash":"6e30363836ada67ee6894061505bf35478cad281","modified":1563973755717},{"_id":"themes/next/layout/_partials/post-edit.swig","hash":"06dac109504812b63766a80ede9ddacbd42d227d","modified":1622430393253},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"d66bc7ec3cc03f60fcc7d555368a5b9b010f7f11","modified":1622430393255},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"dbe321bcf3cf45917cc11a3e3f50d8572bac2c70","modified":1622430393253},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"edaff4766e0c05fd5c889d9dd32884d376bef9d9","modified":1622430393256},{"_id":"themes/next/layout/_macro/post.swig","hash":"10187fafe566b3e5bfa4e7e10c77ea9026d9081d","modified":1622430393249},{"_id":"themes/next/layout/_scripts/exturl.swig","hash":"d359e638a86bd9664101c48e9344f21ec96e6a15","modified":1622430393256},{"_id":"themes/next/layout/_scripts/scroll-cookie.swig","hash":"1b250c1b7945cb1029b9e855edb09854f7c8250a","modified":1622430393257},{"_id":"themes/next/layout/_scripts/next-boot.swig","hash":"82032af75320f496ae40fce5d0781e05eb96453c","modified":1622430393256},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"83470eb401f78f4683907c48ad6760b90730daa3","modified":1622430393257},{"_id":"source/_posts/如何优雅地遍历并删除一个map中的元素.md","hash":"4324bbe1188e4a593ee31d15024a1db0c5244b08","modified":1553099522935},{"_id":"themes/next/layout/_third-party/chatra.swig","hash":"eefb68b69b4b0ed558ee0324ccd711990059b20d","modified":1622430393264},{"_id":"themes/next/layout/_third-party/baidu-push.swig","hash":"4ccf2abbfd070874265b0436a3eff21f7c998dfb","modified":1622430393263},{"_id":"themes/next/layout/_third-party/bookmark.swig","hash":"10b61a8bac671e375916a4d234c120117098a78f","modified":1622430393263},{"_id":"themes/next/layout/_third-party/mermaid.swig","hash":"d6e6ddda836bd9e2e8d9767a910c7d3280080e81","modified":1622430393266},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"2c4a66be4677d3e4dec3f169ac8a769098dad1fe","modified":1622430393266},{"_id":"themes/next/layout/_third-party/copy-code.swig","hash":"01ded5e1bad89a6f8d64cd063e3e4e42c20d33bc","modified":1622430393265},{"_id":"themes/next/layout/_third-party/pangu.swig","hash":"c28f9dc96ab735daeb7f599f86470aa5a83c03cf","modified":1622430393266},{"_id":"themes/next/scripts/filters/exturl.js","hash":"79ad823ca803cb00e0bfc648aa6c9d59711e0519","modified":1622430393269},{"_id":"themes/next/scripts/helpers/engine.js","hash":"60eb1554456d9d0e5afc4a2d16f1580a0aa02da8","modified":1622430393269},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"799a042bbf497a4c7a2981aa2014ff28fa1bb382","modified":1622430393269},{"_id":"themes/next/scripts/tags/button.js","hash":"279a04037fce9b5e3cc55aef0581cd34172aea98","modified":1622430393269},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"f13430d9d1c9773b390787c2f046bb1f12a79878","modified":1622430393270},{"_id":"themes/next/scripts/tags/exturl.js","hash":"e3854f1951e6295220f94bd9d3eafe5364491390","modified":1622430393270},{"_id":"themes/next/scripts/tags/full-image.js","hash":"6dc82ae9df2341d9c7bd05eacb5cf90208c2a44c","modified":1622430393270},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"46bac5a4cf7821e37b548f7ed22c83aeae321857","modified":1622430393270},{"_id":"themes/next/scripts/tags/include-raw.js","hash":"5db59d56f4f4082382bf1c16722e6c383892b0c5","modified":1622430393270},{"_id":"themes/next/scripts/tags/label.js","hash":"64e6f95e2ccde49413bb5a8d2926f6df2f9a670a","modified":1622430393270},{"_id":"themes/next/scripts/tags/pdf.js","hash":"ebd903785b4fd9163c58fef3707fb28eda6dc8e6","modified":1622430393270},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"d007598ab83babcff824bb44a2e858ef6537f627","modified":1622430393270},{"_id":"themes/next/scripts/tags/tabs.js","hash":"8b1e9043db8f19ea4a12c473b3f729bd3b5bcb0e","modified":1622430393270},{"_id":"themes/next/scripts/tags/video.js","hash":"2a4d5bfc5318f66887936c51f54088f7611e686f","modified":1622430393271},{"_id":"themes/next/scripts/tags/note.js","hash":"84ce2d2c0646baafc82083e261b093b1c515f63c","modified":1622430393270},{"_id":"themes/next/layout/_third-party/tidio.swig","hash":"912368c41de675f458b267a49a99ae3e7e420ebb","modified":1622430393267},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"cbe40cb67dad15ade967b0f396c1a95b6871f76a","modified":1622430393267},{"_id":"themes/next/layout/_third-party/pdf.swig","hash":"810a9b2a6059f46c4a2ddb178f1eaa4c5e23750b","modified":1622430393266},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1553009878373},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1622430393285},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1553009878372},{"_id":"themes/next/source/css/main.styl","hash":"e010ec8ac73268a0f137204c89e0080ab8d59b3d","modified":1622430393284},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"2398e5cd0cb466953b6e7a42c2b2caddebf3c348","modified":1622430393267},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1622430393285},{"_id":"themes/next/layout/_third-party/quicklink.swig","hash":"5db80e8d7ea3f29e998320f79508f7e14342a33c","modified":1622430393266},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1622430393285},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1622430393285},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1622430393286},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1622430393285},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1553009878399},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1553009878401},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1622430393286},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1622430393286},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1553009878400},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1622430393286},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1622430393286},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1553009878402},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1622430393286},{"_id":"source/images/1559568139040.png","hash":"559932dc49023ac51b1efc7cf29cb20ac0bbf451","modified":1559568139076},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1553009878407},{"_id":"source/images/pasted-16.png","hash":"62bc028ca4a4c593a049a964036aa9394b7527c6","modified":1553002258825},{"_id":"source/images/pasted-18.png","hash":"37677ac1df362c6fe7e28c2da2f95e833cdddf73","modified":1553002258829},{"_id":"source/images/1548985987329.png","hash":"c38ca2c2a8b601bc97e50702177c830cf66b4b24","modified":1553002258515},{"_id":"source/images/kafka.png","hash":"1f31a5be42a398d4d49d881668193cccdbb5eec8","modified":1553002258617},{"_id":"source/images/pasted-22.png","hash":"42129287146e43832115b4d65530c00c76ba88b6","modified":1553002258837},{"_id":"source/images/pasted-21.png","hash":"a4eff7602c459321e6316c96f91bc07fe9840e7b","modified":1553002258835},{"_id":"source/images/pasted-23.png","hash":"dffac47cc509f485291141408f77d15a52c6316c","modified":1553002258839},{"_id":"source/images/pasted-26.png","hash":"b6c01a308be3d6ea5a0242355a21f281cf02bde7","modified":1553002258843},{"_id":"source/images/pasted-28.png","hash":"65eca2f65c07405761a471c45cbe06c6abbda72c","modified":1553002258847},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553009878272},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553009878281},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553009878272},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553009878353},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553009878364},{"_id":"source/images/pasted-10.png","hash":"0e52a8f50388a77bab8493832614d8c2c624365f","modified":1553002258772},{"_id":"source/images/pasted-13.png","hash":"77cc92fd2ca699617a96f000233a94e2808196c0","modified":1553002258784},{"_id":"source/images/pasted-15.png","hash":"1618139831d7a4314e6b04b48e346b1b41e90e48","modified":1553002258824},{"_id":"source/images/pasted-11.png","hash":"f2565ba35cae83dbd0be52b499b11ee854da6364","modified":1553002258780},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"fc6bafc8c633afadc538c5afa5620ea2a1cdcb84","modified":1622430393250},{"_id":"themes/next/layout/_macro/menu/menu-badge.swig","hash":"65c5e585982dae7ae1542cada71858b4ea1f73d6","modified":1622430393249},{"_id":"source/images/pasted-27.png","hash":"266b8a7f0501f78f05a97a47d24cb63e9e786b94","modified":1553002258845},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"dc53a41196b675268bfd2a944f6258c57ed44e91","modified":1622430393251},{"_id":"themes/next/layout/_partials/page/breadcrumb.swig","hash":"69722be16ce5eae5c027168f9b2fded4776e1b53","modified":1622430393252},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"bfd2431c0786a82c2c155631f31371431ab4d991","modified":1622430393251},{"_id":"themes/next/layout/_macro/menu/menu-item.swig","hash":"fb33f499022cd02722f834fcef1a0e193362cfde","modified":1622430393249},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"648bf7eda66629592cb915c4004534b3913cbc22","modified":1622430393251},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"5adc60100e129c1d0307bdcaa0c7b8e8375a6ea4","modified":1622430393252},{"_id":"themes/next/layout/_partials/page/page-header.swig","hash":"2940df694fff28e8bf71b6546b4162f1e38227db","modified":1622430393252},{"_id":"themes/next/layout/_partials/post/post-copyright.swig","hash":"3615db591dd910fb9fa96542734c7ec0ef05019c","modified":1622430393253},{"_id":"themes/next/layout/_partials/post/wechat-subscriber.swig","hash":"ef11b5be5bfb2f0affe82cf521c002b37fef9819","modified":1622430393254},{"_id":"themes/next/layout/_partials/post/reward.swig","hash":"d44f025eb93c99ddf90202d8293ccf80689a00c7","modified":1622430393253},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"7d1693416a5dc098f4723a53da2e2d1fc2d6e075","modified":1622430393254},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1622430393254},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"a5587bd1f60d35e58618576cec45e662aa44ea1f","modified":1622430393254},{"_id":"themes/next/layout/_partials/search/algolia-search.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1622430393254},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"15b542f5b06b7532234af367340b9ed9fcebb0ac","modified":1622430393255},{"_id":"themes/next/layout/_partials/post/post-related.swig","hash":"eea95b785c9c36d28e1839619793f66e89773bee","modified":1622430393253},{"_id":"themes/next/layout/_partials/share/likely.swig","hash":"b45e934d24d76ec6b6a790e92bdb3d56186b0e2a","modified":1622430393255},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"ffc8e8836714ea79abeb77b75859634615652877","modified":1622430393256},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"108b157fbd1ac3baaf19ae87234fa8728ab79556","modified":1622430393257},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"c7f2855f19dfdf18aba8c58d55b7489e631ed035","modified":1622430393256},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"a5723950c343d220270bfd27bd30050eda6c3fb3","modified":1622430393258},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"94e106755c5fb6f40431b621beeba0bd33877e57","modified":1622430393257},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"6f181cc188ecbe5e607fd989756e470d4cb9765d","modified":1622430393255},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"be24f204a515d5211bf3ba98a030e3bf61d4cc16","modified":1622430393257},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"71af31fea5913fd30c233e555ef13cf2c9768f72","modified":1622430393252},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"2082f5077551123e695e8afec471c9c44b436acb","modified":1622430393251},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"798d67e4a736613ab899eabe6529091bbcda7850","modified":1622430393258},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"050ea01f25cfe492be9bb77b409644d623fdf2dc","modified":1622430393260},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"8eadb929c9e50e58502ccad2dc2657746f8c592a","modified":1622430393258},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"4a966b7ffe2d80ff1b3dd0fd14b355766dc5c70f","modified":1622430393261},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"fae69a0e1a1d42f7bb44e594a29857d94594698b","modified":1622430393260},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"08cd47ef8572121b7811342d3c9a84a338a18191","modified":1622430393259},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"d422beaf35a5d2646feaa098bc3e5adf691c7565","modified":1622430393261},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"438c6f5e6665d72f4ea7ee206011d669246f6102","modified":1622430393262},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"92e04a2b9e0c3df594bc22235d1894e5ad458dfc","modified":1622430393263},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"591b2ccd9713ccb922b9fcf5e278b6de9c5ec30b","modified":1622430393258},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"f240a50cd9b627620d9a374a29cf95f0c5e99d7c","modified":1622430393263},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"0dd5b315d1da55dbfc10f51a1f8952f72eba2720","modified":1622430393263},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"3cfeafefc672d9a7704650ebfb2f9d8668b38d9a","modified":1622430393264},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"c754f699c90f6278b9159eff1855c17bc713ee96","modified":1622430393262},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"3533167c4295637b91d90f3bae7c651cd128bb6e","modified":1622430393264},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"4a908b613518878b9b69576c5dba4a5185f552ab","modified":1622430393265},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"2cbaae65a020bbb0e9265364488aff8bf84fa48d","modified":1622430393265},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"a7e304b05a44279d3e4f611908d7faef9dc14d7c","modified":1622430393265},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"e8f91c571ceb4b80aafebc4d36b89fb41b1ae040","modified":1622430393264},{"_id":"themes/next/layout/_third-party/comments/disqusjs.swig","hash":"c77a2e7ef5f449a445fb4d36b055721fba4a81af","modified":1622430393264},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"388efc86af7f19c05ad0e26720cd24ee012d20b9","modified":1622430393265},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"c2cb2f384bc30d31cdccf9794a729c03e687b45c","modified":1622430393265},{"_id":"themes/next/layout/_third-party/search/algolia-search.swig","hash":"cd86bed852fec6e6933898067122a03755bc17f0","modified":1622430393267},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"ea94aa85034c6d1b6bb865aecea55c73f8a14501","modified":1622430393267},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1622430393280},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"601774d8672577aefbcefac82c94b01f0338da31","modified":1622430393266},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1622430393281},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"2e8fb29aa92325df39054b5450757858c6cebc41","modified":1622430393281},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"5856d5f701e51dfae1fd6fb486cefde67effd555","modified":1622430393265},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"b3eaab6a269aa3fcbafe24fd06f0c9206dc12716","modified":1622430393267},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"a8aa41625b94cf17a7f473ed10dcbe683b1db705","modified":1622430393284},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1622430393284},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"b21e39bd906b48332acfe3acfe3b5f476a3a73a9","modified":1622430393281},{"_id":"themes/next/source/js/src/affix.js","hash":"a2aab233d99297435a5274bf512c3c753fe08e80","modified":1622430393287},{"_id":"themes/next/source/css/_variables/base.styl","hash":"d0e97b205d3320421c380f2eee445457430c8152","modified":1622430393284},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"1f7f10c579e7703d0f6acb8b73f3d78a07d0c623","modified":1622430393287},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"fc15e277d1504532a09b7b1bd31f900ad95ec4b8","modified":1622430393284},{"_id":"themes/next/source/js/src/exturl.js","hash":"54825acc8de4793feac415be227b965428f4e97d","modified":1622430393287},{"_id":"themes/next/source/js/src/post-details.js","hash":"0dde5e6d4547587662a3256317a9d5d1db507692","modified":1622430393287},{"_id":"themes/next/source/js/src/motion.js","hash":"a16bc0b701646bf6653484675f4d5dc0f892d184","modified":1622430393287},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"e0afce539f1fb81d59e3c6f0a68d736e2fb45d93","modified":1622430393287},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"d07b3776708d4ae79ed2037c4c7391d5c9b06b19","modified":1622430393288},{"_id":"themes/next/source/js/src/next-boot.js","hash":"e0615efab5f81ba0fd39c0527eac31144deac7ce","modified":1622430393287},{"_id":"themes/next/source/js/src/utils.js","hash":"703375f367acfbd0596733c34437d1b2681abf72","modified":1622430393288},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fa3c92968bcdbcb8d95a1729f7659d9753cbd077","modified":1622430393288},{"_id":"themes/next/source/lib/canvas-nest/LICENSE","hash":"336611e76f0638d3d8aeca6b1b97138d2a07523f","modified":1553088800645},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1553088800682},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1622430393289},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1622430393289},{"_id":"themes/next/source/lib/canvas-nest/README.md","hash":"28bc2250a16e22c705cba7b3c17fcc15081e50f2","modified":1553088800652},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1622430393289},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1622430393289},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1622430393289},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest-nomobile.min.js","hash":"6b4437a9cd8aa04329cc6220a595acfe1fb9b598","modified":1553088800672},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1622430393296},{"_id":"source/images/pasted-17.png","hash":"07ca26cc665a98d3eddddfe07d6e88137412bf27","modified":1553002258827},{"_id":"source/images/pasted-14.png","hash":"ec9bbb26029475e2553647553b05831ef92e2376","modified":1553002258821},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1622430393296},{"_id":"source/images/pasted-0.png","hash":"7a0e5c05ba596029f62d0abdb73a8fb38f0ba075","modified":1553002258769},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1622430393295},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1622430393271},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"8175b9a275d04718f6caf6dc6ae483035ad71b0c","modified":1622430393271},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"7729491514f8ccdf96777de8f71420e6873c5423","modified":1622430393271},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"0c6cbc0c9d9111116cad27ffb0a14fa7d06a3f35","modified":1622430393271},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1622430393271},{"_id":"themes/next/source/css/_common/components/rainbow.styl","hash":"e53256fca6b1f4aeca8fdaf99bd4549ced700485","modified":1622430393275},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"61ca40856e5cacd48e0fa9728fde4605c7dd4c94","modified":1622430393277},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"7e51ea64611ab5d678c112b4688d4db4fd2737e2","modified":1622430393280},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"676c2d4d3fa16e795249a83acecad7f5706f02e2","modified":1622430393280},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"e3ad313825d7ad03e24bb76d036deeb50587022b","modified":1622430393280},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1622430393273},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"7ffde343bdf10add1f052f3c4308a15180eb4404","modified":1622430393280},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"bb9b753d3cc3a816340bd697512a83e757f907fb","modified":1622430393280},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"6f1a0fe6b45eb8849114b8b60ba600767d08b6df","modified":1622430393280},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1622430393294},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1622430393280},{"_id":"themes/next/source/css/_common/components/scrollbar.styl","hash":"d7b8bcf2a6031296c84bb4f4ecfb037af01d2d82","modified":1622430393276},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"0bef9f0dc134215bc4d0984ba3a16a1a0b6f87ec","modified":1622430393281},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"a5bef4fdde80951f3b8c154d79cb1e581638a988","modified":1622430393282},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"0ce070b14eff003570e0b91da425ed7881ebff4c","modified":1622430393281},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1622430393282},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"a96e46a6ae86c423f932bc2bc78b9f7453e4e4e5","modified":1622430393282},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fa33213aceed7bf4bf25437ca9c1a00f7734ae65","modified":1622430393282},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1622430393282},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1622430393283},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"e6148917961e8babfd0d8e3dd2edb8f3b0436848","modified":1622430393281},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"8d9ad35fcbec361421af5bba55755f18fa6b9d90","modified":1622430393282},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"fc160583f742c94316a0fee05c18468033173534","modified":1622430393282},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"09b5054ae34ba83c0d614821e574da265af55a14","modified":1622430393283},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"a5bef4fdde80951f3b8c154d79cb1e581638a988","modified":1622430393283},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"b5b936dddb7b4de4720cd1e8428b30a2f06d63fb","modified":1622430393283},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"47f93162fbf6b3917331fe2c2d8884cebc25b4a1","modified":1622430393283},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"9b076c92abdadcf9acee75da64592ff3badd69b8","modified":1622430393283},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"232aedbd44243b3b80c4503c947060d3269c1afc","modified":1622430393284},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"01888542d4b2fb95107a7096352d8ba820f02614","modified":1622430393283},{"_id":"themes/next/source/js/src/schemes/muse.js","hash":"e9bfa6b343b67625f58757efce46ccdaac8f308c","modified":1622430393288},{"_id":"themes/next/source/lib/canvas-nest/.github/stale.yml","hash":"dbd5e6bf89b76ad1f2b081578b239c7ae32755af","modified":1553088800639},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"1ba399ca21e681cc9811e92e351dd920df71689a","modified":1622430393283},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"9eb63cba0327d3d11b6cbfcbe40b88e97a8378a3","modified":1622430393288},{"_id":"themes/next/source/lib/canvas-nest/.git/config","hash":"78c4459d066ad795856608d603d780b53488073d","modified":1553088800619},{"_id":"themes/next/source/lib/canvas-nest/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1553088800604},{"_id":"themes/next/source/lib/canvas-nest/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1553088793919},{"_id":"themes/next/source/lib/canvas-nest/.git/packed-refs","hash":"949c61b7ce3b6e582b7d47f985a3d13ddfbb82ca","modified":1553088800595},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1622430393290},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1622430393290},{"_id":"source/images/pasted-12.png","hash":"b36412b4c5a0d1d18da2265976a19dce05b7f009","modified":1553002258782},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1622430393290},{"_id":"themes/next/source/lib/canvas-nest/.git/index","hash":"7991889cccdfe83e1637a558567bdaba8b66ff63","modified":1564412738853},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1553009878544},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1553009878548},{"_id":"themes/next/source/css/_common/components/header/github-banner.styl","hash":"9e0f215868df17cb27a4a522fd31156c66428c2d","modified":1622430393272},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"c0d9e18a9210fdcaf33e488518b3b288eb58c0a1","modified":1622430393272},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"4cfeec9434a72d5efc6ca225d3445d084d4590f7","modified":1622430393271},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1622430393272},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"6c4990d375b640ee4551e62c48c1cbe4c3d62212","modified":1622430393272},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"71d8d1cc22a2a7627a6db7240f0c4902a14f9bea","modified":1622430393272},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"e9dd8de7d98f1478ac7d351624fffd3d8738c905","modified":1622430393272},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"2d142c6f39853916256ad8fc79eb6b85f4001ae8","modified":1622430393273},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"6904fd7ea6455e008d9884558b68254608af9a3c","modified":1622430393273},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1622430393273},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"05e68adae13f4d99a6ac6493daab39c92e39a6bd","modified":1622430393272},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1622430393272},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1622430393273},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"61af2f656f6e916f9920277bd048c5d58ff32a60","modified":1622430393273},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"3b5a37ba5e70f92c1ee707c8053524e38adbb710","modified":1622430393274},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"fb451dc4cc0355b57849c27d3eb110c73562f794","modified":1622430393273},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1622430393273},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"300491cf0e80c34faf5f83a2846c177759ac653f","modified":1622430393274},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"0bf899fab331add63f0c8ead31ca3a3db2ad74d9","modified":1622430393274},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"2356226157e8068b0e9bbe2f7d0f74e1ab49199b","modified":1622430393274},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"42a0769311856a7ea3ede1c8656fb5646994a238","modified":1622430393274},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"b89afe809c9b00777c438991230860c90c591759","modified":1622430393274},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1622430393272},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"1cf64afd4b49143972f7617869539be3adb91a5e","modified":1622430393274},{"_id":"themes/next/source/css/_common/components/post/post-reading_progress.styl","hash":"0e8294d042d7d28c680ead48baa9e3c777d407c5","modified":1622430393274},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1622430393274},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"5440013a081201ca791582db98159dce93ea9e75","modified":1622430393274},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"a6c24393dffbdd94dd5c01cdbec5e180b0bfbbbd","modified":1622430393275},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"9a8377317364939903e14772411b7b366e24e05a","modified":1622430393275},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1622430393275},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"f40dbd838c8458820bb371931114d76ae78a279e","modified":1622430393276},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"8e058c99dd7d41f0bd34c7c28b6ac9fbb17dcb5e","modified":1622430393275},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"f27c906cea6a7a0867b03d0c2c28407b2cdadad3","modified":1622430393276},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1622430393275},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"cc83816614f21c7e1d8d3f867d547ff7c658cec4","modified":1622430393277},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-chat.styl","hash":"37237e512e7d6318d678e801641a91b421de0bf4","modified":1622430393277},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"f9837075189e37c100675211076b5053788e7ba5","modified":1622430393277},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"b05d7e8c387ba60c2abf16121b97cfb2548dcb85","modified":1622430393277},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"f4342e4e06a8061fe02247c624728caf6dfc2c2c","modified":1622430393277},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"9a3bfc878ca797946815bed23cd6f92b24a16358","modified":1622430393277},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"6ec8ea7b11a146777b6b8da0f71f0cc1dbd129df","modified":1622430393278},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"859371a20acb2ea8a1baf23c2bbe23976448750b","modified":1622430393277},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1622430393278},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"b5e585d85aeb164c3141e6a3e7f8de11865223f8","modified":1622430393277},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"9097db6f3ddd810b94ac4cbb0328e86792402090","modified":1622430393277},{"_id":"themes/next/source/css/_common/components/tags/pdf.styl","hash":"deafbca5bc2e6bbc5923bbb2036ffa2896ce71fc","modified":1622430393278},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"75f7876136fe1cae9b42d2c220e7f8b37b8d2f55","modified":1622430393278},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1622430393278},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"47344d8e1a7478ce49c543fac12c5e27731f24bb","modified":1622430393278},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1622430393278},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"344c0d7d3cd4fa0709744d2d0b611a05021fbdb1","modified":1622430393278},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"7d2222f66a1c1a0a3cc90bfd5d817d9b859f4a68","modified":1622430393279},{"_id":"themes/next/source/css/_common/components/third-party/copy-code.styl","hash":"688ca3eccc26727d050ad098b32b40934719588a","modified":1622430393279},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"3ae254c97be53cd8a277391f4f43f96705202560","modified":1622430393279},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"ac7753d536341aa824d7bce0332735e838916995","modified":1622430393279},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"7059e24235b7c57a07f3f8abaa06b0bd6a7eda2f","modified":1622430393279},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"f466e92fa1466dd4d8957309623c8d661aeb1d8c","modified":1622430393278},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1622430393279},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"2d4f318644bf37c50e5b1fab8d62b2673fbab9e8","modified":1622430393279},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"a2f61adb7dd48743f62c7a8f7900de201bae891e","modified":1622430393279},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1622430393282},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1622430393282},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"9fac89c8146eb2675721a26f528d7d0f8be7debe","modified":1622430393279},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1622430393283},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"36cfd06979b7f7070f645c11edc745c7bcda8fbd","modified":1622430393280},{"_id":"themes/next/source/lib/canvas-nest/.git/logs/HEAD","hash":"d5a6a18da3af966e8f439d434c779a71c297273c","modified":1553088800610},{"_id":"themes/next/source/lib/canvas-nest/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1553088793948},{"_id":"themes/next/source/lib/canvas-nest/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1553088794032},{"_id":"themes/next/source/lib/canvas-nest/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1553088793961},{"_id":"themes/next/source/lib/canvas-nest/.git/hooks/fsmonitor-watchman.sample","hash":"f7c0aa40cb0d620ff0bca3efe3521ec79e5d7156","modified":1553088793957},{"_id":"themes/next/source/lib/canvas-nest/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1553088793964},{"_id":"themes/next/source/lib/canvas-nest/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1553088793952},{"_id":"themes/next/source/lib/canvas-nest/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1553088793962},{"_id":"themes/next/source/lib/canvas-nest/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1553088793994},{"_id":"themes/next/source/lib/canvas-nest/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1553088793998},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1622430393295},{"_id":"themes/next/source/lib/canvas-nest/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1553088794000},{"_id":"themes/next/source/lib/canvas-nest/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1553088793968},{"_id":"themes/next/source/lib/canvas-nest/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1553088794001},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1553009878540},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/0c/dada082d621dbfdd00f7020c33dc751129167f","hash":"b490c11cdefde6b331a7d4ddb055e34ad08459d8","modified":1553088800116},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/45/9262fe92f0115707bf8d8764f1886bc5e7c9e0","hash":"36040483f8af76775b7e4b6d87cec53729625399","modified":1553088800466},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/2a/f622a4d7df40a2708946e91d6d7a0df1dc468c","hash":"3da7207fb18d361b83c56f4e35f67e9e945abd82","modified":1553088800417},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/2f/9eba51ec174b1e0c719d12cafa7c3c07140471","hash":"fc994d9d8b3b21ec7c941eea7e3862970e297e9b","modified":1553088800141},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/50/dd2a6539498a70226c81a587db486b47e839ff","hash":"3844b0c815d0b4b32c6312c751a826bf9dc2c945","modified":1553088799882},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/5e/8ae972c99b04af7dd56dabfc485e8fdae5094d","hash":"791b3349c5696ccacae00bffbdbb8d88a03e61a9","modified":1553088799908},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/5a/69ce9c2e4a1a34f6063ae9a121af1555669c69","hash":"dad25cc0f450e2827b5676975f4a70636e3fd2c8","modified":1553088800189},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/44/6ddf9b6c0e5ade17ca5cb99f9b3a5300919c57","hash":"fb72799ff98445f72fda041337da4cf105d9dcba","modified":1553088800258},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/69/a20d65d83035fdb01734a8eabe3340f740a4cb","hash":"9e95b02d8e43ec92e06bee3f60dffb74e8e7b9fa","modified":1553088800166},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/69/39233ece53c9bdb9a1faf3271ed5768b034aad","hash":"5a770d418c1bb7b0f031f4d5416530002032fcf3","modified":1553088800232},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/90/f6477118d05f5f96ce0a63c6f18b7b2baea200","hash":"385f58e92981f27fa54eb52bf60424e87c70a9d8","modified":1553088800022},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/7b/c7e3186212b6f2e06d3370502565e2c6326890","hash":"379f3c6486f589fc9c1ab07d0382adacf4f655a2","modified":1553088799932},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/75/de2b8fa62d52690de32c351c63ab6446104ed5","hash":"52d10122d633ce4895a0690c5955e1b356f5a391","modified":1553088800441},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/98/67d1132e0e50bbb7df754a63358d70741df6d5","hash":"3cb710a1faee73c08036f5e2df7df3a7ce29e9dd","modified":1553088799958},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/91/f99a0c53b26dd54f56b9e452c68f56b06f8f7e","hash":"3dca8a5629e66599b6e0f146aa32f1b7ce023d89","modified":1553088800359},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/46/cad4f872aa93e813aed99547c4705322ca483f","hash":"b0465d3186e2d58a8a99c56c6e68aa2965a396d4","modified":1553088799855},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/86/1c9f4241fe0eb6af02ad770d5ce04c1f68972b","hash":"7005c3e36015a4af30d4b91bd5a849a7861a073e","modified":1553088800383},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/51/7c5eb7dcc2cb9769efea2e7375ff6e04123150","hash":"ec53157077d47430f4729bf164999d18d370aeab","modified":1553088800279},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/b1/bb278ca2e50dff1b343f9d5ca025272859432f","hash":"74f0afa72a30268d84613fb0d1d893bba866f01d","modified":1553088800333},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/aa/da83ad9aa55faa2b34ede31b1d41e16966f80b","hash":"b304541ab95b7969a63ba2ec4f60f5391bd8bb44","modified":1553088799983},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/bb/5755c22b6c1b7461319624f0f000bc947882ee","hash":"2b87a2a354a0fa77cbddf461b03b0b8e43c16a4f","modified":1553088800214},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/d4/95d28a8fab74d23908f6ccef9e4db2625fbacb","hash":"59e6067b0a806deee7bda6460b36c0f63e2e1db5","modified":1553088800308},{"_id":"themes/next/source/lib/canvas-nest/.git/refs/heads/master","hash":"42b96d49f5eae1a58b8413a60a0c2699e94df28d","modified":1553088800609},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/ca/3466a8cbf05c2982c58199d6ee71ec6d0271ca","hash":"a9b80b5d827b5e84229b1afd7920d9218dce610f","modified":1553088800062},{"_id":"themes/next/source/lib/canvas-nest/.git/objects/99/be66a33ab4ebc34f62f2880a0e0cc6d334d0f2","hash":"f2346fe8ddd7d7abf38f2946f3083d8150f502d2","modified":1553088800091},{"_id":"source/images/pasted-30.png","hash":"1e93636f55ad3943419c2fe175c7127a62054fa8","modified":1566140040055},{"_id":"themes/next/source/lib/canvas-nest/.git/logs/refs/heads/master","hash":"d5a6a18da3af966e8f439d434c779a71c297273c","modified":1553088800612},{"_id":"themes/next/source/lib/canvas-nest/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1553088800603},{"_id":"themes/next/source/lib/canvas-nest/.git/logs/refs/remotes/origin/HEAD","hash":"d5a6a18da3af966e8f439d434c779a71c297273c","modified":1553088800601},{"_id":"source/images/avatar.jpg","hash":"b66e0fe3b14ee5efd3e6355e737f54e6c3285075","modified":1479488719329},{"_id":"source/_drafts/gossip协议初探——原理及应用.md","hash":"982c101683968d5bdce031aede5037ad57b3c12d","modified":1599969169796},{"_id":"source/_posts/gossip协议初探——原理及应用.md","hash":"f881302c29e34c726aed47837d97ca41d55697c1","modified":1599969211078}],"Category":[{"name":"基础知识","_id":"ckf0h31gt0005acts6b4gt8s1"},{"name":"大数据","_id":"ckf0h31hd000aactsyqk11vun"},{"name":"读书笔记","_id":"ckf0h31hm000nactsv9uk46sp"},{"name":"工具使用","_id":"ckf0h31hq000vactsp7tmvqhx"}],"Data":[],"Page":[{"title":"tags","date":"2019-01-21T06:17:42.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-01-21 14:17:42\ntype: tags\n---\n","updated":"2021-05-31T03:06:33.235Z","path":"tags/index.html","_id":"ckf0h31g60000acts8q1kfbwy","comments":1,"layout":"page","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2019-03-18T01:54:08.000Z","type":"categories","_content":"\n","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-03-18 09:54:08\ntype: categories\n---\n\n","updated":"2021-05-31T03:06:33.203Z","path":"categories/index.html","_id":"ckf0h31gp0002actsyr1nh0sk","comments":1,"layout":"page","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"《深入理解计算机系统》读书笔记——Chapter 12(2)","author":"天渊","_content":"","source":"_drafts/《深入理解计算机系统》读书笔记——Chapter-12-2.md","raw":"---\ntitle: 《深入理解计算机系统》读书笔记——Chapter 12(2)\nauthor: 天渊\ntags:\n---\n","slug":"《深入理解计算机系统》读书笔记——Chapter-12-2","published":0,"date":"2019-12-25T13:29:53.170Z","updated":"2019-12-25T13:29:53.172Z","_id":"ckf0h31gf0001acts0e58rbzr","comments":1,"layout":"post","photos":[],"link":"","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Netty概览","author":"天渊","date":"2019-08-12T08:06:00.000Z","_content":"\n### Netty是什么\n\nNetty是一款用于快速开发高性能网络应用的Java框架，封装了网络编程的复杂性，使网络编程和web技术的最新进展能够比以往更广泛的让开发人员接触到。\n<!--more-->\n\n#### 为什么要用Netty\n\nNetty是一个网络通信框架，目的就是屏蔽底层复杂的网络编程细节，提供更便捷的编程模型。\n\n##### 开箱即用的网络组件\n\n有了Netty，你可以实现自己的HTTP服务器，FTP服务器，UDP服务器，RPC服务器，WebSocket服务器，Redis的Proxy服务器，MySQL的Proxy服务器等等。\n\n反过来看看，不使用netty，直接基于BIO或者NIO编写网络程序，你需要做什么：\n\n1. 创建一个ServerSocket，监听并绑定一个端口\n2. 一系列客户端来请求这个端口\n3. 服务器使用Accept，获得一个来自客户端的Socket连接对象\n4. 启动一个新线程处理连接\n\n   - 读Socket，得到字节流\n\n   - 解码协议，得到反序列化后的请求对象\n\n   - 处理请求对象，得到一个结果，封装成一个返回对象\n\n   - 编码协议，将结果序列化字节流\n\n   - 写Socket，将字节流发给客户端\n5. 继续循环步骤3\n\nNetty并不需要你针对这些基础的IO过程编写大量的代码，已经封装好了成熟的IO库，开发人员只需要关注逻辑处理部分就可以。\n\n##### 高性能并发机制\n\n对于高性能网络组件，还得关注它的并发性能，这就涉及到多线程并发编程，Netty提供了便捷的开箱即用多线程框架，保证了成熟的异步回调和事件驱动机制\n\n##### 高性能长连接支持\n\n因为TCP连接的特性，我们还要使用连接池来进行管理：\n\n1. 对于频繁的TCP通讯，很多时候需要保持长连接，保持连接效果更好\n2. 对于并发请求，可能需要建立多个连接\n3. 维护多个连接后，每次通讯，需要选择某一可用连接\n4. 连接超时和关闭机制\n\nNetty能够支持高性能长连接机制，因此在即时通讯和物联网等领域有很大的用武之地\n\n##### 众多开源项目鼎力支持\n\n一个优秀的开源项目离不开高质量的社区，Netty作为基础组件被众多开源项目和大型互联网企业采用，社区质量也是非常之高，如Apple，Twitter，Google和阿里等大型企业，还有Akka, Vert.x，Hadoop，ElasticSearch, Cassandra等优秀的开源项目，都在给Netty源源不断地贡献代码\n\n![](http://img.mantian.site/images/1564638670965.png)\n\n### Java NIO\n\n介绍Netty基本特性之前，需要对NIO (non-blocking IO, 也叫做new IO)有一定的了解\n\nJava NIO最早于Jdk 1.4版本引入，跟传统IO（BIO，也叫NIO）相比，极大的缓解了线程池处理海量连接的瓶颈，提高了IO密集型应用的处理效率\n\n关于NIO的技术介绍可以看美团这篇文章：[Java NIO浅析](https://tech.meituan.com/2016/11/04/nio.html)，更进一步可以看Doug Lea的这篇论文：[Scalable IO in Java](http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf)\n\nNetty对底层网络模型进行了一系列的封装和抽象，包括NIO和BIO，不过最常用的还是基于NIO的抽象，在Java NIO的`Selector`，`Channel`和`Buffer`基础上进行了丰富的抽象和封装，极大的简化了Java原生NIO组件复杂的编程模型，并在此基础上实现了reactor线程模型，能做到非常高效的并发处理\n\n以下是一个简单的NIO网络模型：\n\n![](http://img.mantian.site/201908131112_661.png)\n\nNIO网络模型最重要的组件就是`Selector`，底层基于操作系统的`epoll`或者`kqueue`等机制实现事件驱动式非阻塞IO操作，`Selector`在某些时候又称作`Reactor`（响应器，选择器，分派器......）\n\n在Netty中，`Selector`(或者`Reactor`) 称作`EventLoop`，在Netty中采用的是`单bossEventLoop+多workEventLoop`的模式，由`bossEventLoop`负责响应client的连接请求，并建立连接，由多个`workEventLoop`负责维护客户端socket的数据交互和读写工作，每个`EventLoop`都会在一个独立的线程中执行\n\n![](http://img.mantian.site/201908131115_71.png)\n\n### Netty核心特性浅析\n\n#### Netty核心组件\n\n摘自Netty官网的核心组件构成：\n\n![](https://netty.io/images/components.png)\n\nNetty核心功能由三部分组成：\n\n##### Extensible Event Model\n\n在我看来，Netty之所以这么优秀，除了对NIO网络模型进行了很好的抽象封装，另外一点就是其提供的方便高效的事件驱动的设计思想\n\n###### 事件\n\nNetty使用不同的事件来通知我们状态的改变或是操作的状态，我们能基于已经发生的事件来触发适当的动作，在Netty中事件类型分为两大类：`入站事件`，`出站事件`\n\n> 入站事件：`Socket连接激活或连接失活`，`数据读取`，`用户事件`，`错误事件（Exception）`\n>\n> 出站事件：`打开/关闭远程连接`，`写数据到Socket`\n>\n\n###### Channel\n\n事件的作用对象是`Channel`通道，`Channel`是Java NIO中表示连接的基本组件，代表到实体（硬件设备，文件描述符，socket网络套接字等）的开放连接，可以把它看作入站或出站的数据载体，对应`Channel`的事件就有读数据，写数据，开启或关闭等\n\n事件的发起者即为`EventLoop`选择器，当检测到某个`Channel`状态发生变化（数据可读，可写等），即产生一个事件，并触发一系列的回调\n\nChannel的生命周期：\n\n![](http://img.mantian.site/201908131118_392.png)\n\n每一个阶段都会产生相应的事件并触发对应的回调，并且在`ChannelActive`和`ChannelInactive`两个状态之间还会产生读写事件，用户事件和错误事件\n\n###### ChannelHandler\n\n既然定义了事件，那就得有相应的事件回调处理器，在Netty中所有回调处理器均实现`ChannelHandler`这个接口，根据入站或出站事件又分为`ChannelInboundHandler`和`ChannelOutboundHandler`\n\n![](http://img.mantian.site/201908131118_15.png)\n\n`ChannelHandler`由开发人员自己实现，开发人员可以根据不同的事件实现不同回调处理器的不同方法，例如某个handler需要捕获Channel激活的事件，可以像如下方式实现一个`ChannelInboundHandler`，服务端一旦检测到连接激活，则向客户端回复一条消息：\n\n```java\npublic class FirstServerHandler extends ChannelInboundHandlerAdapter{\n    @Override\n    public void channelActive(ChannelHandlerContext ctx) throws Exception {\n        ByteBuf buffer = ctx.alloc().buffer();\n        byte[] bytes = \"Connection successfully\".getBytes(Charset.forName(\"UTF-8\"));\n        buffer.writeBytes(bytes);\n        ctx.channel().writeAndFlush(buffer);\n    }\n}    \n```\n\n一个`ChannelHandler`可以实现多个回调方法，一个入站handler可以同时订阅激活事件，读事件，用户自定义事件以及错误事件\n\n`ChannelHandler`编写完后注册到`ChannelPipeline`上，至于如何注册handler回调处理器，将在后续的sample中展示\n\n###### ChannelPipeline和ChannelHandlerContext\n\n`ChannelPipeline`是一个拦截流经`Channel`入站和出站事件的链条，所有`ChannelHandler`都需要挂载在`ChannelPipeline`上，每一个新创建的`Channel`都会分配一个新的`ChannelPipeline`\n\n![](http://img.mantian.site/201908131120_873.png)\n\n上图是事件在每个`ChannelHandler`上的传播顺序\n\n`ChannelHandlerContext`就是`ChannelHandler`和`ChannelPipeline`之间沟通的桥梁，每当一个新的`ChannelHandler`添加到pipeline中时，都会创建一个对应的`ChannelHandlerContext`，其主要功能时管理它所关联的`ChannelHandler`和在同一个pipeline中的其他`ChannelHandler`之间的数据交互\n\n![](http://img.mantian.site/201908131120_370.png)\n\n如上图：\n\n1. 事件（入站或者出站）传给`ChannelPipeline`的第一个handler\n2. 通过与这个handler关联的`ChannelHandlerContext`将事件传递给下一个handler\n3. 同2\n\n##### Zero-Copy-Capable Rich Byte Buffer\n\nnetty使用`ByteBuf`来取代jdk自带的`ByteBuffer`作为nio的数据传输载体，相比于jdk原生的ByteBuffer实现，功能更加丰富，灵活性更强，具有以下优点：\n\n- 扩展性好，用户可自定义所需要的缓冲区实现\n- 内置复合缓冲区实现了零拷贝功能\n- 容量按需增长\n- 读数据和写数据有独立的index，互相隔离，互不干扰\n- 支持引用计数和池化\n\n在netty中`ByteBuf`有三种实现：`heapBuffer`，`directBuffer`，`compositeBuffer`，通常情况下使用directBuffer：\n\n- heapBuffer：即将数据存储通过java Byte数组的方式（称为支撑数组）存储在jvm heap中，使用以下方式快速创建一个heapBuffer，但java进行io读写时仍然需要将堆内内存的数据拷贝到堆外并传递给底层的C库:\n\n```java\nByteBuf buffer = ByteBufAllocator.DEFAULT.heapBuffer();\n// 可以直接将所需Byte数组拿出来\nif (buffer.hasArray()) {\n\tbyte[] bufferArray = buffer.array();\n\tint offset = buffer.arrayOffset() + buffer.readerIndex();\n\tint length = buffer.readableBytes();\n    // 通过读指针和可读长度获取所需的数据\n\tbyte[] neededData = Arrays.copyOfRange(bufferArray, offset, offset + length);\n}\n```\n\n- directBuffer：使用堆外内存存储数据，直接使用堆外内存进行io操作，好处是比`heapBuffer`少一次内存拷贝且在io操作频繁的时候大大降低了gc压力，缺点是需要手动释放内存空间：\n\n```java\nByteBuf buffer = ByteBufAllocator.DEFAULT.directBuffer();\n```\n\n`directBuffer`没有支撑数组，因此不能直接提取Byte数组，需要通过读写指针取数据\n\n- compositeBuffer：复合buffer，其中可同时包含堆内数据和堆外数据，其实现是`ByteBuf`的子类：`CompositeByteBuf`，通过以下方式组装一个复合buffer，访问复合buffer的方式也类似于`directBuffer`，不能直接访问其支撑数组：\n\n```java\nCompositeByteBuf compBuf = ByteBufAllocator.DEFAULT.compositeBuffer();\ncompBuf.addComponents(buffer, heapBuffer);\n```\n\n复合buffer广泛运用于需要组合多种不同数据源的buffer，在对不同数据源的数据进行整合后提供统一的ByteBuf API供用户使用\n\nNetty的零拷贝Buffer概念与操作系统层面的零拷贝不是一回事（Netty传输文件时已经通过Java NIO的DirectBuffer实现了基于DMA引擎的零拷贝），Netty的零拷贝描述的是组合buffer时不需要申请新的buffer内存，直接在原buffer的基础上通过`CompositeByteBuf`进行buffer的合并，而Java原生的ByteBuffer在这种情况下需要开辟新的buffer内存：\n\n![](http://img.mantian.site/201908131119_969.png)\n\n##### Universal Communication API\n\n统一的通讯API，Java原生的BIO和NIO使用了不同的API，而Netty则提供了统一的API(`org.jboss.netty.channel.Channel`)来封装这两种I/O模型。这部分代码在`org.jboss.netty.channel`包中\n\n在核心功能之上，Netty还提供了很多开箱即用的API，为用户的协议解析，tcp层面的粘包拆包以及文件编码和安全认证等基础需求提供了诸多需求\n\n#### Netty运行架构\n\nNetty整体运行架构如下：\n\n![](http://img.mantian.site/201908131138_346.png)\n   \n\n### Netty基础使用 （sample）\n\nNetty目前最新版本是`4.1.38.Final`，下列分析基本上都是基于4.x版本 （开发中的5.x版本因为某些原因作废了）\n\n用Netty先实现一个最简单的tcp服务，发送一段简单的文本并获取相应\n\n#### 启动Server端\n\n启动一个能够运行的Netty服务端进程，大致有以下几步：\n\n```java\n1. 添加boss和work线程组\n2. 指定io模型为nio方式\n3. 指定server端启动时的初始化handler\n4. 指定ChannelHandler，即具体的业务处理逻辑\n5. 给NioServerSocketChannel指定attributes，后续可以通过channel.attr()取出这个属性\n6. 给NioSocketChannel指定attributes\n7. 给NioSocketChannel指定一些选项，比如是否开启TCP心跳机制或者Nagle算法等\n8. 给NioServerSocketChannel指定一些选项，比如设置完成三次握手的请求的缓存队列大小00\n```\n\n代码如下：\n\n```java\nserverBootstrap.group(bossGroup, workerGroup)\n    .channel(NioServerSocketChannel.class)\n    .handler(new ChannelInitializer<NioServerSocketChannel>() {\n        @Override\n        protected void initChannel(NioServerSocketChannel channel){\n            logger.debug(\"服务端启动中...\");\n        }\n    })\n    .childHandler(new ChannelInitializer<NioSocketChannel>() {\n        protected void initChannel(NioSocketChannel nioSocketChannel){\n            //（责任链模式）pipeline添加逻辑处理器，当接收到客户端数据时按顺序执行回调\n            nioSocketChannel.pipeline()\n                .addLast();\n        }\n    })\n    .attr(AttributeKey.newInstance(\"serverName\"), \"nettyServer\")\n    .childAttr(AttributeKey.newInstance(\"clientKey\"), \"clientValue\")\n    .childOption(ChannelOption.SO_KEEPALIVE, true)\n    .childOption(ChannelOption.TCP_NODELAY, true)\n    .option(ChannelOption.SO_BACKLOG, 1024);\n\n//绑定端口是一个异步过程，设置回调方法查看是否绑定成功\n//默认绑定的ip地址是0.0.0.0\nserverBootstrap.bind(8000).addListener(future -> {\n    if(future.isSuccess()){\n        logger.debug(\"8000端口绑定成功！\");\n    }else {\n        logger.debug(\"8000端口绑定失败！\");\n    }\n});\n```\n\n如上，`childHandler()`方法用于在建立连接的channel上绑定handler，一旦有事件触发， 事件会沿着添加的顺序进行传播，现在把`FirstServerHandler`这个handler绑定上:\n\n```java\n...\n.addLast(new FirstServerHandler());\n...\n```\n\n每一个成功建立连接的channel都会绑定一个`FirstServerHandler`，一旦channel激活，就会触发`channelActive`这个方法\n\n#### 启动client端\n\n启动一个Netty client，大致需要以下几步：\n\n```java\n1. 添加work线程组\n2. 指定io模型为nio方式\n3. 指定ChannelHandler，即具体的业务处理逻辑\n4. 给NioSocketChannel添加attributes\n5. 给NioSocketChannel指定一些选项，比如是否开启心跳以及设置连接超时时间，以及Nagle算法\n```\n\n代码如下：\n\n```java\nbootstrap.group(workerGroup)\n\t.channel(NioSocketChannel.class)\n\t.handler(new ChannelInitializer<NioSocketChannel>() {\n\t\t@Override\n\t\tprotected void initChannel(NioSocketChannel nioSocketChannel) {\n\t\t\t//添加ClientHandler，连接上处理和服务器端的数据交互\n\t\t\tnioSocketChannel.pipeline().addLast(new FirstClientHandler());\n\t\t}\n\t}).attr(AttributeKey.newInstance(\"attrName\"), \"attrValue\")\n\t.option(ChannelOption.SO_KEEPALIVE, true)\n\t.option(ChannelOption.TCP_NODELAY, true)\n\t.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000);\n\nbootstrap.connect(\"127.0.0.1\", 8000).addListener(future -> {\n\tif (future.isSuccess()){\n\t\tlogger.debug(\"连接建立成功！\");\n\t\tChannel channel = ((ChannelFuture) future).channel();\n\t} else {\n\t\tlogger.error(\"连接建立失败！\");\n\t}\n});\n```\n\nclient端实现一个`FirstClientHandler`来读取服务器发过来的信息：\n\n```java\npublic class FirstClientHandler extends ChannelInboundHandlerAdapter {\n\tprivate static Logger logger = LoggerFactory.getLogger(FirstClientHandler.class);\n\t@Override\n\tpublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n\t\tByteBuf buffer = (ByteBuf) msg;\n\t\tlogger.debug(\"客户端读到数据：\" + buffer.toString(Charset.forName(\"UTF-8\")));\n\t}\n}\n```\n\n以上就是一个最简单的Netty Server-Client demo\n\n### Tips\n\n使用Netty的过程中的一些知识点，小技巧和需要注意的地方\n\n#### 调用ByteBuf.release()手动释放内存\n\n由于netty默认使用的`ByteBuf`是`directBuffer`，不受gc影响，因此需要手动释放内存\n\n> 对于入站消息，如果不调用`ctx.fireChannelRead(msg)`把消息往下传，则需要原地将消息释放\n```java\n@Override\npublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n    ByteBuf buffer = null;\n    try {\n        buffer = (ByteBuf) msg;\n        logger.debug(\"服务器端读到数据：\" + buffer.toString(Charset.forName(\"UTF-8\")));\n    } finally {\n        buffer.release();\n    }\n}\n```\n\n> 出站消息无需手动释放，netty最终会将其释放\n\nnetty提供了内存泄漏检测机制，日志中出现的`LEAK`字样需要格外引起注意\n\n#### 异步Future\n\nNetty中，进行IO操作如向channel写数据是异步操作，Netty提供了`ChannelFuture`，以异步的方式向channel写数据，保证不阻塞EventLoop线程，可以通过添加listenner获取异步发送的结果：\n\n```java\nctx.channel().writeAndFlush(buffer).addListener(future -> {\n    if (future.isSuccess()){\n        logger.debug(\"Server数据发送成功\");\n    } else {\n        logger.debug(\"Server数据发送失败\");\n    }\n});\n```\n\n#### Attribute\n\nNetty提供了`Attribute`类来实现属性绑定，使用`.childAttr()`方法在初始化阶段给每一个连上服务器的channel绑定属性：\n\n```java\n​```\n.childAttr(AttributeKey.newInstance(\"clientKey\"), \"clientValue\")\n​```\n```\n\n属性跟随Channel整个生命周期存在，除非手动删除；运行阶段也可以动态绑定，修改或者删除属性值：\n\n```java\n// login\nchannel.attr(\"login\").set(true);\n//logout\nchannel.attr(\"login\").set(false);\n//check login status\nAttribute<Boolean> loginAttr = channel.attr(\"login\");\nBoolean isLogin = loginAttr.get();\n```\n\n\n\n#### 自定义协议\n\nNetty的网络组件只负责连接层（tcp或者udp）的数据解析和交互，剩下的应用层协议都需要用户自己实现\n\nNetty已经提供了一些支持目前主流应用层协议的基础通信组件（http, websocket, mqtt, smtp, 还有redis协议等），除了这些开箱即用的应用层协议组件，大多数情况下都是基于Netty构建自定义协议来进行个性化开发\n\n##### 设计协议\n\n首先需要根据需要自己设计一个协议，便于解析二进制数据包满足业务需求，下面是一个经典的自定义二进制协议格式：\n\n![](http://img.mantian.site/201908131121_32.png)\n\n#####  确定序列化算法\n\n读取或者写入数据使用的载体是`ByteBuf`，需要某种序列化算法（json， protobuf，thrift等）使得Java对象和`ByteBuf`互相转化\n\n##### 封装协议解析过程\n\n以下是一个简单的例子：\n\n```java\npublic class ProtocolCodeC {\n\n    public static final int MAGIC_NUMBER = 0x12345678;\n\n    //对象编码，返回\n    public static ByteBuf encode(ByteBuf byteBuf, Packet packet){\n        //序列化java对象\n        byte[] bytes = Serializer.DEFAULT.serialize(packet);\n        //写入数据\n        byteBuf.writeInt(MAGIC_NUMBER);\n        byteBuf.writeByte(packet.getVersion());\n        byteBuf.writeByte(Serializer.DEFAULT.getSerializerAlgorithm());\n        byteBuf.writeByte(packet.getCommand());\n        byteBuf.writeInt(bytes.length);\n        byteBuf.writeBytes(bytes);\n        return byteBuf;\n    }\n\n    public static Packet decode(ByteBuf byteBuf){\n        // 校验魔数\n        byteBuf.skipBytes(4);\n        // 校验版本\n        byteBuf.skipBytes(1);\n        // 解析序列化算法\n        byte algorithmCode = byteBuf.readByte();\n        // 解析指令\n        byte command = byteBuf.readByte();\n        // 解析消息长度\n        int length = byteBuf.readInt();\n        // 解析消息体\n        byte[] data = new byte[length];\n        byteBuf.readBytes(data);\n        \n        // 将消息体解析为具体的Java dto\n        Class<? extends Packet> requireType = getRequireClass(command);\n        Serializer serializer = getSerializer(algorithmCode);\n        if(requireType != null && serializer != null){\n            return serializer.deserialize(requireType, data);\n        }\n        return null;\n    }\n}\n```\n\n##### 注册Netty编解码器\n\n将自定义协议组件封装为Netty提供的编解码器：\n\n```java\npublic class PacketCodecHandler extends MessageToMessageCodec<ByteBuf, Packet> {\n    public static final PacketCodecHandler INSTANCE = new PacketCodecHandler();\n    private PacketCodecHandler(){}\n\n    @Override\n    protected void encode(ChannelHandlerContext ctx, Packet msg, List<Object> out) throws Exception {\n        // 将ByteBuf序列化为Java对象（由出站事件触发）\n        ByteBuf byteBuf = ctx.alloc().ioBuffer();\n        PacketCodeC.encode(byteBuf, msg);\n        out.add(byteBuf);\n    }\n\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf msg, List<Object> out) throws Exception {\n        // 将Java对象反序列化为ByteBuf（由入站事件触发）\n        Packet packet = PacketCodeC.decode(msg);\n        out.add(packet);\n    }\n}\n```\n\n将编解码器注册到`ChannelPipeline`上，需要注意注册顺序：\n\n```java\nnioSocketChannel.pipeline()\n    .addLast(new PacketCodecHandler())\n    .addLast(...业务逻辑handler......)\n```\n\n\n\n#### 粘包/拆包\n\nTCP连接过程中，粘包和拆包是经常发生的现象\n\n> 拆包：由于TCP报文有长度限制，如果单体报文过长会拆包，将一个大包拆成几个小包，或者程序写入数据大小大于socket缓冲区，也会发生拆包\n>\n> 粘包：要发送的数据小于TCP发送缓冲区的大小，网卡将多次写入缓冲区的数据一次发送出去，将会发生粘包，或者接收端没有按时读取socket缓冲区的数据，导致一次性读取多个包的数据，也会发生粘包\n\n如何解决这种粘包和拆包的情况？\n\n> 1. 如果当前读取的数据不足以拼接成一个完整的业务数据包，那就保留该数据，继续从 TCP 缓冲区中读取，直到得到一个完整的数据包。\n> 2. 如果当前读到的数据加上已经读取的数据足够拼接成一个数据包，那就将已经读取的数据拼接上本次读取的数据，构成一个完整的业务数据包传递到业务逻辑，多余的数据仍然保留，以便和下次读到的数据尝试拼接。\n\n通常判断完整数据包的方法通常有以下几种：\n\n> 1. 使用带消息头的协议、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。\n> 2. 设置定长消息，服务端每次读取既定长度的内容作为一条完整消息，当消息不够长时，空位补上固定字符。\n> 3. 设置消息边界，服务端从网络流中读消息时通过'\\n'等特殊字符判断消息边界来拆分消息\n\nNetty对于粘包拆包的问题也提供了开箱即用的拆包合包器：\n\n```java\n1. 固定长度的拆包器 FixedLengthFrameDecoder\n最简单的拆包器，Netty会把一个个长度为 100 的数据包 (ByteBuf) 传递到下一个ChannelHandler\n\n2. 行拆包器 LineBasedFrameDecoder\n发送端发送数据包的时候，每个数据包之间以换行符作为分隔，接收端通过 LineBasedFrameDecoder 将粘过的 ByteBuf 拆分成一个个完整的应用层数据包\n\n3. 分隔符拆包器 DelimiterBasedFrameDecoder\nDelimiterBasedFrameDecoder是行拆包器的通用版本，可以自定义分隔符。\n\n4. 基于长度域拆包器 LengthFieldBasedFrameDecoder\n只要自定义协议中包含长度域字段，均可以使用这个拆包器来实现应用层拆包\n```\n\n### Netty实战\n\n#### Netty进阶——开发Http MVC框架\n\n#### Netty进阶——开发RPC框架\n\n#### Netty进阶——开发IM系统","source":"_posts/Netty概览-1.md","raw":"title: Netty概览\nauthor: 天渊\ntags:\n  - netty\ncategories:\n  - 基础知识\ndate: 2019-08-12 16:06:00\n---\n\n### Netty是什么\n\nNetty是一款用于快速开发高性能网络应用的Java框架，封装了网络编程的复杂性，使网络编程和web技术的最新进展能够比以往更广泛的让开发人员接触到。\n<!--more-->\n\n#### 为什么要用Netty\n\nNetty是一个网络通信框架，目的就是屏蔽底层复杂的网络编程细节，提供更便捷的编程模型。\n\n##### 开箱即用的网络组件\n\n有了Netty，你可以实现自己的HTTP服务器，FTP服务器，UDP服务器，RPC服务器，WebSocket服务器，Redis的Proxy服务器，MySQL的Proxy服务器等等。\n\n反过来看看，不使用netty，直接基于BIO或者NIO编写网络程序，你需要做什么：\n\n1. 创建一个ServerSocket，监听并绑定一个端口\n2. 一系列客户端来请求这个端口\n3. 服务器使用Accept，获得一个来自客户端的Socket连接对象\n4. 启动一个新线程处理连接\n\n   - 读Socket，得到字节流\n\n   - 解码协议，得到反序列化后的请求对象\n\n   - 处理请求对象，得到一个结果，封装成一个返回对象\n\n   - 编码协议，将结果序列化字节流\n\n   - 写Socket，将字节流发给客户端\n5. 继续循环步骤3\n\nNetty并不需要你针对这些基础的IO过程编写大量的代码，已经封装好了成熟的IO库，开发人员只需要关注逻辑处理部分就可以。\n\n##### 高性能并发机制\n\n对于高性能网络组件，还得关注它的并发性能，这就涉及到多线程并发编程，Netty提供了便捷的开箱即用多线程框架，保证了成熟的异步回调和事件驱动机制\n\n##### 高性能长连接支持\n\n因为TCP连接的特性，我们还要使用连接池来进行管理：\n\n1. 对于频繁的TCP通讯，很多时候需要保持长连接，保持连接效果更好\n2. 对于并发请求，可能需要建立多个连接\n3. 维护多个连接后，每次通讯，需要选择某一可用连接\n4. 连接超时和关闭机制\n\nNetty能够支持高性能长连接机制，因此在即时通讯和物联网等领域有很大的用武之地\n\n##### 众多开源项目鼎力支持\n\n一个优秀的开源项目离不开高质量的社区，Netty作为基础组件被众多开源项目和大型互联网企业采用，社区质量也是非常之高，如Apple，Twitter，Google和阿里等大型企业，还有Akka, Vert.x，Hadoop，ElasticSearch, Cassandra等优秀的开源项目，都在给Netty源源不断地贡献代码\n\n![](http://img.mantian.site/images/1564638670965.png)\n\n### Java NIO\n\n介绍Netty基本特性之前，需要对NIO (non-blocking IO, 也叫做new IO)有一定的了解\n\nJava NIO最早于Jdk 1.4版本引入，跟传统IO（BIO，也叫NIO）相比，极大的缓解了线程池处理海量连接的瓶颈，提高了IO密集型应用的处理效率\n\n关于NIO的技术介绍可以看美团这篇文章：[Java NIO浅析](https://tech.meituan.com/2016/11/04/nio.html)，更进一步可以看Doug Lea的这篇论文：[Scalable IO in Java](http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf)\n\nNetty对底层网络模型进行了一系列的封装和抽象，包括NIO和BIO，不过最常用的还是基于NIO的抽象，在Java NIO的`Selector`，`Channel`和`Buffer`基础上进行了丰富的抽象和封装，极大的简化了Java原生NIO组件复杂的编程模型，并在此基础上实现了reactor线程模型，能做到非常高效的并发处理\n\n以下是一个简单的NIO网络模型：\n\n![](http://img.mantian.site/201908131112_661.png)\n\nNIO网络模型最重要的组件就是`Selector`，底层基于操作系统的`epoll`或者`kqueue`等机制实现事件驱动式非阻塞IO操作，`Selector`在某些时候又称作`Reactor`（响应器，选择器，分派器......）\n\n在Netty中，`Selector`(或者`Reactor`) 称作`EventLoop`，在Netty中采用的是`单bossEventLoop+多workEventLoop`的模式，由`bossEventLoop`负责响应client的连接请求，并建立连接，由多个`workEventLoop`负责维护客户端socket的数据交互和读写工作，每个`EventLoop`都会在一个独立的线程中执行\n\n![](http://img.mantian.site/201908131115_71.png)\n\n### Netty核心特性浅析\n\n#### Netty核心组件\n\n摘自Netty官网的核心组件构成：\n\n![](https://netty.io/images/components.png)\n\nNetty核心功能由三部分组成：\n\n##### Extensible Event Model\n\n在我看来，Netty之所以这么优秀，除了对NIO网络模型进行了很好的抽象封装，另外一点就是其提供的方便高效的事件驱动的设计思想\n\n###### 事件\n\nNetty使用不同的事件来通知我们状态的改变或是操作的状态，我们能基于已经发生的事件来触发适当的动作，在Netty中事件类型分为两大类：`入站事件`，`出站事件`\n\n> 入站事件：`Socket连接激活或连接失活`，`数据读取`，`用户事件`，`错误事件（Exception）`\n>\n> 出站事件：`打开/关闭远程连接`，`写数据到Socket`\n>\n\n###### Channel\n\n事件的作用对象是`Channel`通道，`Channel`是Java NIO中表示连接的基本组件，代表到实体（硬件设备，文件描述符，socket网络套接字等）的开放连接，可以把它看作入站或出站的数据载体，对应`Channel`的事件就有读数据，写数据，开启或关闭等\n\n事件的发起者即为`EventLoop`选择器，当检测到某个`Channel`状态发生变化（数据可读，可写等），即产生一个事件，并触发一系列的回调\n\nChannel的生命周期：\n\n![](http://img.mantian.site/201908131118_392.png)\n\n每一个阶段都会产生相应的事件并触发对应的回调，并且在`ChannelActive`和`ChannelInactive`两个状态之间还会产生读写事件，用户事件和错误事件\n\n###### ChannelHandler\n\n既然定义了事件，那就得有相应的事件回调处理器，在Netty中所有回调处理器均实现`ChannelHandler`这个接口，根据入站或出站事件又分为`ChannelInboundHandler`和`ChannelOutboundHandler`\n\n![](http://img.mantian.site/201908131118_15.png)\n\n`ChannelHandler`由开发人员自己实现，开发人员可以根据不同的事件实现不同回调处理器的不同方法，例如某个handler需要捕获Channel激活的事件，可以像如下方式实现一个`ChannelInboundHandler`，服务端一旦检测到连接激活，则向客户端回复一条消息：\n\n```java\npublic class FirstServerHandler extends ChannelInboundHandlerAdapter{\n    @Override\n    public void channelActive(ChannelHandlerContext ctx) throws Exception {\n        ByteBuf buffer = ctx.alloc().buffer();\n        byte[] bytes = \"Connection successfully\".getBytes(Charset.forName(\"UTF-8\"));\n        buffer.writeBytes(bytes);\n        ctx.channel().writeAndFlush(buffer);\n    }\n}    \n```\n\n一个`ChannelHandler`可以实现多个回调方法，一个入站handler可以同时订阅激活事件，读事件，用户自定义事件以及错误事件\n\n`ChannelHandler`编写完后注册到`ChannelPipeline`上，至于如何注册handler回调处理器，将在后续的sample中展示\n\n###### ChannelPipeline和ChannelHandlerContext\n\n`ChannelPipeline`是一个拦截流经`Channel`入站和出站事件的链条，所有`ChannelHandler`都需要挂载在`ChannelPipeline`上，每一个新创建的`Channel`都会分配一个新的`ChannelPipeline`\n\n![](http://img.mantian.site/201908131120_873.png)\n\n上图是事件在每个`ChannelHandler`上的传播顺序\n\n`ChannelHandlerContext`就是`ChannelHandler`和`ChannelPipeline`之间沟通的桥梁，每当一个新的`ChannelHandler`添加到pipeline中时，都会创建一个对应的`ChannelHandlerContext`，其主要功能时管理它所关联的`ChannelHandler`和在同一个pipeline中的其他`ChannelHandler`之间的数据交互\n\n![](http://img.mantian.site/201908131120_370.png)\n\n如上图：\n\n1. 事件（入站或者出站）传给`ChannelPipeline`的第一个handler\n2. 通过与这个handler关联的`ChannelHandlerContext`将事件传递给下一个handler\n3. 同2\n\n##### Zero-Copy-Capable Rich Byte Buffer\n\nnetty使用`ByteBuf`来取代jdk自带的`ByteBuffer`作为nio的数据传输载体，相比于jdk原生的ByteBuffer实现，功能更加丰富，灵活性更强，具有以下优点：\n\n- 扩展性好，用户可自定义所需要的缓冲区实现\n- 内置复合缓冲区实现了零拷贝功能\n- 容量按需增长\n- 读数据和写数据有独立的index，互相隔离，互不干扰\n- 支持引用计数和池化\n\n在netty中`ByteBuf`有三种实现：`heapBuffer`，`directBuffer`，`compositeBuffer`，通常情况下使用directBuffer：\n\n- heapBuffer：即将数据存储通过java Byte数组的方式（称为支撑数组）存储在jvm heap中，使用以下方式快速创建一个heapBuffer，但java进行io读写时仍然需要将堆内内存的数据拷贝到堆外并传递给底层的C库:\n\n```java\nByteBuf buffer = ByteBufAllocator.DEFAULT.heapBuffer();\n// 可以直接将所需Byte数组拿出来\nif (buffer.hasArray()) {\n\tbyte[] bufferArray = buffer.array();\n\tint offset = buffer.arrayOffset() + buffer.readerIndex();\n\tint length = buffer.readableBytes();\n    // 通过读指针和可读长度获取所需的数据\n\tbyte[] neededData = Arrays.copyOfRange(bufferArray, offset, offset + length);\n}\n```\n\n- directBuffer：使用堆外内存存储数据，直接使用堆外内存进行io操作，好处是比`heapBuffer`少一次内存拷贝且在io操作频繁的时候大大降低了gc压力，缺点是需要手动释放内存空间：\n\n```java\nByteBuf buffer = ByteBufAllocator.DEFAULT.directBuffer();\n```\n\n`directBuffer`没有支撑数组，因此不能直接提取Byte数组，需要通过读写指针取数据\n\n- compositeBuffer：复合buffer，其中可同时包含堆内数据和堆外数据，其实现是`ByteBuf`的子类：`CompositeByteBuf`，通过以下方式组装一个复合buffer，访问复合buffer的方式也类似于`directBuffer`，不能直接访问其支撑数组：\n\n```java\nCompositeByteBuf compBuf = ByteBufAllocator.DEFAULT.compositeBuffer();\ncompBuf.addComponents(buffer, heapBuffer);\n```\n\n复合buffer广泛运用于需要组合多种不同数据源的buffer，在对不同数据源的数据进行整合后提供统一的ByteBuf API供用户使用\n\nNetty的零拷贝Buffer概念与操作系统层面的零拷贝不是一回事（Netty传输文件时已经通过Java NIO的DirectBuffer实现了基于DMA引擎的零拷贝），Netty的零拷贝描述的是组合buffer时不需要申请新的buffer内存，直接在原buffer的基础上通过`CompositeByteBuf`进行buffer的合并，而Java原生的ByteBuffer在这种情况下需要开辟新的buffer内存：\n\n![](http://img.mantian.site/201908131119_969.png)\n\n##### Universal Communication API\n\n统一的通讯API，Java原生的BIO和NIO使用了不同的API，而Netty则提供了统一的API(`org.jboss.netty.channel.Channel`)来封装这两种I/O模型。这部分代码在`org.jboss.netty.channel`包中\n\n在核心功能之上，Netty还提供了很多开箱即用的API，为用户的协议解析，tcp层面的粘包拆包以及文件编码和安全认证等基础需求提供了诸多需求\n\n#### Netty运行架构\n\nNetty整体运行架构如下：\n\n![](http://img.mantian.site/201908131138_346.png)\n   \n\n### Netty基础使用 （sample）\n\nNetty目前最新版本是`4.1.38.Final`，下列分析基本上都是基于4.x版本 （开发中的5.x版本因为某些原因作废了）\n\n用Netty先实现一个最简单的tcp服务，发送一段简单的文本并获取相应\n\n#### 启动Server端\n\n启动一个能够运行的Netty服务端进程，大致有以下几步：\n\n```java\n1. 添加boss和work线程组\n2. 指定io模型为nio方式\n3. 指定server端启动时的初始化handler\n4. 指定ChannelHandler，即具体的业务处理逻辑\n5. 给NioServerSocketChannel指定attributes，后续可以通过channel.attr()取出这个属性\n6. 给NioSocketChannel指定attributes\n7. 给NioSocketChannel指定一些选项，比如是否开启TCP心跳机制或者Nagle算法等\n8. 给NioServerSocketChannel指定一些选项，比如设置完成三次握手的请求的缓存队列大小00\n```\n\n代码如下：\n\n```java\nserverBootstrap.group(bossGroup, workerGroup)\n    .channel(NioServerSocketChannel.class)\n    .handler(new ChannelInitializer<NioServerSocketChannel>() {\n        @Override\n        protected void initChannel(NioServerSocketChannel channel){\n            logger.debug(\"服务端启动中...\");\n        }\n    })\n    .childHandler(new ChannelInitializer<NioSocketChannel>() {\n        protected void initChannel(NioSocketChannel nioSocketChannel){\n            //（责任链模式）pipeline添加逻辑处理器，当接收到客户端数据时按顺序执行回调\n            nioSocketChannel.pipeline()\n                .addLast();\n        }\n    })\n    .attr(AttributeKey.newInstance(\"serverName\"), \"nettyServer\")\n    .childAttr(AttributeKey.newInstance(\"clientKey\"), \"clientValue\")\n    .childOption(ChannelOption.SO_KEEPALIVE, true)\n    .childOption(ChannelOption.TCP_NODELAY, true)\n    .option(ChannelOption.SO_BACKLOG, 1024);\n\n//绑定端口是一个异步过程，设置回调方法查看是否绑定成功\n//默认绑定的ip地址是0.0.0.0\nserverBootstrap.bind(8000).addListener(future -> {\n    if(future.isSuccess()){\n        logger.debug(\"8000端口绑定成功！\");\n    }else {\n        logger.debug(\"8000端口绑定失败！\");\n    }\n});\n```\n\n如上，`childHandler()`方法用于在建立连接的channel上绑定handler，一旦有事件触发， 事件会沿着添加的顺序进行传播，现在把`FirstServerHandler`这个handler绑定上:\n\n```java\n...\n.addLast(new FirstServerHandler());\n...\n```\n\n每一个成功建立连接的channel都会绑定一个`FirstServerHandler`，一旦channel激活，就会触发`channelActive`这个方法\n\n#### 启动client端\n\n启动一个Netty client，大致需要以下几步：\n\n```java\n1. 添加work线程组\n2. 指定io模型为nio方式\n3. 指定ChannelHandler，即具体的业务处理逻辑\n4. 给NioSocketChannel添加attributes\n5. 给NioSocketChannel指定一些选项，比如是否开启心跳以及设置连接超时时间，以及Nagle算法\n```\n\n代码如下：\n\n```java\nbootstrap.group(workerGroup)\n\t.channel(NioSocketChannel.class)\n\t.handler(new ChannelInitializer<NioSocketChannel>() {\n\t\t@Override\n\t\tprotected void initChannel(NioSocketChannel nioSocketChannel) {\n\t\t\t//添加ClientHandler，连接上处理和服务器端的数据交互\n\t\t\tnioSocketChannel.pipeline().addLast(new FirstClientHandler());\n\t\t}\n\t}).attr(AttributeKey.newInstance(\"attrName\"), \"attrValue\")\n\t.option(ChannelOption.SO_KEEPALIVE, true)\n\t.option(ChannelOption.TCP_NODELAY, true)\n\t.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000);\n\nbootstrap.connect(\"127.0.0.1\", 8000).addListener(future -> {\n\tif (future.isSuccess()){\n\t\tlogger.debug(\"连接建立成功！\");\n\t\tChannel channel = ((ChannelFuture) future).channel();\n\t} else {\n\t\tlogger.error(\"连接建立失败！\");\n\t}\n});\n```\n\nclient端实现一个`FirstClientHandler`来读取服务器发过来的信息：\n\n```java\npublic class FirstClientHandler extends ChannelInboundHandlerAdapter {\n\tprivate static Logger logger = LoggerFactory.getLogger(FirstClientHandler.class);\n\t@Override\n\tpublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n\t\tByteBuf buffer = (ByteBuf) msg;\n\t\tlogger.debug(\"客户端读到数据：\" + buffer.toString(Charset.forName(\"UTF-8\")));\n\t}\n}\n```\n\n以上就是一个最简单的Netty Server-Client demo\n\n### Tips\n\n使用Netty的过程中的一些知识点，小技巧和需要注意的地方\n\n#### 调用ByteBuf.release()手动释放内存\n\n由于netty默认使用的`ByteBuf`是`directBuffer`，不受gc影响，因此需要手动释放内存\n\n> 对于入站消息，如果不调用`ctx.fireChannelRead(msg)`把消息往下传，则需要原地将消息释放\n```java\n@Override\npublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n    ByteBuf buffer = null;\n    try {\n        buffer = (ByteBuf) msg;\n        logger.debug(\"服务器端读到数据：\" + buffer.toString(Charset.forName(\"UTF-8\")));\n    } finally {\n        buffer.release();\n    }\n}\n```\n\n> 出站消息无需手动释放，netty最终会将其释放\n\nnetty提供了内存泄漏检测机制，日志中出现的`LEAK`字样需要格外引起注意\n\n#### 异步Future\n\nNetty中，进行IO操作如向channel写数据是异步操作，Netty提供了`ChannelFuture`，以异步的方式向channel写数据，保证不阻塞EventLoop线程，可以通过添加listenner获取异步发送的结果：\n\n```java\nctx.channel().writeAndFlush(buffer).addListener(future -> {\n    if (future.isSuccess()){\n        logger.debug(\"Server数据发送成功\");\n    } else {\n        logger.debug(\"Server数据发送失败\");\n    }\n});\n```\n\n#### Attribute\n\nNetty提供了`Attribute`类来实现属性绑定，使用`.childAttr()`方法在初始化阶段给每一个连上服务器的channel绑定属性：\n\n```java\n​```\n.childAttr(AttributeKey.newInstance(\"clientKey\"), \"clientValue\")\n​```\n```\n\n属性跟随Channel整个生命周期存在，除非手动删除；运行阶段也可以动态绑定，修改或者删除属性值：\n\n```java\n// login\nchannel.attr(\"login\").set(true);\n//logout\nchannel.attr(\"login\").set(false);\n//check login status\nAttribute<Boolean> loginAttr = channel.attr(\"login\");\nBoolean isLogin = loginAttr.get();\n```\n\n\n\n#### 自定义协议\n\nNetty的网络组件只负责连接层（tcp或者udp）的数据解析和交互，剩下的应用层协议都需要用户自己实现\n\nNetty已经提供了一些支持目前主流应用层协议的基础通信组件（http, websocket, mqtt, smtp, 还有redis协议等），除了这些开箱即用的应用层协议组件，大多数情况下都是基于Netty构建自定义协议来进行个性化开发\n\n##### 设计协议\n\n首先需要根据需要自己设计一个协议，便于解析二进制数据包满足业务需求，下面是一个经典的自定义二进制协议格式：\n\n![](http://img.mantian.site/201908131121_32.png)\n\n#####  确定序列化算法\n\n读取或者写入数据使用的载体是`ByteBuf`，需要某种序列化算法（json， protobuf，thrift等）使得Java对象和`ByteBuf`互相转化\n\n##### 封装协议解析过程\n\n以下是一个简单的例子：\n\n```java\npublic class ProtocolCodeC {\n\n    public static final int MAGIC_NUMBER = 0x12345678;\n\n    //对象编码，返回\n    public static ByteBuf encode(ByteBuf byteBuf, Packet packet){\n        //序列化java对象\n        byte[] bytes = Serializer.DEFAULT.serialize(packet);\n        //写入数据\n        byteBuf.writeInt(MAGIC_NUMBER);\n        byteBuf.writeByte(packet.getVersion());\n        byteBuf.writeByte(Serializer.DEFAULT.getSerializerAlgorithm());\n        byteBuf.writeByte(packet.getCommand());\n        byteBuf.writeInt(bytes.length);\n        byteBuf.writeBytes(bytes);\n        return byteBuf;\n    }\n\n    public static Packet decode(ByteBuf byteBuf){\n        // 校验魔数\n        byteBuf.skipBytes(4);\n        // 校验版本\n        byteBuf.skipBytes(1);\n        // 解析序列化算法\n        byte algorithmCode = byteBuf.readByte();\n        // 解析指令\n        byte command = byteBuf.readByte();\n        // 解析消息长度\n        int length = byteBuf.readInt();\n        // 解析消息体\n        byte[] data = new byte[length];\n        byteBuf.readBytes(data);\n        \n        // 将消息体解析为具体的Java dto\n        Class<? extends Packet> requireType = getRequireClass(command);\n        Serializer serializer = getSerializer(algorithmCode);\n        if(requireType != null && serializer != null){\n            return serializer.deserialize(requireType, data);\n        }\n        return null;\n    }\n}\n```\n\n##### 注册Netty编解码器\n\n将自定义协议组件封装为Netty提供的编解码器：\n\n```java\npublic class PacketCodecHandler extends MessageToMessageCodec<ByteBuf, Packet> {\n    public static final PacketCodecHandler INSTANCE = new PacketCodecHandler();\n    private PacketCodecHandler(){}\n\n    @Override\n    protected void encode(ChannelHandlerContext ctx, Packet msg, List<Object> out) throws Exception {\n        // 将ByteBuf序列化为Java对象（由出站事件触发）\n        ByteBuf byteBuf = ctx.alloc().ioBuffer();\n        PacketCodeC.encode(byteBuf, msg);\n        out.add(byteBuf);\n    }\n\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf msg, List<Object> out) throws Exception {\n        // 将Java对象反序列化为ByteBuf（由入站事件触发）\n        Packet packet = PacketCodeC.decode(msg);\n        out.add(packet);\n    }\n}\n```\n\n将编解码器注册到`ChannelPipeline`上，需要注意注册顺序：\n\n```java\nnioSocketChannel.pipeline()\n    .addLast(new PacketCodecHandler())\n    .addLast(...业务逻辑handler......)\n```\n\n\n\n#### 粘包/拆包\n\nTCP连接过程中，粘包和拆包是经常发生的现象\n\n> 拆包：由于TCP报文有长度限制，如果单体报文过长会拆包，将一个大包拆成几个小包，或者程序写入数据大小大于socket缓冲区，也会发生拆包\n>\n> 粘包：要发送的数据小于TCP发送缓冲区的大小，网卡将多次写入缓冲区的数据一次发送出去，将会发生粘包，或者接收端没有按时读取socket缓冲区的数据，导致一次性读取多个包的数据，也会发生粘包\n\n如何解决这种粘包和拆包的情况？\n\n> 1. 如果当前读取的数据不足以拼接成一个完整的业务数据包，那就保留该数据，继续从 TCP 缓冲区中读取，直到得到一个完整的数据包。\n> 2. 如果当前读到的数据加上已经读取的数据足够拼接成一个数据包，那就将已经读取的数据拼接上本次读取的数据，构成一个完整的业务数据包传递到业务逻辑，多余的数据仍然保留，以便和下次读到的数据尝试拼接。\n\n通常判断完整数据包的方法通常有以下几种：\n\n> 1. 使用带消息头的协议、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。\n> 2. 设置定长消息，服务端每次读取既定长度的内容作为一条完整消息，当消息不够长时，空位补上固定字符。\n> 3. 设置消息边界，服务端从网络流中读消息时通过'\\n'等特殊字符判断消息边界来拆分消息\n\nNetty对于粘包拆包的问题也提供了开箱即用的拆包合包器：\n\n```java\n1. 固定长度的拆包器 FixedLengthFrameDecoder\n最简单的拆包器，Netty会把一个个长度为 100 的数据包 (ByteBuf) 传递到下一个ChannelHandler\n\n2. 行拆包器 LineBasedFrameDecoder\n发送端发送数据包的时候，每个数据包之间以换行符作为分隔，接收端通过 LineBasedFrameDecoder 将粘过的 ByteBuf 拆分成一个个完整的应用层数据包\n\n3. 分隔符拆包器 DelimiterBasedFrameDecoder\nDelimiterBasedFrameDecoder是行拆包器的通用版本，可以自定义分隔符。\n\n4. 基于长度域拆包器 LengthFieldBasedFrameDecoder\n只要自定义协议中包含长度域字段，均可以使用这个拆包器来实现应用层拆包\n```\n\n### Netty实战\n\n#### Netty进阶——开发Http MVC框架\n\n#### Netty进阶——开发RPC框架\n\n#### Netty进阶——开发IM系统","slug":"Netty概览-1","published":1,"updated":"2021-05-31T03:06:33.195Z","_id":"ckf0h31gq0003actsgatgxf6i","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"Netty是什么\"><a href=\"#Netty是什么\" class=\"headerlink\" title=\"Netty是什么\"></a>Netty是什么</h3><p>Netty是一款用于快速开发高性能网络应用的Java框架，封装了网络编程的复杂性，使网络编程和web技术的最新进展能够比以往更广泛的让开发人员接触到。<br><a id=\"more\"></a></p>\n<h4 id=\"为什么要用Netty\"><a href=\"#为什么要用Netty\" class=\"headerlink\" title=\"为什么要用Netty\"></a>为什么要用Netty</h4><p>Netty是一个网络通信框架，目的就是屏蔽底层复杂的网络编程细节，提供更便捷的编程模型。</p>\n<h5 id=\"开箱即用的网络组件\"><a href=\"#开箱即用的网络组件\" class=\"headerlink\" title=\"开箱即用的网络组件\"></a>开箱即用的网络组件</h5><p>有了Netty，你可以实现自己的HTTP服务器，FTP服务器，UDP服务器，RPC服务器，WebSocket服务器，Redis的Proxy服务器，MySQL的Proxy服务器等等。</p>\n<p>反过来看看，不使用netty，直接基于BIO或者NIO编写网络程序，你需要做什么：</p>\n<ol>\n<li>创建一个ServerSocket，监听并绑定一个端口</li>\n<li>一系列客户端来请求这个端口</li>\n<li>服务器使用Accept，获得一个来自客户端的Socket连接对象</li>\n<li><p>启动一个新线程处理连接</p>\n<ul>\n<li><p>读Socket，得到字节流</p>\n</li>\n<li><p>解码协议，得到反序列化后的请求对象</p>\n</li>\n<li><p>处理请求对象，得到一个结果，封装成一个返回对象</p>\n</li>\n<li><p>编码协议，将结果序列化字节流</p>\n</li>\n<li><p>写Socket，将字节流发给客户端</p>\n</li>\n</ul>\n</li>\n<li>继续循环步骤3</li>\n</ol>\n<p>Netty并不需要你针对这些基础的IO过程编写大量的代码，已经封装好了成熟的IO库，开发人员只需要关注逻辑处理部分就可以。</p>\n<h5 id=\"高性能并发机制\"><a href=\"#高性能并发机制\" class=\"headerlink\" title=\"高性能并发机制\"></a>高性能并发机制</h5><p>对于高性能网络组件，还得关注它的并发性能，这就涉及到多线程并发编程，Netty提供了便捷的开箱即用多线程框架，保证了成熟的异步回调和事件驱动机制</p>\n<h5 id=\"高性能长连接支持\"><a href=\"#高性能长连接支持\" class=\"headerlink\" title=\"高性能长连接支持\"></a>高性能长连接支持</h5><p>因为TCP连接的特性，我们还要使用连接池来进行管理：</p>\n<ol>\n<li>对于频繁的TCP通讯，很多时候需要保持长连接，保持连接效果更好</li>\n<li>对于并发请求，可能需要建立多个连接</li>\n<li>维护多个连接后，每次通讯，需要选择某一可用连接</li>\n<li>连接超时和关闭机制</li>\n</ol>\n<p>Netty能够支持高性能长连接机制，因此在即时通讯和物联网等领域有很大的用武之地</p>\n<h5 id=\"众多开源项目鼎力支持\"><a href=\"#众多开源项目鼎力支持\" class=\"headerlink\" title=\"众多开源项目鼎力支持\"></a>众多开源项目鼎力支持</h5><p>一个优秀的开源项目离不开高质量的社区，Netty作为基础组件被众多开源项目和大型互联网企业采用，社区质量也是非常之高，如Apple，Twitter，Google和阿里等大型企业，还有Akka, Vert.x，Hadoop，ElasticSearch, Cassandra等优秀的开源项目，都在给Netty源源不断地贡献代码</p>\n<p><img src=\"http://img.mantian.site/images/1564638670965.png\" alt></p>\n<h3 id=\"Java-NIO\"><a href=\"#Java-NIO\" class=\"headerlink\" title=\"Java NIO\"></a>Java NIO</h3><p>介绍Netty基本特性之前，需要对NIO (non-blocking IO, 也叫做new IO)有一定的了解</p>\n<p>Java NIO最早于Jdk 1.4版本引入，跟传统IO（BIO，也叫NIO）相比，极大的缓解了线程池处理海量连接的瓶颈，提高了IO密集型应用的处理效率</p>\n<p>关于NIO的技术介绍可以看美团这篇文章：<a href=\"https://tech.meituan.com/2016/11/04/nio.html\" target=\"_blank\" rel=\"noopener\">Java NIO浅析</a>，更进一步可以看Doug Lea的这篇论文：<a href=\"http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf\" target=\"_blank\" rel=\"noopener\">Scalable IO in Java</a></p>\n<p>Netty对底层网络模型进行了一系列的封装和抽象，包括NIO和BIO，不过最常用的还是基于NIO的抽象，在Java NIO的<code>Selector</code>，<code>Channel</code>和<code>Buffer</code>基础上进行了丰富的抽象和封装，极大的简化了Java原生NIO组件复杂的编程模型，并在此基础上实现了reactor线程模型，能做到非常高效的并发处理</p>\n<p>以下是一个简单的NIO网络模型：</p>\n<p><img src=\"http://img.mantian.site/201908131112_661.png\" alt></p>\n<p>NIO网络模型最重要的组件就是<code>Selector</code>，底层基于操作系统的<code>epoll</code>或者<code>kqueue</code>等机制实现事件驱动式非阻塞IO操作，<code>Selector</code>在某些时候又称作<code>Reactor</code>（响应器，选择器，分派器……）</p>\n<p>在Netty中，<code>Selector</code>(或者<code>Reactor</code>) 称作<code>EventLoop</code>，在Netty中采用的是<code>单bossEventLoop+多workEventLoop</code>的模式，由<code>bossEventLoop</code>负责响应client的连接请求，并建立连接，由多个<code>workEventLoop</code>负责维护客户端socket的数据交互和读写工作，每个<code>EventLoop</code>都会在一个独立的线程中执行</p>\n<p><img src=\"http://img.mantian.site/201908131115_71.png\" alt></p>\n<h3 id=\"Netty核心特性浅析\"><a href=\"#Netty核心特性浅析\" class=\"headerlink\" title=\"Netty核心特性浅析\"></a>Netty核心特性浅析</h3><h4 id=\"Netty核心组件\"><a href=\"#Netty核心组件\" class=\"headerlink\" title=\"Netty核心组件\"></a>Netty核心组件</h4><p>摘自Netty官网的核心组件构成：</p>\n<p><img src=\"https://netty.io/images/components.png\" alt></p>\n<p>Netty核心功能由三部分组成：</p>\n<h5 id=\"Extensible-Event-Model\"><a href=\"#Extensible-Event-Model\" class=\"headerlink\" title=\"Extensible Event Model\"></a>Extensible Event Model</h5><p>在我看来，Netty之所以这么优秀，除了对NIO网络模型进行了很好的抽象封装，另外一点就是其提供的方便高效的事件驱动的设计思想</p>\n<h6 id=\"事件\"><a href=\"#事件\" class=\"headerlink\" title=\"事件\"></a>事件</h6><p>Netty使用不同的事件来通知我们状态的改变或是操作的状态，我们能基于已经发生的事件来触发适当的动作，在Netty中事件类型分为两大类：<code>入站事件</code>，<code>出站事件</code></p>\n<blockquote>\n<p>入站事件：<code>Socket连接激活或连接失活</code>，<code>数据读取</code>，<code>用户事件</code>，<code>错误事件（Exception）</code></p>\n<p>出站事件：<code>打开/关闭远程连接</code>，<code>写数据到Socket</code></p>\n</blockquote>\n<h6 id=\"Channel\"><a href=\"#Channel\" class=\"headerlink\" title=\"Channel\"></a>Channel</h6><p>事件的作用对象是<code>Channel</code>通道，<code>Channel</code>是Java NIO中表示连接的基本组件，代表到实体（硬件设备，文件描述符，socket网络套接字等）的开放连接，可以把它看作入站或出站的数据载体，对应<code>Channel</code>的事件就有读数据，写数据，开启或关闭等</p>\n<p>事件的发起者即为<code>EventLoop</code>选择器，当检测到某个<code>Channel</code>状态发生变化（数据可读，可写等），即产生一个事件，并触发一系列的回调</p>\n<p>Channel的生命周期：</p>\n<p><img src=\"http://img.mantian.site/201908131118_392.png\" alt></p>\n<p>每一个阶段都会产生相应的事件并触发对应的回调，并且在<code>ChannelActive</code>和<code>ChannelInactive</code>两个状态之间还会产生读写事件，用户事件和错误事件</p>\n<h6 id=\"ChannelHandler\"><a href=\"#ChannelHandler\" class=\"headerlink\" title=\"ChannelHandler\"></a>ChannelHandler</h6><p>既然定义了事件，那就得有相应的事件回调处理器，在Netty中所有回调处理器均实现<code>ChannelHandler</code>这个接口，根据入站或出站事件又分为<code>ChannelInboundHandler</code>和<code>ChannelOutboundHandler</code></p>\n<p><img src=\"http://img.mantian.site/201908131118_15.png\" alt></p>\n<p><code>ChannelHandler</code>由开发人员自己实现，开发人员可以根据不同的事件实现不同回调处理器的不同方法，例如某个handler需要捕获Channel激活的事件，可以像如下方式实现一个<code>ChannelInboundHandler</code>，服务端一旦检测到连接激活，则向客户端回复一条消息：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FirstServerHandler</span> <span class=\"keyword\">extends</span> <span class=\"title\">ChannelInboundHandlerAdapter</span></span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">channelActive</span><span class=\"params\">(ChannelHandlerContext ctx)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        ByteBuf buffer = ctx.alloc().buffer();</span><br><span class=\"line\">        <span class=\"keyword\">byte</span>[] bytes = <span class=\"string\">\"Connection successfully\"</span>.getBytes(Charset.forName(<span class=\"string\">\"UTF-8\"</span>));</span><br><span class=\"line\">        buffer.writeBytes(bytes);</span><br><span class=\"line\">        ctx.channel().writeAndFlush(buffer);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>一个<code>ChannelHandler</code>可以实现多个回调方法，一个入站handler可以同时订阅激活事件，读事件，用户自定义事件以及错误事件</p>\n<p><code>ChannelHandler</code>编写完后注册到<code>ChannelPipeline</code>上，至于如何注册handler回调处理器，将在后续的sample中展示</p>\n<h6 id=\"ChannelPipeline和ChannelHandlerContext\"><a href=\"#ChannelPipeline和ChannelHandlerContext\" class=\"headerlink\" title=\"ChannelPipeline和ChannelHandlerContext\"></a>ChannelPipeline和ChannelHandlerContext</h6><p><code>ChannelPipeline</code>是一个拦截流经<code>Channel</code>入站和出站事件的链条，所有<code>ChannelHandler</code>都需要挂载在<code>ChannelPipeline</code>上，每一个新创建的<code>Channel</code>都会分配一个新的<code>ChannelPipeline</code></p>\n<p><img src=\"http://img.mantian.site/201908131120_873.png\" alt></p>\n<p>上图是事件在每个<code>ChannelHandler</code>上的传播顺序</p>\n<p><code>ChannelHandlerContext</code>就是<code>ChannelHandler</code>和<code>ChannelPipeline</code>之间沟通的桥梁，每当一个新的<code>ChannelHandler</code>添加到pipeline中时，都会创建一个对应的<code>ChannelHandlerContext</code>，其主要功能时管理它所关联的<code>ChannelHandler</code>和在同一个pipeline中的其他<code>ChannelHandler</code>之间的数据交互</p>\n<p><img src=\"http://img.mantian.site/201908131120_370.png\" alt></p>\n<p>如上图：</p>\n<ol>\n<li>事件（入站或者出站）传给<code>ChannelPipeline</code>的第一个handler</li>\n<li>通过与这个handler关联的<code>ChannelHandlerContext</code>将事件传递给下一个handler</li>\n<li>同2</li>\n</ol>\n<h5 id=\"Zero-Copy-Capable-Rich-Byte-Buffer\"><a href=\"#Zero-Copy-Capable-Rich-Byte-Buffer\" class=\"headerlink\" title=\"Zero-Copy-Capable Rich Byte Buffer\"></a>Zero-Copy-Capable Rich Byte Buffer</h5><p>netty使用<code>ByteBuf</code>来取代jdk自带的<code>ByteBuffer</code>作为nio的数据传输载体，相比于jdk原生的ByteBuffer实现，功能更加丰富，灵活性更强，具有以下优点：</p>\n<ul>\n<li>扩展性好，用户可自定义所需要的缓冲区实现</li>\n<li>内置复合缓冲区实现了零拷贝功能</li>\n<li>容量按需增长</li>\n<li>读数据和写数据有独立的index，互相隔离，互不干扰</li>\n<li>支持引用计数和池化</li>\n</ul>\n<p>在netty中<code>ByteBuf</code>有三种实现：<code>heapBuffer</code>，<code>directBuffer</code>，<code>compositeBuffer</code>，通常情况下使用directBuffer：</p>\n<ul>\n<li>heapBuffer：即将数据存储通过java Byte数组的方式（称为支撑数组）存储在jvm heap中，使用以下方式快速创建一个heapBuffer，但java进行io读写时仍然需要将堆内内存的数据拷贝到堆外并传递给底层的C库:</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ByteBuf buffer = ByteBufAllocator.DEFAULT.heapBuffer();</span><br><span class=\"line\"><span class=\"comment\">// 可以直接将所需Byte数组拿出来</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (buffer.hasArray()) &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">byte</span>[] bufferArray = buffer.array();</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> offset = buffer.arrayOffset() + buffer.readerIndex();</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> length = buffer.readableBytes();</span><br><span class=\"line\">    <span class=\"comment\">// 通过读指针和可读长度获取所需的数据</span></span><br><span class=\"line\">\t<span class=\"keyword\">byte</span>[] neededData = Arrays.copyOfRange(bufferArray, offset, offset + length);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>directBuffer：使用堆外内存存储数据，直接使用堆外内存进行io操作，好处是比<code>heapBuffer</code>少一次内存拷贝且在io操作频繁的时候大大降低了gc压力，缺点是需要手动释放内存空间：</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ByteBuf buffer = ByteBufAllocator.DEFAULT.directBuffer();</span><br></pre></td></tr></table></figure>\n<p><code>directBuffer</code>没有支撑数组，因此不能直接提取Byte数组，需要通过读写指针取数据</p>\n<ul>\n<li>compositeBuffer：复合buffer，其中可同时包含堆内数据和堆外数据，其实现是<code>ByteBuf</code>的子类：<code>CompositeByteBuf</code>，通过以下方式组装一个复合buffer，访问复合buffer的方式也类似于<code>directBuffer</code>，不能直接访问其支撑数组：</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CompositeByteBuf compBuf = ByteBufAllocator.DEFAULT.compositeBuffer();</span><br><span class=\"line\">compBuf.addComponents(buffer, heapBuffer);</span><br></pre></td></tr></table></figure>\n<p>复合buffer广泛运用于需要组合多种不同数据源的buffer，在对不同数据源的数据进行整合后提供统一的ByteBuf API供用户使用</p>\n<p>Netty的零拷贝Buffer概念与操作系统层面的零拷贝不是一回事（Netty传输文件时已经通过Java NIO的DirectBuffer实现了基于DMA引擎的零拷贝），Netty的零拷贝描述的是组合buffer时不需要申请新的buffer内存，直接在原buffer的基础上通过<code>CompositeByteBuf</code>进行buffer的合并，而Java原生的ByteBuffer在这种情况下需要开辟新的buffer内存：</p>\n<p><img src=\"http://img.mantian.site/201908131119_969.png\" alt></p>\n<h5 id=\"Universal-Communication-API\"><a href=\"#Universal-Communication-API\" class=\"headerlink\" title=\"Universal Communication API\"></a>Universal Communication API</h5><p>统一的通讯API，Java原生的BIO和NIO使用了不同的API，而Netty则提供了统一的API(<code>org.jboss.netty.channel.Channel</code>)来封装这两种I/O模型。这部分代码在<code>org.jboss.netty.channel</code>包中</p>\n<p>在核心功能之上，Netty还提供了很多开箱即用的API，为用户的协议解析，tcp层面的粘包拆包以及文件编码和安全认证等基础需求提供了诸多需求</p>\n<h4 id=\"Netty运行架构\"><a href=\"#Netty运行架构\" class=\"headerlink\" title=\"Netty运行架构\"></a>Netty运行架构</h4><p>Netty整体运行架构如下：</p>\n<p><img src=\"http://img.mantian.site/201908131138_346.png\" alt></p>\n<h3 id=\"Netty基础使用-（sample）\"><a href=\"#Netty基础使用-（sample）\" class=\"headerlink\" title=\"Netty基础使用 （sample）\"></a>Netty基础使用 （sample）</h3><p>Netty目前最新版本是<code>4.1.38.Final</code>，下列分析基本上都是基于4.x版本 （开发中的5.x版本因为某些原因作废了）</p>\n<p>用Netty先实现一个最简单的tcp服务，发送一段简单的文本并获取相应</p>\n<h4 id=\"启动Server端\"><a href=\"#启动Server端\" class=\"headerlink\" title=\"启动Server端\"></a>启动Server端</h4><p>启动一个能够运行的Netty服务端进程，大致有以下几步：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>. 添加boss和work线程组</span><br><span class=\"line\"><span class=\"number\">2</span>. 指定io模型为nio方式</span><br><span class=\"line\"><span class=\"number\">3</span>. 指定server端启动时的初始化handler</span><br><span class=\"line\"><span class=\"number\">4</span>. 指定ChannelHandler，即具体的业务处理逻辑</span><br><span class=\"line\"><span class=\"number\">5</span>. 给NioServerSocketChannel指定attributes，后续可以通过channel.attr()取出这个属性</span><br><span class=\"line\"><span class=\"number\">6</span>. 给NioSocketChannel指定attributes</span><br><span class=\"line\"><span class=\"number\">7</span>. 给NioSocketChannel指定一些选项，比如是否开启TCP心跳机制或者Nagle算法等</span><br><span class=\"line\"><span class=\"number\">8</span>. 给NioServerSocketChannel指定一些选项，比如设置完成三次握手的请求的缓存队列大小<span class=\"number\">00</span></span><br></pre></td></tr></table></figure>\n<p>代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">serverBootstrap.group(bossGroup, workerGroup)</span><br><span class=\"line\">    .channel(NioServerSocketChannel.class)</span><br><span class=\"line\">    .handler(<span class=\"keyword\">new</span> ChannelInitializer&lt;NioServerSocketChannel&gt;() &#123;</span><br><span class=\"line\">        <span class=\"meta\">@Override</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">initChannel</span><span class=\"params\">(NioServerSocketChannel channel)</span></span>&#123;</span><br><span class=\"line\">            logger.debug(<span class=\"string\">\"服务端启动中...\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">    .childHandler(<span class=\"keyword\">new</span> ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">initChannel</span><span class=\"params\">(NioSocketChannel nioSocketChannel)</span></span>&#123;</span><br><span class=\"line\">            <span class=\"comment\">//（责任链模式）pipeline添加逻辑处理器，当接收到客户端数据时按顺序执行回调</span></span><br><span class=\"line\">            nioSocketChannel.pipeline()</span><br><span class=\"line\">                .addLast();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">    .attr(AttributeKey.newInstance(<span class=\"string\">\"serverName\"</span>), <span class=\"string\">\"nettyServer\"</span>)</span><br><span class=\"line\">    .childAttr(AttributeKey.newInstance(<span class=\"string\">\"clientKey\"</span>), <span class=\"string\">\"clientValue\"</span>)</span><br><span class=\"line\">    .childOption(ChannelOption.SO_KEEPALIVE, <span class=\"keyword\">true</span>)</span><br><span class=\"line\">    .childOption(ChannelOption.TCP_NODELAY, <span class=\"keyword\">true</span>)</span><br><span class=\"line\">    .option(ChannelOption.SO_BACKLOG, <span class=\"number\">1024</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//绑定端口是一个异步过程，设置回调方法查看是否绑定成功</span></span><br><span class=\"line\"><span class=\"comment\">//默认绑定的ip地址是0.0.0.0</span></span><br><span class=\"line\">serverBootstrap.bind(<span class=\"number\">8000</span>).addListener(future -&gt; &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(future.isSuccess())&#123;</span><br><span class=\"line\">        logger.debug(<span class=\"string\">\"8000端口绑定成功！\"</span>);</span><br><span class=\"line\">    &#125;<span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        logger.debug(<span class=\"string\">\"8000端口绑定失败！\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>如上，<code>childHandler()</code>方法用于在建立连接的channel上绑定handler，一旦有事件触发， 事件会沿着添加的顺序进行传播，现在把<code>FirstServerHandler</code>这个handler绑定上:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">.addLast(<span class=\"keyword\">new</span> FirstServerHandler());</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>每一个成功建立连接的channel都会绑定一个<code>FirstServerHandler</code>，一旦channel激活，就会触发<code>channelActive</code>这个方法</p>\n<h4 id=\"启动client端\"><a href=\"#启动client端\" class=\"headerlink\" title=\"启动client端\"></a>启动client端</h4><p>启动一个Netty client，大致需要以下几步：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>. 添加work线程组</span><br><span class=\"line\"><span class=\"number\">2</span>. 指定io模型为nio方式</span><br><span class=\"line\"><span class=\"number\">3</span>. 指定ChannelHandler，即具体的业务处理逻辑</span><br><span class=\"line\"><span class=\"number\">4</span>. 给NioSocketChannel添加attributes</span><br><span class=\"line\"><span class=\"number\">5</span>. 给NioSocketChannel指定一些选项，比如是否开启心跳以及设置连接超时时间，以及Nagle算法</span><br></pre></td></tr></table></figure>\n<p>代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bootstrap.group(workerGroup)</span><br><span class=\"line\">\t.channel(NioSocketChannel.class)</span><br><span class=\"line\">\t.handler(<span class=\"keyword\">new</span> ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class=\"line\">\t\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t\t<span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">initChannel</span><span class=\"params\">(NioSocketChannel nioSocketChannel)</span> </span>&#123;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">//添加ClientHandler，连接上处理和服务器端的数据交互</span></span><br><span class=\"line\">\t\t\tnioSocketChannel.pipeline().addLast(<span class=\"keyword\">new</span> FirstClientHandler());</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;).attr(AttributeKey.newInstance(<span class=\"string\">\"attrName\"</span>), <span class=\"string\">\"attrValue\"</span>)</span><br><span class=\"line\">\t.option(ChannelOption.SO_KEEPALIVE, <span class=\"keyword\">true</span>)</span><br><span class=\"line\">\t.option(ChannelOption.TCP_NODELAY, <span class=\"keyword\">true</span>)</span><br><span class=\"line\">\t.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, <span class=\"number\">5000</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">bootstrap.connect(<span class=\"string\">\"127.0.0.1\"</span>, <span class=\"number\">8000</span>).addListener(future -&gt; &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (future.isSuccess())&#123;</span><br><span class=\"line\">\t\tlogger.debug(<span class=\"string\">\"连接建立成功！\"</span>);</span><br><span class=\"line\">\t\tChannel channel = ((ChannelFuture) future).channel();</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\tlogger.error(<span class=\"string\">\"连接建立失败！\"</span>);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>client端实现一个<code>FirstClientHandler</code>来读取服务器发过来的信息：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FirstClientHandler</span> <span class=\"keyword\">extends</span> <span class=\"title\">ChannelInboundHandlerAdapter</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Logger logger = LoggerFactory.getLogger(FirstClientHandler.class);</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">channelRead</span><span class=\"params\">(ChannelHandlerContext ctx, Object msg)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\t\tByteBuf buffer = (ByteBuf) msg;</span><br><span class=\"line\">\t\tlogger.debug(<span class=\"string\">\"客户端读到数据：\"</span> + buffer.toString(Charset.forName(<span class=\"string\">\"UTF-8\"</span>)));</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>以上就是一个最简单的Netty Server-Client demo</p>\n<h3 id=\"Tips\"><a href=\"#Tips\" class=\"headerlink\" title=\"Tips\"></a>Tips</h3><p>使用Netty的过程中的一些知识点，小技巧和需要注意的地方</p>\n<h4 id=\"调用ByteBuf-release-手动释放内存\"><a href=\"#调用ByteBuf-release-手动释放内存\" class=\"headerlink\" title=\"调用ByteBuf.release()手动释放内存\"></a>调用ByteBuf.release()手动释放内存</h4><p>由于netty默认使用的<code>ByteBuf</code>是<code>directBuffer</code>，不受gc影响，因此需要手动释放内存</p>\n<blockquote>\n<p>对于入站消息，如果不调用<code>ctx.fireChannelRead(msg)</code>把消息往下传，则需要原地将消息释放<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">channelRead</span><span class=\"params\">(ChannelHandlerContext ctx, Object msg)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">    ByteBuf buffer = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        buffer = (ByteBuf) msg;</span><br><span class=\"line\">        logger.debug(<span class=\"string\">\"服务器端读到数据：\"</span> + buffer.toString(Charset.forName(<span class=\"string\">\"UTF-8\"</span>)));</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        buffer.release();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n</blockquote>\n<blockquote>\n<p>出站消息无需手动释放，netty最终会将其释放</p>\n</blockquote>\n<p>netty提供了内存泄漏检测机制，日志中出现的<code>LEAK</code>字样需要格外引起注意</p>\n<h4 id=\"异步Future\"><a href=\"#异步Future\" class=\"headerlink\" title=\"异步Future\"></a>异步Future</h4><p>Netty中，进行IO操作如向channel写数据是异步操作，Netty提供了<code>ChannelFuture</code>，以异步的方式向channel写数据，保证不阻塞EventLoop线程，可以通过添加listenner获取异步发送的结果：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ctx.channel().writeAndFlush(buffer).addListener(future -&gt; &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (future.isSuccess())&#123;</span><br><span class=\"line\">        logger.debug(<span class=\"string\">\"Server数据发送成功\"</span>);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        logger.debug(<span class=\"string\">\"Server数据发送失败\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<h4 id=\"Attribute\"><a href=\"#Attribute\" class=\"headerlink\" title=\"Attribute\"></a>Attribute</h4><p>Netty提供了<code>Attribute</code>类来实现属性绑定，使用<code>.childAttr()</code>方法在初始化阶段给每一个连上服务器的channel绑定属性：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">​</span><br></pre></td></tr></table></figure>\n<p>.childAttr(AttributeKey.newInstance(“clientKey”), “clientValue”)<br>​<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">```</span><br><span class=\"line\"></span><br><span class=\"line\">属性跟随Channel整个生命周期存在，除非手动删除；运行阶段也可以动态绑定，修改或者删除属性值：</span><br><span class=\"line\"></span><br><span class=\"line\">```java</span><br><span class=\"line\">// login</span><br><span class=\"line\">channel.attr(&quot;login&quot;).set(true);</span><br><span class=\"line\">//logout</span><br><span class=\"line\">channel.attr(&quot;login&quot;).set(false);</span><br><span class=\"line\">//check login status</span><br><span class=\"line\">Attribute&lt;Boolean&gt; loginAttr = channel.attr(&quot;login&quot;);</span><br><span class=\"line\">Boolean isLogin = loginAttr.get();</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"自定义协议\"><a href=\"#自定义协议\" class=\"headerlink\" title=\"自定义协议\"></a>自定义协议</h4><p>Netty的网络组件只负责连接层（tcp或者udp）的数据解析和交互，剩下的应用层协议都需要用户自己实现</p>\n<p>Netty已经提供了一些支持目前主流应用层协议的基础通信组件（http, websocket, mqtt, smtp, 还有redis协议等），除了这些开箱即用的应用层协议组件，大多数情况下都是基于Netty构建自定义协议来进行个性化开发</p>\n<h5 id=\"设计协议\"><a href=\"#设计协议\" class=\"headerlink\" title=\"设计协议\"></a>设计协议</h5><p>首先需要根据需要自己设计一个协议，便于解析二进制数据包满足业务需求，下面是一个经典的自定义二进制协议格式：</p>\n<p><img src=\"http://img.mantian.site/201908131121_32.png\" alt></p>\n<h5 id=\"确定序列化算法\"><a href=\"#确定序列化算法\" class=\"headerlink\" title=\"确定序列化算法\"></a>确定序列化算法</h5><p>读取或者写入数据使用的载体是<code>ByteBuf</code>，需要某种序列化算法（json， protobuf，thrift等）使得Java对象和<code>ByteBuf</code>互相转化</p>\n<h5 id=\"封装协议解析过程\"><a href=\"#封装协议解析过程\" class=\"headerlink\" title=\"封装协议解析过程\"></a>封装协议解析过程</h5><p>以下是一个简单的例子：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ProtocolCodeC</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> MAGIC_NUMBER = <span class=\"number\">0x12345678</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//对象编码，返回</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> ByteBuf <span class=\"title\">encode</span><span class=\"params\">(ByteBuf byteBuf, Packet packet)</span></span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//序列化java对象</span></span><br><span class=\"line\">        <span class=\"keyword\">byte</span>[] bytes = Serializer.DEFAULT.serialize(packet);</span><br><span class=\"line\">        <span class=\"comment\">//写入数据</span></span><br><span class=\"line\">        byteBuf.writeInt(MAGIC_NUMBER);</span><br><span class=\"line\">        byteBuf.writeByte(packet.getVersion());</span><br><span class=\"line\">        byteBuf.writeByte(Serializer.DEFAULT.getSerializerAlgorithm());</span><br><span class=\"line\">        byteBuf.writeByte(packet.getCommand());</span><br><span class=\"line\">        byteBuf.writeInt(bytes.length);</span><br><span class=\"line\">        byteBuf.writeBytes(bytes);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> byteBuf;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Packet <span class=\"title\">decode</span><span class=\"params\">(ByteBuf byteBuf)</span></span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 校验魔数</span></span><br><span class=\"line\">        byteBuf.skipBytes(<span class=\"number\">4</span>);</span><br><span class=\"line\">        <span class=\"comment\">// 校验版本</span></span><br><span class=\"line\">        byteBuf.skipBytes(<span class=\"number\">1</span>);</span><br><span class=\"line\">        <span class=\"comment\">// 解析序列化算法</span></span><br><span class=\"line\">        <span class=\"keyword\">byte</span> algorithmCode = byteBuf.readByte();</span><br><span class=\"line\">        <span class=\"comment\">// 解析指令</span></span><br><span class=\"line\">        <span class=\"keyword\">byte</span> command = byteBuf.readByte();</span><br><span class=\"line\">        <span class=\"comment\">// 解析消息长度</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> length = byteBuf.readInt();</span><br><span class=\"line\">        <span class=\"comment\">// 解析消息体</span></span><br><span class=\"line\">        <span class=\"keyword\">byte</span>[] data = <span class=\"keyword\">new</span> <span class=\"keyword\">byte</span>[length];</span><br><span class=\"line\">        byteBuf.readBytes(data);</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\">// 将消息体解析为具体的Java dto</span></span><br><span class=\"line\">        Class&lt;? extends Packet&gt; requireType = getRequireClass(command);</span><br><span class=\"line\">        Serializer serializer = getSerializer(algorithmCode);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(requireType != <span class=\"keyword\">null</span> &amp;&amp; serializer != <span class=\"keyword\">null</span>)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> serializer.deserialize(requireType, data);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"注册Netty编解码器\"><a href=\"#注册Netty编解码器\" class=\"headerlink\" title=\"注册Netty编解码器\"></a>注册Netty编解码器</h5><p>将自定义协议组件封装为Netty提供的编解码器：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PacketCodecHandler</span> <span class=\"keyword\">extends</span> <span class=\"title\">MessageToMessageCodec</span>&lt;<span class=\"title\">ByteBuf</span>, <span class=\"title\">Packet</span>&gt; </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> PacketCodecHandler INSTANCE = <span class=\"keyword\">new</span> PacketCodecHandler();</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"title\">PacketCodecHandler</span><span class=\"params\">()</span></span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">encode</span><span class=\"params\">(ChannelHandlerContext ctx, Packet msg, List&lt;Object&gt; out)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 将ByteBuf序列化为Java对象（由出站事件触发）</span></span><br><span class=\"line\">        ByteBuf byteBuf = ctx.alloc().ioBuffer();</span><br><span class=\"line\">        PacketCodeC.encode(byteBuf, msg);</span><br><span class=\"line\">        out.add(byteBuf);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">decode</span><span class=\"params\">(ChannelHandlerContext ctx, ByteBuf msg, List&lt;Object&gt; out)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 将Java对象反序列化为ByteBuf（由入站事件触发）</span></span><br><span class=\"line\">        Packet packet = PacketCodeC.decode(msg);</span><br><span class=\"line\">        out.add(packet);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>将编解码器注册到<code>ChannelPipeline</code>上，需要注意注册顺序：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nioSocketChannel.pipeline()</span><br><span class=\"line\">    .addLast(<span class=\"keyword\">new</span> PacketCodecHandler())</span><br><span class=\"line\">    .addLast(...业务逻辑handler......)</span><br></pre></td></tr></table></figure>\n<h4 id=\"粘包-拆包\"><a href=\"#粘包-拆包\" class=\"headerlink\" title=\"粘包/拆包\"></a>粘包/拆包</h4><p>TCP连接过程中，粘包和拆包是经常发生的现象</p>\n<blockquote>\n<p>拆包：由于TCP报文有长度限制，如果单体报文过长会拆包，将一个大包拆成几个小包，或者程序写入数据大小大于socket缓冲区，也会发生拆包</p>\n<p>粘包：要发送的数据小于TCP发送缓冲区的大小，网卡将多次写入缓冲区的数据一次发送出去，将会发生粘包，或者接收端没有按时读取socket缓冲区的数据，导致一次性读取多个包的数据，也会发生粘包</p>\n</blockquote>\n<p>如何解决这种粘包和拆包的情况？</p>\n<blockquote>\n<ol>\n<li>如果当前读取的数据不足以拼接成一个完整的业务数据包，那就保留该数据，继续从 TCP 缓冲区中读取，直到得到一个完整的数据包。</li>\n<li>如果当前读到的数据加上已经读取的数据足够拼接成一个数据包，那就将已经读取的数据拼接上本次读取的数据，构成一个完整的业务数据包传递到业务逻辑，多余的数据仍然保留，以便和下次读到的数据尝试拼接。</li>\n</ol>\n</blockquote>\n<p>通常判断完整数据包的方法通常有以下几种：</p>\n<blockquote>\n<ol>\n<li>使用带消息头的协议、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。</li>\n<li>设置定长消息，服务端每次读取既定长度的内容作为一条完整消息，当消息不够长时，空位补上固定字符。</li>\n<li>设置消息边界，服务端从网络流中读消息时通过’\\n’等特殊字符判断消息边界来拆分消息</li>\n</ol>\n</blockquote>\n<p>Netty对于粘包拆包的问题也提供了开箱即用的拆包合包器：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>. 固定长度的拆包器 FixedLengthFrameDecoder</span><br><span class=\"line\">最简单的拆包器，Netty会把一个个长度为 <span class=\"number\">100</span> 的数据包 (ByteBuf) 传递到下一个ChannelHandler</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"number\">2</span>. 行拆包器 LineBasedFrameDecoder</span><br><span class=\"line\">发送端发送数据包的时候，每个数据包之间以换行符作为分隔，接收端通过 LineBasedFrameDecoder 将粘过的 ByteBuf 拆分成一个个完整的应用层数据包</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"number\">3</span>. 分隔符拆包器 DelimiterBasedFrameDecoder</span><br><span class=\"line\">DelimiterBasedFrameDecoder是行拆包器的通用版本，可以自定义分隔符。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"number\">4</span>. 基于长度域拆包器 LengthFieldBasedFrameDecoder</span><br><span class=\"line\">只要自定义协议中包含长度域字段，均可以使用这个拆包器来实现应用层拆包</span><br></pre></td></tr></table></figure>\n<h3 id=\"Netty实战\"><a href=\"#Netty实战\" class=\"headerlink\" title=\"Netty实战\"></a>Netty实战</h3><h4 id=\"Netty进阶——开发Http-MVC框架\"><a href=\"#Netty进阶——开发Http-MVC框架\" class=\"headerlink\" title=\"Netty进阶——开发Http MVC框架\"></a>Netty进阶——开发Http MVC框架</h4><h4 id=\"Netty进阶——开发RPC框架\"><a href=\"#Netty进阶——开发RPC框架\" class=\"headerlink\" title=\"Netty进阶——开发RPC框架\"></a>Netty进阶——开发RPC框架</h4><h4 id=\"Netty进阶——开发IM系统\"><a href=\"#Netty进阶——开发IM系统\" class=\"headerlink\" title=\"Netty进阶——开发IM系统\"></a>Netty进阶——开发IM系统</h4>","site":{"data":{}},"excerpt":"<h3 id=\"Netty是什么\"><a href=\"#Netty是什么\" class=\"headerlink\" title=\"Netty是什么\"></a>Netty是什么</h3><p>Netty是一款用于快速开发高性能网络应用的Java框架，封装了网络编程的复杂性，使网络编程和web技术的最新进展能够比以往更广泛的让开发人员接触到。<br>","more":"</p>\n<h4 id=\"为什么要用Netty\"><a href=\"#为什么要用Netty\" class=\"headerlink\" title=\"为什么要用Netty\"></a>为什么要用Netty</h4><p>Netty是一个网络通信框架，目的就是屏蔽底层复杂的网络编程细节，提供更便捷的编程模型。</p>\n<h5 id=\"开箱即用的网络组件\"><a href=\"#开箱即用的网络组件\" class=\"headerlink\" title=\"开箱即用的网络组件\"></a>开箱即用的网络组件</h5><p>有了Netty，你可以实现自己的HTTP服务器，FTP服务器，UDP服务器，RPC服务器，WebSocket服务器，Redis的Proxy服务器，MySQL的Proxy服务器等等。</p>\n<p>反过来看看，不使用netty，直接基于BIO或者NIO编写网络程序，你需要做什么：</p>\n<ol>\n<li>创建一个ServerSocket，监听并绑定一个端口</li>\n<li>一系列客户端来请求这个端口</li>\n<li>服务器使用Accept，获得一个来自客户端的Socket连接对象</li>\n<li><p>启动一个新线程处理连接</p>\n<ul>\n<li><p>读Socket，得到字节流</p>\n</li>\n<li><p>解码协议，得到反序列化后的请求对象</p>\n</li>\n<li><p>处理请求对象，得到一个结果，封装成一个返回对象</p>\n</li>\n<li><p>编码协议，将结果序列化字节流</p>\n</li>\n<li><p>写Socket，将字节流发给客户端</p>\n</li>\n</ul>\n</li>\n<li>继续循环步骤3</li>\n</ol>\n<p>Netty并不需要你针对这些基础的IO过程编写大量的代码，已经封装好了成熟的IO库，开发人员只需要关注逻辑处理部分就可以。</p>\n<h5 id=\"高性能并发机制\"><a href=\"#高性能并发机制\" class=\"headerlink\" title=\"高性能并发机制\"></a>高性能并发机制</h5><p>对于高性能网络组件，还得关注它的并发性能，这就涉及到多线程并发编程，Netty提供了便捷的开箱即用多线程框架，保证了成熟的异步回调和事件驱动机制</p>\n<h5 id=\"高性能长连接支持\"><a href=\"#高性能长连接支持\" class=\"headerlink\" title=\"高性能长连接支持\"></a>高性能长连接支持</h5><p>因为TCP连接的特性，我们还要使用连接池来进行管理：</p>\n<ol>\n<li>对于频繁的TCP通讯，很多时候需要保持长连接，保持连接效果更好</li>\n<li>对于并发请求，可能需要建立多个连接</li>\n<li>维护多个连接后，每次通讯，需要选择某一可用连接</li>\n<li>连接超时和关闭机制</li>\n</ol>\n<p>Netty能够支持高性能长连接机制，因此在即时通讯和物联网等领域有很大的用武之地</p>\n<h5 id=\"众多开源项目鼎力支持\"><a href=\"#众多开源项目鼎力支持\" class=\"headerlink\" title=\"众多开源项目鼎力支持\"></a>众多开源项目鼎力支持</h5><p>一个优秀的开源项目离不开高质量的社区，Netty作为基础组件被众多开源项目和大型互联网企业采用，社区质量也是非常之高，如Apple，Twitter，Google和阿里等大型企业，还有Akka, Vert.x，Hadoop，ElasticSearch, Cassandra等优秀的开源项目，都在给Netty源源不断地贡献代码</p>\n<p><img src=\"http://img.mantian.site/images/1564638670965.png\" alt></p>\n<h3 id=\"Java-NIO\"><a href=\"#Java-NIO\" class=\"headerlink\" title=\"Java NIO\"></a>Java NIO</h3><p>介绍Netty基本特性之前，需要对NIO (non-blocking IO, 也叫做new IO)有一定的了解</p>\n<p>Java NIO最早于Jdk 1.4版本引入，跟传统IO（BIO，也叫NIO）相比，极大的缓解了线程池处理海量连接的瓶颈，提高了IO密集型应用的处理效率</p>\n<p>关于NIO的技术介绍可以看美团这篇文章：<a href=\"https://tech.meituan.com/2016/11/04/nio.html\" target=\"_blank\" rel=\"noopener\">Java NIO浅析</a>，更进一步可以看Doug Lea的这篇论文：<a href=\"http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf\" target=\"_blank\" rel=\"noopener\">Scalable IO in Java</a></p>\n<p>Netty对底层网络模型进行了一系列的封装和抽象，包括NIO和BIO，不过最常用的还是基于NIO的抽象，在Java NIO的<code>Selector</code>，<code>Channel</code>和<code>Buffer</code>基础上进行了丰富的抽象和封装，极大的简化了Java原生NIO组件复杂的编程模型，并在此基础上实现了reactor线程模型，能做到非常高效的并发处理</p>\n<p>以下是一个简单的NIO网络模型：</p>\n<p><img src=\"http://img.mantian.site/201908131112_661.png\" alt></p>\n<p>NIO网络模型最重要的组件就是<code>Selector</code>，底层基于操作系统的<code>epoll</code>或者<code>kqueue</code>等机制实现事件驱动式非阻塞IO操作，<code>Selector</code>在某些时候又称作<code>Reactor</code>（响应器，选择器，分派器……）</p>\n<p>在Netty中，<code>Selector</code>(或者<code>Reactor</code>) 称作<code>EventLoop</code>，在Netty中采用的是<code>单bossEventLoop+多workEventLoop</code>的模式，由<code>bossEventLoop</code>负责响应client的连接请求，并建立连接，由多个<code>workEventLoop</code>负责维护客户端socket的数据交互和读写工作，每个<code>EventLoop</code>都会在一个独立的线程中执行</p>\n<p><img src=\"http://img.mantian.site/201908131115_71.png\" alt></p>\n<h3 id=\"Netty核心特性浅析\"><a href=\"#Netty核心特性浅析\" class=\"headerlink\" title=\"Netty核心特性浅析\"></a>Netty核心特性浅析</h3><h4 id=\"Netty核心组件\"><a href=\"#Netty核心组件\" class=\"headerlink\" title=\"Netty核心组件\"></a>Netty核心组件</h4><p>摘自Netty官网的核心组件构成：</p>\n<p><img src=\"https://netty.io/images/components.png\" alt></p>\n<p>Netty核心功能由三部分组成：</p>\n<h5 id=\"Extensible-Event-Model\"><a href=\"#Extensible-Event-Model\" class=\"headerlink\" title=\"Extensible Event Model\"></a>Extensible Event Model</h5><p>在我看来，Netty之所以这么优秀，除了对NIO网络模型进行了很好的抽象封装，另外一点就是其提供的方便高效的事件驱动的设计思想</p>\n<h6 id=\"事件\"><a href=\"#事件\" class=\"headerlink\" title=\"事件\"></a>事件</h6><p>Netty使用不同的事件来通知我们状态的改变或是操作的状态，我们能基于已经发生的事件来触发适当的动作，在Netty中事件类型分为两大类：<code>入站事件</code>，<code>出站事件</code></p>\n<blockquote>\n<p>入站事件：<code>Socket连接激活或连接失活</code>，<code>数据读取</code>，<code>用户事件</code>，<code>错误事件（Exception）</code></p>\n<p>出站事件：<code>打开/关闭远程连接</code>，<code>写数据到Socket</code></p>\n</blockquote>\n<h6 id=\"Channel\"><a href=\"#Channel\" class=\"headerlink\" title=\"Channel\"></a>Channel</h6><p>事件的作用对象是<code>Channel</code>通道，<code>Channel</code>是Java NIO中表示连接的基本组件，代表到实体（硬件设备，文件描述符，socket网络套接字等）的开放连接，可以把它看作入站或出站的数据载体，对应<code>Channel</code>的事件就有读数据，写数据，开启或关闭等</p>\n<p>事件的发起者即为<code>EventLoop</code>选择器，当检测到某个<code>Channel</code>状态发生变化（数据可读，可写等），即产生一个事件，并触发一系列的回调</p>\n<p>Channel的生命周期：</p>\n<p><img src=\"http://img.mantian.site/201908131118_392.png\" alt></p>\n<p>每一个阶段都会产生相应的事件并触发对应的回调，并且在<code>ChannelActive</code>和<code>ChannelInactive</code>两个状态之间还会产生读写事件，用户事件和错误事件</p>\n<h6 id=\"ChannelHandler\"><a href=\"#ChannelHandler\" class=\"headerlink\" title=\"ChannelHandler\"></a>ChannelHandler</h6><p>既然定义了事件，那就得有相应的事件回调处理器，在Netty中所有回调处理器均实现<code>ChannelHandler</code>这个接口，根据入站或出站事件又分为<code>ChannelInboundHandler</code>和<code>ChannelOutboundHandler</code></p>\n<p><img src=\"http://img.mantian.site/201908131118_15.png\" alt></p>\n<p><code>ChannelHandler</code>由开发人员自己实现，开发人员可以根据不同的事件实现不同回调处理器的不同方法，例如某个handler需要捕获Channel激活的事件，可以像如下方式实现一个<code>ChannelInboundHandler</code>，服务端一旦检测到连接激活，则向客户端回复一条消息：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FirstServerHandler</span> <span class=\"keyword\">extends</span> <span class=\"title\">ChannelInboundHandlerAdapter</span></span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">channelActive</span><span class=\"params\">(ChannelHandlerContext ctx)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        ByteBuf buffer = ctx.alloc().buffer();</span><br><span class=\"line\">        <span class=\"keyword\">byte</span>[] bytes = <span class=\"string\">\"Connection successfully\"</span>.getBytes(Charset.forName(<span class=\"string\">\"UTF-8\"</span>));</span><br><span class=\"line\">        buffer.writeBytes(bytes);</span><br><span class=\"line\">        ctx.channel().writeAndFlush(buffer);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>一个<code>ChannelHandler</code>可以实现多个回调方法，一个入站handler可以同时订阅激活事件，读事件，用户自定义事件以及错误事件</p>\n<p><code>ChannelHandler</code>编写完后注册到<code>ChannelPipeline</code>上，至于如何注册handler回调处理器，将在后续的sample中展示</p>\n<h6 id=\"ChannelPipeline和ChannelHandlerContext\"><a href=\"#ChannelPipeline和ChannelHandlerContext\" class=\"headerlink\" title=\"ChannelPipeline和ChannelHandlerContext\"></a>ChannelPipeline和ChannelHandlerContext</h6><p><code>ChannelPipeline</code>是一个拦截流经<code>Channel</code>入站和出站事件的链条，所有<code>ChannelHandler</code>都需要挂载在<code>ChannelPipeline</code>上，每一个新创建的<code>Channel</code>都会分配一个新的<code>ChannelPipeline</code></p>\n<p><img src=\"http://img.mantian.site/201908131120_873.png\" alt></p>\n<p>上图是事件在每个<code>ChannelHandler</code>上的传播顺序</p>\n<p><code>ChannelHandlerContext</code>就是<code>ChannelHandler</code>和<code>ChannelPipeline</code>之间沟通的桥梁，每当一个新的<code>ChannelHandler</code>添加到pipeline中时，都会创建一个对应的<code>ChannelHandlerContext</code>，其主要功能时管理它所关联的<code>ChannelHandler</code>和在同一个pipeline中的其他<code>ChannelHandler</code>之间的数据交互</p>\n<p><img src=\"http://img.mantian.site/201908131120_370.png\" alt></p>\n<p>如上图：</p>\n<ol>\n<li>事件（入站或者出站）传给<code>ChannelPipeline</code>的第一个handler</li>\n<li>通过与这个handler关联的<code>ChannelHandlerContext</code>将事件传递给下一个handler</li>\n<li>同2</li>\n</ol>\n<h5 id=\"Zero-Copy-Capable-Rich-Byte-Buffer\"><a href=\"#Zero-Copy-Capable-Rich-Byte-Buffer\" class=\"headerlink\" title=\"Zero-Copy-Capable Rich Byte Buffer\"></a>Zero-Copy-Capable Rich Byte Buffer</h5><p>netty使用<code>ByteBuf</code>来取代jdk自带的<code>ByteBuffer</code>作为nio的数据传输载体，相比于jdk原生的ByteBuffer实现，功能更加丰富，灵活性更强，具有以下优点：</p>\n<ul>\n<li>扩展性好，用户可自定义所需要的缓冲区实现</li>\n<li>内置复合缓冲区实现了零拷贝功能</li>\n<li>容量按需增长</li>\n<li>读数据和写数据有独立的index，互相隔离，互不干扰</li>\n<li>支持引用计数和池化</li>\n</ul>\n<p>在netty中<code>ByteBuf</code>有三种实现：<code>heapBuffer</code>，<code>directBuffer</code>，<code>compositeBuffer</code>，通常情况下使用directBuffer：</p>\n<ul>\n<li>heapBuffer：即将数据存储通过java Byte数组的方式（称为支撑数组）存储在jvm heap中，使用以下方式快速创建一个heapBuffer，但java进行io读写时仍然需要将堆内内存的数据拷贝到堆外并传递给底层的C库:</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ByteBuf buffer = ByteBufAllocator.DEFAULT.heapBuffer();</span><br><span class=\"line\"><span class=\"comment\">// 可以直接将所需Byte数组拿出来</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (buffer.hasArray()) &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">byte</span>[] bufferArray = buffer.array();</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> offset = buffer.arrayOffset() + buffer.readerIndex();</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> length = buffer.readableBytes();</span><br><span class=\"line\">    <span class=\"comment\">// 通过读指针和可读长度获取所需的数据</span></span><br><span class=\"line\">\t<span class=\"keyword\">byte</span>[] neededData = Arrays.copyOfRange(bufferArray, offset, offset + length);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>directBuffer：使用堆外内存存储数据，直接使用堆外内存进行io操作，好处是比<code>heapBuffer</code>少一次内存拷贝且在io操作频繁的时候大大降低了gc压力，缺点是需要手动释放内存空间：</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ByteBuf buffer = ByteBufAllocator.DEFAULT.directBuffer();</span><br></pre></td></tr></table></figure>\n<p><code>directBuffer</code>没有支撑数组，因此不能直接提取Byte数组，需要通过读写指针取数据</p>\n<ul>\n<li>compositeBuffer：复合buffer，其中可同时包含堆内数据和堆外数据，其实现是<code>ByteBuf</code>的子类：<code>CompositeByteBuf</code>，通过以下方式组装一个复合buffer，访问复合buffer的方式也类似于<code>directBuffer</code>，不能直接访问其支撑数组：</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CompositeByteBuf compBuf = ByteBufAllocator.DEFAULT.compositeBuffer();</span><br><span class=\"line\">compBuf.addComponents(buffer, heapBuffer);</span><br></pre></td></tr></table></figure>\n<p>复合buffer广泛运用于需要组合多种不同数据源的buffer，在对不同数据源的数据进行整合后提供统一的ByteBuf API供用户使用</p>\n<p>Netty的零拷贝Buffer概念与操作系统层面的零拷贝不是一回事（Netty传输文件时已经通过Java NIO的DirectBuffer实现了基于DMA引擎的零拷贝），Netty的零拷贝描述的是组合buffer时不需要申请新的buffer内存，直接在原buffer的基础上通过<code>CompositeByteBuf</code>进行buffer的合并，而Java原生的ByteBuffer在这种情况下需要开辟新的buffer内存：</p>\n<p><img src=\"http://img.mantian.site/201908131119_969.png\" alt></p>\n<h5 id=\"Universal-Communication-API\"><a href=\"#Universal-Communication-API\" class=\"headerlink\" title=\"Universal Communication API\"></a>Universal Communication API</h5><p>统一的通讯API，Java原生的BIO和NIO使用了不同的API，而Netty则提供了统一的API(<code>org.jboss.netty.channel.Channel</code>)来封装这两种I/O模型。这部分代码在<code>org.jboss.netty.channel</code>包中</p>\n<p>在核心功能之上，Netty还提供了很多开箱即用的API，为用户的协议解析，tcp层面的粘包拆包以及文件编码和安全认证等基础需求提供了诸多需求</p>\n<h4 id=\"Netty运行架构\"><a href=\"#Netty运行架构\" class=\"headerlink\" title=\"Netty运行架构\"></a>Netty运行架构</h4><p>Netty整体运行架构如下：</p>\n<p><img src=\"http://img.mantian.site/201908131138_346.png\" alt></p>\n<h3 id=\"Netty基础使用-（sample）\"><a href=\"#Netty基础使用-（sample）\" class=\"headerlink\" title=\"Netty基础使用 （sample）\"></a>Netty基础使用 （sample）</h3><p>Netty目前最新版本是<code>4.1.38.Final</code>，下列分析基本上都是基于4.x版本 （开发中的5.x版本因为某些原因作废了）</p>\n<p>用Netty先实现一个最简单的tcp服务，发送一段简单的文本并获取相应</p>\n<h4 id=\"启动Server端\"><a href=\"#启动Server端\" class=\"headerlink\" title=\"启动Server端\"></a>启动Server端</h4><p>启动一个能够运行的Netty服务端进程，大致有以下几步：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>. 添加boss和work线程组</span><br><span class=\"line\"><span class=\"number\">2</span>. 指定io模型为nio方式</span><br><span class=\"line\"><span class=\"number\">3</span>. 指定server端启动时的初始化handler</span><br><span class=\"line\"><span class=\"number\">4</span>. 指定ChannelHandler，即具体的业务处理逻辑</span><br><span class=\"line\"><span class=\"number\">5</span>. 给NioServerSocketChannel指定attributes，后续可以通过channel.attr()取出这个属性</span><br><span class=\"line\"><span class=\"number\">6</span>. 给NioSocketChannel指定attributes</span><br><span class=\"line\"><span class=\"number\">7</span>. 给NioSocketChannel指定一些选项，比如是否开启TCP心跳机制或者Nagle算法等</span><br><span class=\"line\"><span class=\"number\">8</span>. 给NioServerSocketChannel指定一些选项，比如设置完成三次握手的请求的缓存队列大小<span class=\"number\">00</span></span><br></pre></td></tr></table></figure>\n<p>代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">serverBootstrap.group(bossGroup, workerGroup)</span><br><span class=\"line\">    .channel(NioServerSocketChannel.class)</span><br><span class=\"line\">    .handler(<span class=\"keyword\">new</span> ChannelInitializer&lt;NioServerSocketChannel&gt;() &#123;</span><br><span class=\"line\">        <span class=\"meta\">@Override</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">initChannel</span><span class=\"params\">(NioServerSocketChannel channel)</span></span>&#123;</span><br><span class=\"line\">            logger.debug(<span class=\"string\">\"服务端启动中...\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">    .childHandler(<span class=\"keyword\">new</span> ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">initChannel</span><span class=\"params\">(NioSocketChannel nioSocketChannel)</span></span>&#123;</span><br><span class=\"line\">            <span class=\"comment\">//（责任链模式）pipeline添加逻辑处理器，当接收到客户端数据时按顺序执行回调</span></span><br><span class=\"line\">            nioSocketChannel.pipeline()</span><br><span class=\"line\">                .addLast();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">    .attr(AttributeKey.newInstance(<span class=\"string\">\"serverName\"</span>), <span class=\"string\">\"nettyServer\"</span>)</span><br><span class=\"line\">    .childAttr(AttributeKey.newInstance(<span class=\"string\">\"clientKey\"</span>), <span class=\"string\">\"clientValue\"</span>)</span><br><span class=\"line\">    .childOption(ChannelOption.SO_KEEPALIVE, <span class=\"keyword\">true</span>)</span><br><span class=\"line\">    .childOption(ChannelOption.TCP_NODELAY, <span class=\"keyword\">true</span>)</span><br><span class=\"line\">    .option(ChannelOption.SO_BACKLOG, <span class=\"number\">1024</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//绑定端口是一个异步过程，设置回调方法查看是否绑定成功</span></span><br><span class=\"line\"><span class=\"comment\">//默认绑定的ip地址是0.0.0.0</span></span><br><span class=\"line\">serverBootstrap.bind(<span class=\"number\">8000</span>).addListener(future -&gt; &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(future.isSuccess())&#123;</span><br><span class=\"line\">        logger.debug(<span class=\"string\">\"8000端口绑定成功！\"</span>);</span><br><span class=\"line\">    &#125;<span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        logger.debug(<span class=\"string\">\"8000端口绑定失败！\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>如上，<code>childHandler()</code>方法用于在建立连接的channel上绑定handler，一旦有事件触发， 事件会沿着添加的顺序进行传播，现在把<code>FirstServerHandler</code>这个handler绑定上:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">.addLast(<span class=\"keyword\">new</span> FirstServerHandler());</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>每一个成功建立连接的channel都会绑定一个<code>FirstServerHandler</code>，一旦channel激活，就会触发<code>channelActive</code>这个方法</p>\n<h4 id=\"启动client端\"><a href=\"#启动client端\" class=\"headerlink\" title=\"启动client端\"></a>启动client端</h4><p>启动一个Netty client，大致需要以下几步：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>. 添加work线程组</span><br><span class=\"line\"><span class=\"number\">2</span>. 指定io模型为nio方式</span><br><span class=\"line\"><span class=\"number\">3</span>. 指定ChannelHandler，即具体的业务处理逻辑</span><br><span class=\"line\"><span class=\"number\">4</span>. 给NioSocketChannel添加attributes</span><br><span class=\"line\"><span class=\"number\">5</span>. 给NioSocketChannel指定一些选项，比如是否开启心跳以及设置连接超时时间，以及Nagle算法</span><br></pre></td></tr></table></figure>\n<p>代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bootstrap.group(workerGroup)</span><br><span class=\"line\">\t.channel(NioSocketChannel.class)</span><br><span class=\"line\">\t.handler(<span class=\"keyword\">new</span> ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class=\"line\">\t\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t\t<span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">initChannel</span><span class=\"params\">(NioSocketChannel nioSocketChannel)</span> </span>&#123;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">//添加ClientHandler，连接上处理和服务器端的数据交互</span></span><br><span class=\"line\">\t\t\tnioSocketChannel.pipeline().addLast(<span class=\"keyword\">new</span> FirstClientHandler());</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;).attr(AttributeKey.newInstance(<span class=\"string\">\"attrName\"</span>), <span class=\"string\">\"attrValue\"</span>)</span><br><span class=\"line\">\t.option(ChannelOption.SO_KEEPALIVE, <span class=\"keyword\">true</span>)</span><br><span class=\"line\">\t.option(ChannelOption.TCP_NODELAY, <span class=\"keyword\">true</span>)</span><br><span class=\"line\">\t.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, <span class=\"number\">5000</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">bootstrap.connect(<span class=\"string\">\"127.0.0.1\"</span>, <span class=\"number\">8000</span>).addListener(future -&gt; &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (future.isSuccess())&#123;</span><br><span class=\"line\">\t\tlogger.debug(<span class=\"string\">\"连接建立成功！\"</span>);</span><br><span class=\"line\">\t\tChannel channel = ((ChannelFuture) future).channel();</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\tlogger.error(<span class=\"string\">\"连接建立失败！\"</span>);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>client端实现一个<code>FirstClientHandler</code>来读取服务器发过来的信息：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FirstClientHandler</span> <span class=\"keyword\">extends</span> <span class=\"title\">ChannelInboundHandlerAdapter</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Logger logger = LoggerFactory.getLogger(FirstClientHandler.class);</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">channelRead</span><span class=\"params\">(ChannelHandlerContext ctx, Object msg)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\t\tByteBuf buffer = (ByteBuf) msg;</span><br><span class=\"line\">\t\tlogger.debug(<span class=\"string\">\"客户端读到数据：\"</span> + buffer.toString(Charset.forName(<span class=\"string\">\"UTF-8\"</span>)));</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>以上就是一个最简单的Netty Server-Client demo</p>\n<h3 id=\"Tips\"><a href=\"#Tips\" class=\"headerlink\" title=\"Tips\"></a>Tips</h3><p>使用Netty的过程中的一些知识点，小技巧和需要注意的地方</p>\n<h4 id=\"调用ByteBuf-release-手动释放内存\"><a href=\"#调用ByteBuf-release-手动释放内存\" class=\"headerlink\" title=\"调用ByteBuf.release()手动释放内存\"></a>调用ByteBuf.release()手动释放内存</h4><p>由于netty默认使用的<code>ByteBuf</code>是<code>directBuffer</code>，不受gc影响，因此需要手动释放内存</p>\n<blockquote>\n<p>对于入站消息，如果不调用<code>ctx.fireChannelRead(msg)</code>把消息往下传，则需要原地将消息释放<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">channelRead</span><span class=\"params\">(ChannelHandlerContext ctx, Object msg)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">    ByteBuf buffer = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        buffer = (ByteBuf) msg;</span><br><span class=\"line\">        logger.debug(<span class=\"string\">\"服务器端读到数据：\"</span> + buffer.toString(Charset.forName(<span class=\"string\">\"UTF-8\"</span>)));</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        buffer.release();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n</blockquote>\n<blockquote>\n<p>出站消息无需手动释放，netty最终会将其释放</p>\n</blockquote>\n<p>netty提供了内存泄漏检测机制，日志中出现的<code>LEAK</code>字样需要格外引起注意</p>\n<h4 id=\"异步Future\"><a href=\"#异步Future\" class=\"headerlink\" title=\"异步Future\"></a>异步Future</h4><p>Netty中，进行IO操作如向channel写数据是异步操作，Netty提供了<code>ChannelFuture</code>，以异步的方式向channel写数据，保证不阻塞EventLoop线程，可以通过添加listenner获取异步发送的结果：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ctx.channel().writeAndFlush(buffer).addListener(future -&gt; &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (future.isSuccess())&#123;</span><br><span class=\"line\">        logger.debug(<span class=\"string\">\"Server数据发送成功\"</span>);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        logger.debug(<span class=\"string\">\"Server数据发送失败\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<h4 id=\"Attribute\"><a href=\"#Attribute\" class=\"headerlink\" title=\"Attribute\"></a>Attribute</h4><p>Netty提供了<code>Attribute</code>类来实现属性绑定，使用<code>.childAttr()</code>方法在初始化阶段给每一个连上服务器的channel绑定属性：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">​</span><br></pre></td></tr></table></figure>\n<p>.childAttr(AttributeKey.newInstance(“clientKey”), “clientValue”)<br>​<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">```</span><br><span class=\"line\"></span><br><span class=\"line\">属性跟随Channel整个生命周期存在，除非手动删除；运行阶段也可以动态绑定，修改或者删除属性值：</span><br><span class=\"line\"></span><br><span class=\"line\">```java</span><br><span class=\"line\">// login</span><br><span class=\"line\">channel.attr(&quot;login&quot;).set(true);</span><br><span class=\"line\">//logout</span><br><span class=\"line\">channel.attr(&quot;login&quot;).set(false);</span><br><span class=\"line\">//check login status</span><br><span class=\"line\">Attribute&lt;Boolean&gt; loginAttr = channel.attr(&quot;login&quot;);</span><br><span class=\"line\">Boolean isLogin = loginAttr.get();</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"自定义协议\"><a href=\"#自定义协议\" class=\"headerlink\" title=\"自定义协议\"></a>自定义协议</h4><p>Netty的网络组件只负责连接层（tcp或者udp）的数据解析和交互，剩下的应用层协议都需要用户自己实现</p>\n<p>Netty已经提供了一些支持目前主流应用层协议的基础通信组件（http, websocket, mqtt, smtp, 还有redis协议等），除了这些开箱即用的应用层协议组件，大多数情况下都是基于Netty构建自定义协议来进行个性化开发</p>\n<h5 id=\"设计协议\"><a href=\"#设计协议\" class=\"headerlink\" title=\"设计协议\"></a>设计协议</h5><p>首先需要根据需要自己设计一个协议，便于解析二进制数据包满足业务需求，下面是一个经典的自定义二进制协议格式：</p>\n<p><img src=\"http://img.mantian.site/201908131121_32.png\" alt></p>\n<h5 id=\"确定序列化算法\"><a href=\"#确定序列化算法\" class=\"headerlink\" title=\"确定序列化算法\"></a>确定序列化算法</h5><p>读取或者写入数据使用的载体是<code>ByteBuf</code>，需要某种序列化算法（json， protobuf，thrift等）使得Java对象和<code>ByteBuf</code>互相转化</p>\n<h5 id=\"封装协议解析过程\"><a href=\"#封装协议解析过程\" class=\"headerlink\" title=\"封装协议解析过程\"></a>封装协议解析过程</h5><p>以下是一个简单的例子：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ProtocolCodeC</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> MAGIC_NUMBER = <span class=\"number\">0x12345678</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//对象编码，返回</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> ByteBuf <span class=\"title\">encode</span><span class=\"params\">(ByteBuf byteBuf, Packet packet)</span></span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//序列化java对象</span></span><br><span class=\"line\">        <span class=\"keyword\">byte</span>[] bytes = Serializer.DEFAULT.serialize(packet);</span><br><span class=\"line\">        <span class=\"comment\">//写入数据</span></span><br><span class=\"line\">        byteBuf.writeInt(MAGIC_NUMBER);</span><br><span class=\"line\">        byteBuf.writeByte(packet.getVersion());</span><br><span class=\"line\">        byteBuf.writeByte(Serializer.DEFAULT.getSerializerAlgorithm());</span><br><span class=\"line\">        byteBuf.writeByte(packet.getCommand());</span><br><span class=\"line\">        byteBuf.writeInt(bytes.length);</span><br><span class=\"line\">        byteBuf.writeBytes(bytes);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> byteBuf;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Packet <span class=\"title\">decode</span><span class=\"params\">(ByteBuf byteBuf)</span></span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 校验魔数</span></span><br><span class=\"line\">        byteBuf.skipBytes(<span class=\"number\">4</span>);</span><br><span class=\"line\">        <span class=\"comment\">// 校验版本</span></span><br><span class=\"line\">        byteBuf.skipBytes(<span class=\"number\">1</span>);</span><br><span class=\"line\">        <span class=\"comment\">// 解析序列化算法</span></span><br><span class=\"line\">        <span class=\"keyword\">byte</span> algorithmCode = byteBuf.readByte();</span><br><span class=\"line\">        <span class=\"comment\">// 解析指令</span></span><br><span class=\"line\">        <span class=\"keyword\">byte</span> command = byteBuf.readByte();</span><br><span class=\"line\">        <span class=\"comment\">// 解析消息长度</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> length = byteBuf.readInt();</span><br><span class=\"line\">        <span class=\"comment\">// 解析消息体</span></span><br><span class=\"line\">        <span class=\"keyword\">byte</span>[] data = <span class=\"keyword\">new</span> <span class=\"keyword\">byte</span>[length];</span><br><span class=\"line\">        byteBuf.readBytes(data);</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\">// 将消息体解析为具体的Java dto</span></span><br><span class=\"line\">        Class&lt;? extends Packet&gt; requireType = getRequireClass(command);</span><br><span class=\"line\">        Serializer serializer = getSerializer(algorithmCode);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(requireType != <span class=\"keyword\">null</span> &amp;&amp; serializer != <span class=\"keyword\">null</span>)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> serializer.deserialize(requireType, data);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"注册Netty编解码器\"><a href=\"#注册Netty编解码器\" class=\"headerlink\" title=\"注册Netty编解码器\"></a>注册Netty编解码器</h5><p>将自定义协议组件封装为Netty提供的编解码器：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PacketCodecHandler</span> <span class=\"keyword\">extends</span> <span class=\"title\">MessageToMessageCodec</span>&lt;<span class=\"title\">ByteBuf</span>, <span class=\"title\">Packet</span>&gt; </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> PacketCodecHandler INSTANCE = <span class=\"keyword\">new</span> PacketCodecHandler();</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"title\">PacketCodecHandler</span><span class=\"params\">()</span></span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">encode</span><span class=\"params\">(ChannelHandlerContext ctx, Packet msg, List&lt;Object&gt; out)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 将ByteBuf序列化为Java对象（由出站事件触发）</span></span><br><span class=\"line\">        ByteBuf byteBuf = ctx.alloc().ioBuffer();</span><br><span class=\"line\">        PacketCodeC.encode(byteBuf, msg);</span><br><span class=\"line\">        out.add(byteBuf);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">decode</span><span class=\"params\">(ChannelHandlerContext ctx, ByteBuf msg, List&lt;Object&gt; out)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 将Java对象反序列化为ByteBuf（由入站事件触发）</span></span><br><span class=\"line\">        Packet packet = PacketCodeC.decode(msg);</span><br><span class=\"line\">        out.add(packet);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>将编解码器注册到<code>ChannelPipeline</code>上，需要注意注册顺序：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nioSocketChannel.pipeline()</span><br><span class=\"line\">    .addLast(<span class=\"keyword\">new</span> PacketCodecHandler())</span><br><span class=\"line\">    .addLast(...业务逻辑handler......)</span><br></pre></td></tr></table></figure>\n<h4 id=\"粘包-拆包\"><a href=\"#粘包-拆包\" class=\"headerlink\" title=\"粘包/拆包\"></a>粘包/拆包</h4><p>TCP连接过程中，粘包和拆包是经常发生的现象</p>\n<blockquote>\n<p>拆包：由于TCP报文有长度限制，如果单体报文过长会拆包，将一个大包拆成几个小包，或者程序写入数据大小大于socket缓冲区，也会发生拆包</p>\n<p>粘包：要发送的数据小于TCP发送缓冲区的大小，网卡将多次写入缓冲区的数据一次发送出去，将会发生粘包，或者接收端没有按时读取socket缓冲区的数据，导致一次性读取多个包的数据，也会发生粘包</p>\n</blockquote>\n<p>如何解决这种粘包和拆包的情况？</p>\n<blockquote>\n<ol>\n<li>如果当前读取的数据不足以拼接成一个完整的业务数据包，那就保留该数据，继续从 TCP 缓冲区中读取，直到得到一个完整的数据包。</li>\n<li>如果当前读到的数据加上已经读取的数据足够拼接成一个数据包，那就将已经读取的数据拼接上本次读取的数据，构成一个完整的业务数据包传递到业务逻辑，多余的数据仍然保留，以便和下次读到的数据尝试拼接。</li>\n</ol>\n</blockquote>\n<p>通常判断完整数据包的方法通常有以下几种：</p>\n<blockquote>\n<ol>\n<li>使用带消息头的协议、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。</li>\n<li>设置定长消息，服务端每次读取既定长度的内容作为一条完整消息，当消息不够长时，空位补上固定字符。</li>\n<li>设置消息边界，服务端从网络流中读消息时通过’\\n’等特殊字符判断消息边界来拆分消息</li>\n</ol>\n</blockquote>\n<p>Netty对于粘包拆包的问题也提供了开箱即用的拆包合包器：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>. 固定长度的拆包器 FixedLengthFrameDecoder</span><br><span class=\"line\">最简单的拆包器，Netty会把一个个长度为 <span class=\"number\">100</span> 的数据包 (ByteBuf) 传递到下一个ChannelHandler</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"number\">2</span>. 行拆包器 LineBasedFrameDecoder</span><br><span class=\"line\">发送端发送数据包的时候，每个数据包之间以换行符作为分隔，接收端通过 LineBasedFrameDecoder 将粘过的 ByteBuf 拆分成一个个完整的应用层数据包</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"number\">3</span>. 分隔符拆包器 DelimiterBasedFrameDecoder</span><br><span class=\"line\">DelimiterBasedFrameDecoder是行拆包器的通用版本，可以自定义分隔符。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"number\">4</span>. 基于长度域拆包器 LengthFieldBasedFrameDecoder</span><br><span class=\"line\">只要自定义协议中包含长度域字段，均可以使用这个拆包器来实现应用层拆包</span><br></pre></td></tr></table></figure>\n<h3 id=\"Netty实战\"><a href=\"#Netty实战\" class=\"headerlink\" title=\"Netty实战\"></a>Netty实战</h3><h4 id=\"Netty进阶——开发Http-MVC框架\"><a href=\"#Netty进阶——开发Http-MVC框架\" class=\"headerlink\" title=\"Netty进阶——开发Http MVC框架\"></a>Netty进阶——开发Http MVC框架</h4><h4 id=\"Netty进阶——开发RPC框架\"><a href=\"#Netty进阶——开发RPC框架\" class=\"headerlink\" title=\"Netty进阶——开发RPC框架\"></a>Netty进阶——开发RPC框架</h4><h4 id=\"Netty进阶——开发IM系统\"><a href=\"#Netty进阶——开发IM系统\" class=\"headerlink\" title=\"Netty进阶——开发IM系统\"></a>Netty进阶——开发IM系统</h4>"},{"title":"Apahce Nifi学习 —— 何为Nifi?","author":"天渊","date":"2019-07-29T13:49:00.000Z","_content":"Apache Nifi 是一个开源的分布式系统数据流自动化管理工具，官网：[https://nifi.apache.org](https://nifi.apache.org/)\n\nNifi全称是`Niagarafiles`，尼亚加拉files，从名字可以看出这个工具就是用于对付像尼亚加拉瀑布一样的大型数据流\n<!--more-->\n\n#### 为何要有Nifi ？\n\n随着大数据生态的发展和物流网技术的兴起，企业越发重视对系统间数据流交互的可靠性以及稳定性的管理，但系统之间的数据流管理存在以下几个挑战：\n\n1. **系统故障**：网络故障，磁盘故障，软件崩溃，或者人为犯错\n2. **下游系统数据处理瓶颈**：下游系统都有数据处理上限，上游输入的数据量不能超过下游系统处理上限\n3. **异常数据**：数据流中的异常数据是不可避免的（太大，太快，损坏的，错误的数据）\n4. **业务系统升级改造**：业务系统升级，数据类型变更，需要做出快速响应\n5. **系统升级引起的兼容问题**：多系统之间升级不同步引起数据兼容问题，此时如果系统之间耦合性太高的话会导致整个系统不可用\n6. 其他诸如对外界环境变动的响应（法律法规变更，规章制度变更等）和生产环境平滑升级等问题\n\n为了解决以上问题，Nifi应运而生。总的来说，需要Nifi这么一种自动化管理工具来为大型分布式系统提供数据流可靠性管理，数据清洗和过滤，数据流背压控制，或者系统数据接口解耦等功能\n\n#### Nifi的特点\n\n- **基于web的UI**：完全可视化设计，控制和监控\n- **高性能**\n  - 数据丢失容错vs保证交付\n  - 低延迟和高吞吐量\n  - 动态优先级\n  - 流可以在运行时修改\n  - 背压(Back pressure)\n- **数据流跟踪**\n  - 从始至终的数据流追踪机制\n- **高可扩展性**\n  - 定制化Processor\n  - 支持快速开发和有效测试\n- **安全**\n  - 支持SSL,SSH,HTTPS加密等\n  - 多租户授权和内部授权/策略管理\n\n#### Nifi的核心概念\n\n| 术语               | 对应Flow Based Programming的术语 | 描述                                                         |\n| ------------------ | -------------------------------- | ------------------------------------------------------------ |\n| FlowFile           | Information Packet               | Nifi中的基本数据流对象，通过`attribute`来标记各个数据流对象的状态 |\n| FlowFile Processor | Black Box                        | 负责数据流的清洗，过滤，提取和切割等操作，还可以实现数据路由的合并，变换，及系统间的各种协调 |\n| Connection         | Bounded Buffer                   | 连接器为各个处理器提供连通管道，以队列的形式提供优先级设置（先进先出等，优先队列等），还提供背压设置和数据负载均衡设置 |\n| Flow Controller    | Scheduler                        | 流控制器维护处理器之间的连接关系，管理和分配所有处理器使用的线程 |\n| Process Group      | subnet                           | 处理器组，一系列Processor和Connection的集合，通过输入端口（input）接收数据，通过输出端口（output）发送数据 |\n\n以国外某个博主画的图为例（[源地址](https://www.freecodecamp.org/news/nifi-surf-on-your-dataflow-4f3343c50aa2/)）：\n\n![1563333234565](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563333234565.png)\n\n\n\n#### Nifi的架构\n\n##### 单机架构\n\nNifi运行在Jvm中，由`Web Server`，`Flow Controller`，`FlowFile Repository` ，`Content Repository`，`Provenance Repository`等组件组成：\n\n![NiFi Architecture Diagram](https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-node.png)\n\n##### 集群架构\n\nNifi也支持集群架构模式，多节点共同协调处理，每个节点处理逻辑相同，不过各节点分配了不同的数据集。集群中由zookeeper选举出一个`Cluster Coordinator`集群节点协调者，用户在web ui上对Nifi组件的所有改动都由`Cluster Coordinator`通知给所有节点\n\n另外集群中存在一个`Primary Node`主节点，也由zookeeper选举得到，主要用途是提供`Isolated Processor`的配置，在主节点中定义的`Isolated Processor`只在这个主节点上工作，其他节点没有这个Processor。适用场景是提供一个统一的外部数据拉取的接口，然后再通过一些分派机制（loadBalance等）将数据统一分派给剩余节点进行处理，避免多节点同时拉取外部数据发生数据竞争而产生不可预测的后果\n\n![NiFi Cluster Architecture Diagram](https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-cluster.png)\n\n\n\n#### Nifi的基本用法（一个简单的例子）\n\nNifi提供了几十种Processer，用不同的处理逻辑处理不同场景不同格式的数据，具体提供的组件可以参考文档：<https://nifi.apache.org/docs/nifi-docs/>\n\n在这里仅以我做过的一个实际项目为例来进行说明\n\n##### 准备Nifi环境\n\n安装过程就不再赘述了，安装完成后访问任何一个节点的8080端口都能打开web ui，Nifi后续所有操作都在web ui上进行：`http://anynode:8080/nifi/`\n\n进入web ui，长这样，目前已经创建了多个Processor Group：\n\n![1563333859182](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563333859182.png)\n\n##### 创建Processor Group\n\nProcessor Group可以将一系列独立的数据处理逻辑封装在一起，与其他Group进行隔离\n\n将上方的图标拖动到下方界面进行创建\n\n![1563334045695](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563334045695.png)\n\n创建完成后，Group的界面能够显示当前状态，打开关闭情况，输入输出情况和队列缓存情况，双击进入Group面板\n\n##### 创建Processor —— kafka consumer\n\nProcessor是数据流处理的核心控件，可以接收输入，进行路由中转并发送给外部数据源，现在以一个Kafka Consumer Processor为例来进行说明，拖动上方Processor图标到面板中进行创建：\n\n![1563334687067](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563334687067.png)\n\n我们选用`ConsumerKafka_0_11`用来消费外部kafka集群中的数据，采用kafka 0.11版本的Consumer Api实现：\n\n![1563334861136](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563334861136.png)\n\nConsumerKafka_0_11这个Processor支持从kafka消费数据作为输入流，将数据封装为FlowFile进行后续的处理：\n\n![1563342367031](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563342367031.png)\n\n双击Processor面板进行配置，设置面板一共包含四个tab，第一个tab用于一些基本设置：\n\n###### 基础settings\n\n![1563343520868](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563343520868.png)\n\n需要重点关注`Automatically Terminate Relationships`，Relationship表示该Processor对应的输出（即Connection），如果某个Relationship未被勾选，表示无法自动处理，需要用户手动指定Connection指向下游的其他Processor；如果被勾选，那么这个Relationship是可以自动终结的，无需用户指定，Nifi就帮你处理了\n\n###### scheduling配置\n\n第二个tab为scheduling配置，用来指定Processor处理数据的周期和触发处理的规则，默认是基于时间周期性调度，也可以指定Cron表达式进行固定时间的调度：\n\n![1563343869114](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563343869114.png)\n\n###### properties配置\n\n配置Processor的属性，每个Processor都有自己独有的属性设置，并且还可以自己指定attribute用于后续的处理，\n\n![1563343926871](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563343926871.png)\n\n这里面做了一些基本配置，包括kafka集群地址，订阅的topic，group-id等\n\n最后一个comments tab作为备注使用\n\n##### 创建下游Processor ——  EvaluateJsonPath\n\n上游kafka consumer processor获取数据后封装为FlowFile发往下游进行处理，我这里使用的数据结构是json，因此下游处理器采用EvaluateJsonPath解析json数据，将其中的一些值提取出来包装为attribute再发往下游：\n\n![1563344614818](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563344614818.png)\n\nNifi专门提供了JsonPath方式抽取Json数据\n\n两个Processor创建完成后，需要一个Connection将他们连接起来，直接点击ConsumerKafka_0_11上面的箭头并拉到EvaluateJsonPath上就可以进行两个Processor之间的Connection的配置：\n\n![1563344757201](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563344757201.png)\n\n指定Relationships，表示`ConsumerKafka_0_11成功获取到Kafka数据后，将FlowFile发送给下游的EvaluateJsonPath去处理`：\n\n![1563344893717](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563344893717.png)\n\n##### 创建下游Processor —— RouteOnAttribute\n\n提取了Json数据，我们想根据提取出来的数据进行路由，这时候就需要RouteOnAttribute这个Processor：\n\n![1563345038335](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563345038335.png)\n\nNifi提供了Expression Language表达式来进行一些简单的编程操作\n\n使用之前抽取的json字段action作为路由依据，以“create”开头的action则返回true，否则返回false\n\n然后创建EvaluateJsonPath到RouteOnAttribute之间的Connection\n\n##### 创建下游Processor —— InvokeHttp\n\n配置好路由后，我们想将带“create”开头action的数据发送给http接口A，将不带“create”的数据发送给http接口B，那么就得创建两个InvokeHttp，进行一些基本配置包括method和url：\n\n![1563345522963](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563345522963.png)\n\n然后从RouteOnAttribute创建两个连接到这两个InvokeHttp处理器，两个连接分别是isCreation和unmatched（即当前数据不带“create”）：\n\n最终我们的数据处理流构建完成了，这也是一个有向无环图，此时每个Processor都处于停止状态（只有停止状态才能修改配置）：\n\n![1563345754157](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563345754157.png)\n\n##### 启动Processor Group\n\n返回Processor Group处理界面，直接启动整个Group （当然也可以每个Processor分别启动）\n\n![1563346961196](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563346961196.png)\n\n可以看到，整个处理流在5分钟内接收了三条数据，其中2条数据匹配了\"isCreation\"，发往了第一个接口A，其余两条数据发往了接口B，实现了自定义数据路由\n\n##### 调节背压管路\n\n如果某个Processor处理能力有限，就会造成上游数据积压。Nifi的Connection组件提供了一个队列用以缓冲下游暂时处理不了的数据，默认是10000条数据或者1GB size， 并且可以指定过期时间\n\n关闭ConsumerKafka和EvalueteJsonPath这两个Processor，双击\"success\"这个Connection进行配置：\n\n![1563347524271](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563347524271.png)\n\n#### 查看Nifi日志\n\nNifi日志大体上分为**数据日志（Data Provenance）**和**事件日志（Bulletin）**，点击web ui右上角即可查看这两种日志：\n\n![1563347976805](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563347976805.png)\n\n\n\n##### Data Provenance\n\nNifi为每一条进入数据处理流的FlowFile都生成了一个唯一的uuid，可以查看每一条数据在各个节点处理的时间，处理类型（SEND，ROUTE，RECEIVE等），数据大小，以及处理的服务器节点，：\n\n![1563348137310](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563348137310.png)\n\n##### Bulletin\n\n事件日志用于记录Nifi处理器处理数据遇到的一些问题，默认级别是WARN，在这里可以看到数据处理失败的一些信息以及对应的数据uuid和响应的Processer，便于结合`Data Provenance`跟踪追溯：\n\n![1563348249531](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563348249531.png)","source":"_posts/Apahce-Nifi学习-——-何为Nifi.md","raw":"title: Apahce Nifi学习 —— 何为Nifi?\nauthor: 天渊\ntags:\n  - nifi\ncategories:\n  - 大数据\ndate: 2019-07-29 21:49:00\n---\nApache Nifi 是一个开源的分布式系统数据流自动化管理工具，官网：[https://nifi.apache.org](https://nifi.apache.org/)\n\nNifi全称是`Niagarafiles`，尼亚加拉files，从名字可以看出这个工具就是用于对付像尼亚加拉瀑布一样的大型数据流\n<!--more-->\n\n#### 为何要有Nifi ？\n\n随着大数据生态的发展和物流网技术的兴起，企业越发重视对系统间数据流交互的可靠性以及稳定性的管理，但系统之间的数据流管理存在以下几个挑战：\n\n1. **系统故障**：网络故障，磁盘故障，软件崩溃，或者人为犯错\n2. **下游系统数据处理瓶颈**：下游系统都有数据处理上限，上游输入的数据量不能超过下游系统处理上限\n3. **异常数据**：数据流中的异常数据是不可避免的（太大，太快，损坏的，错误的数据）\n4. **业务系统升级改造**：业务系统升级，数据类型变更，需要做出快速响应\n5. **系统升级引起的兼容问题**：多系统之间升级不同步引起数据兼容问题，此时如果系统之间耦合性太高的话会导致整个系统不可用\n6. 其他诸如对外界环境变动的响应（法律法规变更，规章制度变更等）和生产环境平滑升级等问题\n\n为了解决以上问题，Nifi应运而生。总的来说，需要Nifi这么一种自动化管理工具来为大型分布式系统提供数据流可靠性管理，数据清洗和过滤，数据流背压控制，或者系统数据接口解耦等功能\n\n#### Nifi的特点\n\n- **基于web的UI**：完全可视化设计，控制和监控\n- **高性能**\n  - 数据丢失容错vs保证交付\n  - 低延迟和高吞吐量\n  - 动态优先级\n  - 流可以在运行时修改\n  - 背压(Back pressure)\n- **数据流跟踪**\n  - 从始至终的数据流追踪机制\n- **高可扩展性**\n  - 定制化Processor\n  - 支持快速开发和有效测试\n- **安全**\n  - 支持SSL,SSH,HTTPS加密等\n  - 多租户授权和内部授权/策略管理\n\n#### Nifi的核心概念\n\n| 术语               | 对应Flow Based Programming的术语 | 描述                                                         |\n| ------------------ | -------------------------------- | ------------------------------------------------------------ |\n| FlowFile           | Information Packet               | Nifi中的基本数据流对象，通过`attribute`来标记各个数据流对象的状态 |\n| FlowFile Processor | Black Box                        | 负责数据流的清洗，过滤，提取和切割等操作，还可以实现数据路由的合并，变换，及系统间的各种协调 |\n| Connection         | Bounded Buffer                   | 连接器为各个处理器提供连通管道，以队列的形式提供优先级设置（先进先出等，优先队列等），还提供背压设置和数据负载均衡设置 |\n| Flow Controller    | Scheduler                        | 流控制器维护处理器之间的连接关系，管理和分配所有处理器使用的线程 |\n| Process Group      | subnet                           | 处理器组，一系列Processor和Connection的集合，通过输入端口（input）接收数据，通过输出端口（output）发送数据 |\n\n以国外某个博主画的图为例（[源地址](https://www.freecodecamp.org/news/nifi-surf-on-your-dataflow-4f3343c50aa2/)）：\n\n![1563333234565](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563333234565.png)\n\n\n\n#### Nifi的架构\n\n##### 单机架构\n\nNifi运行在Jvm中，由`Web Server`，`Flow Controller`，`FlowFile Repository` ，`Content Repository`，`Provenance Repository`等组件组成：\n\n![NiFi Architecture Diagram](https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-node.png)\n\n##### 集群架构\n\nNifi也支持集群架构模式，多节点共同协调处理，每个节点处理逻辑相同，不过各节点分配了不同的数据集。集群中由zookeeper选举出一个`Cluster Coordinator`集群节点协调者，用户在web ui上对Nifi组件的所有改动都由`Cluster Coordinator`通知给所有节点\n\n另外集群中存在一个`Primary Node`主节点，也由zookeeper选举得到，主要用途是提供`Isolated Processor`的配置，在主节点中定义的`Isolated Processor`只在这个主节点上工作，其他节点没有这个Processor。适用场景是提供一个统一的外部数据拉取的接口，然后再通过一些分派机制（loadBalance等）将数据统一分派给剩余节点进行处理，避免多节点同时拉取外部数据发生数据竞争而产生不可预测的后果\n\n![NiFi Cluster Architecture Diagram](https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-cluster.png)\n\n\n\n#### Nifi的基本用法（一个简单的例子）\n\nNifi提供了几十种Processer，用不同的处理逻辑处理不同场景不同格式的数据，具体提供的组件可以参考文档：<https://nifi.apache.org/docs/nifi-docs/>\n\n在这里仅以我做过的一个实际项目为例来进行说明\n\n##### 准备Nifi环境\n\n安装过程就不再赘述了，安装完成后访问任何一个节点的8080端口都能打开web ui，Nifi后续所有操作都在web ui上进行：`http://anynode:8080/nifi/`\n\n进入web ui，长这样，目前已经创建了多个Processor Group：\n\n![1563333859182](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563333859182.png)\n\n##### 创建Processor Group\n\nProcessor Group可以将一系列独立的数据处理逻辑封装在一起，与其他Group进行隔离\n\n将上方的图标拖动到下方界面进行创建\n\n![1563334045695](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563334045695.png)\n\n创建完成后，Group的界面能够显示当前状态，打开关闭情况，输入输出情况和队列缓存情况，双击进入Group面板\n\n##### 创建Processor —— kafka consumer\n\nProcessor是数据流处理的核心控件，可以接收输入，进行路由中转并发送给外部数据源，现在以一个Kafka Consumer Processor为例来进行说明，拖动上方Processor图标到面板中进行创建：\n\n![1563334687067](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563334687067.png)\n\n我们选用`ConsumerKafka_0_11`用来消费外部kafka集群中的数据，采用kafka 0.11版本的Consumer Api实现：\n\n![1563334861136](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563334861136.png)\n\nConsumerKafka_0_11这个Processor支持从kafka消费数据作为输入流，将数据封装为FlowFile进行后续的处理：\n\n![1563342367031](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563342367031.png)\n\n双击Processor面板进行配置，设置面板一共包含四个tab，第一个tab用于一些基本设置：\n\n###### 基础settings\n\n![1563343520868](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563343520868.png)\n\n需要重点关注`Automatically Terminate Relationships`，Relationship表示该Processor对应的输出（即Connection），如果某个Relationship未被勾选，表示无法自动处理，需要用户手动指定Connection指向下游的其他Processor；如果被勾选，那么这个Relationship是可以自动终结的，无需用户指定，Nifi就帮你处理了\n\n###### scheduling配置\n\n第二个tab为scheduling配置，用来指定Processor处理数据的周期和触发处理的规则，默认是基于时间周期性调度，也可以指定Cron表达式进行固定时间的调度：\n\n![1563343869114](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563343869114.png)\n\n###### properties配置\n\n配置Processor的属性，每个Processor都有自己独有的属性设置，并且还可以自己指定attribute用于后续的处理，\n\n![1563343926871](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563343926871.png)\n\n这里面做了一些基本配置，包括kafka集群地址，订阅的topic，group-id等\n\n最后一个comments tab作为备注使用\n\n##### 创建下游Processor ——  EvaluateJsonPath\n\n上游kafka consumer processor获取数据后封装为FlowFile发往下游进行处理，我这里使用的数据结构是json，因此下游处理器采用EvaluateJsonPath解析json数据，将其中的一些值提取出来包装为attribute再发往下游：\n\n![1563344614818](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563344614818.png)\n\nNifi专门提供了JsonPath方式抽取Json数据\n\n两个Processor创建完成后，需要一个Connection将他们连接起来，直接点击ConsumerKafka_0_11上面的箭头并拉到EvaluateJsonPath上就可以进行两个Processor之间的Connection的配置：\n\n![1563344757201](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563344757201.png)\n\n指定Relationships，表示`ConsumerKafka_0_11成功获取到Kafka数据后，将FlowFile发送给下游的EvaluateJsonPath去处理`：\n\n![1563344893717](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563344893717.png)\n\n##### 创建下游Processor —— RouteOnAttribute\n\n提取了Json数据，我们想根据提取出来的数据进行路由，这时候就需要RouteOnAttribute这个Processor：\n\n![1563345038335](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563345038335.png)\n\nNifi提供了Expression Language表达式来进行一些简单的编程操作\n\n使用之前抽取的json字段action作为路由依据，以“create”开头的action则返回true，否则返回false\n\n然后创建EvaluateJsonPath到RouteOnAttribute之间的Connection\n\n##### 创建下游Processor —— InvokeHttp\n\n配置好路由后，我们想将带“create”开头action的数据发送给http接口A，将不带“create”的数据发送给http接口B，那么就得创建两个InvokeHttp，进行一些基本配置包括method和url：\n\n![1563345522963](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563345522963.png)\n\n然后从RouteOnAttribute创建两个连接到这两个InvokeHttp处理器，两个连接分别是isCreation和unmatched（即当前数据不带“create”）：\n\n最终我们的数据处理流构建完成了，这也是一个有向无环图，此时每个Processor都处于停止状态（只有停止状态才能修改配置）：\n\n![1563345754157](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563345754157.png)\n\n##### 启动Processor Group\n\n返回Processor Group处理界面，直接启动整个Group （当然也可以每个Processor分别启动）\n\n![1563346961196](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563346961196.png)\n\n可以看到，整个处理流在5分钟内接收了三条数据，其中2条数据匹配了\"isCreation\"，发往了第一个接口A，其余两条数据发往了接口B，实现了自定义数据路由\n\n##### 调节背压管路\n\n如果某个Processor处理能力有限，就会造成上游数据积压。Nifi的Connection组件提供了一个队列用以缓冲下游暂时处理不了的数据，默认是10000条数据或者1GB size， 并且可以指定过期时间\n\n关闭ConsumerKafka和EvalueteJsonPath这两个Processor，双击\"success\"这个Connection进行配置：\n\n![1563347524271](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563347524271.png)\n\n#### 查看Nifi日志\n\nNifi日志大体上分为**数据日志（Data Provenance）**和**事件日志（Bulletin）**，点击web ui右上角即可查看这两种日志：\n\n![1563347976805](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563347976805.png)\n\n\n\n##### Data Provenance\n\nNifi为每一条进入数据处理流的FlowFile都生成了一个唯一的uuid，可以查看每一条数据在各个节点处理的时间，处理类型（SEND，ROUTE，RECEIVE等），数据大小，以及处理的服务器节点，：\n\n![1563348137310](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563348137310.png)\n\n##### Bulletin\n\n事件日志用于记录Nifi处理器处理数据遇到的一些问题，默认级别是WARN，在这里可以看到数据处理失败的一些信息以及对应的数据uuid和响应的Processer，便于结合`Data Provenance`跟踪追溯：\n\n![1563348249531](C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563348249531.png)","slug":"Apahce-Nifi学习-——-何为Nifi","published":1,"updated":"2019-07-29T13:51:44.833Z","_id":"ckf0h31gs0004actsh716zpqb","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Apache Nifi 是一个开源的分布式系统数据流自动化管理工具，官网：<a href=\"https://nifi.apache.org/\" target=\"_blank\" rel=\"noopener\">https://nifi.apache.org</a></p>\n<p>Nifi全称是<code>Niagarafiles</code>，尼亚加拉files，从名字可以看出这个工具就是用于对付像尼亚加拉瀑布一样的大型数据流<br><a id=\"more\"></a></p>\n<h4 id=\"为何要有Nifi-？\"><a href=\"#为何要有Nifi-？\" class=\"headerlink\" title=\"为何要有Nifi ？\"></a>为何要有Nifi ？</h4><p>随着大数据生态的发展和物流网技术的兴起，企业越发重视对系统间数据流交互的可靠性以及稳定性的管理，但系统之间的数据流管理存在以下几个挑战：</p>\n<ol>\n<li><strong>系统故障</strong>：网络故障，磁盘故障，软件崩溃，或者人为犯错</li>\n<li><strong>下游系统数据处理瓶颈</strong>：下游系统都有数据处理上限，上游输入的数据量不能超过下游系统处理上限</li>\n<li><strong>异常数据</strong>：数据流中的异常数据是不可避免的（太大，太快，损坏的，错误的数据）</li>\n<li><strong>业务系统升级改造</strong>：业务系统升级，数据类型变更，需要做出快速响应</li>\n<li><strong>系统升级引起的兼容问题</strong>：多系统之间升级不同步引起数据兼容问题，此时如果系统之间耦合性太高的话会导致整个系统不可用</li>\n<li>其他诸如对外界环境变动的响应（法律法规变更，规章制度变更等）和生产环境平滑升级等问题</li>\n</ol>\n<p>为了解决以上问题，Nifi应运而生。总的来说，需要Nifi这么一种自动化管理工具来为大型分布式系统提供数据流可靠性管理，数据清洗和过滤，数据流背压控制，或者系统数据接口解耦等功能</p>\n<h4 id=\"Nifi的特点\"><a href=\"#Nifi的特点\" class=\"headerlink\" title=\"Nifi的特点\"></a>Nifi的特点</h4><ul>\n<li><strong>基于web的UI</strong>：完全可视化设计，控制和监控</li>\n<li><strong>高性能</strong><ul>\n<li>数据丢失容错vs保证交付</li>\n<li>低延迟和高吞吐量</li>\n<li>动态优先级</li>\n<li>流可以在运行时修改</li>\n<li>背压(Back pressure)</li>\n</ul>\n</li>\n<li><strong>数据流跟踪</strong><ul>\n<li>从始至终的数据流追踪机制</li>\n</ul>\n</li>\n<li><strong>高可扩展性</strong><ul>\n<li>定制化Processor</li>\n<li>支持快速开发和有效测试</li>\n</ul>\n</li>\n<li><strong>安全</strong><ul>\n<li>支持SSL,SSH,HTTPS加密等</li>\n<li>多租户授权和内部授权/策略管理</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Nifi的核心概念\"><a href=\"#Nifi的核心概念\" class=\"headerlink\" title=\"Nifi的核心概念\"></a>Nifi的核心概念</h4><table>\n<thead>\n<tr>\n<th>术语</th>\n<th>对应Flow Based Programming的术语</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>FlowFile</td>\n<td>Information Packet</td>\n<td>Nifi中的基本数据流对象，通过<code>attribute</code>来标记各个数据流对象的状态</td>\n</tr>\n<tr>\n<td>FlowFile Processor</td>\n<td>Black Box</td>\n<td>负责数据流的清洗，过滤，提取和切割等操作，还可以实现数据路由的合并，变换，及系统间的各种协调</td>\n</tr>\n<tr>\n<td>Connection</td>\n<td>Bounded Buffer</td>\n<td>连接器为各个处理器提供连通管道，以队列的形式提供优先级设置（先进先出等，优先队列等），还提供背压设置和数据负载均衡设置</td>\n</tr>\n<tr>\n<td>Flow Controller</td>\n<td>Scheduler</td>\n<td>流控制器维护处理器之间的连接关系，管理和分配所有处理器使用的线程</td>\n</tr>\n<tr>\n<td>Process Group</td>\n<td>subnet</td>\n<td>处理器组，一系列Processor和Connection的集合，通过输入端口（input）接收数据，通过输出端口（output）发送数据</td>\n</tr>\n</tbody>\n</table>\n<p>以国外某个博主画的图为例（<a href=\"https://www.freecodecamp.org/news/nifi-surf-on-your-dataflow-4f3343c50aa2/\" target=\"_blank\" rel=\"noopener\">源地址</a>）：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563333234565.png\" alt=\"1563333234565\"></p>\n<h4 id=\"Nifi的架构\"><a href=\"#Nifi的架构\" class=\"headerlink\" title=\"Nifi的架构\"></a>Nifi的架构</h4><h5 id=\"单机架构\"><a href=\"#单机架构\" class=\"headerlink\" title=\"单机架构\"></a>单机架构</h5><p>Nifi运行在Jvm中，由<code>Web Server</code>，<code>Flow Controller</code>，<code>FlowFile Repository</code> ，<code>Content Repository</code>，<code>Provenance Repository</code>等组件组成：</p>\n<p><img src=\"https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-node.png\" alt=\"NiFi Architecture Diagram\"></p>\n<h5 id=\"集群架构\"><a href=\"#集群架构\" class=\"headerlink\" title=\"集群架构\"></a>集群架构</h5><p>Nifi也支持集群架构模式，多节点共同协调处理，每个节点处理逻辑相同，不过各节点分配了不同的数据集。集群中由zookeeper选举出一个<code>Cluster Coordinator</code>集群节点协调者，用户在web ui上对Nifi组件的所有改动都由<code>Cluster Coordinator</code>通知给所有节点</p>\n<p>另外集群中存在一个<code>Primary Node</code>主节点，也由zookeeper选举得到，主要用途是提供<code>Isolated Processor</code>的配置，在主节点中定义的<code>Isolated Processor</code>只在这个主节点上工作，其他节点没有这个Processor。适用场景是提供一个统一的外部数据拉取的接口，然后再通过一些分派机制（loadBalance等）将数据统一分派给剩余节点进行处理，避免多节点同时拉取外部数据发生数据竞争而产生不可预测的后果</p>\n<p><img src=\"https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-cluster.png\" alt=\"NiFi Cluster Architecture Diagram\"></p>\n<h4 id=\"Nifi的基本用法（一个简单的例子）\"><a href=\"#Nifi的基本用法（一个简单的例子）\" class=\"headerlink\" title=\"Nifi的基本用法（一个简单的例子）\"></a>Nifi的基本用法（一个简单的例子）</h4><p>Nifi提供了几十种Processer，用不同的处理逻辑处理不同场景不同格式的数据，具体提供的组件可以参考文档：<a href=\"https://nifi.apache.org/docs/nifi-docs/\" target=\"_blank\" rel=\"noopener\">https://nifi.apache.org/docs/nifi-docs/</a></p>\n<p>在这里仅以我做过的一个实际项目为例来进行说明</p>\n<h5 id=\"准备Nifi环境\"><a href=\"#准备Nifi环境\" class=\"headerlink\" title=\"准备Nifi环境\"></a>准备Nifi环境</h5><p>安装过程就不再赘述了，安装完成后访问任何一个节点的8080端口都能打开web ui，Nifi后续所有操作都在web ui上进行：<code>http://anynode:8080/nifi/</code></p>\n<p>进入web ui，长这样，目前已经创建了多个Processor Group：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563333859182.png\" alt=\"1563333859182\"></p>\n<h5 id=\"创建Processor-Group\"><a href=\"#创建Processor-Group\" class=\"headerlink\" title=\"创建Processor Group\"></a>创建Processor Group</h5><p>Processor Group可以将一系列独立的数据处理逻辑封装在一起，与其他Group进行隔离</p>\n<p>将上方的图标拖动到下方界面进行创建</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563334045695.png\" alt=\"1563334045695\"></p>\n<p>创建完成后，Group的界面能够显示当前状态，打开关闭情况，输入输出情况和队列缓存情况，双击进入Group面板</p>\n<h5 id=\"创建Processor-——-kafka-consumer\"><a href=\"#创建Processor-——-kafka-consumer\" class=\"headerlink\" title=\"创建Processor —— kafka consumer\"></a>创建Processor —— kafka consumer</h5><p>Processor是数据流处理的核心控件，可以接收输入，进行路由中转并发送给外部数据源，现在以一个Kafka Consumer Processor为例来进行说明，拖动上方Processor图标到面板中进行创建：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563334687067.png\" alt=\"1563334687067\"></p>\n<p>我们选用<code>ConsumerKafka_0_11</code>用来消费外部kafka集群中的数据，采用kafka 0.11版本的Consumer Api实现：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563334861136.png\" alt=\"1563334861136\"></p>\n<p>ConsumerKafka_0_11这个Processor支持从kafka消费数据作为输入流，将数据封装为FlowFile进行后续的处理：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563342367031.png\" alt=\"1563342367031\"></p>\n<p>双击Processor面板进行配置，设置面板一共包含四个tab，第一个tab用于一些基本设置：</p>\n<h6 id=\"基础settings\"><a href=\"#基础settings\" class=\"headerlink\" title=\"基础settings\"></a>基础settings</h6><p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563343520868.png\" alt=\"1563343520868\"></p>\n<p>需要重点关注<code>Automatically Terminate Relationships</code>，Relationship表示该Processor对应的输出（即Connection），如果某个Relationship未被勾选，表示无法自动处理，需要用户手动指定Connection指向下游的其他Processor；如果被勾选，那么这个Relationship是可以自动终结的，无需用户指定，Nifi就帮你处理了</p>\n<h6 id=\"scheduling配置\"><a href=\"#scheduling配置\" class=\"headerlink\" title=\"scheduling配置\"></a>scheduling配置</h6><p>第二个tab为scheduling配置，用来指定Processor处理数据的周期和触发处理的规则，默认是基于时间周期性调度，也可以指定Cron表达式进行固定时间的调度：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563343869114.png\" alt=\"1563343869114\"></p>\n<h6 id=\"properties配置\"><a href=\"#properties配置\" class=\"headerlink\" title=\"properties配置\"></a>properties配置</h6><p>配置Processor的属性，每个Processor都有自己独有的属性设置，并且还可以自己指定attribute用于后续的处理，</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563343926871.png\" alt=\"1563343926871\"></p>\n<p>这里面做了一些基本配置，包括kafka集群地址，订阅的topic，group-id等</p>\n<p>最后一个comments tab作为备注使用</p>\n<h5 id=\"创建下游Processor-——-EvaluateJsonPath\"><a href=\"#创建下游Processor-——-EvaluateJsonPath\" class=\"headerlink\" title=\"创建下游Processor ——  EvaluateJsonPath\"></a>创建下游Processor ——  EvaluateJsonPath</h5><p>上游kafka consumer processor获取数据后封装为FlowFile发往下游进行处理，我这里使用的数据结构是json，因此下游处理器采用EvaluateJsonPath解析json数据，将其中的一些值提取出来包装为attribute再发往下游：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563344614818.png\" alt=\"1563344614818\"></p>\n<p>Nifi专门提供了JsonPath方式抽取Json数据</p>\n<p>两个Processor创建完成后，需要一个Connection将他们连接起来，直接点击ConsumerKafka_0_11上面的箭头并拉到EvaluateJsonPath上就可以进行两个Processor之间的Connection的配置：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563344757201.png\" alt=\"1563344757201\"></p>\n<p>指定Relationships，表示<code>ConsumerKafka_0_11成功获取到Kafka数据后，将FlowFile发送给下游的EvaluateJsonPath去处理</code>：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563344893717.png\" alt=\"1563344893717\"></p>\n<h5 id=\"创建下游Processor-——-RouteOnAttribute\"><a href=\"#创建下游Processor-——-RouteOnAttribute\" class=\"headerlink\" title=\"创建下游Processor —— RouteOnAttribute\"></a>创建下游Processor —— RouteOnAttribute</h5><p>提取了Json数据，我们想根据提取出来的数据进行路由，这时候就需要RouteOnAttribute这个Processor：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563345038335.png\" alt=\"1563345038335\"></p>\n<p>Nifi提供了Expression Language表达式来进行一些简单的编程操作</p>\n<p>使用之前抽取的json字段action作为路由依据，以“create”开头的action则返回true，否则返回false</p>\n<p>然后创建EvaluateJsonPath到RouteOnAttribute之间的Connection</p>\n<h5 id=\"创建下游Processor-——-InvokeHttp\"><a href=\"#创建下游Processor-——-InvokeHttp\" class=\"headerlink\" title=\"创建下游Processor —— InvokeHttp\"></a>创建下游Processor —— InvokeHttp</h5><p>配置好路由后，我们想将带“create”开头action的数据发送给http接口A，将不带“create”的数据发送给http接口B，那么就得创建两个InvokeHttp，进行一些基本配置包括method和url：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563345522963.png\" alt=\"1563345522963\"></p>\n<p>然后从RouteOnAttribute创建两个连接到这两个InvokeHttp处理器，两个连接分别是isCreation和unmatched（即当前数据不带“create”）：</p>\n<p>最终我们的数据处理流构建完成了，这也是一个有向无环图，此时每个Processor都处于停止状态（只有停止状态才能修改配置）：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563345754157.png\" alt=\"1563345754157\"></p>\n<h5 id=\"启动Processor-Group\"><a href=\"#启动Processor-Group\" class=\"headerlink\" title=\"启动Processor Group\"></a>启动Processor Group</h5><p>返回Processor Group处理界面，直接启动整个Group （当然也可以每个Processor分别启动）</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563346961196.png\" alt=\"1563346961196\"></p>\n<p>可以看到，整个处理流在5分钟内接收了三条数据，其中2条数据匹配了”isCreation”，发往了第一个接口A，其余两条数据发往了接口B，实现了自定义数据路由</p>\n<h5 id=\"调节背压管路\"><a href=\"#调节背压管路\" class=\"headerlink\" title=\"调节背压管路\"></a>调节背压管路</h5><p>如果某个Processor处理能力有限，就会造成上游数据积压。Nifi的Connection组件提供了一个队列用以缓冲下游暂时处理不了的数据，默认是10000条数据或者1GB size， 并且可以指定过期时间</p>\n<p>关闭ConsumerKafka和EvalueteJsonPath这两个Processor，双击”success”这个Connection进行配置：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563347524271.png\" alt=\"1563347524271\"></p>\n<h4 id=\"查看Nifi日志\"><a href=\"#查看Nifi日志\" class=\"headerlink\" title=\"查看Nifi日志\"></a>查看Nifi日志</h4><p>Nifi日志大体上分为<strong>数据日志（Data Provenance）</strong>和<strong>事件日志（Bulletin）</strong>，点击web ui右上角即可查看这两种日志：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563347976805.png\" alt=\"1563347976805\"></p>\n<h5 id=\"Data-Provenance\"><a href=\"#Data-Provenance\" class=\"headerlink\" title=\"Data Provenance\"></a>Data Provenance</h5><p>Nifi为每一条进入数据处理流的FlowFile都生成了一个唯一的uuid，可以查看每一条数据在各个节点处理的时间，处理类型（SEND，ROUTE，RECEIVE等），数据大小，以及处理的服务器节点，：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563348137310.png\" alt=\"1563348137310\"></p>\n<h5 id=\"Bulletin\"><a href=\"#Bulletin\" class=\"headerlink\" title=\"Bulletin\"></a>Bulletin</h5><p>事件日志用于记录Nifi处理器处理数据遇到的一些问题，默认级别是WARN，在这里可以看到数据处理失败的一些信息以及对应的数据uuid和响应的Processer，便于结合<code>Data Provenance</code>跟踪追溯：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563348249531.png\" alt=\"1563348249531\"></p>\n","site":{"data":{}},"excerpt":"<p>Apache Nifi 是一个开源的分布式系统数据流自动化管理工具，官网：<a href=\"https://nifi.apache.org/\" target=\"_blank\" rel=\"noopener\">https://nifi.apache.org</a></p>\n<p>Nifi全称是<code>Niagarafiles</code>，尼亚加拉files，从名字可以看出这个工具就是用于对付像尼亚加拉瀑布一样的大型数据流<br>","more":"</p>\n<h4 id=\"为何要有Nifi-？\"><a href=\"#为何要有Nifi-？\" class=\"headerlink\" title=\"为何要有Nifi ？\"></a>为何要有Nifi ？</h4><p>随着大数据生态的发展和物流网技术的兴起，企业越发重视对系统间数据流交互的可靠性以及稳定性的管理，但系统之间的数据流管理存在以下几个挑战：</p>\n<ol>\n<li><strong>系统故障</strong>：网络故障，磁盘故障，软件崩溃，或者人为犯错</li>\n<li><strong>下游系统数据处理瓶颈</strong>：下游系统都有数据处理上限，上游输入的数据量不能超过下游系统处理上限</li>\n<li><strong>异常数据</strong>：数据流中的异常数据是不可避免的（太大，太快，损坏的，错误的数据）</li>\n<li><strong>业务系统升级改造</strong>：业务系统升级，数据类型变更，需要做出快速响应</li>\n<li><strong>系统升级引起的兼容问题</strong>：多系统之间升级不同步引起数据兼容问题，此时如果系统之间耦合性太高的话会导致整个系统不可用</li>\n<li>其他诸如对外界环境变动的响应（法律法规变更，规章制度变更等）和生产环境平滑升级等问题</li>\n</ol>\n<p>为了解决以上问题，Nifi应运而生。总的来说，需要Nifi这么一种自动化管理工具来为大型分布式系统提供数据流可靠性管理，数据清洗和过滤，数据流背压控制，或者系统数据接口解耦等功能</p>\n<h4 id=\"Nifi的特点\"><a href=\"#Nifi的特点\" class=\"headerlink\" title=\"Nifi的特点\"></a>Nifi的特点</h4><ul>\n<li><strong>基于web的UI</strong>：完全可视化设计，控制和监控</li>\n<li><strong>高性能</strong><ul>\n<li>数据丢失容错vs保证交付</li>\n<li>低延迟和高吞吐量</li>\n<li>动态优先级</li>\n<li>流可以在运行时修改</li>\n<li>背压(Back pressure)</li>\n</ul>\n</li>\n<li><strong>数据流跟踪</strong><ul>\n<li>从始至终的数据流追踪机制</li>\n</ul>\n</li>\n<li><strong>高可扩展性</strong><ul>\n<li>定制化Processor</li>\n<li>支持快速开发和有效测试</li>\n</ul>\n</li>\n<li><strong>安全</strong><ul>\n<li>支持SSL,SSH,HTTPS加密等</li>\n<li>多租户授权和内部授权/策略管理</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Nifi的核心概念\"><a href=\"#Nifi的核心概念\" class=\"headerlink\" title=\"Nifi的核心概念\"></a>Nifi的核心概念</h4><table>\n<thead>\n<tr>\n<th>术语</th>\n<th>对应Flow Based Programming的术语</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>FlowFile</td>\n<td>Information Packet</td>\n<td>Nifi中的基本数据流对象，通过<code>attribute</code>来标记各个数据流对象的状态</td>\n</tr>\n<tr>\n<td>FlowFile Processor</td>\n<td>Black Box</td>\n<td>负责数据流的清洗，过滤，提取和切割等操作，还可以实现数据路由的合并，变换，及系统间的各种协调</td>\n</tr>\n<tr>\n<td>Connection</td>\n<td>Bounded Buffer</td>\n<td>连接器为各个处理器提供连通管道，以队列的形式提供优先级设置（先进先出等，优先队列等），还提供背压设置和数据负载均衡设置</td>\n</tr>\n<tr>\n<td>Flow Controller</td>\n<td>Scheduler</td>\n<td>流控制器维护处理器之间的连接关系，管理和分配所有处理器使用的线程</td>\n</tr>\n<tr>\n<td>Process Group</td>\n<td>subnet</td>\n<td>处理器组，一系列Processor和Connection的集合，通过输入端口（input）接收数据，通过输出端口（output）发送数据</td>\n</tr>\n</tbody>\n</table>\n<p>以国外某个博主画的图为例（<a href=\"https://www.freecodecamp.org/news/nifi-surf-on-your-dataflow-4f3343c50aa2/\" target=\"_blank\" rel=\"noopener\">源地址</a>）：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563333234565.png\" alt=\"1563333234565\"></p>\n<h4 id=\"Nifi的架构\"><a href=\"#Nifi的架构\" class=\"headerlink\" title=\"Nifi的架构\"></a>Nifi的架构</h4><h5 id=\"单机架构\"><a href=\"#单机架构\" class=\"headerlink\" title=\"单机架构\"></a>单机架构</h5><p>Nifi运行在Jvm中，由<code>Web Server</code>，<code>Flow Controller</code>，<code>FlowFile Repository</code> ，<code>Content Repository</code>，<code>Provenance Repository</code>等组件组成：</p>\n<p><img src=\"https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-node.png\" alt=\"NiFi Architecture Diagram\"></p>\n<h5 id=\"集群架构\"><a href=\"#集群架构\" class=\"headerlink\" title=\"集群架构\"></a>集群架构</h5><p>Nifi也支持集群架构模式，多节点共同协调处理，每个节点处理逻辑相同，不过各节点分配了不同的数据集。集群中由zookeeper选举出一个<code>Cluster Coordinator</code>集群节点协调者，用户在web ui上对Nifi组件的所有改动都由<code>Cluster Coordinator</code>通知给所有节点</p>\n<p>另外集群中存在一个<code>Primary Node</code>主节点，也由zookeeper选举得到，主要用途是提供<code>Isolated Processor</code>的配置，在主节点中定义的<code>Isolated Processor</code>只在这个主节点上工作，其他节点没有这个Processor。适用场景是提供一个统一的外部数据拉取的接口，然后再通过一些分派机制（loadBalance等）将数据统一分派给剩余节点进行处理，避免多节点同时拉取外部数据发生数据竞争而产生不可预测的后果</p>\n<p><img src=\"https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-cluster.png\" alt=\"NiFi Cluster Architecture Diagram\"></p>\n<h4 id=\"Nifi的基本用法（一个简单的例子）\"><a href=\"#Nifi的基本用法（一个简单的例子）\" class=\"headerlink\" title=\"Nifi的基本用法（一个简单的例子）\"></a>Nifi的基本用法（一个简单的例子）</h4><p>Nifi提供了几十种Processer，用不同的处理逻辑处理不同场景不同格式的数据，具体提供的组件可以参考文档：<a href=\"https://nifi.apache.org/docs/nifi-docs/\" target=\"_blank\" rel=\"noopener\">https://nifi.apache.org/docs/nifi-docs/</a></p>\n<p>在这里仅以我做过的一个实际项目为例来进行说明</p>\n<h5 id=\"准备Nifi环境\"><a href=\"#准备Nifi环境\" class=\"headerlink\" title=\"准备Nifi环境\"></a>准备Nifi环境</h5><p>安装过程就不再赘述了，安装完成后访问任何一个节点的8080端口都能打开web ui，Nifi后续所有操作都在web ui上进行：<code>http://anynode:8080/nifi/</code></p>\n<p>进入web ui，长这样，目前已经创建了多个Processor Group：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563333859182.png\" alt=\"1563333859182\"></p>\n<h5 id=\"创建Processor-Group\"><a href=\"#创建Processor-Group\" class=\"headerlink\" title=\"创建Processor Group\"></a>创建Processor Group</h5><p>Processor Group可以将一系列独立的数据处理逻辑封装在一起，与其他Group进行隔离</p>\n<p>将上方的图标拖动到下方界面进行创建</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563334045695.png\" alt=\"1563334045695\"></p>\n<p>创建完成后，Group的界面能够显示当前状态，打开关闭情况，输入输出情况和队列缓存情况，双击进入Group面板</p>\n<h5 id=\"创建Processor-——-kafka-consumer\"><a href=\"#创建Processor-——-kafka-consumer\" class=\"headerlink\" title=\"创建Processor —— kafka consumer\"></a>创建Processor —— kafka consumer</h5><p>Processor是数据流处理的核心控件，可以接收输入，进行路由中转并发送给外部数据源，现在以一个Kafka Consumer Processor为例来进行说明，拖动上方Processor图标到面板中进行创建：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563334687067.png\" alt=\"1563334687067\"></p>\n<p>我们选用<code>ConsumerKafka_0_11</code>用来消费外部kafka集群中的数据，采用kafka 0.11版本的Consumer Api实现：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563334861136.png\" alt=\"1563334861136\"></p>\n<p>ConsumerKafka_0_11这个Processor支持从kafka消费数据作为输入流，将数据封装为FlowFile进行后续的处理：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563342367031.png\" alt=\"1563342367031\"></p>\n<p>双击Processor面板进行配置，设置面板一共包含四个tab，第一个tab用于一些基本设置：</p>\n<h6 id=\"基础settings\"><a href=\"#基础settings\" class=\"headerlink\" title=\"基础settings\"></a>基础settings</h6><p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563343520868.png\" alt=\"1563343520868\"></p>\n<p>需要重点关注<code>Automatically Terminate Relationships</code>，Relationship表示该Processor对应的输出（即Connection），如果某个Relationship未被勾选，表示无法自动处理，需要用户手动指定Connection指向下游的其他Processor；如果被勾选，那么这个Relationship是可以自动终结的，无需用户指定，Nifi就帮你处理了</p>\n<h6 id=\"scheduling配置\"><a href=\"#scheduling配置\" class=\"headerlink\" title=\"scheduling配置\"></a>scheduling配置</h6><p>第二个tab为scheduling配置，用来指定Processor处理数据的周期和触发处理的规则，默认是基于时间周期性调度，也可以指定Cron表达式进行固定时间的调度：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563343869114.png\" alt=\"1563343869114\"></p>\n<h6 id=\"properties配置\"><a href=\"#properties配置\" class=\"headerlink\" title=\"properties配置\"></a>properties配置</h6><p>配置Processor的属性，每个Processor都有自己独有的属性设置，并且还可以自己指定attribute用于后续的处理，</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563343926871.png\" alt=\"1563343926871\"></p>\n<p>这里面做了一些基本配置，包括kafka集群地址，订阅的topic，group-id等</p>\n<p>最后一个comments tab作为备注使用</p>\n<h5 id=\"创建下游Processor-——-EvaluateJsonPath\"><a href=\"#创建下游Processor-——-EvaluateJsonPath\" class=\"headerlink\" title=\"创建下游Processor ——  EvaluateJsonPath\"></a>创建下游Processor ——  EvaluateJsonPath</h5><p>上游kafka consumer processor获取数据后封装为FlowFile发往下游进行处理，我这里使用的数据结构是json，因此下游处理器采用EvaluateJsonPath解析json数据，将其中的一些值提取出来包装为attribute再发往下游：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563344614818.png\" alt=\"1563344614818\"></p>\n<p>Nifi专门提供了JsonPath方式抽取Json数据</p>\n<p>两个Processor创建完成后，需要一个Connection将他们连接起来，直接点击ConsumerKafka_0_11上面的箭头并拉到EvaluateJsonPath上就可以进行两个Processor之间的Connection的配置：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563344757201.png\" alt=\"1563344757201\"></p>\n<p>指定Relationships，表示<code>ConsumerKafka_0_11成功获取到Kafka数据后，将FlowFile发送给下游的EvaluateJsonPath去处理</code>：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563344893717.png\" alt=\"1563344893717\"></p>\n<h5 id=\"创建下游Processor-——-RouteOnAttribute\"><a href=\"#创建下游Processor-——-RouteOnAttribute\" class=\"headerlink\" title=\"创建下游Processor —— RouteOnAttribute\"></a>创建下游Processor —— RouteOnAttribute</h5><p>提取了Json数据，我们想根据提取出来的数据进行路由，这时候就需要RouteOnAttribute这个Processor：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563345038335.png\" alt=\"1563345038335\"></p>\n<p>Nifi提供了Expression Language表达式来进行一些简单的编程操作</p>\n<p>使用之前抽取的json字段action作为路由依据，以“create”开头的action则返回true，否则返回false</p>\n<p>然后创建EvaluateJsonPath到RouteOnAttribute之间的Connection</p>\n<h5 id=\"创建下游Processor-——-InvokeHttp\"><a href=\"#创建下游Processor-——-InvokeHttp\" class=\"headerlink\" title=\"创建下游Processor —— InvokeHttp\"></a>创建下游Processor —— InvokeHttp</h5><p>配置好路由后，我们想将带“create”开头action的数据发送给http接口A，将不带“create”的数据发送给http接口B，那么就得创建两个InvokeHttp，进行一些基本配置包括method和url：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563345522963.png\" alt=\"1563345522963\"></p>\n<p>然后从RouteOnAttribute创建两个连接到这两个InvokeHttp处理器，两个连接分别是isCreation和unmatched（即当前数据不带“create”）：</p>\n<p>最终我们的数据处理流构建完成了，这也是一个有向无环图，此时每个Processor都处于停止状态（只有停止状态才能修改配置）：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563345754157.png\" alt=\"1563345754157\"></p>\n<h5 id=\"启动Processor-Group\"><a href=\"#启动Processor-Group\" class=\"headerlink\" title=\"启动Processor Group\"></a>启动Processor Group</h5><p>返回Processor Group处理界面，直接启动整个Group （当然也可以每个Processor分别启动）</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563346961196.png\" alt=\"1563346961196\"></p>\n<p>可以看到，整个处理流在5分钟内接收了三条数据，其中2条数据匹配了”isCreation”，发往了第一个接口A，其余两条数据发往了接口B，实现了自定义数据路由</p>\n<h5 id=\"调节背压管路\"><a href=\"#调节背压管路\" class=\"headerlink\" title=\"调节背压管路\"></a>调节背压管路</h5><p>如果某个Processor处理能力有限，就会造成上游数据积压。Nifi的Connection组件提供了一个队列用以缓冲下游暂时处理不了的数据，默认是10000条数据或者1GB size， 并且可以指定过期时间</p>\n<p>关闭ConsumerKafka和EvalueteJsonPath这两个Processor，双击”success”这个Connection进行配置：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563347524271.png\" alt=\"1563347524271\"></p>\n<h4 id=\"查看Nifi日志\"><a href=\"#查看Nifi日志\" class=\"headerlink\" title=\"查看Nifi日志\"></a>查看Nifi日志</h4><p>Nifi日志大体上分为<strong>数据日志（Data Provenance）</strong>和<strong>事件日志（Bulletin）</strong>，点击web ui右上角即可查看这两种日志：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563347976805.png\" alt=\"1563347976805\"></p>\n<h5 id=\"Data-Provenance\"><a href=\"#Data-Provenance\" class=\"headerlink\" title=\"Data Provenance\"></a>Data Provenance</h5><p>Nifi为每一条进入数据处理流的FlowFile都生成了一个唯一的uuid，可以查看每一条数据在各个节点处理的时间，处理类型（SEND，ROUTE，RECEIVE等），数据大小，以及处理的服务器节点，：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563348137310.png\" alt=\"1563348137310\"></p>\n<h5 id=\"Bulletin\"><a href=\"#Bulletin\" class=\"headerlink\" title=\"Bulletin\"></a>Bulletin</h5><p>事件日志用于记录Nifi处理器处理数据遇到的一些问题，默认级别是WARN，在这里可以看到数据处理失败的一些信息以及对应的数据uuid和响应的Processer，便于结合<code>Data Provenance</code>跟踪追溯：</p>\n<p><img src=\"C:\\Users\\admin\\AppData\\Roaming\\Typora\\typora-user-images\\1563348249531.png\" alt=\"1563348249531\"></p>"},{"title":"Netty-NioEventLoop的reactor线程模型","author":"天渊","date":"2019-08-16T11:00:00.000Z","_content":"### Netty-NioEventLoop的reactor线程模型\n\nNetty中reactor的核心逻辑主要由`NioEventLoop`及其父类`SingleThreadEventExecutor`和`SingleThreadEventLoop`这几个类进行实现，其中`NioEventLoop`的线程就是主要负责IO事件轮询工作的线程\n<!--more-->\n\n#### NioEventLoop的run方法\n\n每一个`NioEventLoop`都会封装一个核心执行器`ThreadPerTaskExecutor`，`NioEventLoop`依靠这个执行器来启动它自己的核心线程`FastThreadLocalThread`，即eventLoop的reactor线程，由reactor线程来执行`NioEventLoop`的核心逻辑，即`run()`方法，包括NIO的select过程，处理IO事件并执行任务，以下是`NioEventLoop`的`run()`方法的源码：\n\n```java\nprotected void run() {\n    for (;;) {\n        try {\n            switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) {\n                case SelectStrategy.CONTINUE:\n                    continue;\n                case SelectStrategy.SELECT:\n                    select(wakenUp.getAndSet(false));\n                    if (wakenUp.get()) {\n                        selector.wakeup();\n                    }\n                default:\n                    // fallthrough\n            }\n            cancelledKeys = 0;\n            needsToSelectAgain = false;\n            final int ioRatio = this.ioRatio;\n            if (ioRatio == 100) {\n                try {\n                    processSelectedKeys();\n                } finally {\n                    // Ensure we always run tasks.\n                    runAllTasks();\n                }\n            } else {\n                final long ioStartTime = System.nanoTime();\n                try {\n                    processSelectedKeys();\n                } finally {\n                    // Ensure we always run tasks.\n                    final long ioTime = System.nanoTime() - ioStartTime;\n                    runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n                }\n            }\n        } catch (Throwable t) {\n            handleLoopException(t);\n        }\n        // Always handle shutdown even if the loop processing threw an exception.\n        try {\n            if (isShuttingDown()) {\n                closeAll();\n                if (confirmShutdown()) {\n                    return;\n                }\n            }\n        } catch (Throwable t) {\n            handleLoopException(t);\n        }\n    }\n}\n```\n\n这个`run()`方法是一个死循环，单次循环的执行逻辑顺序大致如下：\n\n> 1. 对注册到当前reactor线程selector的所有channel事件进行轮询\n> 2. 处理产生的IO事件\n> 3. 处理eventLoop任务队列中的任务\n\n##### channel事件轮询\n\n这个过程主要是基于jdk nio提供的`Selector`来实现，是eventLoop最核心的操作，对注册的channel IO事件进行轮询并取出已经产生的IO事件供后续的处理，这个操作基于操作系统底层的`epoll`等模型实现：\n\n```java\nselect(wakenUp.getAndSet(false));\nif (wakenUp.get()) {\n    selector.wakeup();\n}\n```\n\n`selector.wakeup()`这个操作能够解除阻塞在`Selector.select()`或者`select(long)`上的线程并立即返回，如果`Selector`当前没有阻塞在select操作上，则本次wakeup调用将作用于下一次select\n\n什么时候需要唤醒？\n\n> 1. 注册了新的channel或者原有channel注册了新的事件\n> 2. channel关闭，取消注册\n> 3. 优先级更高的事件触发，需要及时处理（如急需处理的普通任务或定时任务）\n\n`NioEventLoop`的`select(boolean oldWakenUp)`方法内部是一个死循环，在对`Selector`进行轮询select时，基本上遵循以下顺序：\n\n> 首先，如果eventLoop中有定时任务快到期了则立刻退出轮询，执行一次非阻塞select操作并停止select\n\n```java\nlong timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L;\nif (timeoutMillis <= 0) {\n    if (selectCnt == 0) {\n        selector.selectNow();\n        selectCnt = 1;\n    }\n    break;\n}\n```\n\n> 然后，检测任务队列中如果有待执行的任务，则执行一次非阻塞select操作并立刻退出，需要将wakeup状态设置为true\n\n```java\nif (hasTasks() && wakenUp.compareAndSet(false, true)) {\n    selector.selectNow();\n    selectCnt = 1;\n    break;\n}\n```\n\n> 随后，执行select操作，该操作在超时时间到期前会一直阻塞，超时时间是截至到最早的那个定时任务到期\n>\n> 超时后会进行一系列判断，比如selectedKey的数量，wakeup状态，是否有待执行任务等等，如果满足条件则马上退出轮询\n\n```java\nint selectedKeys = selector.select(timeoutMillis);\nselectCnt ++;\nif (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) {\n    break;\n}\n```\n\n> 最后，由于jdk nio有一个bug会使`Selector`无法成功地阻塞规定的时间，造成无限空轮询，进而导致CPU 100%，netty使用了某种措施规避了这个bug，在一次成功的select操作后，如果仍然无需退出轮询，则判断如果selectCnt（已轮询的次数）大于某个阈值（默认512）后，直接重建`Selector`\n\n```java\nlong time = System.nanoTime();\nif (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) >= currentTimeNanos) {\n    // select持续时间大于规定的超时时间timeoutMillis，说明本次select有效，重置selectCnt并进行下一次轮询\n    selectCnt = 1;\n} else if (SELECTOR_AUTO_REBUILD_THRESHOLD > 0 &&\n        selectCnt >= SELECTOR_AUTO_REBUILD_THRESHOLD) {\n    // selectCnt已经达到空轮询阈值，立即重建Selector\n    rebuildSelector();\n    selector = this.selector;\n    // 进行一次立即返回的select并重置selectCnt\n    selector.selectNow();\n    selectCnt = 1;\n    break;\n}\n```\n\n\n\n##### 处理产生的IO事件\n\n进行完一次成功的select操作后，需要处理产生的IO事件，其中，`ioRatio`是处理IO事件和处理非IO任务（即用户自定义handler的任务）的百分比，默认是50，即IO事件和非IO事件所占用时间一半一半；如果`ioRatio`为100，则对两种事件没有时间限制，代码如下，\n\n```java\nfinal int ioRatio = this.ioRatio;\nif (ioRatio == 100) {\n    try {\n        processSelectedKeys();\n    } finally {\n        // 保证一定会执行任务队列中的任务\n        runAllTasks();\n    }\n} else {\n    final long ioStartTime = System.nanoTime();\n    try {\n        processSelectedKeys();\n    } finally {\n        final long ioTime = System.nanoTime() - ioStartTime;\n        // 非IO任务耗费的时间不能超过ioRatio的比率\n        runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n    }\n}\n```\n\nselect完成后得到的`SelectionKey`位于`selectedKeys`这个成员变量中，其是由netty自己基于`AbstractSet`实现的一个类：`SelectedSelectionKeySet`，在jdk nio `SelectorImpl`中`HashSet`的基础上做了一些优化，将保存`SelectionKey`的容器设置为数组，相比于`HashSet`从时间复杂度和内存占用上都有一定的优化\n\n由`processSelectedKeysOptimized(SelectionKey[] selectedKeys)`方法处理获得的`selectedKeys`：\n\n```java\nprivate void processSelectedKeysOptimized(SelectionKey[] selectedKeys) {\n    for (int i = 0;; i ++) {\n        final SelectionKey k = selectedKeys[i];\n        if (k == null) {\n            break;\n        }\n        selectedKeys[i] = null;\n        // 1. 取出attachment，可能是AbstractNioChannel或者NioTask\n        final Object a = k.attachment();\n        if (a instanceof AbstractNioChannel) {\n            processSelectedKey(k, (AbstractNioChannel) a);\n        } else {\n            @SuppressWarnings(\"unchecked\")\n            NioTask<SelectableChannel> task = (NioTask<SelectableChannel>) a;\n            processSelectedKey(k, task);\n        }\n        if (needsToSelectAgain) {\n            for (;;) {\n                i++;\n                if (selectedKeys[i] == null) {\n                    break;\n                }\n                selectedKeys[i] = null;\n            }\n            selectAgain();\n            selectedKeys = this.selectedKeys.flip();\n            i = -1;\n        }\n    }\n}\n```\n\n遍历`selectedKeys`，每一次循环分为以下几步：\n\n1. 取出`SelectionKey`，将`selectedKeys`数组的当前位置设置为null，在相关的`Channel`关闭后，gc会将这个`SelectionKey`及其与之关联的`Channel`回收掉，防止内存泄漏\n2. 从`SelectionKey`中取出`Attachment`，可能是`AbstractNioChannel`或者`NioTask`，其中`AbstractNioChannel`相关的事件由Netty框架处理，`NioTask`相关的事件由用户自己注册并处理；主要关注`AbstractNioChannel`及其处理方法`processSelectedKey(k, (AbstractNioChannel) a)`\n3. 当前`SelectionKey`处理完成后判断是否该再来一次select轮询，当`needsToSelectAgain`为true时则需要再来一次轮询\n\n> 为何要在处理SelectionKey期间重新进行select轮询？\n>\n> 因为随时都有Channel断线，Channel断线后会执行cancel()方法取消对应的SelectionKey，为了保证现存的SelectionKey都是有效的，需要定期（默认256次cancel后）清理SelectionKey的集合，保证现存的SelectionKey时及时有效的\n\n处理完`SelectionKey`后就是最后一步：处理eventLoop任务队列中的任务\n\n##### 处理eventLoop任务队列中的任务\n\neventLoop任务队列是`taskQueue`，其实现默认是`jctools`包中的同步队列`MpscChunkedArrayQueue`，即多生产者单消费者队列，针对并发写的场景进行了一些优化\n\n`taskQueue`任务队列中的任务主要来自三个途径：\n\n1. 用户调用`eventLoop.execute()`执行的自定义任务，会直接向`taskQueue`添加任务\n2. channel触发的各种事件，比如往channel中写数据会产生出站事件，会向`taskQueue`添加一个`WriteTask`或者`WriteAndFlushTask`\n3. 用户自定义的定时任务，通过调用`eventLoop().schedule()`方法添加一个定时任务用于在一定时间后执行任务，保存定时任务的队列`scheduledTaskQueue`是一个优先队列`PriorityQueue`\n\n###### 自定义任务\n\n用户可以在任意一个handler通过以下方式获取eventLoop实例并调用execute()添加自定义任务，然后由eventLoop线程来执行任务:\n\n```java\nctx.channel().eventLoop().execute(() -> {\n    System.out.println(\"task\");\n});\n```\n\nexecute()方法部分代码如下：\n\n```java\npublic void execute(Runnable task) {\n    //...\n    boolean inEventLoop = inEventLoop();\n    if (inEventLoop) {\n        addTask(task);\n    } else {\n        startThread();\n        addTask(task);\n        if (isShutdown() && removeTask(task)) {\n            reject();\n        }\n    }\n    //...\n}\n```\n\n首先通过inEventLoop()方法判断当前执行线程是否是eventLoop线程，如果不是的话则要先启动执行线程，保证执行任务的始终是唯一确定的eventLoop线程\n\n> 在netty的线程模型中，每一个eventLoop对应一个唯一的执行器ThreadPerTaskExecutor，每个执行器都会提供一个FastThreadLocalThread线程实例，这个线程就是eventLoop的reactor线程，任务队列中的所有任务在执行前都会判断该任务是否由reactor线程来执行，保证了eventLoop的核心逻辑的单线程环境\n\n###### channel事件任务\n\n\n\n\n\n\n\n###### 自定义定时任务","source":"_posts/Netty-NioEventLoop的reactor线程模型.md","raw":"title: Netty-NioEventLoop的reactor线程模型\nauthor: 天渊\ntags:\n  - netty\ncategories:\n  - 基础知识\ndate: 2019-08-16 19:00:00\n---\n### Netty-NioEventLoop的reactor线程模型\n\nNetty中reactor的核心逻辑主要由`NioEventLoop`及其父类`SingleThreadEventExecutor`和`SingleThreadEventLoop`这几个类进行实现，其中`NioEventLoop`的线程就是主要负责IO事件轮询工作的线程\n<!--more-->\n\n#### NioEventLoop的run方法\n\n每一个`NioEventLoop`都会封装一个核心执行器`ThreadPerTaskExecutor`，`NioEventLoop`依靠这个执行器来启动它自己的核心线程`FastThreadLocalThread`，即eventLoop的reactor线程，由reactor线程来执行`NioEventLoop`的核心逻辑，即`run()`方法，包括NIO的select过程，处理IO事件并执行任务，以下是`NioEventLoop`的`run()`方法的源码：\n\n```java\nprotected void run() {\n    for (;;) {\n        try {\n            switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) {\n                case SelectStrategy.CONTINUE:\n                    continue;\n                case SelectStrategy.SELECT:\n                    select(wakenUp.getAndSet(false));\n                    if (wakenUp.get()) {\n                        selector.wakeup();\n                    }\n                default:\n                    // fallthrough\n            }\n            cancelledKeys = 0;\n            needsToSelectAgain = false;\n            final int ioRatio = this.ioRatio;\n            if (ioRatio == 100) {\n                try {\n                    processSelectedKeys();\n                } finally {\n                    // Ensure we always run tasks.\n                    runAllTasks();\n                }\n            } else {\n                final long ioStartTime = System.nanoTime();\n                try {\n                    processSelectedKeys();\n                } finally {\n                    // Ensure we always run tasks.\n                    final long ioTime = System.nanoTime() - ioStartTime;\n                    runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n                }\n            }\n        } catch (Throwable t) {\n            handleLoopException(t);\n        }\n        // Always handle shutdown even if the loop processing threw an exception.\n        try {\n            if (isShuttingDown()) {\n                closeAll();\n                if (confirmShutdown()) {\n                    return;\n                }\n            }\n        } catch (Throwable t) {\n            handleLoopException(t);\n        }\n    }\n}\n```\n\n这个`run()`方法是一个死循环，单次循环的执行逻辑顺序大致如下：\n\n> 1. 对注册到当前reactor线程selector的所有channel事件进行轮询\n> 2. 处理产生的IO事件\n> 3. 处理eventLoop任务队列中的任务\n\n##### channel事件轮询\n\n这个过程主要是基于jdk nio提供的`Selector`来实现，是eventLoop最核心的操作，对注册的channel IO事件进行轮询并取出已经产生的IO事件供后续的处理，这个操作基于操作系统底层的`epoll`等模型实现：\n\n```java\nselect(wakenUp.getAndSet(false));\nif (wakenUp.get()) {\n    selector.wakeup();\n}\n```\n\n`selector.wakeup()`这个操作能够解除阻塞在`Selector.select()`或者`select(long)`上的线程并立即返回，如果`Selector`当前没有阻塞在select操作上，则本次wakeup调用将作用于下一次select\n\n什么时候需要唤醒？\n\n> 1. 注册了新的channel或者原有channel注册了新的事件\n> 2. channel关闭，取消注册\n> 3. 优先级更高的事件触发，需要及时处理（如急需处理的普通任务或定时任务）\n\n`NioEventLoop`的`select(boolean oldWakenUp)`方法内部是一个死循环，在对`Selector`进行轮询select时，基本上遵循以下顺序：\n\n> 首先，如果eventLoop中有定时任务快到期了则立刻退出轮询，执行一次非阻塞select操作并停止select\n\n```java\nlong timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L;\nif (timeoutMillis <= 0) {\n    if (selectCnt == 0) {\n        selector.selectNow();\n        selectCnt = 1;\n    }\n    break;\n}\n```\n\n> 然后，检测任务队列中如果有待执行的任务，则执行一次非阻塞select操作并立刻退出，需要将wakeup状态设置为true\n\n```java\nif (hasTasks() && wakenUp.compareAndSet(false, true)) {\n    selector.selectNow();\n    selectCnt = 1;\n    break;\n}\n```\n\n> 随后，执行select操作，该操作在超时时间到期前会一直阻塞，超时时间是截至到最早的那个定时任务到期\n>\n> 超时后会进行一系列判断，比如selectedKey的数量，wakeup状态，是否有待执行任务等等，如果满足条件则马上退出轮询\n\n```java\nint selectedKeys = selector.select(timeoutMillis);\nselectCnt ++;\nif (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) {\n    break;\n}\n```\n\n> 最后，由于jdk nio有一个bug会使`Selector`无法成功地阻塞规定的时间，造成无限空轮询，进而导致CPU 100%，netty使用了某种措施规避了这个bug，在一次成功的select操作后，如果仍然无需退出轮询，则判断如果selectCnt（已轮询的次数）大于某个阈值（默认512）后，直接重建`Selector`\n\n```java\nlong time = System.nanoTime();\nif (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) >= currentTimeNanos) {\n    // select持续时间大于规定的超时时间timeoutMillis，说明本次select有效，重置selectCnt并进行下一次轮询\n    selectCnt = 1;\n} else if (SELECTOR_AUTO_REBUILD_THRESHOLD > 0 &&\n        selectCnt >= SELECTOR_AUTO_REBUILD_THRESHOLD) {\n    // selectCnt已经达到空轮询阈值，立即重建Selector\n    rebuildSelector();\n    selector = this.selector;\n    // 进行一次立即返回的select并重置selectCnt\n    selector.selectNow();\n    selectCnt = 1;\n    break;\n}\n```\n\n\n\n##### 处理产生的IO事件\n\n进行完一次成功的select操作后，需要处理产生的IO事件，其中，`ioRatio`是处理IO事件和处理非IO任务（即用户自定义handler的任务）的百分比，默认是50，即IO事件和非IO事件所占用时间一半一半；如果`ioRatio`为100，则对两种事件没有时间限制，代码如下，\n\n```java\nfinal int ioRatio = this.ioRatio;\nif (ioRatio == 100) {\n    try {\n        processSelectedKeys();\n    } finally {\n        // 保证一定会执行任务队列中的任务\n        runAllTasks();\n    }\n} else {\n    final long ioStartTime = System.nanoTime();\n    try {\n        processSelectedKeys();\n    } finally {\n        final long ioTime = System.nanoTime() - ioStartTime;\n        // 非IO任务耗费的时间不能超过ioRatio的比率\n        runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n    }\n}\n```\n\nselect完成后得到的`SelectionKey`位于`selectedKeys`这个成员变量中，其是由netty自己基于`AbstractSet`实现的一个类：`SelectedSelectionKeySet`，在jdk nio `SelectorImpl`中`HashSet`的基础上做了一些优化，将保存`SelectionKey`的容器设置为数组，相比于`HashSet`从时间复杂度和内存占用上都有一定的优化\n\n由`processSelectedKeysOptimized(SelectionKey[] selectedKeys)`方法处理获得的`selectedKeys`：\n\n```java\nprivate void processSelectedKeysOptimized(SelectionKey[] selectedKeys) {\n    for (int i = 0;; i ++) {\n        final SelectionKey k = selectedKeys[i];\n        if (k == null) {\n            break;\n        }\n        selectedKeys[i] = null;\n        // 1. 取出attachment，可能是AbstractNioChannel或者NioTask\n        final Object a = k.attachment();\n        if (a instanceof AbstractNioChannel) {\n            processSelectedKey(k, (AbstractNioChannel) a);\n        } else {\n            @SuppressWarnings(\"unchecked\")\n            NioTask<SelectableChannel> task = (NioTask<SelectableChannel>) a;\n            processSelectedKey(k, task);\n        }\n        if (needsToSelectAgain) {\n            for (;;) {\n                i++;\n                if (selectedKeys[i] == null) {\n                    break;\n                }\n                selectedKeys[i] = null;\n            }\n            selectAgain();\n            selectedKeys = this.selectedKeys.flip();\n            i = -1;\n        }\n    }\n}\n```\n\n遍历`selectedKeys`，每一次循环分为以下几步：\n\n1. 取出`SelectionKey`，将`selectedKeys`数组的当前位置设置为null，在相关的`Channel`关闭后，gc会将这个`SelectionKey`及其与之关联的`Channel`回收掉，防止内存泄漏\n2. 从`SelectionKey`中取出`Attachment`，可能是`AbstractNioChannel`或者`NioTask`，其中`AbstractNioChannel`相关的事件由Netty框架处理，`NioTask`相关的事件由用户自己注册并处理；主要关注`AbstractNioChannel`及其处理方法`processSelectedKey(k, (AbstractNioChannel) a)`\n3. 当前`SelectionKey`处理完成后判断是否该再来一次select轮询，当`needsToSelectAgain`为true时则需要再来一次轮询\n\n> 为何要在处理SelectionKey期间重新进行select轮询？\n>\n> 因为随时都有Channel断线，Channel断线后会执行cancel()方法取消对应的SelectionKey，为了保证现存的SelectionKey都是有效的，需要定期（默认256次cancel后）清理SelectionKey的集合，保证现存的SelectionKey时及时有效的\n\n处理完`SelectionKey`后就是最后一步：处理eventLoop任务队列中的任务\n\n##### 处理eventLoop任务队列中的任务\n\neventLoop任务队列是`taskQueue`，其实现默认是`jctools`包中的同步队列`MpscChunkedArrayQueue`，即多生产者单消费者队列，针对并发写的场景进行了一些优化\n\n`taskQueue`任务队列中的任务主要来自三个途径：\n\n1. 用户调用`eventLoop.execute()`执行的自定义任务，会直接向`taskQueue`添加任务\n2. channel触发的各种事件，比如往channel中写数据会产生出站事件，会向`taskQueue`添加一个`WriteTask`或者`WriteAndFlushTask`\n3. 用户自定义的定时任务，通过调用`eventLoop().schedule()`方法添加一个定时任务用于在一定时间后执行任务，保存定时任务的队列`scheduledTaskQueue`是一个优先队列`PriorityQueue`\n\n###### 自定义任务\n\n用户可以在任意一个handler通过以下方式获取eventLoop实例并调用execute()添加自定义任务，然后由eventLoop线程来执行任务:\n\n```java\nctx.channel().eventLoop().execute(() -> {\n    System.out.println(\"task\");\n});\n```\n\nexecute()方法部分代码如下：\n\n```java\npublic void execute(Runnable task) {\n    //...\n    boolean inEventLoop = inEventLoop();\n    if (inEventLoop) {\n        addTask(task);\n    } else {\n        startThread();\n        addTask(task);\n        if (isShutdown() && removeTask(task)) {\n            reject();\n        }\n    }\n    //...\n}\n```\n\n首先通过inEventLoop()方法判断当前执行线程是否是eventLoop线程，如果不是的话则要先启动执行线程，保证执行任务的始终是唯一确定的eventLoop线程\n\n> 在netty的线程模型中，每一个eventLoop对应一个唯一的执行器ThreadPerTaskExecutor，每个执行器都会提供一个FastThreadLocalThread线程实例，这个线程就是eventLoop的reactor线程，任务队列中的所有任务在执行前都会判断该任务是否由reactor线程来执行，保证了eventLoop的核心逻辑的单线程环境\n\n###### channel事件任务\n\n\n\n\n\n\n\n###### 自定义定时任务","slug":"Netty-NioEventLoop的reactor线程模型","published":1,"updated":"2021-05-31T03:06:33.195Z","_id":"ckf0h31h00007actsizyxplq6","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"Netty-NioEventLoop的reactor线程模型\"><a href=\"#Netty-NioEventLoop的reactor线程模型\" class=\"headerlink\" title=\"Netty-NioEventLoop的reactor线程模型\"></a>Netty-NioEventLoop的reactor线程模型</h3><p>Netty中reactor的核心逻辑主要由<code>NioEventLoop</code>及其父类<code>SingleThreadEventExecutor</code>和<code>SingleThreadEventLoop</code>这几个类进行实现，其中<code>NioEventLoop</code>的线程就是主要负责IO事件轮询工作的线程<br><a id=\"more\"></a></p>\n<h4 id=\"NioEventLoop的run方法\"><a href=\"#NioEventLoop的run方法\" class=\"headerlink\" title=\"NioEventLoop的run方法\"></a>NioEventLoop的run方法</h4><p>每一个<code>NioEventLoop</code>都会封装一个核心执行器<code>ThreadPerTaskExecutor</code>，<code>NioEventLoop</code>依靠这个执行器来启动它自己的核心线程<code>FastThreadLocalThread</code>，即eventLoop的reactor线程，由reactor线程来执行<code>NioEventLoop</code>的核心逻辑，即<code>run()</code>方法，包括NIO的select过程，处理IO事件并执行任务，以下是<code>NioEventLoop</code>的<code>run()</code>方法的源码：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">switch</span> (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">case</span> SelectStrategy.CONTINUE:</span><br><span class=\"line\">                    <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">                <span class=\"keyword\">case</span> SelectStrategy.SELECT:</span><br><span class=\"line\">                    select(wakenUp.getAndSet(<span class=\"keyword\">false</span>));</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (wakenUp.get()) &#123;</span><br><span class=\"line\">                        selector.wakeup();</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                <span class=\"keyword\">default</span>:</span><br><span class=\"line\">                    <span class=\"comment\">// fallthrough</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            cancelledKeys = <span class=\"number\">0</span>;</span><br><span class=\"line\">            needsToSelectAgain = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">            <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ioRatio = <span class=\"keyword\">this</span>.ioRatio;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (ioRatio == <span class=\"number\">100</span>) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    processSelectedKeys();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// Ensure we always run tasks.</span></span><br><span class=\"line\">                    runAllTasks();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioStartTime = System.nanoTime();</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    processSelectedKeys();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// Ensure we always run tasks.</span></span><br><span class=\"line\">                    <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioTime = System.nanoTime() - ioStartTime;</span><br><span class=\"line\">                    runAllTasks(ioTime * (<span class=\"number\">100</span> - ioRatio) / ioRatio);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (Throwable t) &#123;</span><br><span class=\"line\">            handleLoopException(t);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// Always handle shutdown even if the loop processing threw an exception.</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (isShuttingDown()) &#123;</span><br><span class=\"line\">                closeAll();</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (confirmShutdown()) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">return</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (Throwable t) &#123;</span><br><span class=\"line\">            handleLoopException(t);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这个<code>run()</code>方法是一个死循环，单次循环的执行逻辑顺序大致如下：</p>\n<blockquote>\n<ol>\n<li>对注册到当前reactor线程selector的所有channel事件进行轮询</li>\n<li>处理产生的IO事件</li>\n<li>处理eventLoop任务队列中的任务</li>\n</ol>\n</blockquote>\n<h5 id=\"channel事件轮询\"><a href=\"#channel事件轮询\" class=\"headerlink\" title=\"channel事件轮询\"></a>channel事件轮询</h5><p>这个过程主要是基于jdk nio提供的<code>Selector</code>来实现，是eventLoop最核心的操作，对注册的channel IO事件进行轮询并取出已经产生的IO事件供后续的处理，这个操作基于操作系统底层的<code>epoll</code>等模型实现：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select(wakenUp.getAndSet(<span class=\"keyword\">false</span>));</span><br><span class=\"line\"><span class=\"keyword\">if</span> (wakenUp.get()) &#123;</span><br><span class=\"line\">    selector.wakeup();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>selector.wakeup()</code>这个操作能够解除阻塞在<code>Selector.select()</code>或者<code>select(long)</code>上的线程并立即返回，如果<code>Selector</code>当前没有阻塞在select操作上，则本次wakeup调用将作用于下一次select</p>\n<p>什么时候需要唤醒？</p>\n<blockquote>\n<ol>\n<li>注册了新的channel或者原有channel注册了新的事件</li>\n<li>channel关闭，取消注册</li>\n<li>优先级更高的事件触发，需要及时处理（如急需处理的普通任务或定时任务）</li>\n</ol>\n</blockquote>\n<p><code>NioEventLoop</code>的<code>select(boolean oldWakenUp)</code>方法内部是一个死循环，在对<code>Selector</code>进行轮询select时，基本上遵循以下顺序：</p>\n<blockquote>\n<p>首先，如果eventLoop中有定时任务快到期了则立刻退出轮询，执行一次非阻塞select操作并停止select</p>\n</blockquote>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">long</span> timeoutMillis = (selectDeadLineNanos - currentTimeNanos + <span class=\"number\">500000L</span>) / <span class=\"number\">1000000L</span>;</span><br><span class=\"line\"><span class=\"keyword\">if</span> (timeoutMillis &lt;= <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (selectCnt == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        selector.selectNow();</span><br><span class=\"line\">        selectCnt = <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>然后，检测任务队列中如果有待执行的任务，则执行一次非阻塞select操作并立刻退出，需要将wakeup状态设置为true</p>\n</blockquote>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (hasTasks() &amp;&amp; wakenUp.compareAndSet(<span class=\"keyword\">false</span>, <span class=\"keyword\">true</span>)) &#123;</span><br><span class=\"line\">    selector.selectNow();</span><br><span class=\"line\">    selectCnt = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>随后，执行select操作，该操作在超时时间到期前会一直阻塞，超时时间是截至到最早的那个定时任务到期</p>\n<p>超时后会进行一系列判断，比如selectedKey的数量，wakeup状态，是否有待执行任务等等，如果满足条件则马上退出轮询</p>\n</blockquote>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> selectedKeys = selector.select(timeoutMillis);</span><br><span class=\"line\">selectCnt ++;</span><br><span class=\"line\"><span class=\"keyword\">if</span> (selectedKeys != <span class=\"number\">0</span> || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>最后，由于jdk nio有一个bug会使<code>Selector</code>无法成功地阻塞规定的时间，造成无限空轮询，进而导致CPU 100%，netty使用了某种措施规避了这个bug，在一次成功的select操作后，如果仍然无需退出轮询，则判断如果selectCnt（已轮询的次数）大于某个阈值（默认512）后，直接重建<code>Selector</code></p>\n</blockquote>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">long</span> time = System.nanoTime();</span><br><span class=\"line\"><span class=\"keyword\">if</span> (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// select持续时间大于规定的超时时间timeoutMillis，说明本次select有效，重置selectCnt并进行下一次轮询</span></span><br><span class=\"line\">    selectCnt = <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; <span class=\"number\">0</span> &amp;&amp;</span><br><span class=\"line\">        selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// selectCnt已经达到空轮询阈值，立即重建Selector</span></span><br><span class=\"line\">    rebuildSelector();</span><br><span class=\"line\">    selector = <span class=\"keyword\">this</span>.selector;</span><br><span class=\"line\">    <span class=\"comment\">// 进行一次立即返回的select并重置selectCnt</span></span><br><span class=\"line\">    selector.selectNow();</span><br><span class=\"line\">    selectCnt = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"处理产生的IO事件\"><a href=\"#处理产生的IO事件\" class=\"headerlink\" title=\"处理产生的IO事件\"></a>处理产生的IO事件</h5><p>进行完一次成功的select操作后，需要处理产生的IO事件，其中，<code>ioRatio</code>是处理IO事件和处理非IO任务（即用户自定义handler的任务）的百分比，默认是50，即IO事件和非IO事件所占用时间一半一半；如果<code>ioRatio</code>为100，则对两种事件没有时间限制，代码如下，</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ioRatio = <span class=\"keyword\">this</span>.ioRatio;</span><br><span class=\"line\"><span class=\"keyword\">if</span> (ioRatio == <span class=\"number\">100</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        processSelectedKeys();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 保证一定会执行任务队列中的任务</span></span><br><span class=\"line\">        runAllTasks();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioStartTime = System.nanoTime();</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        processSelectedKeys();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioTime = System.nanoTime() - ioStartTime;</span><br><span class=\"line\">        <span class=\"comment\">// 非IO任务耗费的时间不能超过ioRatio的比率</span></span><br><span class=\"line\">        runAllTasks(ioTime * (<span class=\"number\">100</span> - ioRatio) / ioRatio);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>select完成后得到的<code>SelectionKey</code>位于<code>selectedKeys</code>这个成员变量中，其是由netty自己基于<code>AbstractSet</code>实现的一个类：<code>SelectedSelectionKeySet</code>，在jdk nio <code>SelectorImpl</code>中<code>HashSet</code>的基础上做了一些优化，将保存<code>SelectionKey</code>的容器设置为数组，相比于<code>HashSet</code>从时间复杂度和内存占用上都有一定的优化</p>\n<p>由<code>processSelectedKeysOptimized(SelectionKey[] selectedKeys)</code>方法处理获得的<code>selectedKeys</code>：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">processSelectedKeysOptimized</span><span class=\"params\">(SelectionKey[] selectedKeys)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;; i ++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> SelectionKey k = selectedKeys[i];</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (k == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        selectedKeys[i] = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"comment\">// 1. 取出attachment，可能是AbstractNioChannel或者NioTask</span></span><br><span class=\"line\">        <span class=\"keyword\">final</span> Object a = k.attachment();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (a <span class=\"keyword\">instanceof</span> AbstractNioChannel) &#123;</span><br><span class=\"line\">            processSelectedKey(k, (AbstractNioChannel) a);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"meta\">@SuppressWarnings</span>(<span class=\"string\">\"unchecked\"</span>)</span><br><span class=\"line\">            NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a;</span><br><span class=\"line\">            processSelectedKey(k, task);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (needsToSelectAgain) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">                i++;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (selectedKeys[i] == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                selectedKeys[i] = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            selectAgain();</span><br><span class=\"line\">            selectedKeys = <span class=\"keyword\">this</span>.selectedKeys.flip();</span><br><span class=\"line\">            i = -<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>遍历<code>selectedKeys</code>，每一次循环分为以下几步：</p>\n<ol>\n<li>取出<code>SelectionKey</code>，将<code>selectedKeys</code>数组的当前位置设置为null，在相关的<code>Channel</code>关闭后，gc会将这个<code>SelectionKey</code>及其与之关联的<code>Channel</code>回收掉，防止内存泄漏</li>\n<li>从<code>SelectionKey</code>中取出<code>Attachment</code>，可能是<code>AbstractNioChannel</code>或者<code>NioTask</code>，其中<code>AbstractNioChannel</code>相关的事件由Netty框架处理，<code>NioTask</code>相关的事件由用户自己注册并处理；主要关注<code>AbstractNioChannel</code>及其处理方法<code>processSelectedKey(k, (AbstractNioChannel) a)</code></li>\n<li>当前<code>SelectionKey</code>处理完成后判断是否该再来一次select轮询，当<code>needsToSelectAgain</code>为true时则需要再来一次轮询</li>\n</ol>\n<blockquote>\n<p>为何要在处理SelectionKey期间重新进行select轮询？</p>\n<p>因为随时都有Channel断线，Channel断线后会执行cancel()方法取消对应的SelectionKey，为了保证现存的SelectionKey都是有效的，需要定期（默认256次cancel后）清理SelectionKey的集合，保证现存的SelectionKey时及时有效的</p>\n</blockquote>\n<p>处理完<code>SelectionKey</code>后就是最后一步：处理eventLoop任务队列中的任务</p>\n<h5 id=\"处理eventLoop任务队列中的任务\"><a href=\"#处理eventLoop任务队列中的任务\" class=\"headerlink\" title=\"处理eventLoop任务队列中的任务\"></a>处理eventLoop任务队列中的任务</h5><p>eventLoop任务队列是<code>taskQueue</code>，其实现默认是<code>jctools</code>包中的同步队列<code>MpscChunkedArrayQueue</code>，即多生产者单消费者队列，针对并发写的场景进行了一些优化</p>\n<p><code>taskQueue</code>任务队列中的任务主要来自三个途径：</p>\n<ol>\n<li>用户调用<code>eventLoop.execute()</code>执行的自定义任务，会直接向<code>taskQueue</code>添加任务</li>\n<li>channel触发的各种事件，比如往channel中写数据会产生出站事件，会向<code>taskQueue</code>添加一个<code>WriteTask</code>或者<code>WriteAndFlushTask</code></li>\n<li>用户自定义的定时任务，通过调用<code>eventLoop().schedule()</code>方法添加一个定时任务用于在一定时间后执行任务，保存定时任务的队列<code>scheduledTaskQueue</code>是一个优先队列<code>PriorityQueue</code></li>\n</ol>\n<h6 id=\"自定义任务\"><a href=\"#自定义任务\" class=\"headerlink\" title=\"自定义任务\"></a>自定义任务</h6><p>用户可以在任意一个handler通过以下方式获取eventLoop实例并调用execute()添加自定义任务，然后由eventLoop线程来执行任务:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ctx.channel().eventLoop().execute(() -&gt; &#123;</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"task\"</span>);</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>execute()方法部分代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">execute</span><span class=\"params\">(Runnable task)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//...</span></span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> inEventLoop = inEventLoop();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (inEventLoop) &#123;</span><br><span class=\"line\">        addTask(task);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        startThread();</span><br><span class=\"line\">        addTask(task);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (isShutdown() &amp;&amp; removeTask(task)) &#123;</span><br><span class=\"line\">            reject();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>首先通过inEventLoop()方法判断当前执行线程是否是eventLoop线程，如果不是的话则要先启动执行线程，保证执行任务的始终是唯一确定的eventLoop线程</p>\n<blockquote>\n<p>在netty的线程模型中，每一个eventLoop对应一个唯一的执行器ThreadPerTaskExecutor，每个执行器都会提供一个FastThreadLocalThread线程实例，这个线程就是eventLoop的reactor线程，任务队列中的所有任务在执行前都会判断该任务是否由reactor线程来执行，保证了eventLoop的核心逻辑的单线程环境</p>\n</blockquote>\n<h6 id=\"channel事件任务\"><a href=\"#channel事件任务\" class=\"headerlink\" title=\"channel事件任务\"></a>channel事件任务</h6><h6 id=\"自定义定时任务\"><a href=\"#自定义定时任务\" class=\"headerlink\" title=\"自定义定时任务\"></a>自定义定时任务</h6>","site":{"data":{}},"excerpt":"<h3 id=\"Netty-NioEventLoop的reactor线程模型\"><a href=\"#Netty-NioEventLoop的reactor线程模型\" class=\"headerlink\" title=\"Netty-NioEventLoop的reactor线程模型\"></a>Netty-NioEventLoop的reactor线程模型</h3><p>Netty中reactor的核心逻辑主要由<code>NioEventLoop</code>及其父类<code>SingleThreadEventExecutor</code>和<code>SingleThreadEventLoop</code>这几个类进行实现，其中<code>NioEventLoop</code>的线程就是主要负责IO事件轮询工作的线程<br>","more":"</p>\n<h4 id=\"NioEventLoop的run方法\"><a href=\"#NioEventLoop的run方法\" class=\"headerlink\" title=\"NioEventLoop的run方法\"></a>NioEventLoop的run方法</h4><p>每一个<code>NioEventLoop</code>都会封装一个核心执行器<code>ThreadPerTaskExecutor</code>，<code>NioEventLoop</code>依靠这个执行器来启动它自己的核心线程<code>FastThreadLocalThread</code>，即eventLoop的reactor线程，由reactor线程来执行<code>NioEventLoop</code>的核心逻辑，即<code>run()</code>方法，包括NIO的select过程，处理IO事件并执行任务，以下是<code>NioEventLoop</code>的<code>run()</code>方法的源码：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">switch</span> (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">case</span> SelectStrategy.CONTINUE:</span><br><span class=\"line\">                    <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">                <span class=\"keyword\">case</span> SelectStrategy.SELECT:</span><br><span class=\"line\">                    select(wakenUp.getAndSet(<span class=\"keyword\">false</span>));</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (wakenUp.get()) &#123;</span><br><span class=\"line\">                        selector.wakeup();</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                <span class=\"keyword\">default</span>:</span><br><span class=\"line\">                    <span class=\"comment\">// fallthrough</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            cancelledKeys = <span class=\"number\">0</span>;</span><br><span class=\"line\">            needsToSelectAgain = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">            <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ioRatio = <span class=\"keyword\">this</span>.ioRatio;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (ioRatio == <span class=\"number\">100</span>) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    processSelectedKeys();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// Ensure we always run tasks.</span></span><br><span class=\"line\">                    runAllTasks();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioStartTime = System.nanoTime();</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    processSelectedKeys();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// Ensure we always run tasks.</span></span><br><span class=\"line\">                    <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioTime = System.nanoTime() - ioStartTime;</span><br><span class=\"line\">                    runAllTasks(ioTime * (<span class=\"number\">100</span> - ioRatio) / ioRatio);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (Throwable t) &#123;</span><br><span class=\"line\">            handleLoopException(t);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// Always handle shutdown even if the loop processing threw an exception.</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (isShuttingDown()) &#123;</span><br><span class=\"line\">                closeAll();</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (confirmShutdown()) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">return</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (Throwable t) &#123;</span><br><span class=\"line\">            handleLoopException(t);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这个<code>run()</code>方法是一个死循环，单次循环的执行逻辑顺序大致如下：</p>\n<blockquote>\n<ol>\n<li>对注册到当前reactor线程selector的所有channel事件进行轮询</li>\n<li>处理产生的IO事件</li>\n<li>处理eventLoop任务队列中的任务</li>\n</ol>\n</blockquote>\n<h5 id=\"channel事件轮询\"><a href=\"#channel事件轮询\" class=\"headerlink\" title=\"channel事件轮询\"></a>channel事件轮询</h5><p>这个过程主要是基于jdk nio提供的<code>Selector</code>来实现，是eventLoop最核心的操作，对注册的channel IO事件进行轮询并取出已经产生的IO事件供后续的处理，这个操作基于操作系统底层的<code>epoll</code>等模型实现：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select(wakenUp.getAndSet(<span class=\"keyword\">false</span>));</span><br><span class=\"line\"><span class=\"keyword\">if</span> (wakenUp.get()) &#123;</span><br><span class=\"line\">    selector.wakeup();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>selector.wakeup()</code>这个操作能够解除阻塞在<code>Selector.select()</code>或者<code>select(long)</code>上的线程并立即返回，如果<code>Selector</code>当前没有阻塞在select操作上，则本次wakeup调用将作用于下一次select</p>\n<p>什么时候需要唤醒？</p>\n<blockquote>\n<ol>\n<li>注册了新的channel或者原有channel注册了新的事件</li>\n<li>channel关闭，取消注册</li>\n<li>优先级更高的事件触发，需要及时处理（如急需处理的普通任务或定时任务）</li>\n</ol>\n</blockquote>\n<p><code>NioEventLoop</code>的<code>select(boolean oldWakenUp)</code>方法内部是一个死循环，在对<code>Selector</code>进行轮询select时，基本上遵循以下顺序：</p>\n<blockquote>\n<p>首先，如果eventLoop中有定时任务快到期了则立刻退出轮询，执行一次非阻塞select操作并停止select</p>\n</blockquote>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">long</span> timeoutMillis = (selectDeadLineNanos - currentTimeNanos + <span class=\"number\">500000L</span>) / <span class=\"number\">1000000L</span>;</span><br><span class=\"line\"><span class=\"keyword\">if</span> (timeoutMillis &lt;= <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (selectCnt == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        selector.selectNow();</span><br><span class=\"line\">        selectCnt = <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>然后，检测任务队列中如果有待执行的任务，则执行一次非阻塞select操作并立刻退出，需要将wakeup状态设置为true</p>\n</blockquote>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (hasTasks() &amp;&amp; wakenUp.compareAndSet(<span class=\"keyword\">false</span>, <span class=\"keyword\">true</span>)) &#123;</span><br><span class=\"line\">    selector.selectNow();</span><br><span class=\"line\">    selectCnt = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>随后，执行select操作，该操作在超时时间到期前会一直阻塞，超时时间是截至到最早的那个定时任务到期</p>\n<p>超时后会进行一系列判断，比如selectedKey的数量，wakeup状态，是否有待执行任务等等，如果满足条件则马上退出轮询</p>\n</blockquote>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> selectedKeys = selector.select(timeoutMillis);</span><br><span class=\"line\">selectCnt ++;</span><br><span class=\"line\"><span class=\"keyword\">if</span> (selectedKeys != <span class=\"number\">0</span> || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>最后，由于jdk nio有一个bug会使<code>Selector</code>无法成功地阻塞规定的时间，造成无限空轮询，进而导致CPU 100%，netty使用了某种措施规避了这个bug，在一次成功的select操作后，如果仍然无需退出轮询，则判断如果selectCnt（已轮询的次数）大于某个阈值（默认512）后，直接重建<code>Selector</code></p>\n</blockquote>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">long</span> time = System.nanoTime();</span><br><span class=\"line\"><span class=\"keyword\">if</span> (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// select持续时间大于规定的超时时间timeoutMillis，说明本次select有效，重置selectCnt并进行下一次轮询</span></span><br><span class=\"line\">    selectCnt = <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; <span class=\"number\">0</span> &amp;&amp;</span><br><span class=\"line\">        selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// selectCnt已经达到空轮询阈值，立即重建Selector</span></span><br><span class=\"line\">    rebuildSelector();</span><br><span class=\"line\">    selector = <span class=\"keyword\">this</span>.selector;</span><br><span class=\"line\">    <span class=\"comment\">// 进行一次立即返回的select并重置selectCnt</span></span><br><span class=\"line\">    selector.selectNow();</span><br><span class=\"line\">    selectCnt = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"处理产生的IO事件\"><a href=\"#处理产生的IO事件\" class=\"headerlink\" title=\"处理产生的IO事件\"></a>处理产生的IO事件</h5><p>进行完一次成功的select操作后，需要处理产生的IO事件，其中，<code>ioRatio</code>是处理IO事件和处理非IO任务（即用户自定义handler的任务）的百分比，默认是50，即IO事件和非IO事件所占用时间一半一半；如果<code>ioRatio</code>为100，则对两种事件没有时间限制，代码如下，</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ioRatio = <span class=\"keyword\">this</span>.ioRatio;</span><br><span class=\"line\"><span class=\"keyword\">if</span> (ioRatio == <span class=\"number\">100</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        processSelectedKeys();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 保证一定会执行任务队列中的任务</span></span><br><span class=\"line\">        runAllTasks();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioStartTime = System.nanoTime();</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        processSelectedKeys();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioTime = System.nanoTime() - ioStartTime;</span><br><span class=\"line\">        <span class=\"comment\">// 非IO任务耗费的时间不能超过ioRatio的比率</span></span><br><span class=\"line\">        runAllTasks(ioTime * (<span class=\"number\">100</span> - ioRatio) / ioRatio);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>select完成后得到的<code>SelectionKey</code>位于<code>selectedKeys</code>这个成员变量中，其是由netty自己基于<code>AbstractSet</code>实现的一个类：<code>SelectedSelectionKeySet</code>，在jdk nio <code>SelectorImpl</code>中<code>HashSet</code>的基础上做了一些优化，将保存<code>SelectionKey</code>的容器设置为数组，相比于<code>HashSet</code>从时间复杂度和内存占用上都有一定的优化</p>\n<p>由<code>processSelectedKeysOptimized(SelectionKey[] selectedKeys)</code>方法处理获得的<code>selectedKeys</code>：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">processSelectedKeysOptimized</span><span class=\"params\">(SelectionKey[] selectedKeys)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;; i ++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> SelectionKey k = selectedKeys[i];</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (k == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        selectedKeys[i] = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"comment\">// 1. 取出attachment，可能是AbstractNioChannel或者NioTask</span></span><br><span class=\"line\">        <span class=\"keyword\">final</span> Object a = k.attachment();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (a <span class=\"keyword\">instanceof</span> AbstractNioChannel) &#123;</span><br><span class=\"line\">            processSelectedKey(k, (AbstractNioChannel) a);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"meta\">@SuppressWarnings</span>(<span class=\"string\">\"unchecked\"</span>)</span><br><span class=\"line\">            NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a;</span><br><span class=\"line\">            processSelectedKey(k, task);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (needsToSelectAgain) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">                i++;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (selectedKeys[i] == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                selectedKeys[i] = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            selectAgain();</span><br><span class=\"line\">            selectedKeys = <span class=\"keyword\">this</span>.selectedKeys.flip();</span><br><span class=\"line\">            i = -<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>遍历<code>selectedKeys</code>，每一次循环分为以下几步：</p>\n<ol>\n<li>取出<code>SelectionKey</code>，将<code>selectedKeys</code>数组的当前位置设置为null，在相关的<code>Channel</code>关闭后，gc会将这个<code>SelectionKey</code>及其与之关联的<code>Channel</code>回收掉，防止内存泄漏</li>\n<li>从<code>SelectionKey</code>中取出<code>Attachment</code>，可能是<code>AbstractNioChannel</code>或者<code>NioTask</code>，其中<code>AbstractNioChannel</code>相关的事件由Netty框架处理，<code>NioTask</code>相关的事件由用户自己注册并处理；主要关注<code>AbstractNioChannel</code>及其处理方法<code>processSelectedKey(k, (AbstractNioChannel) a)</code></li>\n<li>当前<code>SelectionKey</code>处理完成后判断是否该再来一次select轮询，当<code>needsToSelectAgain</code>为true时则需要再来一次轮询</li>\n</ol>\n<blockquote>\n<p>为何要在处理SelectionKey期间重新进行select轮询？</p>\n<p>因为随时都有Channel断线，Channel断线后会执行cancel()方法取消对应的SelectionKey，为了保证现存的SelectionKey都是有效的，需要定期（默认256次cancel后）清理SelectionKey的集合，保证现存的SelectionKey时及时有效的</p>\n</blockquote>\n<p>处理完<code>SelectionKey</code>后就是最后一步：处理eventLoop任务队列中的任务</p>\n<h5 id=\"处理eventLoop任务队列中的任务\"><a href=\"#处理eventLoop任务队列中的任务\" class=\"headerlink\" title=\"处理eventLoop任务队列中的任务\"></a>处理eventLoop任务队列中的任务</h5><p>eventLoop任务队列是<code>taskQueue</code>，其实现默认是<code>jctools</code>包中的同步队列<code>MpscChunkedArrayQueue</code>，即多生产者单消费者队列，针对并发写的场景进行了一些优化</p>\n<p><code>taskQueue</code>任务队列中的任务主要来自三个途径：</p>\n<ol>\n<li>用户调用<code>eventLoop.execute()</code>执行的自定义任务，会直接向<code>taskQueue</code>添加任务</li>\n<li>channel触发的各种事件，比如往channel中写数据会产生出站事件，会向<code>taskQueue</code>添加一个<code>WriteTask</code>或者<code>WriteAndFlushTask</code></li>\n<li>用户自定义的定时任务，通过调用<code>eventLoop().schedule()</code>方法添加一个定时任务用于在一定时间后执行任务，保存定时任务的队列<code>scheduledTaskQueue</code>是一个优先队列<code>PriorityQueue</code></li>\n</ol>\n<h6 id=\"自定义任务\"><a href=\"#自定义任务\" class=\"headerlink\" title=\"自定义任务\"></a>自定义任务</h6><p>用户可以在任意一个handler通过以下方式获取eventLoop实例并调用execute()添加自定义任务，然后由eventLoop线程来执行任务:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ctx.channel().eventLoop().execute(() -&gt; &#123;</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"task\"</span>);</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>execute()方法部分代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">execute</span><span class=\"params\">(Runnable task)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//...</span></span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> inEventLoop = inEventLoop();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (inEventLoop) &#123;</span><br><span class=\"line\">        addTask(task);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        startThread();</span><br><span class=\"line\">        addTask(task);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (isShutdown() &amp;&amp; removeTask(task)) &#123;</span><br><span class=\"line\">            reject();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>首先通过inEventLoop()方法判断当前执行线程是否是eventLoop线程，如果不是的话则要先启动执行线程，保证执行任务的始终是唯一确定的eventLoop线程</p>\n<blockquote>\n<p>在netty的线程模型中，每一个eventLoop对应一个唯一的执行器ThreadPerTaskExecutor，每个执行器都会提供一个FastThreadLocalThread线程实例，这个线程就是eventLoop的reactor线程，任务队列中的所有任务在执行前都会判断该任务是否由reactor线程来执行，保证了eventLoop的核心逻辑的单线程环境</p>\n</blockquote>\n<h6 id=\"channel事件任务\"><a href=\"#channel事件任务\" class=\"headerlink\" title=\"channel事件任务\"></a>channel事件任务</h6><h6 id=\"自定义定时任务\"><a href=\"#自定义定时任务\" class=\"headerlink\" title=\"自定义定时任务\"></a>自定义定时任务</h6>"},{"title":"Nginx -- root和alias路径映射","author":"天渊","date":"2019-03-18T04:40:00.000Z","_content":"在nginx中，`root`和`alias`命令都用于将http请求和服务器上的资源地址进行映射，不过使用方式不太相同\n<!--more-->\n### 使用范围\n两个命令在nginx.conf中的作用范围如下：\n- root: http、server、location和if中均可配置，用于指定当前范围的根路径\n- alias: 尽在location中有效\n\n### 使用方法\nroot与alias主要区别在于nginx如何解释location后面的uri，这会使两者分别以不同的方式将请求映射到服务器文件上，两者使用方法均为 `root/alisa path`\n#### root映射方式：\n\nroot路径 + location路径\n如下配置中，nginx将会把`/blog/***`这样的请求路径映射到` /root/deploy/static-file/blog`目录下的资源中，因此`/blog/index.html`请求得到的资源即为`/root/deploy/static-file/blog/index.html`\n\n```lua\nlocation /blog {\n    root /root/deploy/static-file;\n}\n```\n\n#### alias映射方式：\n\n  alias路径直接替换原请求路径\n  对于alias，如下配置，`/blog/index.html`请求得到的资源仍然为`/root/deploy/static-file/blog/index.html`，\n\n  ```lua\nlocation /blog {\n    alias /root/deploy/static-file/blog/;\n}\n  ```\n  因此root和alias主要区别在于，当映射文件路径的时候，前者用于指定根路径，将原请求在根路径的基础上组合成新的路径，而后者用于指定url别名，将该别名作为新路径替换掉原请求路径\n\n**注意**：alias后面的路径必须加`/`正斜杠\n\n### proxy_pass\n相应的，`proxy_pass`作为反响代理时，对`/`正斜杠也有一定的讲究\n##### path加正斜杠\n`proxy_pass`的path加正斜杠时，用法与`alias`一样，都是用新路径替换掉原路径：\n\n```lua\nlocation /tomcat {\n    proxy_pass http://localhost:8080/;\n}\n```\n\n如上配置，nginx监听80端口，当请求`localhost/tomcat`时，请求转发到`http://localhost:8080/`\n\n##### path不加正斜杠\n\n```lua\nlocation /tomcat {\n    proxy_pass http://localhost:8080;\n}\n```\n\n如果去掉正斜杠，当请求`localhost/tomcat`时，请求转发到`http://localhost:8080/tomcat`\n\n这个地方容易踩坑，需要注意","source":"_posts/Nginx-root和alias路径映射.md","raw":"title: Nginx -- root和alias路径映射\nauthor: 天渊\ntags:\n  - Nginx\ncategories:\n  - 基础知识\ndate: 2019-03-18 12:40:00\n---\n在nginx中，`root`和`alias`命令都用于将http请求和服务器上的资源地址进行映射，不过使用方式不太相同\n<!--more-->\n### 使用范围\n两个命令在nginx.conf中的作用范围如下：\n- root: http、server、location和if中均可配置，用于指定当前范围的根路径\n- alias: 尽在location中有效\n\n### 使用方法\nroot与alias主要区别在于nginx如何解释location后面的uri，这会使两者分别以不同的方式将请求映射到服务器文件上，两者使用方法均为 `root/alisa path`\n#### root映射方式：\n\nroot路径 + location路径\n如下配置中，nginx将会把`/blog/***`这样的请求路径映射到` /root/deploy/static-file/blog`目录下的资源中，因此`/blog/index.html`请求得到的资源即为`/root/deploy/static-file/blog/index.html`\n\n```lua\nlocation /blog {\n    root /root/deploy/static-file;\n}\n```\n\n#### alias映射方式：\n\n  alias路径直接替换原请求路径\n  对于alias，如下配置，`/blog/index.html`请求得到的资源仍然为`/root/deploy/static-file/blog/index.html`，\n\n  ```lua\nlocation /blog {\n    alias /root/deploy/static-file/blog/;\n}\n  ```\n  因此root和alias主要区别在于，当映射文件路径的时候，前者用于指定根路径，将原请求在根路径的基础上组合成新的路径，而后者用于指定url别名，将该别名作为新路径替换掉原请求路径\n\n**注意**：alias后面的路径必须加`/`正斜杠\n\n### proxy_pass\n相应的，`proxy_pass`作为反响代理时，对`/`正斜杠也有一定的讲究\n##### path加正斜杠\n`proxy_pass`的path加正斜杠时，用法与`alias`一样，都是用新路径替换掉原路径：\n\n```lua\nlocation /tomcat {\n    proxy_pass http://localhost:8080/;\n}\n```\n\n如上配置，nginx监听80端口，当请求`localhost/tomcat`时，请求转发到`http://localhost:8080/`\n\n##### path不加正斜杠\n\n```lua\nlocation /tomcat {\n    proxy_pass http://localhost:8080;\n}\n```\n\n如果去掉正斜杠，当请求`localhost/tomcat`时，请求转发到`http://localhost:8080/tomcat`\n\n这个地方容易踩坑，需要注意","slug":"Nginx-root和alias路径映射","published":1,"updated":"2021-05-31T03:06:33.196Z","_id":"ckf0h31h30008actsy095kgil","comments":1,"layout":"post","photos":[],"link":"","content":"<p>在nginx中，<code>root</code>和<code>alias</code>命令都用于将http请求和服务器上的资源地址进行映射，不过使用方式不太相同<br><a id=\"more\"></a></p>\n<h3 id=\"使用范围\"><a href=\"#使用范围\" class=\"headerlink\" title=\"使用范围\"></a>使用范围</h3><p>两个命令在nginx.conf中的作用范围如下：</p>\n<ul>\n<li>root: http、server、location和if中均可配置，用于指定当前范围的根路径</li>\n<li>alias: 尽在location中有效</li>\n</ul>\n<h3 id=\"使用方法\"><a href=\"#使用方法\" class=\"headerlink\" title=\"使用方法\"></a>使用方法</h3><p>root与alias主要区别在于nginx如何解释location后面的uri，这会使两者分别以不同的方式将请求映射到服务器文件上，两者使用方法均为 <code>root/alisa path</code></p>\n<h4 id=\"root映射方式：\"><a href=\"#root映射方式：\" class=\"headerlink\" title=\"root映射方式：\"></a>root映射方式：</h4><p>root路径 + location路径<br>如下配置中，nginx将会把<code>/blog/***</code>这样的请求路径映射到<code>/root/deploy/static-file/blog</code>目录下的资源中，因此<code>/blog/index.html</code>请求得到的资源即为<code>/root/deploy/static-file/blog/index.html</code></p>\n<figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /blog &#123;</span><br><span class=\"line\">    root /root/deploy/static-file;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"alias映射方式：\"><a href=\"#alias映射方式：\" class=\"headerlink\" title=\"alias映射方式：\"></a>alias映射方式：</h4><p>  alias路径直接替换原请求路径<br>  对于alias，如下配置，<code>/blog/index.html</code>请求得到的资源仍然为<code>/root/deploy/static-file/blog/index.html</code>，</p>\n  <figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /blog &#123;</span><br><span class=\"line\">    alias /root/deploy/static-file/blog/;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>  因此root和alias主要区别在于，当映射文件路径的时候，前者用于指定根路径，将原请求在根路径的基础上组合成新的路径，而后者用于指定url别名，将该别名作为新路径替换掉原请求路径</p>\n<p><strong>注意</strong>：alias后面的路径必须加<code>/</code>正斜杠</p>\n<h3 id=\"proxy-pass\"><a href=\"#proxy-pass\" class=\"headerlink\" title=\"proxy_pass\"></a>proxy_pass</h3><p>相应的，<code>proxy_pass</code>作为反响代理时，对<code>/</code>正斜杠也有一定的讲究</p>\n<h5 id=\"path加正斜杠\"><a href=\"#path加正斜杠\" class=\"headerlink\" title=\"path加正斜杠\"></a>path加正斜杠</h5><p><code>proxy_pass</code>的path加正斜杠时，用法与<code>alias</code>一样，都是用新路径替换掉原路径：</p>\n<figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /tomcat &#123;</span><br><span class=\"line\">    proxy_pass http://localhost:<span class=\"number\">8080</span>/;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如上配置，nginx监听80端口，当请求<code>localhost/tomcat</code>时，请求转发到<code>http://localhost:8080/</code></p>\n<h5 id=\"path不加正斜杠\"><a href=\"#path不加正斜杠\" class=\"headerlink\" title=\"path不加正斜杠\"></a>path不加正斜杠</h5><figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /tomcat &#123;</span><br><span class=\"line\">    proxy_pass http://localhost:<span class=\"number\">8080</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如果去掉正斜杠，当请求<code>localhost/tomcat</code>时，请求转发到<code>http://localhost:8080/tomcat</code></p>\n<p>这个地方容易踩坑，需要注意</p>\n","site":{"data":{}},"excerpt":"<p>在nginx中，<code>root</code>和<code>alias</code>命令都用于将http请求和服务器上的资源地址进行映射，不过使用方式不太相同<br>","more":"</p>\n<h3 id=\"使用范围\"><a href=\"#使用范围\" class=\"headerlink\" title=\"使用范围\"></a>使用范围</h3><p>两个命令在nginx.conf中的作用范围如下：</p>\n<ul>\n<li>root: http、server、location和if中均可配置，用于指定当前范围的根路径</li>\n<li>alias: 尽在location中有效</li>\n</ul>\n<h3 id=\"使用方法\"><a href=\"#使用方法\" class=\"headerlink\" title=\"使用方法\"></a>使用方法</h3><p>root与alias主要区别在于nginx如何解释location后面的uri，这会使两者分别以不同的方式将请求映射到服务器文件上，两者使用方法均为 <code>root/alisa path</code></p>\n<h4 id=\"root映射方式：\"><a href=\"#root映射方式：\" class=\"headerlink\" title=\"root映射方式：\"></a>root映射方式：</h4><p>root路径 + location路径<br>如下配置中，nginx将会把<code>/blog/***</code>这样的请求路径映射到<code>/root/deploy/static-file/blog</code>目录下的资源中，因此<code>/blog/index.html</code>请求得到的资源即为<code>/root/deploy/static-file/blog/index.html</code></p>\n<figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /blog &#123;</span><br><span class=\"line\">    root /root/deploy/static-file;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"alias映射方式：\"><a href=\"#alias映射方式：\" class=\"headerlink\" title=\"alias映射方式：\"></a>alias映射方式：</h4><p>  alias路径直接替换原请求路径<br>  对于alias，如下配置，<code>/blog/index.html</code>请求得到的资源仍然为<code>/root/deploy/static-file/blog/index.html</code>，</p>\n  <figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /blog &#123;</span><br><span class=\"line\">    alias /root/deploy/static-file/blog/;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>  因此root和alias主要区别在于，当映射文件路径的时候，前者用于指定根路径，将原请求在根路径的基础上组合成新的路径，而后者用于指定url别名，将该别名作为新路径替换掉原请求路径</p>\n<p><strong>注意</strong>：alias后面的路径必须加<code>/</code>正斜杠</p>\n<h3 id=\"proxy-pass\"><a href=\"#proxy-pass\" class=\"headerlink\" title=\"proxy_pass\"></a>proxy_pass</h3><p>相应的，<code>proxy_pass</code>作为反响代理时，对<code>/</code>正斜杠也有一定的讲究</p>\n<h5 id=\"path加正斜杠\"><a href=\"#path加正斜杠\" class=\"headerlink\" title=\"path加正斜杠\"></a>path加正斜杠</h5><p><code>proxy_pass</code>的path加正斜杠时，用法与<code>alias</code>一样，都是用新路径替换掉原路径：</p>\n<figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /tomcat &#123;</span><br><span class=\"line\">    proxy_pass http://localhost:<span class=\"number\">8080</span>/;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如上配置，nginx监听80端口，当请求<code>localhost/tomcat</code>时，请求转发到<code>http://localhost:8080/</code></p>\n<h5 id=\"path不加正斜杠\"><a href=\"#path不加正斜杠\" class=\"headerlink\" title=\"path不加正斜杠\"></a>path不加正斜杠</h5><figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /tomcat &#123;</span><br><span class=\"line\">    proxy_pass http://localhost:<span class=\"number\">8080</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如果去掉正斜杠，当请求<code>localhost/tomcat</code>时，请求转发到<code>http://localhost:8080/tomcat</code></p>\n<p>这个地方容易踩坑，需要注意</p>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 9(2)","author":"天渊","date":"2019-08-12T08:06:00.000Z","_content":"第九章：`虚拟内存`（2）\n\n这一部分主要学习虚拟内存地址翻译的一些知识点\n\n<!--more-->\n\n### 虚拟地址翻译的基本知识\n\n虚拟地址和物理地址的信息映射主要体现在页表上，因此进行地址翻译主要就是借助页表中的PTE页表项中记录的信息（有效位，物理页地址或者磁盘地址）\n\nn位的虚拟地址由两部分组成：\n\n- **虚拟页号（VPN）**：表示该地址对应的虚拟页的index，用于在页表中找到对应的PTE\n- **虚拟页偏移量（VPO）**：表示该地址在虚拟页中的偏移位置，VPO与具体的物理页偏移量PPO是相同的，用于在物理页中找到具体的数据位置\n\n如下图所示：\n\n![](http://img.mantian.site/201911221128_827.png)\n\n在进行虚拟寻址的过程中，`页表基址寄存器（PTBR）`中存储了当前进程的页表位置，` 内存管理单元(MMU) `通过VPN找到该虚拟地址对应的页表PTE项，首先判断有效位，如果**不缺页**的话就取出存储的物理页号PPN，物理页号加上物理页偏移量PPO（也就是虚拟页号VPO）就是具体的物理内存地址，下图就是MMU取数据时的整个流程：\n\n![](http://img.mantian.site/201911221139_752.png)\n\n其中MMU通过步骤3拿到PTE的数据后会判断是否命中页面，如果没有的话就要触发缺页异常：\n\n![](http://img.mantian.site/201911221327_876.png)\n\nMMU触发缺页异常，将控制权交给缺页处理程序，缺页处理程序进行换页操作，将需要的页换回主存，控制权交回给MMU重新执行步骤3，后续就跟之前相同了\n\n**通过L1高速缓存加速获取PTE**：上图中，MMU通过虚拟地址获取PTE的过程，既可以从物理内存中获取，也可以从SRAM高速缓存中获取，如果能够命中的话能够将整个过程的时钟周期从上百个减少到一两个\n\n**通过TLB高速缓存加速获取PTE**：现在很多主流CPU在MMU中集成了一个特有的专门用于存放PTE信息的缓存，叫做`翻译后备缓冲器TLB（Translation Lookaside Buffer）`，能够极大的加速获取PTE信息的过程，步骤如下\n\n1. MMU接收到虚拟地址，MMU使用虚拟地址的虚拟页号VPN从TLB中寻找具体的PTE，VPN由`TLB索引`和`TLB标记`组成\n2. MMU使用PTE取出找到数据的物理地址，从高速缓存或者内存中取出数据\n\n如果MMU在TLB中没有找到对应的PTE，则需要从高速缓存或者内存中获取PTE，存放到TLB中，再从内存中获取数据：\n\n![](http://img.mantian.site/201911221550_41.png)\n\n\n\n#### 多级页表\n\n> **为什么需要多级页表?**\n>\n> 每一个进程启动后，系统都会给它分配一个常驻的页表，如果是32位系统，每个PTE大小位4 bytes，那\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Netty概览.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 9(2)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-08-12 16:06:00\n---\n第九章：`虚拟内存`（2）\n\n这一部分主要学习虚拟内存地址翻译的一些知识点\n\n<!--more-->\n\n### 虚拟地址翻译的基本知识\n\n虚拟地址和物理地址的信息映射主要体现在页表上，因此进行地址翻译主要就是借助页表中的PTE页表项中记录的信息（有效位，物理页地址或者磁盘地址）\n\nn位的虚拟地址由两部分组成：\n\n- **虚拟页号（VPN）**：表示该地址对应的虚拟页的index，用于在页表中找到对应的PTE\n- **虚拟页偏移量（VPO）**：表示该地址在虚拟页中的偏移位置，VPO与具体的物理页偏移量PPO是相同的，用于在物理页中找到具体的数据位置\n\n如下图所示：\n\n![](http://img.mantian.site/201911221128_827.png)\n\n在进行虚拟寻址的过程中，`页表基址寄存器（PTBR）`中存储了当前进程的页表位置，` 内存管理单元(MMU) `通过VPN找到该虚拟地址对应的页表PTE项，首先判断有效位，如果**不缺页**的话就取出存储的物理页号PPN，物理页号加上物理页偏移量PPO（也就是虚拟页号VPO）就是具体的物理内存地址，下图就是MMU取数据时的整个流程：\n\n![](http://img.mantian.site/201911221139_752.png)\n\n其中MMU通过步骤3拿到PTE的数据后会判断是否命中页面，如果没有的话就要触发缺页异常：\n\n![](http://img.mantian.site/201911221327_876.png)\n\nMMU触发缺页异常，将控制权交给缺页处理程序，缺页处理程序进行换页操作，将需要的页换回主存，控制权交回给MMU重新执行步骤3，后续就跟之前相同了\n\n**通过L1高速缓存加速获取PTE**：上图中，MMU通过虚拟地址获取PTE的过程，既可以从物理内存中获取，也可以从SRAM高速缓存中获取，如果能够命中的话能够将整个过程的时钟周期从上百个减少到一两个\n\n**通过TLB高速缓存加速获取PTE**：现在很多主流CPU在MMU中集成了一个特有的专门用于存放PTE信息的缓存，叫做`翻译后备缓冲器TLB（Translation Lookaside Buffer）`，能够极大的加速获取PTE信息的过程，步骤如下\n\n1. MMU接收到虚拟地址，MMU使用虚拟地址的虚拟页号VPN从TLB中寻找具体的PTE，VPN由`TLB索引`和`TLB标记`组成\n2. MMU使用PTE取出找到数据的物理地址，从高速缓存或者内存中取出数据\n\n如果MMU在TLB中没有找到对应的PTE，则需要从高速缓存或者内存中获取PTE，存放到TLB中，再从内存中获取数据：\n\n![](http://img.mantian.site/201911221550_41.png)\n\n\n\n#### 多级页表\n\n> **为什么需要多级页表?**\n>\n> 每一个进程启动后，系统都会给它分配一个常驻的页表，如果是32位系统，每个PTE大小位4 bytes，那\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Netty概览","published":1,"updated":"2021-05-31T03:06:33.196Z","_id":"ckf0h31hb0009acts5vnz2noq","comments":1,"layout":"post","photos":[],"link":"","content":"<p>第九章：<code>虚拟内存</code>（2）</p>\n<p>这一部分主要学习虚拟内存地址翻译的一些知识点</p>\n<a id=\"more\"></a>\n<h3 id=\"虚拟地址翻译的基本知识\"><a href=\"#虚拟地址翻译的基本知识\" class=\"headerlink\" title=\"虚拟地址翻译的基本知识\"></a>虚拟地址翻译的基本知识</h3><p>虚拟地址和物理地址的信息映射主要体现在页表上，因此进行地址翻译主要就是借助页表中的PTE页表项中记录的信息（有效位，物理页地址或者磁盘地址）</p>\n<p>n位的虚拟地址由两部分组成：</p>\n<ul>\n<li><strong>虚拟页号（VPN）</strong>：表示该地址对应的虚拟页的index，用于在页表中找到对应的PTE</li>\n<li><strong>虚拟页偏移量（VPO）</strong>：表示该地址在虚拟页中的偏移位置，VPO与具体的物理页偏移量PPO是相同的，用于在物理页中找到具体的数据位置</li>\n</ul>\n<p>如下图所示：</p>\n<p><img src=\"http://img.mantian.site/201911221128_827.png\" alt></p>\n<p>在进行虚拟寻址的过程中，<code>页表基址寄存器（PTBR）</code>中存储了当前进程的页表位置，<code>内存管理单元(MMU)</code>通过VPN找到该虚拟地址对应的页表PTE项，首先判断有效位，如果<strong>不缺页</strong>的话就取出存储的物理页号PPN，物理页号加上物理页偏移量PPO（也就是虚拟页号VPO）就是具体的物理内存地址，下图就是MMU取数据时的整个流程：</p>\n<p><img src=\"http://img.mantian.site/201911221139_752.png\" alt></p>\n<p>其中MMU通过步骤3拿到PTE的数据后会判断是否命中页面，如果没有的话就要触发缺页异常：</p>\n<p><img src=\"http://img.mantian.site/201911221327_876.png\" alt></p>\n<p>MMU触发缺页异常，将控制权交给缺页处理程序，缺页处理程序进行换页操作，将需要的页换回主存，控制权交回给MMU重新执行步骤3，后续就跟之前相同了</p>\n<p><strong>通过L1高速缓存加速获取PTE</strong>：上图中，MMU通过虚拟地址获取PTE的过程，既可以从物理内存中获取，也可以从SRAM高速缓存中获取，如果能够命中的话能够将整个过程的时钟周期从上百个减少到一两个</p>\n<p><strong>通过TLB高速缓存加速获取PTE</strong>：现在很多主流CPU在MMU中集成了一个特有的专门用于存放PTE信息的缓存，叫做<code>翻译后备缓冲器TLB（Translation Lookaside Buffer）</code>，能够极大的加速获取PTE信息的过程，步骤如下</p>\n<ol>\n<li>MMU接收到虚拟地址，MMU使用虚拟地址的虚拟页号VPN从TLB中寻找具体的PTE，VPN由<code>TLB索引</code>和<code>TLB标记</code>组成</li>\n<li>MMU使用PTE取出找到数据的物理地址，从高速缓存或者内存中取出数据</li>\n</ol>\n<p>如果MMU在TLB中没有找到对应的PTE，则需要从高速缓存或者内存中获取PTE，存放到TLB中，再从内存中获取数据：</p>\n<p><img src=\"http://img.mantian.site/201911221550_41.png\" alt></p>\n<h4 id=\"多级页表\"><a href=\"#多级页表\" class=\"headerlink\" title=\"多级页表\"></a>多级页表</h4><blockquote>\n<p><strong>为什么需要多级页表?</strong></p>\n<p>每一个进程启动后，系统都会给它分配一个常驻的页表，如果是32位系统，每个PTE大小位4 bytes，那</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<p>第九章：<code>虚拟内存</code>（2）</p>\n<p>这一部分主要学习虚拟内存地址翻译的一些知识点</p>","more":"<h3 id=\"虚拟地址翻译的基本知识\"><a href=\"#虚拟地址翻译的基本知识\" class=\"headerlink\" title=\"虚拟地址翻译的基本知识\"></a>虚拟地址翻译的基本知识</h3><p>虚拟地址和物理地址的信息映射主要体现在页表上，因此进行地址翻译主要就是借助页表中的PTE页表项中记录的信息（有效位，物理页地址或者磁盘地址）</p>\n<p>n位的虚拟地址由两部分组成：</p>\n<ul>\n<li><strong>虚拟页号（VPN）</strong>：表示该地址对应的虚拟页的index，用于在页表中找到对应的PTE</li>\n<li><strong>虚拟页偏移量（VPO）</strong>：表示该地址在虚拟页中的偏移位置，VPO与具体的物理页偏移量PPO是相同的，用于在物理页中找到具体的数据位置</li>\n</ul>\n<p>如下图所示：</p>\n<p><img src=\"http://img.mantian.site/201911221128_827.png\" alt></p>\n<p>在进行虚拟寻址的过程中，<code>页表基址寄存器（PTBR）</code>中存储了当前进程的页表位置，<code>内存管理单元(MMU)</code>通过VPN找到该虚拟地址对应的页表PTE项，首先判断有效位，如果<strong>不缺页</strong>的话就取出存储的物理页号PPN，物理页号加上物理页偏移量PPO（也就是虚拟页号VPO）就是具体的物理内存地址，下图就是MMU取数据时的整个流程：</p>\n<p><img src=\"http://img.mantian.site/201911221139_752.png\" alt></p>\n<p>其中MMU通过步骤3拿到PTE的数据后会判断是否命中页面，如果没有的话就要触发缺页异常：</p>\n<p><img src=\"http://img.mantian.site/201911221327_876.png\" alt></p>\n<p>MMU触发缺页异常，将控制权交给缺页处理程序，缺页处理程序进行换页操作，将需要的页换回主存，控制权交回给MMU重新执行步骤3，后续就跟之前相同了</p>\n<p><strong>通过L1高速缓存加速获取PTE</strong>：上图中，MMU通过虚拟地址获取PTE的过程，既可以从物理内存中获取，也可以从SRAM高速缓存中获取，如果能够命中的话能够将整个过程的时钟周期从上百个减少到一两个</p>\n<p><strong>通过TLB高速缓存加速获取PTE</strong>：现在很多主流CPU在MMU中集成了一个特有的专门用于存放PTE信息的缓存，叫做<code>翻译后备缓冲器TLB（Translation Lookaside Buffer）</code>，能够极大的加速获取PTE信息的过程，步骤如下</p>\n<ol>\n<li>MMU接收到虚拟地址，MMU使用虚拟地址的虚拟页号VPN从TLB中寻找具体的PTE，VPN由<code>TLB索引</code>和<code>TLB标记</code>组成</li>\n<li>MMU使用PTE取出找到数据的物理地址，从高速缓存或者内存中取出数据</li>\n</ol>\n<p>如果MMU在TLB中没有找到对应的PTE，则需要从高速缓存或者内存中获取PTE，存放到TLB中，再从内存中获取数据：</p>\n<p><img src=\"http://img.mantian.site/201911221550_41.png\" alt></p>\n<h4 id=\"多级页表\"><a href=\"#多级页表\" class=\"headerlink\" title=\"多级页表\"></a>多级页表</h4><blockquote>\n<p><strong>为什么需要多级页表?</strong></p>\n<p>每一个进程启动后，系统都会给它分配一个常驻的页表，如果是32位系统，每个PTE大小位4 bytes，那</p>\n</blockquote>"},{"title":"Reactor-Kafka（1）","author":"天渊","date":"2019-02-02T10:10:00.000Z","_content":"reactor-kafka项目是遵循响应式流（Reactive Streams）规范的Kafka client，有Producer实现和Consumer实现。\n<!-- more -->\n\n### 首先讲讲Reactive Streams规范\n\n在传统的编程范式中，我们一般通过迭代器（Iterator）模式来遍历一个序列。这种遍历方式是由调用者来控制节奏的，采用的是拉的方式。每次由调用者通过 next()方法来获取序列中的下一个值。\n\n响应式流（Reactive Streams）规范则是推的方式，即常见的发布者-订阅者模式。当发布者有新的数据产生时，这些数据会被推送到订阅者来进行处理。在反应式流上可以添加各种不同的操作来对数据进行处理，形成数据处理链。这个以声明式的方式添加的处理链只在订阅者进行订阅操作时才会真正执行。\n\n响应式流规范体现到Jdk中即为Java 8的Stream Api和Java 9的Flow Api，再结合Java 8的Lambda函数式编程模型，形成了独特的Reactive响应式异步编程模型，目前最重要的Reactive实现项目即为Pivatol维护的`project-reactor`，诸多项目基于`project-reactor`对原有项目进行了遵循响应式规范的重构，包括`WebFlux`和`Reactor-mongodb`，以及这里要介绍的`Reactor-Kafka`。\n\n#### Flux和Mono\n\nFlux和Mono是project-reactor中最重要的两个基本概念，可以把他们理解为发布订阅模型中的发布者，他们均实现了`org.reactivestreams.Publisher`接口，Mono表示的是包含 0 到 1 个发布者的异步序列，Flux 表示的是包含 0 到 N 个发布者的异步序列。\n\n在Flux和Mono发布订阅序列中可以包含三种不同类型的消息通知：正常的包含元素的消息、序列结束的消息和序列出错的消息，分别包含`onNext()`, `onComplete()`和 `onError()`三个回调；当发布者产生需要消费的元素时，用户使用Stream流处理的方式对序列上的元素进行处理，比如`map()`或者`filter()`等等；最终调用`onSubscribe()`完成订阅。\n\n如下图所示，通过Flux（或者Mono）将整个数据库调用链以响应式异步序列的方式贯通起来，再由reactive的web服务器（通常是reactive-netty）发布给用户：\n\n![1548985987329](/blog/images/1548985987329.png)\n\n整个过程均为非阻塞，吞吐量能得到极大提升。\n\n### Reactor-Kafka\n\n关于`Reactor-Kafka`，官方文档描述如下：\n\n> [Reactor Kafka](https://projectreactor.io/docs/kafka/release/api/index.html) is a reactive API for Kafka based on Reactor and the Kafka Producer/Consumer API. Reactor Kafka API enables messages to be published to Kafka and consumed from Kafka using functional APIs with non-blocking back-pressure and very low overheads. This enables applications using Reactor to use Kafka as a message bus or streaming platform and integrate with other systems to provide an end-to-end reactive pipeline.\n\n> Reactor-Kafka是基于Reactor和kafka Producer/Consumer API开发的kafka响应式API客户端，可以通过非阻塞的函数式API来发布消息到kafka并消费kafka的消息，性能消耗很低。这套API能够让那些使用Reactor标准库（即Flux和Mono）的应用程序像message bus或者streaming platform一样使用kafka，并且和其他系统集成，提供端到端的响应式管道。\n\n也就是说这套Reactor-Kafka的API能够让使用者很轻易地将Kafka与其他使用Reactor api的系统集成起来，形成一套完整的响应式流处理管路。\n\n#### 加入java依赖\n\nmaven：\n\n```xml\n<dependency>\n    <groupId>io.projectreactor.kafka</groupId>\n    <artifactId>reactor-kafka</artifactId>\n    <version>1.1.0.RELEASE</version>\n</dependency>\n```\n\ngradle:\n\n```groovy\ndependencies {\n    compile \"io.projectreactor.kafka:reactor-kafka:1.1.0.RELEASE\"\n}\n```\n\n#### reactor consumer api\n\nReactor-Kafka的consumer的核心api是`reactor.kafka.receiver.KafkaReceiver`\n\n**属性配置**：\n\n```java\nMap<String, Object> consumerProps = new HashMap<>();\nconsumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nconsumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);\nconsumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\nconsumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n```\n\n对基本的bootstrapServers和groupId以及serializer等基本属性进行配置，其他的consumer属性参考Kafka官方文档；创建一个`ReceiverOptions`对象对属性进行封装：\n\n```java\nReceiverOptions<String, String> receiverOptions = ReceiverOptions.<String, String>create(consumerProps())\n    .subscription(Collections.singleton(\"resource-v1-TestProduct-TestType\"));\n```\n\n`.subscription`方法可以订阅多个topic\n\n**KafkaReceiver**：\n\n`KafkaReceiver`是reactor-kafka的consumer核心api：\n\n```java\nFlux<ReceiverRecord<String, String>> recordFlux = KafkaReceiver.create(receiverOptions()).receive();\n```\n\n`FLux`对象用于多个发布者，也就是说在`KafkaReceiver`中对应多个topic进行消费，其中key和value均设置为`String`类型：\n\n```java\nrecordFlux\n\t.log()\t//打印日志\n    .doOnNext(r -> r.receiverOffset().acknowledge()) //将当前record标记为已处理\n    .map(ReceiverRecord::value) //将元素由ReceiverRecord对象替换为其value\n    .doOnNext(r -> handler.saveResource(r)) //处理获得的record的value\n    .doOnError(e -> log.warn(\"消费出错\", e)) //处理过程中出错则打印日志\n    .subscribe(); //启动订阅\n```\n\n在该调用链上设置多个回调函数，对发布的消息进行顺序消费；\n\n该方法是非阻塞的，调用完后立即返回，不会阻塞用户线程，而是由reactor-kafka启动异步的EventLoop进行消息的获取并由worker线程调用用户设置的回调函数进行消费；\n\n如果`KafkaReceiver`接收到某个topic的一条消息则会顺序地调用回调函数进行处理；\n\n需要注意的是调用链最后都要调用`subscribe()`方法启动订阅，否则整个调用链并不会生效，并且一个`Flux`或者`Mono`对象只能订阅一次，如果多次订阅的话会报错：\n\n```java\njava.lang.IllegalStateException: Multiple subscribers are not supported for KafkaReceiver flux\n```\n\n如果不想马上结束整个流处理过程的话，可以不用立即调用`subscribe()`方法，而是将`Flux`对象作为一个载体传下去，这也就是官网提到的`use Kafka as a message bus or streaming platform and integrate with other systems to provide an end-to-end reactive pipeline`的意义所在，比如，我想将消费得到的String存入mongodb，则可以当前`Flux`对象传给`reactor-mongodb`，再由`reactor-mongodb`返回一个`Flux`对象，形成完整的Stream链：\n\n```java\n// 从kafka消费得到String数据\nFlux<String> receivedStrFlux = KafkaReceiver\n    .create(receiverOptions())\n    .receive()\n    .log()\n    .doOnNext(r -> r.receiverOffset().acknowledge())\n    .map(ReceiverRecord::value)\n    .doOnError(e -> log.warn(\"消费出错\", e));\n// 将String经过一系列转换得到一个包含Resource对象的Flux\nFlux<Resource> resourceFlux = receivedStrFlux\n\t.map(this::handleResourceString)\n    .flatMap(Flux::fromIterable)\n    .map(resourceData -> {\n        Resource resource = new Resource();\n        BeanUtils.copyProperties(resourceData, resource);\n        return resource;\n    });\n// 将包含Resource对象的Flux通过reactor-mongodb进行存储\n// 得到另一个Flux<Resource>\nFlux<Resource> resourceSavedFlux = resourceRepository.saveAll(resourceFlux);\n// 对这个Flux<Resource>进行订阅\nresourceSavedFlux\n\t.doOnError(e -> log.warn(\"出错啦！\", e))\n    .doOnComplete(() -> log.info(\"都存完啦！\"))\n    .log()\n    .subscribe();\n```\n\n以上就是一个完整的reactor-kafka+reactor-mongodb的异步响应式流处理链\n\n#### reactor consumer api其他配置\n\n除了基本的配置，reactor consumer api还可以进行一些进一步的设置\n\n单独订阅序号为0的partition：\n\n```java\nreceiverOptions = receiverOptions.assignment(Collections.singleton(new TopicPartition(topic, 0)));\n```\n\n当调用`.doOnNext(r -> r.receiverOffset().acknowledge())`时，该record的offset并不会立即提交，而是加入一个等待提交队列进行周期性自动提交，当然也可以调用`r.receiverOffset().commit()`方法手动提交该offset，`commit()`后依然返回的是一个`Mono`对象：\n\n```java\n.doOnNext(r -> r.receiverOffset().commit().doOnSuccess(aVoid -> log.info(\"offset提交成功！\")).subscribe())\n```\n\n`KafkaReceiver`接收kafka信息除了使用`receive()`消费最新的record，还可以手动指定`offset`进行消费：\n\n```java\nReceiverOptions.<String, String>create(consumerProps())\t.addAssignListener(receiverPartitions -> receiverPartitions.forEach(ReceiverPartition::seekToBeginning))\t\t.subscription(Collections.singleton(\"resource-v1-TestProduct-TestType\"));\n```\n\n使用`seekToBeginning`在每次初始化后从头开始消费，或者直接指定offset：\n\n```java\nReceiverOptions.<String, String>create(consumerProps())\t.addAssignListener(receiverPartitions -> receiverPartitions.forEach(r -> r.seek(140))).subscription(Collections.singleton(\"resource-v1-TestProduct-TestType\"));\n```\n\n从offset=140的位置开始消费\n\n#### reactor-kafka-consumer的生命周期\n\n每个`KafkaReceiver`实例的生命周期都跟对应的`Flux`相关，`Flux`结束消费则相应的`KafkaReceiver`就会被关闭.","source":"_posts/Reactor-Kafka（1）.md","raw":"title: Reactor-Kafka（1）\nauthor: 天渊\ntags:\n  - Kafka\n  - reactor\ncategories:\n  - 基础知识\ndate: 2019-02-02 18:10:00\n---\nreactor-kafka项目是遵循响应式流（Reactive Streams）规范的Kafka client，有Producer实现和Consumer实现。\n<!-- more -->\n\n### 首先讲讲Reactive Streams规范\n\n在传统的编程范式中，我们一般通过迭代器（Iterator）模式来遍历一个序列。这种遍历方式是由调用者来控制节奏的，采用的是拉的方式。每次由调用者通过 next()方法来获取序列中的下一个值。\n\n响应式流（Reactive Streams）规范则是推的方式，即常见的发布者-订阅者模式。当发布者有新的数据产生时，这些数据会被推送到订阅者来进行处理。在反应式流上可以添加各种不同的操作来对数据进行处理，形成数据处理链。这个以声明式的方式添加的处理链只在订阅者进行订阅操作时才会真正执行。\n\n响应式流规范体现到Jdk中即为Java 8的Stream Api和Java 9的Flow Api，再结合Java 8的Lambda函数式编程模型，形成了独特的Reactive响应式异步编程模型，目前最重要的Reactive实现项目即为Pivatol维护的`project-reactor`，诸多项目基于`project-reactor`对原有项目进行了遵循响应式规范的重构，包括`WebFlux`和`Reactor-mongodb`，以及这里要介绍的`Reactor-Kafka`。\n\n#### Flux和Mono\n\nFlux和Mono是project-reactor中最重要的两个基本概念，可以把他们理解为发布订阅模型中的发布者，他们均实现了`org.reactivestreams.Publisher`接口，Mono表示的是包含 0 到 1 个发布者的异步序列，Flux 表示的是包含 0 到 N 个发布者的异步序列。\n\n在Flux和Mono发布订阅序列中可以包含三种不同类型的消息通知：正常的包含元素的消息、序列结束的消息和序列出错的消息，分别包含`onNext()`, `onComplete()`和 `onError()`三个回调；当发布者产生需要消费的元素时，用户使用Stream流处理的方式对序列上的元素进行处理，比如`map()`或者`filter()`等等；最终调用`onSubscribe()`完成订阅。\n\n如下图所示，通过Flux（或者Mono）将整个数据库调用链以响应式异步序列的方式贯通起来，再由reactive的web服务器（通常是reactive-netty）发布给用户：\n\n![1548985987329](/blog/images/1548985987329.png)\n\n整个过程均为非阻塞，吞吐量能得到极大提升。\n\n### Reactor-Kafka\n\n关于`Reactor-Kafka`，官方文档描述如下：\n\n> [Reactor Kafka](https://projectreactor.io/docs/kafka/release/api/index.html) is a reactive API for Kafka based on Reactor and the Kafka Producer/Consumer API. Reactor Kafka API enables messages to be published to Kafka and consumed from Kafka using functional APIs with non-blocking back-pressure and very low overheads. This enables applications using Reactor to use Kafka as a message bus or streaming platform and integrate with other systems to provide an end-to-end reactive pipeline.\n\n> Reactor-Kafka是基于Reactor和kafka Producer/Consumer API开发的kafka响应式API客户端，可以通过非阻塞的函数式API来发布消息到kafka并消费kafka的消息，性能消耗很低。这套API能够让那些使用Reactor标准库（即Flux和Mono）的应用程序像message bus或者streaming platform一样使用kafka，并且和其他系统集成，提供端到端的响应式管道。\n\n也就是说这套Reactor-Kafka的API能够让使用者很轻易地将Kafka与其他使用Reactor api的系统集成起来，形成一套完整的响应式流处理管路。\n\n#### 加入java依赖\n\nmaven：\n\n```xml\n<dependency>\n    <groupId>io.projectreactor.kafka</groupId>\n    <artifactId>reactor-kafka</artifactId>\n    <version>1.1.0.RELEASE</version>\n</dependency>\n```\n\ngradle:\n\n```groovy\ndependencies {\n    compile \"io.projectreactor.kafka:reactor-kafka:1.1.0.RELEASE\"\n}\n```\n\n#### reactor consumer api\n\nReactor-Kafka的consumer的核心api是`reactor.kafka.receiver.KafkaReceiver`\n\n**属性配置**：\n\n```java\nMap<String, Object> consumerProps = new HashMap<>();\nconsumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nconsumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);\nconsumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\nconsumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n```\n\n对基本的bootstrapServers和groupId以及serializer等基本属性进行配置，其他的consumer属性参考Kafka官方文档；创建一个`ReceiverOptions`对象对属性进行封装：\n\n```java\nReceiverOptions<String, String> receiverOptions = ReceiverOptions.<String, String>create(consumerProps())\n    .subscription(Collections.singleton(\"resource-v1-TestProduct-TestType\"));\n```\n\n`.subscription`方法可以订阅多个topic\n\n**KafkaReceiver**：\n\n`KafkaReceiver`是reactor-kafka的consumer核心api：\n\n```java\nFlux<ReceiverRecord<String, String>> recordFlux = KafkaReceiver.create(receiverOptions()).receive();\n```\n\n`FLux`对象用于多个发布者，也就是说在`KafkaReceiver`中对应多个topic进行消费，其中key和value均设置为`String`类型：\n\n```java\nrecordFlux\n\t.log()\t//打印日志\n    .doOnNext(r -> r.receiverOffset().acknowledge()) //将当前record标记为已处理\n    .map(ReceiverRecord::value) //将元素由ReceiverRecord对象替换为其value\n    .doOnNext(r -> handler.saveResource(r)) //处理获得的record的value\n    .doOnError(e -> log.warn(\"消费出错\", e)) //处理过程中出错则打印日志\n    .subscribe(); //启动订阅\n```\n\n在该调用链上设置多个回调函数，对发布的消息进行顺序消费；\n\n该方法是非阻塞的，调用完后立即返回，不会阻塞用户线程，而是由reactor-kafka启动异步的EventLoop进行消息的获取并由worker线程调用用户设置的回调函数进行消费；\n\n如果`KafkaReceiver`接收到某个topic的一条消息则会顺序地调用回调函数进行处理；\n\n需要注意的是调用链最后都要调用`subscribe()`方法启动订阅，否则整个调用链并不会生效，并且一个`Flux`或者`Mono`对象只能订阅一次，如果多次订阅的话会报错：\n\n```java\njava.lang.IllegalStateException: Multiple subscribers are not supported for KafkaReceiver flux\n```\n\n如果不想马上结束整个流处理过程的话，可以不用立即调用`subscribe()`方法，而是将`Flux`对象作为一个载体传下去，这也就是官网提到的`use Kafka as a message bus or streaming platform and integrate with other systems to provide an end-to-end reactive pipeline`的意义所在，比如，我想将消费得到的String存入mongodb，则可以当前`Flux`对象传给`reactor-mongodb`，再由`reactor-mongodb`返回一个`Flux`对象，形成完整的Stream链：\n\n```java\n// 从kafka消费得到String数据\nFlux<String> receivedStrFlux = KafkaReceiver\n    .create(receiverOptions())\n    .receive()\n    .log()\n    .doOnNext(r -> r.receiverOffset().acknowledge())\n    .map(ReceiverRecord::value)\n    .doOnError(e -> log.warn(\"消费出错\", e));\n// 将String经过一系列转换得到一个包含Resource对象的Flux\nFlux<Resource> resourceFlux = receivedStrFlux\n\t.map(this::handleResourceString)\n    .flatMap(Flux::fromIterable)\n    .map(resourceData -> {\n        Resource resource = new Resource();\n        BeanUtils.copyProperties(resourceData, resource);\n        return resource;\n    });\n// 将包含Resource对象的Flux通过reactor-mongodb进行存储\n// 得到另一个Flux<Resource>\nFlux<Resource> resourceSavedFlux = resourceRepository.saveAll(resourceFlux);\n// 对这个Flux<Resource>进行订阅\nresourceSavedFlux\n\t.doOnError(e -> log.warn(\"出错啦！\", e))\n    .doOnComplete(() -> log.info(\"都存完啦！\"))\n    .log()\n    .subscribe();\n```\n\n以上就是一个完整的reactor-kafka+reactor-mongodb的异步响应式流处理链\n\n#### reactor consumer api其他配置\n\n除了基本的配置，reactor consumer api还可以进行一些进一步的设置\n\n单独订阅序号为0的partition：\n\n```java\nreceiverOptions = receiverOptions.assignment(Collections.singleton(new TopicPartition(topic, 0)));\n```\n\n当调用`.doOnNext(r -> r.receiverOffset().acknowledge())`时，该record的offset并不会立即提交，而是加入一个等待提交队列进行周期性自动提交，当然也可以调用`r.receiverOffset().commit()`方法手动提交该offset，`commit()`后依然返回的是一个`Mono`对象：\n\n```java\n.doOnNext(r -> r.receiverOffset().commit().doOnSuccess(aVoid -> log.info(\"offset提交成功！\")).subscribe())\n```\n\n`KafkaReceiver`接收kafka信息除了使用`receive()`消费最新的record，还可以手动指定`offset`进行消费：\n\n```java\nReceiverOptions.<String, String>create(consumerProps())\t.addAssignListener(receiverPartitions -> receiverPartitions.forEach(ReceiverPartition::seekToBeginning))\t\t.subscription(Collections.singleton(\"resource-v1-TestProduct-TestType\"));\n```\n\n使用`seekToBeginning`在每次初始化后从头开始消费，或者直接指定offset：\n\n```java\nReceiverOptions.<String, String>create(consumerProps())\t.addAssignListener(receiverPartitions -> receiverPartitions.forEach(r -> r.seek(140))).subscription(Collections.singleton(\"resource-v1-TestProduct-TestType\"));\n```\n\n从offset=140的位置开始消费\n\n#### reactor-kafka-consumer的生命周期\n\n每个`KafkaReceiver`实例的生命周期都跟对应的`Flux`相关，`Flux`结束消费则相应的`KafkaReceiver`就会被关闭.","slug":"Reactor-Kafka（1）","published":1,"updated":"2021-05-31T03:06:33.196Z","_id":"ckf0h31he000dacts9v395nsa","comments":1,"layout":"post","photos":[],"link":"","content":"<p>reactor-kafka项目是遵循响应式流（Reactive Streams）规范的Kafka client，有Producer实现和Consumer实现。<br><a id=\"more\"></a></p>\n<h3 id=\"首先讲讲Reactive-Streams规范\"><a href=\"#首先讲讲Reactive-Streams规范\" class=\"headerlink\" title=\"首先讲讲Reactive Streams规范\"></a>首先讲讲Reactive Streams规范</h3><p>在传统的编程范式中，我们一般通过迭代器（Iterator）模式来遍历一个序列。这种遍历方式是由调用者来控制节奏的，采用的是拉的方式。每次由调用者通过 next()方法来获取序列中的下一个值。</p>\n<p>响应式流（Reactive Streams）规范则是推的方式，即常见的发布者-订阅者模式。当发布者有新的数据产生时，这些数据会被推送到订阅者来进行处理。在反应式流上可以添加各种不同的操作来对数据进行处理，形成数据处理链。这个以声明式的方式添加的处理链只在订阅者进行订阅操作时才会真正执行。</p>\n<p>响应式流规范体现到Jdk中即为Java 8的Stream Api和Java 9的Flow Api，再结合Java 8的Lambda函数式编程模型，形成了独特的Reactive响应式异步编程模型，目前最重要的Reactive实现项目即为Pivatol维护的<code>project-reactor</code>，诸多项目基于<code>project-reactor</code>对原有项目进行了遵循响应式规范的重构，包括<code>WebFlux</code>和<code>Reactor-mongodb</code>，以及这里要介绍的<code>Reactor-Kafka</code>。</p>\n<h4 id=\"Flux和Mono\"><a href=\"#Flux和Mono\" class=\"headerlink\" title=\"Flux和Mono\"></a>Flux和Mono</h4><p>Flux和Mono是project-reactor中最重要的两个基本概念，可以把他们理解为发布订阅模型中的发布者，他们均实现了<code>org.reactivestreams.Publisher</code>接口，Mono表示的是包含 0 到 1 个发布者的异步序列，Flux 表示的是包含 0 到 N 个发布者的异步序列。</p>\n<p>在Flux和Mono发布订阅序列中可以包含三种不同类型的消息通知：正常的包含元素的消息、序列结束的消息和序列出错的消息，分别包含<code>onNext()</code>, <code>onComplete()</code>和 <code>onError()</code>三个回调；当发布者产生需要消费的元素时，用户使用Stream流处理的方式对序列上的元素进行处理，比如<code>map()</code>或者<code>filter()</code>等等；最终调用<code>onSubscribe()</code>完成订阅。</p>\n<p>如下图所示，通过Flux（或者Mono）将整个数据库调用链以响应式异步序列的方式贯通起来，再由reactive的web服务器（通常是reactive-netty）发布给用户：</p>\n<p><img src=\"/blog/images/1548985987329.png\" alt=\"1548985987329\"></p>\n<p>整个过程均为非阻塞，吞吐量能得到极大提升。</p>\n<h3 id=\"Reactor-Kafka\"><a href=\"#Reactor-Kafka\" class=\"headerlink\" title=\"Reactor-Kafka\"></a>Reactor-Kafka</h3><p>关于<code>Reactor-Kafka</code>，官方文档描述如下：</p>\n<blockquote>\n<p><a href=\"https://projectreactor.io/docs/kafka/release/api/index.html\" target=\"_blank\" rel=\"noopener\">Reactor Kafka</a> is a reactive API for Kafka based on Reactor and the Kafka Producer/Consumer API. Reactor Kafka API enables messages to be published to Kafka and consumed from Kafka using functional APIs with non-blocking back-pressure and very low overheads. This enables applications using Reactor to use Kafka as a message bus or streaming platform and integrate with other systems to provide an end-to-end reactive pipeline.</p>\n</blockquote>\n<blockquote>\n<p>Reactor-Kafka是基于Reactor和kafka Producer/Consumer API开发的kafka响应式API客户端，可以通过非阻塞的函数式API来发布消息到kafka并消费kafka的消息，性能消耗很低。这套API能够让那些使用Reactor标准库（即Flux和Mono）的应用程序像message bus或者streaming platform一样使用kafka，并且和其他系统集成，提供端到端的响应式管道。</p>\n</blockquote>\n<p>也就是说这套Reactor-Kafka的API能够让使用者很轻易地将Kafka与其他使用Reactor api的系统集成起来，形成一套完整的响应式流处理管路。</p>\n<h4 id=\"加入java依赖\"><a href=\"#加入java依赖\" class=\"headerlink\" title=\"加入java依赖\"></a>加入java依赖</h4><p>maven：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>io.projectreactor.kafka<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>reactor-kafka<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.1.0.RELEASE<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>gradle:</p>\n<figure class=\"highlight groovy\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dependencies &#123;</span><br><span class=\"line\">    compile <span class=\"string\">\"io.projectreactor.kafka:reactor-kafka:1.1.0.RELEASE\"</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"reactor-consumer-api\"><a href=\"#reactor-consumer-api\" class=\"headerlink\" title=\"reactor consumer api\"></a>reactor consumer api</h4><p>Reactor-Kafka的consumer的核心api是<code>reactor.kafka.receiver.KafkaReceiver</code></p>\n<p><strong>属性配置</strong>：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Map&lt;String, Object&gt; consumerProps = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">consumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);</span><br><span class=\"line\">consumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);</span><br><span class=\"line\">consumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class=\"line\">consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br></pre></td></tr></table></figure>\n<p>对基本的bootstrapServers和groupId以及serializer等基本属性进行配置，其他的consumer属性参考Kafka官方文档；创建一个<code>ReceiverOptions</code>对象对属性进行封装：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ReceiverOptions&lt;String, String&gt; receiverOptions = ReceiverOptions.&lt;String, String&gt;create(consumerProps())</span><br><span class=\"line\">    .subscription(Collections.singleton(<span class=\"string\">\"resource-v1-TestProduct-TestType\"</span>));</span><br></pre></td></tr></table></figure>\n<p><code>.subscription</code>方法可以订阅多个topic</p>\n<p><strong>KafkaReceiver</strong>：</p>\n<p><code>KafkaReceiver</code>是reactor-kafka的consumer核心api：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flux&lt;ReceiverRecord&lt;String, String&gt;&gt; recordFlux = KafkaReceiver.create(receiverOptions()).receive();</span><br></pre></td></tr></table></figure>\n<p><code>FLux</code>对象用于多个发布者，也就是说在<code>KafkaReceiver</code>中对应多个topic进行消费，其中key和value均设置为<code>String</code>类型：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">recordFlux</span><br><span class=\"line\">\t.log()\t<span class=\"comment\">//打印日志</span></span><br><span class=\"line\">    .doOnNext(r -&gt; r.receiverOffset().acknowledge()) <span class=\"comment\">//将当前record标记为已处理</span></span><br><span class=\"line\">    .map(ReceiverRecord::value) <span class=\"comment\">//将元素由ReceiverRecord对象替换为其value</span></span><br><span class=\"line\">    .doOnNext(r -&gt; handler.saveResource(r)) <span class=\"comment\">//处理获得的record的value</span></span><br><span class=\"line\">    .doOnError(e -&gt; log.warn(<span class=\"string\">\"消费出错\"</span>, e)) <span class=\"comment\">//处理过程中出错则打印日志</span></span><br><span class=\"line\">    .subscribe(); <span class=\"comment\">//启动订阅</span></span><br></pre></td></tr></table></figure>\n<p>在该调用链上设置多个回调函数，对发布的消息进行顺序消费；</p>\n<p>该方法是非阻塞的，调用完后立即返回，不会阻塞用户线程，而是由reactor-kafka启动异步的EventLoop进行消息的获取并由worker线程调用用户设置的回调函数进行消费；</p>\n<p>如果<code>KafkaReceiver</code>接收到某个topic的一条消息则会顺序地调用回调函数进行处理；</p>\n<p>需要注意的是调用链最后都要调用<code>subscribe()</code>方法启动订阅，否则整个调用链并不会生效，并且一个<code>Flux</code>或者<code>Mono</code>对象只能订阅一次，如果多次订阅的话会报错：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">java.lang.IllegalStateException: Multiple subscribers are not supported <span class=\"keyword\">for</span> KafkaReceiver flux</span><br></pre></td></tr></table></figure>\n<p>如果不想马上结束整个流处理过程的话，可以不用立即调用<code>subscribe()</code>方法，而是将<code>Flux</code>对象作为一个载体传下去，这也就是官网提到的<code>use Kafka as a message bus or streaming platform and integrate with other systems to provide an end-to-end reactive pipeline</code>的意义所在，比如，我想将消费得到的String存入mongodb，则可以当前<code>Flux</code>对象传给<code>reactor-mongodb</code>，再由<code>reactor-mongodb</code>返回一个<code>Flux</code>对象，形成完整的Stream链：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 从kafka消费得到String数据</span></span><br><span class=\"line\">Flux&lt;String&gt; receivedStrFlux = KafkaReceiver</span><br><span class=\"line\">    .create(receiverOptions())</span><br><span class=\"line\">    .receive()</span><br><span class=\"line\">    .log()</span><br><span class=\"line\">    .doOnNext(r -&gt; r.receiverOffset().acknowledge())</span><br><span class=\"line\">    .map(ReceiverRecord::value)</span><br><span class=\"line\">    .doOnError(e -&gt; log.warn(<span class=\"string\">\"消费出错\"</span>, e));</span><br><span class=\"line\"><span class=\"comment\">// 将String经过一系列转换得到一个包含Resource对象的Flux</span></span><br><span class=\"line\">Flux&lt;Resource&gt; resourceFlux = receivedStrFlux</span><br><span class=\"line\">\t.map(<span class=\"keyword\">this</span>::handleResourceString)</span><br><span class=\"line\">    .flatMap(Flux::fromIterable)</span><br><span class=\"line\">    .map(resourceData -&gt; &#123;</span><br><span class=\"line\">        Resource resource = <span class=\"keyword\">new</span> Resource();</span><br><span class=\"line\">        BeanUtils.copyProperties(resourceData, resource);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> resource;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\"><span class=\"comment\">// 将包含Resource对象的Flux通过reactor-mongodb进行存储</span></span><br><span class=\"line\"><span class=\"comment\">// 得到另一个Flux&lt;Resource&gt;</span></span><br><span class=\"line\">Flux&lt;Resource&gt; resourceSavedFlux = resourceRepository.saveAll(resourceFlux);</span><br><span class=\"line\"><span class=\"comment\">// 对这个Flux&lt;Resource&gt;进行订阅</span></span><br><span class=\"line\">resourceSavedFlux</span><br><span class=\"line\">\t.doOnError(e -&gt; log.warn(<span class=\"string\">\"出错啦！\"</span>, e))</span><br><span class=\"line\">    .doOnComplete(() -&gt; log.info(<span class=\"string\">\"都存完啦！\"</span>))</span><br><span class=\"line\">    .log()</span><br><span class=\"line\">    .subscribe();</span><br></pre></td></tr></table></figure>\n<p>以上就是一个完整的reactor-kafka+reactor-mongodb的异步响应式流处理链</p>\n<h4 id=\"reactor-consumer-api其他配置\"><a href=\"#reactor-consumer-api其他配置\" class=\"headerlink\" title=\"reactor consumer api其他配置\"></a>reactor consumer api其他配置</h4><p>除了基本的配置，reactor consumer api还可以进行一些进一步的设置</p>\n<p>单独订阅序号为0的partition：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">receiverOptions = receiverOptions.assignment(Collections.singleton(<span class=\"keyword\">new</span> TopicPartition(topic, <span class=\"number\">0</span>)));</span><br></pre></td></tr></table></figure>\n<p>当调用<code>.doOnNext(r -&gt; r.receiverOffset().acknowledge())</code>时，该record的offset并不会立即提交，而是加入一个等待提交队列进行周期性自动提交，当然也可以调用<code>r.receiverOffset().commit()</code>方法手动提交该offset，<code>commit()</code>后依然返回的是一个<code>Mono</code>对象：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.doOnNext(r -&gt; r.receiverOffset().commit().doOnSuccess(aVoid -&gt; log.info(<span class=\"string\">\"offset提交成功！\"</span>)).subscribe())</span><br></pre></td></tr></table></figure>\n<p><code>KafkaReceiver</code>接收kafka信息除了使用<code>receive()</code>消费最新的record，还可以手动指定<code>offset</code>进行消费：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ReceiverOptions.&lt;String, String&gt;create(consumerProps())\t.addAssignListener(receiverPartitions -&gt; receiverPartitions.forEach(ReceiverPartition::seekToBeginning))\t\t.subscription(Collections.singleton(<span class=\"string\">\"resource-v1-TestProduct-TestType\"</span>));</span><br></pre></td></tr></table></figure>\n<p>使用<code>seekToBeginning</code>在每次初始化后从头开始消费，或者直接指定offset：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ReceiverOptions.&lt;String, String&gt;create(consumerProps())\t.addAssignListener(receiverPartitions -&gt; receiverPartitions.forEach(r -&gt; r.seek(<span class=\"number\">140</span>))).subscription(Collections.singleton(<span class=\"string\">\"resource-v1-TestProduct-TestType\"</span>));</span><br></pre></td></tr></table></figure>\n<p>从offset=140的位置开始消费</p>\n<h4 id=\"reactor-kafka-consumer的生命周期\"><a href=\"#reactor-kafka-consumer的生命周期\" class=\"headerlink\" title=\"reactor-kafka-consumer的生命周期\"></a>reactor-kafka-consumer的生命周期</h4><p>每个<code>KafkaReceiver</code>实例的生命周期都跟对应的<code>Flux</code>相关，<code>Flux</code>结束消费则相应的<code>KafkaReceiver</code>就会被关闭.</p>\n","site":{"data":{}},"excerpt":"<p>reactor-kafka项目是遵循响应式流（Reactive Streams）规范的Kafka client，有Producer实现和Consumer实现。<br>","more":"</p>\n<h3 id=\"首先讲讲Reactive-Streams规范\"><a href=\"#首先讲讲Reactive-Streams规范\" class=\"headerlink\" title=\"首先讲讲Reactive Streams规范\"></a>首先讲讲Reactive Streams规范</h3><p>在传统的编程范式中，我们一般通过迭代器（Iterator）模式来遍历一个序列。这种遍历方式是由调用者来控制节奏的，采用的是拉的方式。每次由调用者通过 next()方法来获取序列中的下一个值。</p>\n<p>响应式流（Reactive Streams）规范则是推的方式，即常见的发布者-订阅者模式。当发布者有新的数据产生时，这些数据会被推送到订阅者来进行处理。在反应式流上可以添加各种不同的操作来对数据进行处理，形成数据处理链。这个以声明式的方式添加的处理链只在订阅者进行订阅操作时才会真正执行。</p>\n<p>响应式流规范体现到Jdk中即为Java 8的Stream Api和Java 9的Flow Api，再结合Java 8的Lambda函数式编程模型，形成了独特的Reactive响应式异步编程模型，目前最重要的Reactive实现项目即为Pivatol维护的<code>project-reactor</code>，诸多项目基于<code>project-reactor</code>对原有项目进行了遵循响应式规范的重构，包括<code>WebFlux</code>和<code>Reactor-mongodb</code>，以及这里要介绍的<code>Reactor-Kafka</code>。</p>\n<h4 id=\"Flux和Mono\"><a href=\"#Flux和Mono\" class=\"headerlink\" title=\"Flux和Mono\"></a>Flux和Mono</h4><p>Flux和Mono是project-reactor中最重要的两个基本概念，可以把他们理解为发布订阅模型中的发布者，他们均实现了<code>org.reactivestreams.Publisher</code>接口，Mono表示的是包含 0 到 1 个发布者的异步序列，Flux 表示的是包含 0 到 N 个发布者的异步序列。</p>\n<p>在Flux和Mono发布订阅序列中可以包含三种不同类型的消息通知：正常的包含元素的消息、序列结束的消息和序列出错的消息，分别包含<code>onNext()</code>, <code>onComplete()</code>和 <code>onError()</code>三个回调；当发布者产生需要消费的元素时，用户使用Stream流处理的方式对序列上的元素进行处理，比如<code>map()</code>或者<code>filter()</code>等等；最终调用<code>onSubscribe()</code>完成订阅。</p>\n<p>如下图所示，通过Flux（或者Mono）将整个数据库调用链以响应式异步序列的方式贯通起来，再由reactive的web服务器（通常是reactive-netty）发布给用户：</p>\n<p><img src=\"/blog/images/1548985987329.png\" alt=\"1548985987329\"></p>\n<p>整个过程均为非阻塞，吞吐量能得到极大提升。</p>\n<h3 id=\"Reactor-Kafka\"><a href=\"#Reactor-Kafka\" class=\"headerlink\" title=\"Reactor-Kafka\"></a>Reactor-Kafka</h3><p>关于<code>Reactor-Kafka</code>，官方文档描述如下：</p>\n<blockquote>\n<p><a href=\"https://projectreactor.io/docs/kafka/release/api/index.html\" target=\"_blank\" rel=\"noopener\">Reactor Kafka</a> is a reactive API for Kafka based on Reactor and the Kafka Producer/Consumer API. Reactor Kafka API enables messages to be published to Kafka and consumed from Kafka using functional APIs with non-blocking back-pressure and very low overheads. This enables applications using Reactor to use Kafka as a message bus or streaming platform and integrate with other systems to provide an end-to-end reactive pipeline.</p>\n</blockquote>\n<blockquote>\n<p>Reactor-Kafka是基于Reactor和kafka Producer/Consumer API开发的kafka响应式API客户端，可以通过非阻塞的函数式API来发布消息到kafka并消费kafka的消息，性能消耗很低。这套API能够让那些使用Reactor标准库（即Flux和Mono）的应用程序像message bus或者streaming platform一样使用kafka，并且和其他系统集成，提供端到端的响应式管道。</p>\n</blockquote>\n<p>也就是说这套Reactor-Kafka的API能够让使用者很轻易地将Kafka与其他使用Reactor api的系统集成起来，形成一套完整的响应式流处理管路。</p>\n<h4 id=\"加入java依赖\"><a href=\"#加入java依赖\" class=\"headerlink\" title=\"加入java依赖\"></a>加入java依赖</h4><p>maven：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>io.projectreactor.kafka<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>reactor-kafka<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.1.0.RELEASE<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>gradle:</p>\n<figure class=\"highlight groovy\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dependencies &#123;</span><br><span class=\"line\">    compile <span class=\"string\">\"io.projectreactor.kafka:reactor-kafka:1.1.0.RELEASE\"</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"reactor-consumer-api\"><a href=\"#reactor-consumer-api\" class=\"headerlink\" title=\"reactor consumer api\"></a>reactor consumer api</h4><p>Reactor-Kafka的consumer的核心api是<code>reactor.kafka.receiver.KafkaReceiver</code></p>\n<p><strong>属性配置</strong>：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Map&lt;String, Object&gt; consumerProps = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">consumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);</span><br><span class=\"line\">consumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);</span><br><span class=\"line\">consumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class=\"line\">consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br></pre></td></tr></table></figure>\n<p>对基本的bootstrapServers和groupId以及serializer等基本属性进行配置，其他的consumer属性参考Kafka官方文档；创建一个<code>ReceiverOptions</code>对象对属性进行封装：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ReceiverOptions&lt;String, String&gt; receiverOptions = ReceiverOptions.&lt;String, String&gt;create(consumerProps())</span><br><span class=\"line\">    .subscription(Collections.singleton(<span class=\"string\">\"resource-v1-TestProduct-TestType\"</span>));</span><br></pre></td></tr></table></figure>\n<p><code>.subscription</code>方法可以订阅多个topic</p>\n<p><strong>KafkaReceiver</strong>：</p>\n<p><code>KafkaReceiver</code>是reactor-kafka的consumer核心api：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Flux&lt;ReceiverRecord&lt;String, String&gt;&gt; recordFlux = KafkaReceiver.create(receiverOptions()).receive();</span><br></pre></td></tr></table></figure>\n<p><code>FLux</code>对象用于多个发布者，也就是说在<code>KafkaReceiver</code>中对应多个topic进行消费，其中key和value均设置为<code>String</code>类型：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">recordFlux</span><br><span class=\"line\">\t.log()\t<span class=\"comment\">//打印日志</span></span><br><span class=\"line\">    .doOnNext(r -&gt; r.receiverOffset().acknowledge()) <span class=\"comment\">//将当前record标记为已处理</span></span><br><span class=\"line\">    .map(ReceiverRecord::value) <span class=\"comment\">//将元素由ReceiverRecord对象替换为其value</span></span><br><span class=\"line\">    .doOnNext(r -&gt; handler.saveResource(r)) <span class=\"comment\">//处理获得的record的value</span></span><br><span class=\"line\">    .doOnError(e -&gt; log.warn(<span class=\"string\">\"消费出错\"</span>, e)) <span class=\"comment\">//处理过程中出错则打印日志</span></span><br><span class=\"line\">    .subscribe(); <span class=\"comment\">//启动订阅</span></span><br></pre></td></tr></table></figure>\n<p>在该调用链上设置多个回调函数，对发布的消息进行顺序消费；</p>\n<p>该方法是非阻塞的，调用完后立即返回，不会阻塞用户线程，而是由reactor-kafka启动异步的EventLoop进行消息的获取并由worker线程调用用户设置的回调函数进行消费；</p>\n<p>如果<code>KafkaReceiver</code>接收到某个topic的一条消息则会顺序地调用回调函数进行处理；</p>\n<p>需要注意的是调用链最后都要调用<code>subscribe()</code>方法启动订阅，否则整个调用链并不会生效，并且一个<code>Flux</code>或者<code>Mono</code>对象只能订阅一次，如果多次订阅的话会报错：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">java.lang.IllegalStateException: Multiple subscribers are not supported <span class=\"keyword\">for</span> KafkaReceiver flux</span><br></pre></td></tr></table></figure>\n<p>如果不想马上结束整个流处理过程的话，可以不用立即调用<code>subscribe()</code>方法，而是将<code>Flux</code>对象作为一个载体传下去，这也就是官网提到的<code>use Kafka as a message bus or streaming platform and integrate with other systems to provide an end-to-end reactive pipeline</code>的意义所在，比如，我想将消费得到的String存入mongodb，则可以当前<code>Flux</code>对象传给<code>reactor-mongodb</code>，再由<code>reactor-mongodb</code>返回一个<code>Flux</code>对象，形成完整的Stream链：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 从kafka消费得到String数据</span></span><br><span class=\"line\">Flux&lt;String&gt; receivedStrFlux = KafkaReceiver</span><br><span class=\"line\">    .create(receiverOptions())</span><br><span class=\"line\">    .receive()</span><br><span class=\"line\">    .log()</span><br><span class=\"line\">    .doOnNext(r -&gt; r.receiverOffset().acknowledge())</span><br><span class=\"line\">    .map(ReceiverRecord::value)</span><br><span class=\"line\">    .doOnError(e -&gt; log.warn(<span class=\"string\">\"消费出错\"</span>, e));</span><br><span class=\"line\"><span class=\"comment\">// 将String经过一系列转换得到一个包含Resource对象的Flux</span></span><br><span class=\"line\">Flux&lt;Resource&gt; resourceFlux = receivedStrFlux</span><br><span class=\"line\">\t.map(<span class=\"keyword\">this</span>::handleResourceString)</span><br><span class=\"line\">    .flatMap(Flux::fromIterable)</span><br><span class=\"line\">    .map(resourceData -&gt; &#123;</span><br><span class=\"line\">        Resource resource = <span class=\"keyword\">new</span> Resource();</span><br><span class=\"line\">        BeanUtils.copyProperties(resourceData, resource);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> resource;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\"><span class=\"comment\">// 将包含Resource对象的Flux通过reactor-mongodb进行存储</span></span><br><span class=\"line\"><span class=\"comment\">// 得到另一个Flux&lt;Resource&gt;</span></span><br><span class=\"line\">Flux&lt;Resource&gt; resourceSavedFlux = resourceRepository.saveAll(resourceFlux);</span><br><span class=\"line\"><span class=\"comment\">// 对这个Flux&lt;Resource&gt;进行订阅</span></span><br><span class=\"line\">resourceSavedFlux</span><br><span class=\"line\">\t.doOnError(e -&gt; log.warn(<span class=\"string\">\"出错啦！\"</span>, e))</span><br><span class=\"line\">    .doOnComplete(() -&gt; log.info(<span class=\"string\">\"都存完啦！\"</span>))</span><br><span class=\"line\">    .log()</span><br><span class=\"line\">    .subscribe();</span><br></pre></td></tr></table></figure>\n<p>以上就是一个完整的reactor-kafka+reactor-mongodb的异步响应式流处理链</p>\n<h4 id=\"reactor-consumer-api其他配置\"><a href=\"#reactor-consumer-api其他配置\" class=\"headerlink\" title=\"reactor consumer api其他配置\"></a>reactor consumer api其他配置</h4><p>除了基本的配置，reactor consumer api还可以进行一些进一步的设置</p>\n<p>单独订阅序号为0的partition：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">receiverOptions = receiverOptions.assignment(Collections.singleton(<span class=\"keyword\">new</span> TopicPartition(topic, <span class=\"number\">0</span>)));</span><br></pre></td></tr></table></figure>\n<p>当调用<code>.doOnNext(r -&gt; r.receiverOffset().acknowledge())</code>时，该record的offset并不会立即提交，而是加入一个等待提交队列进行周期性自动提交，当然也可以调用<code>r.receiverOffset().commit()</code>方法手动提交该offset，<code>commit()</code>后依然返回的是一个<code>Mono</code>对象：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.doOnNext(r -&gt; r.receiverOffset().commit().doOnSuccess(aVoid -&gt; log.info(<span class=\"string\">\"offset提交成功！\"</span>)).subscribe())</span><br></pre></td></tr></table></figure>\n<p><code>KafkaReceiver</code>接收kafka信息除了使用<code>receive()</code>消费最新的record，还可以手动指定<code>offset</code>进行消费：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ReceiverOptions.&lt;String, String&gt;create(consumerProps())\t.addAssignListener(receiverPartitions -&gt; receiverPartitions.forEach(ReceiverPartition::seekToBeginning))\t\t.subscription(Collections.singleton(<span class=\"string\">\"resource-v1-TestProduct-TestType\"</span>));</span><br></pre></td></tr></table></figure>\n<p>使用<code>seekToBeginning</code>在每次初始化后从头开始消费，或者直接指定offset：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ReceiverOptions.&lt;String, String&gt;create(consumerProps())\t.addAssignListener(receiverPartitions -&gt; receiverPartitions.forEach(r -&gt; r.seek(<span class=\"number\">140</span>))).subscription(Collections.singleton(<span class=\"string\">\"resource-v1-TestProduct-TestType\"</span>));</span><br></pre></td></tr></table></figure>\n<p>从offset=140的位置开始消费</p>\n<h4 id=\"reactor-kafka-consumer的生命周期\"><a href=\"#reactor-kafka-consumer的生命周期\" class=\"headerlink\" title=\"reactor-kafka-consumer的生命周期\"></a>reactor-kafka-consumer的生命周期</h4><p>每个<code>KafkaReceiver</code>实例的生命周期都跟对应的<code>Flux</code>相关，<code>Flux</code>结束消费则相应的<code>KafkaReceiver</code>就会被关闭.</p>"},{"title":"TCP连接 - Nagle 和 Cork","author":"天渊","date":"2019-02-13T07:02:00.000Z","_content":"TCP连接涉及到的参数设置及调优策略纷繁多样，其中跟到数据包发送策略有关的有`Nagle算法`和`Cork算法`，这两种算法的都涉及到化TCP通讯过程中的小数据包传输优化，初学时感觉很类似，不容易区分，需要一探究竟\n<!-- more -->\n\n### Nagle有什么用\n\nTCP/IP网络传输的发送端，在某些场景下可能会在短时间发送大量小数据包，导致网络拥塞（例如`糊涂窗口综合症`），`Nagle算法`初衷就是想解决这样的问题。TCP/IP协议中，无论发送多少数据，总是要在数据前面加上协议头，同时，对方接收到数据，也需要发送ACK表示确认。如果在数据包中，除开协议头后实际的数据尺寸太小，此类小数据包大量堆积会造成极大的网络拥塞，因此`Nagle`算法决定降低此类小包的发送频率，希望每次都能够以`MSS尺寸`的数据块来发送数据，或者在当前窗口还存在未Ack的数据包时，延迟发送后续的数据包，避免网络中充斥着许多小数据块。\n\n`Nagle算法`的逻辑流程：\n\n![](/blog/images/nagle.jpg)\n\n### Nagle的劣势\n\n`Nagle算法`并没有阻止小包发送，只是阻止了短时间内大量小包的发送，而且在某种程度上降低了数据实时性\n\n`Nagle算法`与TCP接收端的`延迟ACK`策略在某些情况下会造成冲突，极大的降低数据实时性：\n\n> tcp对每个数据包都发送一个ack确认，那么只是一个单独的数据包为了发送一个ack代价比较高，所以tcp会延迟一段时间，如果这段时间内有数据发送到对端，则捎带发送ack，如果在延迟ack定时器触发时候，发现ack尚未发送，则立即单独发送\n\n如果`Nagle算法`和`延迟ACK`同时在发送端和接收端存在，则会造成以下现象：\n\n1. 写-写-读的场景，发送端首先发送了小数据包A\n2. 接收端接收到数据包A，延迟本次ACK待下一次发送数据时再一并将ACK发送回去\n3. 发送端未收到数据包A的ACK，因此进行等待，暂不发送后续的数据包B\n4. 双方僵持，直到发送端或接收端等待超时\n\n如果对数据实时性要求高而且网络资源充足的情况下可以将其关闭，例如在Netty中可以对Channel设置`TCP_NODELAY`属性来关闭Nagle功能：\n\n```java\nbootstrap.childOption(ChannelOption.TCP_NODELAY, true)\n```\n\n\n\n### Cork算法有什么用\n\n`Nagle算法`并没有完全解决小数据包问题，仅仅是解决了发送大量小包带来的网络拥塞问题，但`Cork算法`的出现就能很好地降低小数据包带来的影响\n\n`Cork算法`和`Nagle算法`非常类似，但是它们的着眼点不一样，CORK算法则是为了提高网络的利用率，使得总体上协议头占用的比例尽可能的小，方法是如果当前数据包小于MSS大小，则在缓冲区等待，待后续数据包到来时合并未同一个数据包，将小包合并为大包共享一个协议头，这样就达到了消灭小包的目的\n\n通过设置`TCP_CORK`来开启`Cork算法`，并如果开启了`Cork算法`的话，`Nagle`算法也是默认开启的","source":"_posts/TCP连接-Nagle-和-Cork-1.md","raw":"title: TCP连接 - Nagle 和 Cork\nauthor: 天渊\ntags:\n  - TCP\n  - 计算机网络\ncategories:\n  - 基础知识\ndate: 2019-02-13 15:02:00\n---\nTCP连接涉及到的参数设置及调优策略纷繁多样，其中跟到数据包发送策略有关的有`Nagle算法`和`Cork算法`，这两种算法的都涉及到化TCP通讯过程中的小数据包传输优化，初学时感觉很类似，不容易区分，需要一探究竟\n<!-- more -->\n\n### Nagle有什么用\n\nTCP/IP网络传输的发送端，在某些场景下可能会在短时间发送大量小数据包，导致网络拥塞（例如`糊涂窗口综合症`），`Nagle算法`初衷就是想解决这样的问题。TCP/IP协议中，无论发送多少数据，总是要在数据前面加上协议头，同时，对方接收到数据，也需要发送ACK表示确认。如果在数据包中，除开协议头后实际的数据尺寸太小，此类小数据包大量堆积会造成极大的网络拥塞，因此`Nagle`算法决定降低此类小包的发送频率，希望每次都能够以`MSS尺寸`的数据块来发送数据，或者在当前窗口还存在未Ack的数据包时，延迟发送后续的数据包，避免网络中充斥着许多小数据块。\n\n`Nagle算法`的逻辑流程：\n\n![](/blog/images/nagle.jpg)\n\n### Nagle的劣势\n\n`Nagle算法`并没有阻止小包发送，只是阻止了短时间内大量小包的发送，而且在某种程度上降低了数据实时性\n\n`Nagle算法`与TCP接收端的`延迟ACK`策略在某些情况下会造成冲突，极大的降低数据实时性：\n\n> tcp对每个数据包都发送一个ack确认，那么只是一个单独的数据包为了发送一个ack代价比较高，所以tcp会延迟一段时间，如果这段时间内有数据发送到对端，则捎带发送ack，如果在延迟ack定时器触发时候，发现ack尚未发送，则立即单独发送\n\n如果`Nagle算法`和`延迟ACK`同时在发送端和接收端存在，则会造成以下现象：\n\n1. 写-写-读的场景，发送端首先发送了小数据包A\n2. 接收端接收到数据包A，延迟本次ACK待下一次发送数据时再一并将ACK发送回去\n3. 发送端未收到数据包A的ACK，因此进行等待，暂不发送后续的数据包B\n4. 双方僵持，直到发送端或接收端等待超时\n\n如果对数据实时性要求高而且网络资源充足的情况下可以将其关闭，例如在Netty中可以对Channel设置`TCP_NODELAY`属性来关闭Nagle功能：\n\n```java\nbootstrap.childOption(ChannelOption.TCP_NODELAY, true)\n```\n\n\n\n### Cork算法有什么用\n\n`Nagle算法`并没有完全解决小数据包问题，仅仅是解决了发送大量小包带来的网络拥塞问题，但`Cork算法`的出现就能很好地降低小数据包带来的影响\n\n`Cork算法`和`Nagle算法`非常类似，但是它们的着眼点不一样，CORK算法则是为了提高网络的利用率，使得总体上协议头占用的比例尽可能的小，方法是如果当前数据包小于MSS大小，则在缓冲区等待，待后续数据包到来时合并未同一个数据包，将小包合并为大包共享一个协议头，这样就达到了消灭小包的目的\n\n通过设置`TCP_CORK`来开启`Cork算法`，并如果开启了`Cork算法`的话，`Nagle`算法也是默认开启的","slug":"TCP连接-Nagle-和-Cork-1","published":1,"updated":"2021-05-31T03:06:33.196Z","_id":"ckf0h31hg000eactsyvzid657","comments":1,"layout":"post","photos":[],"link":"","content":"<p>TCP连接涉及到的参数设置及调优策略纷繁多样，其中跟到数据包发送策略有关的有<code>Nagle算法</code>和<code>Cork算法</code>，这两种算法的都涉及到化TCP通讯过程中的小数据包传输优化，初学时感觉很类似，不容易区分，需要一探究竟<br><a id=\"more\"></a></p>\n<h3 id=\"Nagle有什么用\"><a href=\"#Nagle有什么用\" class=\"headerlink\" title=\"Nagle有什么用\"></a>Nagle有什么用</h3><p>TCP/IP网络传输的发送端，在某些场景下可能会在短时间发送大量小数据包，导致网络拥塞（例如<code>糊涂窗口综合症</code>），<code>Nagle算法</code>初衷就是想解决这样的问题。TCP/IP协议中，无论发送多少数据，总是要在数据前面加上协议头，同时，对方接收到数据，也需要发送ACK表示确认。如果在数据包中，除开协议头后实际的数据尺寸太小，此类小数据包大量堆积会造成极大的网络拥塞，因此<code>Nagle</code>算法决定降低此类小包的发送频率，希望每次都能够以<code>MSS尺寸</code>的数据块来发送数据，或者在当前窗口还存在未Ack的数据包时，延迟发送后续的数据包，避免网络中充斥着许多小数据块。</p>\n<p><code>Nagle算法</code>的逻辑流程：</p>\n<p><img src=\"/blog/images/nagle.jpg\" alt></p>\n<h3 id=\"Nagle的劣势\"><a href=\"#Nagle的劣势\" class=\"headerlink\" title=\"Nagle的劣势\"></a>Nagle的劣势</h3><p><code>Nagle算法</code>并没有阻止小包发送，只是阻止了短时间内大量小包的发送，而且在某种程度上降低了数据实时性</p>\n<p><code>Nagle算法</code>与TCP接收端的<code>延迟ACK</code>策略在某些情况下会造成冲突，极大的降低数据实时性：</p>\n<blockquote>\n<p>tcp对每个数据包都发送一个ack确认，那么只是一个单独的数据包为了发送一个ack代价比较高，所以tcp会延迟一段时间，如果这段时间内有数据发送到对端，则捎带发送ack，如果在延迟ack定时器触发时候，发现ack尚未发送，则立即单独发送</p>\n</blockquote>\n<p>如果<code>Nagle算法</code>和<code>延迟ACK</code>同时在发送端和接收端存在，则会造成以下现象：</p>\n<ol>\n<li>写-写-读的场景，发送端首先发送了小数据包A</li>\n<li>接收端接收到数据包A，延迟本次ACK待下一次发送数据时再一并将ACK发送回去</li>\n<li>发送端未收到数据包A的ACK，因此进行等待，暂不发送后续的数据包B</li>\n<li>双方僵持，直到发送端或接收端等待超时</li>\n</ol>\n<p>如果对数据实时性要求高而且网络资源充足的情况下可以将其关闭，例如在Netty中可以对Channel设置<code>TCP_NODELAY</code>属性来关闭Nagle功能：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bootstrap.childOption(ChannelOption.TCP_NODELAY, <span class=\"keyword\">true</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Cork算法有什么用\"><a href=\"#Cork算法有什么用\" class=\"headerlink\" title=\"Cork算法有什么用\"></a>Cork算法有什么用</h3><p><code>Nagle算法</code>并没有完全解决小数据包问题，仅仅是解决了发送大量小包带来的网络拥塞问题，但<code>Cork算法</code>的出现就能很好地降低小数据包带来的影响</p>\n<p><code>Cork算法</code>和<code>Nagle算法</code>非常类似，但是它们的着眼点不一样，CORK算法则是为了提高网络的利用率，使得总体上协议头占用的比例尽可能的小，方法是如果当前数据包小于MSS大小，则在缓冲区等待，待后续数据包到来时合并未同一个数据包，将小包合并为大包共享一个协议头，这样就达到了消灭小包的目的</p>\n<p>通过设置<code>TCP_CORK</code>来开启<code>Cork算法</code>，并如果开启了<code>Cork算法</code>的话，<code>Nagle</code>算法也是默认开启的</p>\n","site":{"data":{}},"excerpt":"<p>TCP连接涉及到的参数设置及调优策略纷繁多样，其中跟到数据包发送策略有关的有<code>Nagle算法</code>和<code>Cork算法</code>，这两种算法的都涉及到化TCP通讯过程中的小数据包传输优化，初学时感觉很类似，不容易区分，需要一探究竟<br>","more":"</p>\n<h3 id=\"Nagle有什么用\"><a href=\"#Nagle有什么用\" class=\"headerlink\" title=\"Nagle有什么用\"></a>Nagle有什么用</h3><p>TCP/IP网络传输的发送端，在某些场景下可能会在短时间发送大量小数据包，导致网络拥塞（例如<code>糊涂窗口综合症</code>），<code>Nagle算法</code>初衷就是想解决这样的问题。TCP/IP协议中，无论发送多少数据，总是要在数据前面加上协议头，同时，对方接收到数据，也需要发送ACK表示确认。如果在数据包中，除开协议头后实际的数据尺寸太小，此类小数据包大量堆积会造成极大的网络拥塞，因此<code>Nagle</code>算法决定降低此类小包的发送频率，希望每次都能够以<code>MSS尺寸</code>的数据块来发送数据，或者在当前窗口还存在未Ack的数据包时，延迟发送后续的数据包，避免网络中充斥着许多小数据块。</p>\n<p><code>Nagle算法</code>的逻辑流程：</p>\n<p><img src=\"/blog/images/nagle.jpg\" alt></p>\n<h3 id=\"Nagle的劣势\"><a href=\"#Nagle的劣势\" class=\"headerlink\" title=\"Nagle的劣势\"></a>Nagle的劣势</h3><p><code>Nagle算法</code>并没有阻止小包发送，只是阻止了短时间内大量小包的发送，而且在某种程度上降低了数据实时性</p>\n<p><code>Nagle算法</code>与TCP接收端的<code>延迟ACK</code>策略在某些情况下会造成冲突，极大的降低数据实时性：</p>\n<blockquote>\n<p>tcp对每个数据包都发送一个ack确认，那么只是一个单独的数据包为了发送一个ack代价比较高，所以tcp会延迟一段时间，如果这段时间内有数据发送到对端，则捎带发送ack，如果在延迟ack定时器触发时候，发现ack尚未发送，则立即单独发送</p>\n</blockquote>\n<p>如果<code>Nagle算法</code>和<code>延迟ACK</code>同时在发送端和接收端存在，则会造成以下现象：</p>\n<ol>\n<li>写-写-读的场景，发送端首先发送了小数据包A</li>\n<li>接收端接收到数据包A，延迟本次ACK待下一次发送数据时再一并将ACK发送回去</li>\n<li>发送端未收到数据包A的ACK，因此进行等待，暂不发送后续的数据包B</li>\n<li>双方僵持，直到发送端或接收端等待超时</li>\n</ol>\n<p>如果对数据实时性要求高而且网络资源充足的情况下可以将其关闭，例如在Netty中可以对Channel设置<code>TCP_NODELAY</code>属性来关闭Nagle功能：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bootstrap.childOption(ChannelOption.TCP_NODELAY, <span class=\"keyword\">true</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Cork算法有什么用\"><a href=\"#Cork算法有什么用\" class=\"headerlink\" title=\"Cork算法有什么用\"></a>Cork算法有什么用</h3><p><code>Nagle算法</code>并没有完全解决小数据包问题，仅仅是解决了发送大量小包带来的网络拥塞问题，但<code>Cork算法</code>的出现就能很好地降低小数据包带来的影响</p>\n<p><code>Cork算法</code>和<code>Nagle算法</code>非常类似，但是它们的着眼点不一样，CORK算法则是为了提高网络的利用率，使得总体上协议头占用的比例尽可能的小，方法是如果当前数据包小于MSS大小，则在缓冲区等待，待后续数据包到来时合并未同一个数据包，将小包合并为大包共享一个协议头，这样就达到了消灭小包的目的</p>\n<p>通过设置<code>TCP_CORK</code>来开启<code>Cork算法</code>，并如果开启了<code>Cork算法</code>的话，<code>Nagle</code>算法也是默认开启的</p>"},{"title":"Kubernetes学习 —— 如何将自己的应用部署为k8s service","author":"天渊","date":"2019-07-12T13:14:00.000Z","_content":"`Service`是kubernetes对用户应用服务的一层抽象封装，一个`Service`对应多个具有相同功能的应用实例（`Pod`），为外界访问服务提供统一的入口，将请求负载均衡分发到多个`Pod`上\n<!--more-->\n用户在k8s上将自己的应用发布为`Deployment`后，只能通过`kubernetes Proxy`间接访问`Pod`的形式来调用服务，由于`Pod`生命周期的不确定性，这种方法可行性不高，因此需要将应用程序以`Service`的形式进行暴露，将应用程序实例和服务抽象进行充分解耦，集群中其他服务对该服务的调用就不会受到集群down机和动态缩/扩容的影响，用户在调试时也可以通过Node Port的方式直接在外界访问这个服务\n\n#### 发布一个Nginx服务\n\n将应用程序发布为`Service`有以下几个基本步骤：\n\n1. 创建docker image\n2. 基于应用程序的Docker Image发布k8s deployment，并设置需要暴露的端口和副本数\n3. 查看`replica set`和`pod`的状态，并指定`Labels`和`Selector`\n4. 将`deployment`暴露为`service`\n\n##### 创建docker image\n\n（略）\n\n##### 发布deployment\n\n`deployment`是k8s提供的用于发布无状态服务的资源形式，对应由`Deployment Controller`对用户发布的无状态应用程序进行统一管理，基于`deployment`可以随时启动，删除和动态缩/扩容`pod`，并暴露为外界可调用的`service`\n\n一旦应用发布为`deployment`，`Deployment Controller`便创建相应的`ReplicaSet`和`Pod`，并交给k8s scheduler调度到有空闲资源的服务器节点上启动运行\n\n用`kubectl run`命令直接创建一个Nginx的`deployment`（类似于docker run命令创建容器）：\n\n```shell\nkubectl run nginx --image=nginx:latest --port=80 --replicas=1\n```\n\n1. run后面指定该`deployment`的名称，这个名称是该应用在集群中的唯一标识\n2. `--image`是必带参数，指定Docker镜像，k8s会自动从远程registry拉取所需要的docker镜像\n3. `--port`是可选参数，指定该`deployment`的`pod`需要暴露的端口号，比如nginx服务就需要暴露它的80端口\n4. `--replicas`是可选参数，指定`pod`副本数量\n\n启动完成后，`Deployment Controller`会自动创建`Replica Set`（管理pod的副本集）和多个`pod`（由`--replicas`参数指定）\n\n用kubectl get deployments命令查看创建的nginx deployment (如果不指定名称nginx，则显示所有的deployment)：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl get deployments nginx\nNAME    READY   UP-TO-DATE   AVAILABLE   AGE\nnginx   1/1     1            1           17h\n```\n\n使用describe命令查看这个deployment的配置细节：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl describe deployments nginx\nName:                   nginx\nNamespace:              default\nCreationTimestamp:      Mon, 08 Jul 2019 17:46:20 +0900\nLabels:                 run=nginx\nAnnotations:            deployment.kubernetes.io/revision: 1\nSelector:               run=nginx\nReplicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  run=nginx\n  Containers:\n   nginx:\n    Image:        registry.navercorp.com/ncp-image/ncp-nginx:latest\n    Port:         80/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    NewReplicaSetAvailable\nOldReplicaSets:  <none>\nNewReplicaSet:   nginx-79b9dfdd46 (1/1 replicas created)\nEvents:          <none>\n```\n\n在这里面可以查看当前deployment的状态，比如名称，namespace，创建时间，当前副本整体状态，还有就是`Labels`和`Selector`，用于后续`replica set`和`pod`还有`service`和`pod`之间的配对关系\n\n##### 查看`replica set`和`pod`\n\n使用`kubectl run`命令创建`deployment`的话，会自动创建默认的`replica set`和`pod` ，这也是k8s官方推荐的方式 （如果不采用这种方式，则需要自己指定template然后使用`kubectl create`分别创建deployment, replica set和pod）\n\n使用以下命令查看刚创建的`replica set`\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl get replicasets\nNAME               DESIRED   CURRENT   READY   AGE\ncurl-6bf6db5c4f    1         1         1       25h\nnginx-79b9dfdd46   1         1         1       18h\n```\n\n默认创建的`replica set`是nginx-79b9dfdd46，使用`kubectl describe`命令查看详情：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl describe replicaset nginx-79b9dfdd46\nName:           nginx-79b9dfdd46\nNamespace:      default\nSelector:       pod-template-hash=79b9dfdd46,run=nginx\nLabels:         pod-template-hash=79b9dfdd46\n                run=nginx\nAnnotations:    deployment.kubernetes.io/desired-replicas: 1\n                deployment.kubernetes.io/max-replicas: 2\n                deployment.kubernetes.io/revision: 1\nControlled By:  Deployment/nginx\nReplicas:       1 current / 1 desired\nPods Status:    1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  pod-template-hash=79b9dfdd46\n           run=nginx\n  Containers:\n   nginx:\n    Image:        registry.navercorp.com/ncp-image/ncp-nginx:latest\n    Port:         80/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:           <none>\n```\n\n参数与`deployment`差别不大，可重点关注以下参数：\n\n1. `deployment.kubernetes.io/desired-replicas`和`deployment.kubernetes.io/max-replicas`参数，配置了期望副本数和最大副本数\n2. Controlled By参数，说明是由nginx的这个`deployment`来进行管理\n3. Pods Status：当前管理的pod状态\n4. Replicas：当前副本集状态，`1 current / 1 desired`说明当前已经成功启动一个pod，并且期望的pod副本数也为1个\n\n使用以下命令查看`pod`：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl get pods\nNAME                     READY   STATUS    RESTARTS   AGE\ncurl-6bf6db5c4f-4mkxk    1/1     Running   0          18h\nnginx-79b9dfdd46-qc94z   1/1     Running   0          18h\n```\n\n可以看到，刚创建的默认pod只有一个，status为Running，说明当前运行健康（若为Pending或者Unknown等状态说明pod调度失败）\n\n查看`pod`详情：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl describe pods nginx-79b9dfdd46-qc94z\nName:           nginx-79b9dfdd46-qc94z\nNamespace:      default\nPriority:       0\nNode:           dev-ncc-slave-1-ncl/10.106.147.158\nStart Time:     Mon, 08 Jul 2019 18:58:40 +0900\nLabels:         pod-template-hash=79b9dfdd46\n                run=nginx\nAnnotations:    <none>\nStatus:         Running\nIP:             10.244.2.2\nControlled By:  ReplicaSet/nginx-79b9dfdd46\nContainers:\n  nginx:\n    Container ID:   docker://4c06715be9d3fc575285621f595c5c2d9f67ef5fbd6d792618f0fb3449f85892\n    Image:          registry.navercorp.com/ncp-image/ncp-nginx:latest\n    Image ID:       docker-pullable://registry.navercorp.com/ncp-image/ncp-nginx@sha256:650cfc6f4e39b5bd5ec6bc57063886ba6e8808d691ac99200ac39fac2252c6ea\n    Port:           80/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 08 Jul 2019 18:59:01 +0900\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-zbdxq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-zbdxq:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-zbdxq\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:          <none>\n```\n\n重点关注以下参数：\n\n1. Node：当前pod被调度至服务器节点的host name\n2. Labels：标签，只有当labels与之前`replica set`的`Selector`保持一致，才会被相应的`Replica Controller`纳入管理进行动态缩/扩容；后续的`service`也是通过标签来discover当前有效的pod；标签可以在运行时动态修改\n3. IP：pod在k8s集群内部的ip\n4. Controlled By：标明当前pod是由哪个`replica set`进行管理\n5. Containers：pod封装的容器信息，一个pod可以有多个容器\n6. Tolerations：指定该pod多长时间未达到Ready状态或者k8s多长时间未检测到pod心跳后，允许k8s重新调度pod\n7. Events：pod经历的事件，deployment的滚动升级和缩/扩容等都会产生事件\n\n在确认`replica set`和`pod`状态确认无误后，即可将该应用暴露为服务\n\n##### 暴露服务\n\n使用`kubectl expose`命令将nginx deployment暴露为服务：\n\n```shell\nkubectl expose deployment/nginx --type=\"NodePort\" --port 80\n```\n\n1. --type：当前暴露形式，指定`NodePort`的话，k8s会给当前服务随机分派一个30000-32767之间的端口号，外界可以直接通过`服务器node ip + node port `的方式访问这个服务\n2. --port：指定应用所需要暴露的端口，nginx服务则需要暴露他的80端口\n\n查看暴露的服务：\n\n```shell\n$ kubectl get services\nNAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubernetes            ClusterIP   10.96.0.1       <none>        443/TCP          12m\nnginx                 NodePort    10.109.107.109   <none>        80:31482/TCP   5m1s\n```\n\n查看详情：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl describe services nginx\nName:                     nginx\nNamespace:                default\nLabels:                   run=nginx\nAnnotations:              <none>\nSelector:                 run=nginx\nType:                     NodePort\nIP:                       10.109.107.109\nPort:                     <unset>  80/TCP\nTargetPort:               80/TCP\nNodePort:                 <unset>  31482/TCP\nEndpoints:                10.244.2.2:80\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   <none>\n```\n\n默认情况下，`service`名称和`deployment`名称保持一致，其他参数：\n\n- Selector：`service`通过`Selector`选择来匹配对应的`pod`，k8s会通过`Endpoints Controller`来定期更新健康的符合`Selector`匹配规则的`pod`路由表，在这里nginx service将寻找所有labels为run=nginx的`pod`作为路由对象\n- IP：`service`在集群中的唯一ip地址\n\n`service`的`NodePort`是31482，因此我们可以直接在本机使用localhost访问这个nginx服务了：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ curl localhost:31482\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n</style>\n...\n```\n\n至此已经成功发布nginx service\n\n`Service`和`Deployment`,`Replica Set`还有`Pod`之间的关系：\n\n![upload successful](\\blog\\images\\image.png)\n\n一个`deployment`可以创建多个`replica set`和`pod`以及`service`，`replica set`和`service`通过`Selector`指定的值来匹配带有相关`Labels`的`pod`\n\n#### k8s内部的服务发现\n\nk8s内部通过何种方式发现我们发布的`nginx service` ?\n\n目前有三种方式：\n\n1. `NodePort方式`：即上面通过`node ip + node port`将访问路径固定，这种方式不够灵活，通常只能用于外界调试\n\n2. `环境变量方式`：k8s默认会在每个 pod 启动时候会把所有服务的 IP 和 port 信息配置到当前pod的环境变量中，这样 pod 中的应用可以通过读取环境变量来获取依赖服务的地址信息。这种方式服务和环境变量的匹配关系有一定的规范，使用起来也相对简单，但是有个很大的问题：依赖的服务必须在 pod 启动之前就存在，不然是不会出现在环境变量中的。\n\n3. `kube-dns`方式：k8s官方推荐通过`kubeDNS + dnsmasq`的方式配置kube-dns插件，kube-dns可以缓存所有已经存在的`service`信息供服务调用方发现并调用服务，其他服务可以直接使用以下方式调用nginx服务：\n\n   ```shell\n   http://<service_name>.<namespace>.svc.<domain>:80/\n   ```\n\n   `service_name`：即服务名nginx\n\n   `namespace`：k8s命名空间，创建deployment时不特别指定的话，`namespace`均为\"default\"\n\n   `domain`：域名后缀，默认为`cluster.local`\n\n   在 `pod` 中访问也可以使用缩写 `service_name.namespace`，如果 pod 和 service 在同一个 `namespace`，可以直接使用 `service_name`，因此如果同一个`namespace`有其他服务要访问nginx，则直接使用`nginx`作为域名即可：\n\n   ```shell\n   http://nginx:80/\n   ```\n\n##### 测试服务发现\n\n手动测试`service`的服务发现需要进入到`pod`内部，执行以下命令进入`pod`内部环境，进入到`pod`后可以通过curl命令访问`http://nginx:80/` (镜像没有安装curl，可用yum进行安装)：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl get pods\nNAME                     READY   STATUS    RESTARTS   AGE\ncurl-6bf6db5c4f-4mkxk    1/1     Running   0          22h\nnginx-5ff9d6cc77-5nxpn   1/1     Running   0          59m\n[irteam@dev-ncc-client-ncl ~]$ kubectl exec nginx-5ff9d6cc77-5nxpn -it -- /bin/bash\nroot@nginx-5ff9d6cc77-5nxpn:/# curl nginx:80/\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n</style>\n......\n```\n\n使用`Ctrl P + Ctrl Q`命令退出`pod`环境\n\n#### 删除service和deployment\n\n`kubectl`工具提供一键式删除`service`和`deployment`，当`deployment`被删除后，对应的`pod`同时被回收\n\n使用以下命令删除nginx service:\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl delete services nginx\nservice \"nginx\" deleted\n```\n\n使用以下命令删除nginx deployment:\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl delete deployments nginx\ndeployment.extensions \"nginx\" deleted\n```\n\n随后再查看`pod`可以发现之前创建的`pod`均被删除","source":"_posts/Kubernetes学习-——-如何将自己的应用部署为k8s-service.md","raw":"title: Kubernetes学习 —— 如何将自己的应用部署为k8s service\nauthor: 天渊\ntags:\n  - k8s\n  - devops\n  - 云原生\ncategories: []\ndate: 2019-07-12 21:14:00\n---\n`Service`是kubernetes对用户应用服务的一层抽象封装，一个`Service`对应多个具有相同功能的应用实例（`Pod`），为外界访问服务提供统一的入口，将请求负载均衡分发到多个`Pod`上\n<!--more-->\n用户在k8s上将自己的应用发布为`Deployment`后，只能通过`kubernetes Proxy`间接访问`Pod`的形式来调用服务，由于`Pod`生命周期的不确定性，这种方法可行性不高，因此需要将应用程序以`Service`的形式进行暴露，将应用程序实例和服务抽象进行充分解耦，集群中其他服务对该服务的调用就不会受到集群down机和动态缩/扩容的影响，用户在调试时也可以通过Node Port的方式直接在外界访问这个服务\n\n#### 发布一个Nginx服务\n\n将应用程序发布为`Service`有以下几个基本步骤：\n\n1. 创建docker image\n2. 基于应用程序的Docker Image发布k8s deployment，并设置需要暴露的端口和副本数\n3. 查看`replica set`和`pod`的状态，并指定`Labels`和`Selector`\n4. 将`deployment`暴露为`service`\n\n##### 创建docker image\n\n（略）\n\n##### 发布deployment\n\n`deployment`是k8s提供的用于发布无状态服务的资源形式，对应由`Deployment Controller`对用户发布的无状态应用程序进行统一管理，基于`deployment`可以随时启动，删除和动态缩/扩容`pod`，并暴露为外界可调用的`service`\n\n一旦应用发布为`deployment`，`Deployment Controller`便创建相应的`ReplicaSet`和`Pod`，并交给k8s scheduler调度到有空闲资源的服务器节点上启动运行\n\n用`kubectl run`命令直接创建一个Nginx的`deployment`（类似于docker run命令创建容器）：\n\n```shell\nkubectl run nginx --image=nginx:latest --port=80 --replicas=1\n```\n\n1. run后面指定该`deployment`的名称，这个名称是该应用在集群中的唯一标识\n2. `--image`是必带参数，指定Docker镜像，k8s会自动从远程registry拉取所需要的docker镜像\n3. `--port`是可选参数，指定该`deployment`的`pod`需要暴露的端口号，比如nginx服务就需要暴露它的80端口\n4. `--replicas`是可选参数，指定`pod`副本数量\n\n启动完成后，`Deployment Controller`会自动创建`Replica Set`（管理pod的副本集）和多个`pod`（由`--replicas`参数指定）\n\n用kubectl get deployments命令查看创建的nginx deployment (如果不指定名称nginx，则显示所有的deployment)：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl get deployments nginx\nNAME    READY   UP-TO-DATE   AVAILABLE   AGE\nnginx   1/1     1            1           17h\n```\n\n使用describe命令查看这个deployment的配置细节：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl describe deployments nginx\nName:                   nginx\nNamespace:              default\nCreationTimestamp:      Mon, 08 Jul 2019 17:46:20 +0900\nLabels:                 run=nginx\nAnnotations:            deployment.kubernetes.io/revision: 1\nSelector:               run=nginx\nReplicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  run=nginx\n  Containers:\n   nginx:\n    Image:        registry.navercorp.com/ncp-image/ncp-nginx:latest\n    Port:         80/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    NewReplicaSetAvailable\nOldReplicaSets:  <none>\nNewReplicaSet:   nginx-79b9dfdd46 (1/1 replicas created)\nEvents:          <none>\n```\n\n在这里面可以查看当前deployment的状态，比如名称，namespace，创建时间，当前副本整体状态，还有就是`Labels`和`Selector`，用于后续`replica set`和`pod`还有`service`和`pod`之间的配对关系\n\n##### 查看`replica set`和`pod`\n\n使用`kubectl run`命令创建`deployment`的话，会自动创建默认的`replica set`和`pod` ，这也是k8s官方推荐的方式 （如果不采用这种方式，则需要自己指定template然后使用`kubectl create`分别创建deployment, replica set和pod）\n\n使用以下命令查看刚创建的`replica set`\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl get replicasets\nNAME               DESIRED   CURRENT   READY   AGE\ncurl-6bf6db5c4f    1         1         1       25h\nnginx-79b9dfdd46   1         1         1       18h\n```\n\n默认创建的`replica set`是nginx-79b9dfdd46，使用`kubectl describe`命令查看详情：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl describe replicaset nginx-79b9dfdd46\nName:           nginx-79b9dfdd46\nNamespace:      default\nSelector:       pod-template-hash=79b9dfdd46,run=nginx\nLabels:         pod-template-hash=79b9dfdd46\n                run=nginx\nAnnotations:    deployment.kubernetes.io/desired-replicas: 1\n                deployment.kubernetes.io/max-replicas: 2\n                deployment.kubernetes.io/revision: 1\nControlled By:  Deployment/nginx\nReplicas:       1 current / 1 desired\nPods Status:    1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  pod-template-hash=79b9dfdd46\n           run=nginx\n  Containers:\n   nginx:\n    Image:        registry.navercorp.com/ncp-image/ncp-nginx:latest\n    Port:         80/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:           <none>\n```\n\n参数与`deployment`差别不大，可重点关注以下参数：\n\n1. `deployment.kubernetes.io/desired-replicas`和`deployment.kubernetes.io/max-replicas`参数，配置了期望副本数和最大副本数\n2. Controlled By参数，说明是由nginx的这个`deployment`来进行管理\n3. Pods Status：当前管理的pod状态\n4. Replicas：当前副本集状态，`1 current / 1 desired`说明当前已经成功启动一个pod，并且期望的pod副本数也为1个\n\n使用以下命令查看`pod`：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl get pods\nNAME                     READY   STATUS    RESTARTS   AGE\ncurl-6bf6db5c4f-4mkxk    1/1     Running   0          18h\nnginx-79b9dfdd46-qc94z   1/1     Running   0          18h\n```\n\n可以看到，刚创建的默认pod只有一个，status为Running，说明当前运行健康（若为Pending或者Unknown等状态说明pod调度失败）\n\n查看`pod`详情：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl describe pods nginx-79b9dfdd46-qc94z\nName:           nginx-79b9dfdd46-qc94z\nNamespace:      default\nPriority:       0\nNode:           dev-ncc-slave-1-ncl/10.106.147.158\nStart Time:     Mon, 08 Jul 2019 18:58:40 +0900\nLabels:         pod-template-hash=79b9dfdd46\n                run=nginx\nAnnotations:    <none>\nStatus:         Running\nIP:             10.244.2.2\nControlled By:  ReplicaSet/nginx-79b9dfdd46\nContainers:\n  nginx:\n    Container ID:   docker://4c06715be9d3fc575285621f595c5c2d9f67ef5fbd6d792618f0fb3449f85892\n    Image:          registry.navercorp.com/ncp-image/ncp-nginx:latest\n    Image ID:       docker-pullable://registry.navercorp.com/ncp-image/ncp-nginx@sha256:650cfc6f4e39b5bd5ec6bc57063886ba6e8808d691ac99200ac39fac2252c6ea\n    Port:           80/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 08 Jul 2019 18:59:01 +0900\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-zbdxq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-zbdxq:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-zbdxq\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:          <none>\n```\n\n重点关注以下参数：\n\n1. Node：当前pod被调度至服务器节点的host name\n2. Labels：标签，只有当labels与之前`replica set`的`Selector`保持一致，才会被相应的`Replica Controller`纳入管理进行动态缩/扩容；后续的`service`也是通过标签来discover当前有效的pod；标签可以在运行时动态修改\n3. IP：pod在k8s集群内部的ip\n4. Controlled By：标明当前pod是由哪个`replica set`进行管理\n5. Containers：pod封装的容器信息，一个pod可以有多个容器\n6. Tolerations：指定该pod多长时间未达到Ready状态或者k8s多长时间未检测到pod心跳后，允许k8s重新调度pod\n7. Events：pod经历的事件，deployment的滚动升级和缩/扩容等都会产生事件\n\n在确认`replica set`和`pod`状态确认无误后，即可将该应用暴露为服务\n\n##### 暴露服务\n\n使用`kubectl expose`命令将nginx deployment暴露为服务：\n\n```shell\nkubectl expose deployment/nginx --type=\"NodePort\" --port 80\n```\n\n1. --type：当前暴露形式，指定`NodePort`的话，k8s会给当前服务随机分派一个30000-32767之间的端口号，外界可以直接通过`服务器node ip + node port `的方式访问这个服务\n2. --port：指定应用所需要暴露的端口，nginx服务则需要暴露他的80端口\n\n查看暴露的服务：\n\n```shell\n$ kubectl get services\nNAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nkubernetes            ClusterIP   10.96.0.1       <none>        443/TCP          12m\nnginx                 NodePort    10.109.107.109   <none>        80:31482/TCP   5m1s\n```\n\n查看详情：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl describe services nginx\nName:                     nginx\nNamespace:                default\nLabels:                   run=nginx\nAnnotations:              <none>\nSelector:                 run=nginx\nType:                     NodePort\nIP:                       10.109.107.109\nPort:                     <unset>  80/TCP\nTargetPort:               80/TCP\nNodePort:                 <unset>  31482/TCP\nEndpoints:                10.244.2.2:80\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   <none>\n```\n\n默认情况下，`service`名称和`deployment`名称保持一致，其他参数：\n\n- Selector：`service`通过`Selector`选择来匹配对应的`pod`，k8s会通过`Endpoints Controller`来定期更新健康的符合`Selector`匹配规则的`pod`路由表，在这里nginx service将寻找所有labels为run=nginx的`pod`作为路由对象\n- IP：`service`在集群中的唯一ip地址\n\n`service`的`NodePort`是31482，因此我们可以直接在本机使用localhost访问这个nginx服务了：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ curl localhost:31482\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n</style>\n...\n```\n\n至此已经成功发布nginx service\n\n`Service`和`Deployment`,`Replica Set`还有`Pod`之间的关系：\n\n![upload successful](\\blog\\images\\image.png)\n\n一个`deployment`可以创建多个`replica set`和`pod`以及`service`，`replica set`和`service`通过`Selector`指定的值来匹配带有相关`Labels`的`pod`\n\n#### k8s内部的服务发现\n\nk8s内部通过何种方式发现我们发布的`nginx service` ?\n\n目前有三种方式：\n\n1. `NodePort方式`：即上面通过`node ip + node port`将访问路径固定，这种方式不够灵活，通常只能用于外界调试\n\n2. `环境变量方式`：k8s默认会在每个 pod 启动时候会把所有服务的 IP 和 port 信息配置到当前pod的环境变量中，这样 pod 中的应用可以通过读取环境变量来获取依赖服务的地址信息。这种方式服务和环境变量的匹配关系有一定的规范，使用起来也相对简单，但是有个很大的问题：依赖的服务必须在 pod 启动之前就存在，不然是不会出现在环境变量中的。\n\n3. `kube-dns`方式：k8s官方推荐通过`kubeDNS + dnsmasq`的方式配置kube-dns插件，kube-dns可以缓存所有已经存在的`service`信息供服务调用方发现并调用服务，其他服务可以直接使用以下方式调用nginx服务：\n\n   ```shell\n   http://<service_name>.<namespace>.svc.<domain>:80/\n   ```\n\n   `service_name`：即服务名nginx\n\n   `namespace`：k8s命名空间，创建deployment时不特别指定的话，`namespace`均为\"default\"\n\n   `domain`：域名后缀，默认为`cluster.local`\n\n   在 `pod` 中访问也可以使用缩写 `service_name.namespace`，如果 pod 和 service 在同一个 `namespace`，可以直接使用 `service_name`，因此如果同一个`namespace`有其他服务要访问nginx，则直接使用`nginx`作为域名即可：\n\n   ```shell\n   http://nginx:80/\n   ```\n\n##### 测试服务发现\n\n手动测试`service`的服务发现需要进入到`pod`内部，执行以下命令进入`pod`内部环境，进入到`pod`后可以通过curl命令访问`http://nginx:80/` (镜像没有安装curl，可用yum进行安装)：\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl get pods\nNAME                     READY   STATUS    RESTARTS   AGE\ncurl-6bf6db5c4f-4mkxk    1/1     Running   0          22h\nnginx-5ff9d6cc77-5nxpn   1/1     Running   0          59m\n[irteam@dev-ncc-client-ncl ~]$ kubectl exec nginx-5ff9d6cc77-5nxpn -it -- /bin/bash\nroot@nginx-5ff9d6cc77-5nxpn:/# curl nginx:80/\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n</style>\n......\n```\n\n使用`Ctrl P + Ctrl Q`命令退出`pod`环境\n\n#### 删除service和deployment\n\n`kubectl`工具提供一键式删除`service`和`deployment`，当`deployment`被删除后，对应的`pod`同时被回收\n\n使用以下命令删除nginx service:\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl delete services nginx\nservice \"nginx\" deleted\n```\n\n使用以下命令删除nginx deployment:\n\n```shell\n[irteam@dev-ncc-client-ncl ~]$ kubectl delete deployments nginx\ndeployment.extensions \"nginx\" deleted\n```\n\n随后再查看`pod`可以发现之前创建的`pod`均被删除","slug":"Kubernetes学习-——-如何将自己的应用部署为k8s-service","published":1,"updated":"2019-07-12T13:16:47.820Z","_id":"ckf0h31hj000iactsgpio04r0","comments":1,"layout":"post","photos":[],"link":"","content":"<p><code>Service</code>是kubernetes对用户应用服务的一层抽象封装，一个<code>Service</code>对应多个具有相同功能的应用实例（<code>Pod</code>），为外界访问服务提供统一的入口，将请求负载均衡分发到多个<code>Pod</code>上<br><a id=\"more\"></a><br>用户在k8s上将自己的应用发布为<code>Deployment</code>后，只能通过<code>kubernetes Proxy</code>间接访问<code>Pod</code>的形式来调用服务，由于<code>Pod</code>生命周期的不确定性，这种方法可行性不高，因此需要将应用程序以<code>Service</code>的形式进行暴露，将应用程序实例和服务抽象进行充分解耦，集群中其他服务对该服务的调用就不会受到集群down机和动态缩/扩容的影响，用户在调试时也可以通过Node Port的方式直接在外界访问这个服务</p>\n<h4 id=\"发布一个Nginx服务\"><a href=\"#发布一个Nginx服务\" class=\"headerlink\" title=\"发布一个Nginx服务\"></a>发布一个Nginx服务</h4><p>将应用程序发布为<code>Service</code>有以下几个基本步骤：</p>\n<ol>\n<li>创建docker image</li>\n<li>基于应用程序的Docker Image发布k8s deployment，并设置需要暴露的端口和副本数</li>\n<li>查看<code>replica set</code>和<code>pod</code>的状态，并指定<code>Labels</code>和<code>Selector</code></li>\n<li>将<code>deployment</code>暴露为<code>service</code></li>\n</ol>\n<h5 id=\"创建docker-image\"><a href=\"#创建docker-image\" class=\"headerlink\" title=\"创建docker image\"></a>创建docker image</h5><p>（略）</p>\n<h5 id=\"发布deployment\"><a href=\"#发布deployment\" class=\"headerlink\" title=\"发布deployment\"></a>发布deployment</h5><p><code>deployment</code>是k8s提供的用于发布无状态服务的资源形式，对应由<code>Deployment Controller</code>对用户发布的无状态应用程序进行统一管理，基于<code>deployment</code>可以随时启动，删除和动态缩/扩容<code>pod</code>，并暴露为外界可调用的<code>service</code></p>\n<p>一旦应用发布为<code>deployment</code>，<code>Deployment Controller</code>便创建相应的<code>ReplicaSet</code>和<code>Pod</code>，并交给k8s scheduler调度到有空闲资源的服务器节点上启动运行</p>\n<p>用<code>kubectl run</code>命令直接创建一个Nginx的<code>deployment</code>（类似于docker run命令创建容器）：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl run nginx --image=nginx:latest --port=80 --replicas=1</span><br></pre></td></tr></table></figure>\n<ol>\n<li>run后面指定该<code>deployment</code>的名称，这个名称是该应用在集群中的唯一标识</li>\n<li><code>--image</code>是必带参数，指定Docker镜像，k8s会自动从远程registry拉取所需要的docker镜像</li>\n<li><code>--port</code>是可选参数，指定该<code>deployment</code>的<code>pod</code>需要暴露的端口号，比如nginx服务就需要暴露它的80端口</li>\n<li><code>--replicas</code>是可选参数，指定<code>pod</code>副本数量</li>\n</ol>\n<p>启动完成后，<code>Deployment Controller</code>会自动创建<code>Replica Set</code>（管理pod的副本集）和多个<code>pod</code>（由<code>--replicas</code>参数指定）</p>\n<p>用kubectl get deployments命令查看创建的nginx deployment (如果不指定名称nginx，则显示所有的deployment)：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl get deployments nginx</span><br><span class=\"line\">NAME    READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class=\"line\">nginx   1/1     1            1           17h</span><br></pre></td></tr></table></figure>\n<p>使用describe命令查看这个deployment的配置细节：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl describe deployments nginx</span><br><span class=\"line\">Name:                   nginx</span><br><span class=\"line\">Namespace:              default</span><br><span class=\"line\">CreationTimestamp:      Mon, 08 Jul 2019 17:46:20 +0900</span><br><span class=\"line\">Labels:                 run=nginx</span><br><span class=\"line\">Annotations:            deployment.kubernetes.io/revision: 1</span><br><span class=\"line\">Selector:               run=nginx</span><br><span class=\"line\">Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable</span><br><span class=\"line\">StrategyType:           RollingUpdate</span><br><span class=\"line\">MinReadySeconds:        0</span><br><span class=\"line\">RollingUpdateStrategy:  25% max unavailable, 25% max surge</span><br><span class=\"line\">Pod Template:</span><br><span class=\"line\">  Labels:  run=nginx</span><br><span class=\"line\">  Containers:</span><br><span class=\"line\">   nginx:</span><br><span class=\"line\">    Image:        registry.navercorp.com/ncp-image/ncp-nginx:latest</span><br><span class=\"line\">    Port:         80/TCP</span><br><span class=\"line\">    Host Port:    0/TCP</span><br><span class=\"line\">    Environment:  &lt;none&gt;</span><br><span class=\"line\">    Mounts:       &lt;none&gt;</span><br><span class=\"line\">  Volumes:        &lt;none&gt;</span><br><span class=\"line\">Conditions:</span><br><span class=\"line\">  Type           Status  Reason</span><br><span class=\"line\">  ----           ------  ------</span><br><span class=\"line\">  Available      True    MinimumReplicasAvailable</span><br><span class=\"line\">  Progressing    True    NewReplicaSetAvailable</span><br><span class=\"line\">OldReplicaSets:  &lt;none&gt;</span><br><span class=\"line\">NewReplicaSet:   nginx-79b9dfdd46 (1/1 replicas created)</span><br><span class=\"line\">Events:          &lt;none&gt;</span><br></pre></td></tr></table></figure>\n<p>在这里面可以查看当前deployment的状态，比如名称，namespace，创建时间，当前副本整体状态，还有就是<code>Labels</code>和<code>Selector</code>，用于后续<code>replica set</code>和<code>pod</code>还有<code>service</code>和<code>pod</code>之间的配对关系</p>\n<h5 id=\"查看replica-set和pod\"><a href=\"#查看replica-set和pod\" class=\"headerlink\" title=\"查看replica set和pod\"></a>查看<code>replica set</code>和<code>pod</code></h5><p>使用<code>kubectl run</code>命令创建<code>deployment</code>的话，会自动创建默认的<code>replica set</code>和<code>pod</code> ，这也是k8s官方推荐的方式 （如果不采用这种方式，则需要自己指定template然后使用<code>kubectl create</code>分别创建deployment, replica set和pod）</p>\n<p>使用以下命令查看刚创建的<code>replica set</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl get replicasets</span><br><span class=\"line\">NAME               DESIRED   CURRENT   READY   AGE</span><br><span class=\"line\">curl-6bf6db5c4f    1         1         1       25h</span><br><span class=\"line\">nginx-79b9dfdd46   1         1         1       18h</span><br></pre></td></tr></table></figure>\n<p>默认创建的<code>replica set</code>是nginx-79b9dfdd46，使用<code>kubectl describe</code>命令查看详情：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl describe replicaset nginx-79b9dfdd46</span><br><span class=\"line\">Name:           nginx-79b9dfdd46</span><br><span class=\"line\">Namespace:      default</span><br><span class=\"line\">Selector:       pod-template-hash=79b9dfdd46,run=nginx</span><br><span class=\"line\">Labels:         pod-template-hash=79b9dfdd46</span><br><span class=\"line\">                run=nginx</span><br><span class=\"line\">Annotations:    deployment.kubernetes.io/desired-replicas: 1</span><br><span class=\"line\">                deployment.kubernetes.io/max-replicas: 2</span><br><span class=\"line\">                deployment.kubernetes.io/revision: 1</span><br><span class=\"line\">Controlled By:  Deployment/nginx</span><br><span class=\"line\">Replicas:       1 current / 1 desired</span><br><span class=\"line\">Pods Status:    1 Running / 0 Waiting / 0 Succeeded / 0 Failed</span><br><span class=\"line\">Pod Template:</span><br><span class=\"line\">  Labels:  pod-template-hash=79b9dfdd46</span><br><span class=\"line\">           run=nginx</span><br><span class=\"line\">  Containers:</span><br><span class=\"line\">   nginx:</span><br><span class=\"line\">    Image:        registry.navercorp.com/ncp-image/ncp-nginx:latest</span><br><span class=\"line\">    Port:         80/TCP</span><br><span class=\"line\">    Host Port:    0/TCP</span><br><span class=\"line\">    Environment:  &lt;none&gt;</span><br><span class=\"line\">    Mounts:       &lt;none&gt;</span><br><span class=\"line\">  Volumes:        &lt;none&gt;</span><br><span class=\"line\">Events:           &lt;none&gt;</span><br></pre></td></tr></table></figure>\n<p>参数与<code>deployment</code>差别不大，可重点关注以下参数：</p>\n<ol>\n<li><code>deployment.kubernetes.io/desired-replicas</code>和<code>deployment.kubernetes.io/max-replicas</code>参数，配置了期望副本数和最大副本数</li>\n<li>Controlled By参数，说明是由nginx的这个<code>deployment</code>来进行管理</li>\n<li>Pods Status：当前管理的pod状态</li>\n<li>Replicas：当前副本集状态，<code>1 current / 1 desired</code>说明当前已经成功启动一个pod，并且期望的pod副本数也为1个</li>\n</ol>\n<p>使用以下命令查看<code>pod</code>：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl get pods</span><br><span class=\"line\">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">curl-6bf6db5c4f-4mkxk    1/1     Running   0          18h</span><br><span class=\"line\">nginx-79b9dfdd46-qc94z   1/1     Running   0          18h</span><br></pre></td></tr></table></figure>\n<p>可以看到，刚创建的默认pod只有一个，status为Running，说明当前运行健康（若为Pending或者Unknown等状态说明pod调度失败）</p>\n<p>查看<code>pod</code>详情：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl describe pods nginx-79b9dfdd46-qc94z</span><br><span class=\"line\">Name:           nginx-79b9dfdd46-qc94z</span><br><span class=\"line\">Namespace:      default</span><br><span class=\"line\">Priority:       0</span><br><span class=\"line\">Node:           dev-ncc-slave-1-ncl/10.106.147.158</span><br><span class=\"line\">Start Time:     Mon, 08 Jul 2019 18:58:40 +0900</span><br><span class=\"line\">Labels:         pod-template-hash=79b9dfdd46</span><br><span class=\"line\">                run=nginx</span><br><span class=\"line\">Annotations:    &lt;none&gt;</span><br><span class=\"line\">Status:         Running</span><br><span class=\"line\">IP:             10.244.2.2</span><br><span class=\"line\">Controlled By:  ReplicaSet/nginx-79b9dfdd46</span><br><span class=\"line\">Containers:</span><br><span class=\"line\">  nginx:</span><br><span class=\"line\">    Container ID:   docker://4c06715be9d3fc575285621f595c5c2d9f67ef5fbd6d792618f0fb3449f85892</span><br><span class=\"line\">    Image:          registry.navercorp.com/ncp-image/ncp-nginx:latest</span><br><span class=\"line\">    Image ID:       docker-pullable://registry.navercorp.com/ncp-image/ncp-nginx@sha256:650cfc6f4e39b5bd5ec6bc57063886ba6e8808d691ac99200ac39fac2252c6ea</span><br><span class=\"line\">    Port:           80/TCP</span><br><span class=\"line\">    Host Port:      0/TCP</span><br><span class=\"line\">    State:          Running</span><br><span class=\"line\">      Started:      Mon, 08 Jul 2019 18:59:01 +0900</span><br><span class=\"line\">    Ready:          True</span><br><span class=\"line\">    Restart Count:  0</span><br><span class=\"line\">    Environment:    &lt;none&gt;</span><br><span class=\"line\">    Mounts:</span><br><span class=\"line\">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-zbdxq (ro)</span><br><span class=\"line\">Conditions:</span><br><span class=\"line\">  Type              Status</span><br><span class=\"line\">  Initialized       True </span><br><span class=\"line\">  Ready             True </span><br><span class=\"line\">  ContainersReady   True </span><br><span class=\"line\">  PodScheduled      True </span><br><span class=\"line\">Volumes:</span><br><span class=\"line\">  default-token-zbdxq:</span><br><span class=\"line\">    Type:        Secret (a volume populated by a Secret)</span><br><span class=\"line\">    SecretName:  default-token-zbdxq</span><br><span class=\"line\">    Optional:    false</span><br><span class=\"line\">QoS Class:       BestEffort</span><br><span class=\"line\">Node-Selectors:  &lt;none&gt;</span><br><span class=\"line\">Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s</span><br><span class=\"line\">                 node.kubernetes.io/unreachable:NoExecute for 300s</span><br><span class=\"line\">Events:          &lt;none&gt;</span><br></pre></td></tr></table></figure>\n<p>重点关注以下参数：</p>\n<ol>\n<li>Node：当前pod被调度至服务器节点的host name</li>\n<li>Labels：标签，只有当labels与之前<code>replica set</code>的<code>Selector</code>保持一致，才会被相应的<code>Replica Controller</code>纳入管理进行动态缩/扩容；后续的<code>service</code>也是通过标签来discover当前有效的pod；标签可以在运行时动态修改</li>\n<li>IP：pod在k8s集群内部的ip</li>\n<li>Controlled By：标明当前pod是由哪个<code>replica set</code>进行管理</li>\n<li>Containers：pod封装的容器信息，一个pod可以有多个容器</li>\n<li>Tolerations：指定该pod多长时间未达到Ready状态或者k8s多长时间未检测到pod心跳后，允许k8s重新调度pod</li>\n<li>Events：pod经历的事件，deployment的滚动升级和缩/扩容等都会产生事件</li>\n</ol>\n<p>在确认<code>replica set</code>和<code>pod</code>状态确认无误后，即可将该应用暴露为服务</p>\n<h5 id=\"暴露服务\"><a href=\"#暴露服务\" class=\"headerlink\" title=\"暴露服务\"></a>暴露服务</h5><p>使用<code>kubectl expose</code>命令将nginx deployment暴露为服务：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl expose deployment/nginx --type=\"NodePort\" --port 80</span><br></pre></td></tr></table></figure>\n<ol>\n<li>–type：当前暴露形式，指定<code>NodePort</code>的话，k8s会给当前服务随机分派一个30000-32767之间的端口号，外界可以直接通过<code>服务器node ip + node port</code>的方式访问这个服务</li>\n<li>–port：指定应用所需要暴露的端口，nginx服务则需要暴露他的80端口</li>\n</ol>\n<p>查看暴露的服务：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span> kubectl get services</span><br><span class=\"line\">NAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class=\"line\">kubernetes            ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP          12m</span><br><span class=\"line\">nginx                 NodePort    10.109.107.109   &lt;none&gt;        80:31482/TCP   5m1s</span><br></pre></td></tr></table></figure>\n<p>查看详情：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl describe services nginx</span><br><span class=\"line\">Name:                     nginx</span><br><span class=\"line\">Namespace:                default</span><br><span class=\"line\">Labels:                   run=nginx</span><br><span class=\"line\">Annotations:              &lt;none&gt;</span><br><span class=\"line\">Selector:                 run=nginx</span><br><span class=\"line\">Type:                     NodePort</span><br><span class=\"line\">IP:                       10.109.107.109</span><br><span class=\"line\">Port:                     &lt;unset&gt;  80/TCP</span><br><span class=\"line\">TargetPort:               80/TCP</span><br><span class=\"line\">NodePort:                 &lt;unset&gt;  31482/TCP</span><br><span class=\"line\">Endpoints:                10.244.2.2:80</span><br><span class=\"line\">Session Affinity:         None</span><br><span class=\"line\">External Traffic Policy:  Cluster</span><br><span class=\"line\">Events:                   &lt;none&gt;</span><br></pre></td></tr></table></figure>\n<p>默认情况下，<code>service</code>名称和<code>deployment</code>名称保持一致，其他参数：</p>\n<ul>\n<li>Selector：<code>service</code>通过<code>Selector</code>选择来匹配对应的<code>pod</code>，k8s会通过<code>Endpoints Controller</code>来定期更新健康的符合<code>Selector</code>匹配规则的<code>pod</code>路由表，在这里nginx service将寻找所有labels为run=nginx的<code>pod</code>作为路由对象</li>\n<li>IP：<code>service</code>在集群中的唯一ip地址</li>\n</ul>\n<p><code>service</code>的<code>NodePort</code>是31482，因此我们可以直接在本机使用localhost访问这个nginx服务了：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ curl localhost:31482</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;</span><br><span class=\"line\">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class=\"line\">&lt;style&gt;</span><br><span class=\"line\">    body &#123;</span><br><span class=\"line\">        width: 35em;</span><br><span class=\"line\">        margin: 0 auto;</span><br><span class=\"line\">        font-family: Tahoma, Verdana, Arial, sans-serif;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&lt;/style&gt;</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>至此已经成功发布nginx service</p>\n<p><code>Service</code>和<code>Deployment</code>,<code>Replica Set</code>还有<code>Pod</code>之间的关系：</p>\n<p><img src=\"\\blog\\images\\image.png\" alt=\"upload successful\"></p>\n<p>一个<code>deployment</code>可以创建多个<code>replica set</code>和<code>pod</code>以及<code>service</code>，<code>replica set</code>和<code>service</code>通过<code>Selector</code>指定的值来匹配带有相关<code>Labels</code>的<code>pod</code></p>\n<h4 id=\"k8s内部的服务发现\"><a href=\"#k8s内部的服务发现\" class=\"headerlink\" title=\"k8s内部的服务发现\"></a>k8s内部的服务发现</h4><p>k8s内部通过何种方式发现我们发布的<code>nginx service</code> ?</p>\n<p>目前有三种方式：</p>\n<ol>\n<li><p><code>NodePort方式</code>：即上面通过<code>node ip + node port</code>将访问路径固定，这种方式不够灵活，通常只能用于外界调试</p>\n</li>\n<li><p><code>环境变量方式</code>：k8s默认会在每个 pod 启动时候会把所有服务的 IP 和 port 信息配置到当前pod的环境变量中，这样 pod 中的应用可以通过读取环境变量来获取依赖服务的地址信息。这种方式服务和环境变量的匹配关系有一定的规范，使用起来也相对简单，但是有个很大的问题：依赖的服务必须在 pod 启动之前就存在，不然是不会出现在环境变量中的。</p>\n</li>\n<li><p><code>kube-dns</code>方式：k8s官方推荐通过<code>kubeDNS + dnsmasq</code>的方式配置kube-dns插件，kube-dns可以缓存所有已经存在的<code>service</code>信息供服务调用方发现并调用服务，其他服务可以直接使用以下方式调用nginx服务：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://&lt;service_name&gt;.&lt;namespace&gt;.svc.&lt;domain&gt;:80/</span><br></pre></td></tr></table></figure>\n<p><code>service_name</code>：即服务名nginx</p>\n<p><code>namespace</code>：k8s命名空间，创建deployment时不特别指定的话，<code>namespace</code>均为”default”</p>\n<p><code>domain</code>：域名后缀，默认为<code>cluster.local</code></p>\n<p>在 <code>pod</code> 中访问也可以使用缩写 <code>service_name.namespace</code>，如果 pod 和 service 在同一个 <code>namespace</code>，可以直接使用 <code>service_name</code>，因此如果同一个<code>namespace</code>有其他服务要访问nginx，则直接使用<code>nginx</code>作为域名即可：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://nginx:80/</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h5 id=\"测试服务发现\"><a href=\"#测试服务发现\" class=\"headerlink\" title=\"测试服务发现\"></a>测试服务发现</h5><p>手动测试<code>service</code>的服务发现需要进入到<code>pod</code>内部，执行以下命令进入<code>pod</code>内部环境，进入到<code>pod</code>后可以通过curl命令访问<code>http://nginx:80/</code> (镜像没有安装curl，可用yum进行安装)：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl get pods</span><br><span class=\"line\">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">curl-6bf6db5c4f-4mkxk    1/1     Running   0          22h</span><br><span class=\"line\">nginx-5ff9d6cc77-5nxpn   1/1     Running   0          59m</span><br><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl exec nginx-5ff9d6cc77-5nxpn -it -- /bin/bash</span><br><span class=\"line\">root@nginx-5ff9d6cc77-5nxpn:/# curl nginx:80/</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;</span><br><span class=\"line\">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class=\"line\">&lt;style&gt;</span><br><span class=\"line\">    body &#123;</span><br><span class=\"line\">        width: 35em;</span><br><span class=\"line\">        margin: 0 auto;</span><br><span class=\"line\">        font-family: Tahoma, Verdana, Arial, sans-serif;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&lt;/style&gt;</span><br><span class=\"line\">......</span><br></pre></td></tr></table></figure>\n<p>使用<code>Ctrl P + Ctrl Q</code>命令退出<code>pod</code>环境</p>\n<h4 id=\"删除service和deployment\"><a href=\"#删除service和deployment\" class=\"headerlink\" title=\"删除service和deployment\"></a>删除service和deployment</h4><p><code>kubectl</code>工具提供一键式删除<code>service</code>和<code>deployment</code>，当<code>deployment</code>被删除后，对应的<code>pod</code>同时被回收</p>\n<p>使用以下命令删除nginx service:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl delete services nginx</span><br><span class=\"line\">service \"nginx\" deleted</span><br></pre></td></tr></table></figure>\n<p>使用以下命令删除nginx deployment:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl delete deployments nginx</span><br><span class=\"line\">deployment.extensions \"nginx\" deleted</span><br></pre></td></tr></table></figure>\n<p>随后再查看<code>pod</code>可以发现之前创建的<code>pod</code>均被删除</p>\n","site":{"data":{}},"excerpt":"<p><code>Service</code>是kubernetes对用户应用服务的一层抽象封装，一个<code>Service</code>对应多个具有相同功能的应用实例（<code>Pod</code>），为外界访问服务提供统一的入口，将请求负载均衡分发到多个<code>Pod</code>上<br>","more":"<br>用户在k8s上将自己的应用发布为<code>Deployment</code>后，只能通过<code>kubernetes Proxy</code>间接访问<code>Pod</code>的形式来调用服务，由于<code>Pod</code>生命周期的不确定性，这种方法可行性不高，因此需要将应用程序以<code>Service</code>的形式进行暴露，将应用程序实例和服务抽象进行充分解耦，集群中其他服务对该服务的调用就不会受到集群down机和动态缩/扩容的影响，用户在调试时也可以通过Node Port的方式直接在外界访问这个服务</p>\n<h4 id=\"发布一个Nginx服务\"><a href=\"#发布一个Nginx服务\" class=\"headerlink\" title=\"发布一个Nginx服务\"></a>发布一个Nginx服务</h4><p>将应用程序发布为<code>Service</code>有以下几个基本步骤：</p>\n<ol>\n<li>创建docker image</li>\n<li>基于应用程序的Docker Image发布k8s deployment，并设置需要暴露的端口和副本数</li>\n<li>查看<code>replica set</code>和<code>pod</code>的状态，并指定<code>Labels</code>和<code>Selector</code></li>\n<li>将<code>deployment</code>暴露为<code>service</code></li>\n</ol>\n<h5 id=\"创建docker-image\"><a href=\"#创建docker-image\" class=\"headerlink\" title=\"创建docker image\"></a>创建docker image</h5><p>（略）</p>\n<h5 id=\"发布deployment\"><a href=\"#发布deployment\" class=\"headerlink\" title=\"发布deployment\"></a>发布deployment</h5><p><code>deployment</code>是k8s提供的用于发布无状态服务的资源形式，对应由<code>Deployment Controller</code>对用户发布的无状态应用程序进行统一管理，基于<code>deployment</code>可以随时启动，删除和动态缩/扩容<code>pod</code>，并暴露为外界可调用的<code>service</code></p>\n<p>一旦应用发布为<code>deployment</code>，<code>Deployment Controller</code>便创建相应的<code>ReplicaSet</code>和<code>Pod</code>，并交给k8s scheduler调度到有空闲资源的服务器节点上启动运行</p>\n<p>用<code>kubectl run</code>命令直接创建一个Nginx的<code>deployment</code>（类似于docker run命令创建容器）：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl run nginx --image=nginx:latest --port=80 --replicas=1</span><br></pre></td></tr></table></figure>\n<ol>\n<li>run后面指定该<code>deployment</code>的名称，这个名称是该应用在集群中的唯一标识</li>\n<li><code>--image</code>是必带参数，指定Docker镜像，k8s会自动从远程registry拉取所需要的docker镜像</li>\n<li><code>--port</code>是可选参数，指定该<code>deployment</code>的<code>pod</code>需要暴露的端口号，比如nginx服务就需要暴露它的80端口</li>\n<li><code>--replicas</code>是可选参数，指定<code>pod</code>副本数量</li>\n</ol>\n<p>启动完成后，<code>Deployment Controller</code>会自动创建<code>Replica Set</code>（管理pod的副本集）和多个<code>pod</code>（由<code>--replicas</code>参数指定）</p>\n<p>用kubectl get deployments命令查看创建的nginx deployment (如果不指定名称nginx，则显示所有的deployment)：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl get deployments nginx</span><br><span class=\"line\">NAME    READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class=\"line\">nginx   1/1     1            1           17h</span><br></pre></td></tr></table></figure>\n<p>使用describe命令查看这个deployment的配置细节：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl describe deployments nginx</span><br><span class=\"line\">Name:                   nginx</span><br><span class=\"line\">Namespace:              default</span><br><span class=\"line\">CreationTimestamp:      Mon, 08 Jul 2019 17:46:20 +0900</span><br><span class=\"line\">Labels:                 run=nginx</span><br><span class=\"line\">Annotations:            deployment.kubernetes.io/revision: 1</span><br><span class=\"line\">Selector:               run=nginx</span><br><span class=\"line\">Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable</span><br><span class=\"line\">StrategyType:           RollingUpdate</span><br><span class=\"line\">MinReadySeconds:        0</span><br><span class=\"line\">RollingUpdateStrategy:  25% max unavailable, 25% max surge</span><br><span class=\"line\">Pod Template:</span><br><span class=\"line\">  Labels:  run=nginx</span><br><span class=\"line\">  Containers:</span><br><span class=\"line\">   nginx:</span><br><span class=\"line\">    Image:        registry.navercorp.com/ncp-image/ncp-nginx:latest</span><br><span class=\"line\">    Port:         80/TCP</span><br><span class=\"line\">    Host Port:    0/TCP</span><br><span class=\"line\">    Environment:  &lt;none&gt;</span><br><span class=\"line\">    Mounts:       &lt;none&gt;</span><br><span class=\"line\">  Volumes:        &lt;none&gt;</span><br><span class=\"line\">Conditions:</span><br><span class=\"line\">  Type           Status  Reason</span><br><span class=\"line\">  ----           ------  ------</span><br><span class=\"line\">  Available      True    MinimumReplicasAvailable</span><br><span class=\"line\">  Progressing    True    NewReplicaSetAvailable</span><br><span class=\"line\">OldReplicaSets:  &lt;none&gt;</span><br><span class=\"line\">NewReplicaSet:   nginx-79b9dfdd46 (1/1 replicas created)</span><br><span class=\"line\">Events:          &lt;none&gt;</span><br></pre></td></tr></table></figure>\n<p>在这里面可以查看当前deployment的状态，比如名称，namespace，创建时间，当前副本整体状态，还有就是<code>Labels</code>和<code>Selector</code>，用于后续<code>replica set</code>和<code>pod</code>还有<code>service</code>和<code>pod</code>之间的配对关系</p>\n<h5 id=\"查看replica-set和pod\"><a href=\"#查看replica-set和pod\" class=\"headerlink\" title=\"查看replica set和pod\"></a>查看<code>replica set</code>和<code>pod</code></h5><p>使用<code>kubectl run</code>命令创建<code>deployment</code>的话，会自动创建默认的<code>replica set</code>和<code>pod</code> ，这也是k8s官方推荐的方式 （如果不采用这种方式，则需要自己指定template然后使用<code>kubectl create</code>分别创建deployment, replica set和pod）</p>\n<p>使用以下命令查看刚创建的<code>replica set</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl get replicasets</span><br><span class=\"line\">NAME               DESIRED   CURRENT   READY   AGE</span><br><span class=\"line\">curl-6bf6db5c4f    1         1         1       25h</span><br><span class=\"line\">nginx-79b9dfdd46   1         1         1       18h</span><br></pre></td></tr></table></figure>\n<p>默认创建的<code>replica set</code>是nginx-79b9dfdd46，使用<code>kubectl describe</code>命令查看详情：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl describe replicaset nginx-79b9dfdd46</span><br><span class=\"line\">Name:           nginx-79b9dfdd46</span><br><span class=\"line\">Namespace:      default</span><br><span class=\"line\">Selector:       pod-template-hash=79b9dfdd46,run=nginx</span><br><span class=\"line\">Labels:         pod-template-hash=79b9dfdd46</span><br><span class=\"line\">                run=nginx</span><br><span class=\"line\">Annotations:    deployment.kubernetes.io/desired-replicas: 1</span><br><span class=\"line\">                deployment.kubernetes.io/max-replicas: 2</span><br><span class=\"line\">                deployment.kubernetes.io/revision: 1</span><br><span class=\"line\">Controlled By:  Deployment/nginx</span><br><span class=\"line\">Replicas:       1 current / 1 desired</span><br><span class=\"line\">Pods Status:    1 Running / 0 Waiting / 0 Succeeded / 0 Failed</span><br><span class=\"line\">Pod Template:</span><br><span class=\"line\">  Labels:  pod-template-hash=79b9dfdd46</span><br><span class=\"line\">           run=nginx</span><br><span class=\"line\">  Containers:</span><br><span class=\"line\">   nginx:</span><br><span class=\"line\">    Image:        registry.navercorp.com/ncp-image/ncp-nginx:latest</span><br><span class=\"line\">    Port:         80/TCP</span><br><span class=\"line\">    Host Port:    0/TCP</span><br><span class=\"line\">    Environment:  &lt;none&gt;</span><br><span class=\"line\">    Mounts:       &lt;none&gt;</span><br><span class=\"line\">  Volumes:        &lt;none&gt;</span><br><span class=\"line\">Events:           &lt;none&gt;</span><br></pre></td></tr></table></figure>\n<p>参数与<code>deployment</code>差别不大，可重点关注以下参数：</p>\n<ol>\n<li><code>deployment.kubernetes.io/desired-replicas</code>和<code>deployment.kubernetes.io/max-replicas</code>参数，配置了期望副本数和最大副本数</li>\n<li>Controlled By参数，说明是由nginx的这个<code>deployment</code>来进行管理</li>\n<li>Pods Status：当前管理的pod状态</li>\n<li>Replicas：当前副本集状态，<code>1 current / 1 desired</code>说明当前已经成功启动一个pod，并且期望的pod副本数也为1个</li>\n</ol>\n<p>使用以下命令查看<code>pod</code>：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl get pods</span><br><span class=\"line\">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">curl-6bf6db5c4f-4mkxk    1/1     Running   0          18h</span><br><span class=\"line\">nginx-79b9dfdd46-qc94z   1/1     Running   0          18h</span><br></pre></td></tr></table></figure>\n<p>可以看到，刚创建的默认pod只有一个，status为Running，说明当前运行健康（若为Pending或者Unknown等状态说明pod调度失败）</p>\n<p>查看<code>pod</code>详情：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl describe pods nginx-79b9dfdd46-qc94z</span><br><span class=\"line\">Name:           nginx-79b9dfdd46-qc94z</span><br><span class=\"line\">Namespace:      default</span><br><span class=\"line\">Priority:       0</span><br><span class=\"line\">Node:           dev-ncc-slave-1-ncl/10.106.147.158</span><br><span class=\"line\">Start Time:     Mon, 08 Jul 2019 18:58:40 +0900</span><br><span class=\"line\">Labels:         pod-template-hash=79b9dfdd46</span><br><span class=\"line\">                run=nginx</span><br><span class=\"line\">Annotations:    &lt;none&gt;</span><br><span class=\"line\">Status:         Running</span><br><span class=\"line\">IP:             10.244.2.2</span><br><span class=\"line\">Controlled By:  ReplicaSet/nginx-79b9dfdd46</span><br><span class=\"line\">Containers:</span><br><span class=\"line\">  nginx:</span><br><span class=\"line\">    Container ID:   docker://4c06715be9d3fc575285621f595c5c2d9f67ef5fbd6d792618f0fb3449f85892</span><br><span class=\"line\">    Image:          registry.navercorp.com/ncp-image/ncp-nginx:latest</span><br><span class=\"line\">    Image ID:       docker-pullable://registry.navercorp.com/ncp-image/ncp-nginx@sha256:650cfc6f4e39b5bd5ec6bc57063886ba6e8808d691ac99200ac39fac2252c6ea</span><br><span class=\"line\">    Port:           80/TCP</span><br><span class=\"line\">    Host Port:      0/TCP</span><br><span class=\"line\">    State:          Running</span><br><span class=\"line\">      Started:      Mon, 08 Jul 2019 18:59:01 +0900</span><br><span class=\"line\">    Ready:          True</span><br><span class=\"line\">    Restart Count:  0</span><br><span class=\"line\">    Environment:    &lt;none&gt;</span><br><span class=\"line\">    Mounts:</span><br><span class=\"line\">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-zbdxq (ro)</span><br><span class=\"line\">Conditions:</span><br><span class=\"line\">  Type              Status</span><br><span class=\"line\">  Initialized       True </span><br><span class=\"line\">  Ready             True </span><br><span class=\"line\">  ContainersReady   True </span><br><span class=\"line\">  PodScheduled      True </span><br><span class=\"line\">Volumes:</span><br><span class=\"line\">  default-token-zbdxq:</span><br><span class=\"line\">    Type:        Secret (a volume populated by a Secret)</span><br><span class=\"line\">    SecretName:  default-token-zbdxq</span><br><span class=\"line\">    Optional:    false</span><br><span class=\"line\">QoS Class:       BestEffort</span><br><span class=\"line\">Node-Selectors:  &lt;none&gt;</span><br><span class=\"line\">Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s</span><br><span class=\"line\">                 node.kubernetes.io/unreachable:NoExecute for 300s</span><br><span class=\"line\">Events:          &lt;none&gt;</span><br></pre></td></tr></table></figure>\n<p>重点关注以下参数：</p>\n<ol>\n<li>Node：当前pod被调度至服务器节点的host name</li>\n<li>Labels：标签，只有当labels与之前<code>replica set</code>的<code>Selector</code>保持一致，才会被相应的<code>Replica Controller</code>纳入管理进行动态缩/扩容；后续的<code>service</code>也是通过标签来discover当前有效的pod；标签可以在运行时动态修改</li>\n<li>IP：pod在k8s集群内部的ip</li>\n<li>Controlled By：标明当前pod是由哪个<code>replica set</code>进行管理</li>\n<li>Containers：pod封装的容器信息，一个pod可以有多个容器</li>\n<li>Tolerations：指定该pod多长时间未达到Ready状态或者k8s多长时间未检测到pod心跳后，允许k8s重新调度pod</li>\n<li>Events：pod经历的事件，deployment的滚动升级和缩/扩容等都会产生事件</li>\n</ol>\n<p>在确认<code>replica set</code>和<code>pod</code>状态确认无误后，即可将该应用暴露为服务</p>\n<h5 id=\"暴露服务\"><a href=\"#暴露服务\" class=\"headerlink\" title=\"暴露服务\"></a>暴露服务</h5><p>使用<code>kubectl expose</code>命令将nginx deployment暴露为服务：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl expose deployment/nginx --type=\"NodePort\" --port 80</span><br></pre></td></tr></table></figure>\n<ol>\n<li>–type：当前暴露形式，指定<code>NodePort</code>的话，k8s会给当前服务随机分派一个30000-32767之间的端口号，外界可以直接通过<code>服务器node ip + node port</code>的方式访问这个服务</li>\n<li>–port：指定应用所需要暴露的端口，nginx服务则需要暴露他的80端口</li>\n</ol>\n<p>查看暴露的服务：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span> kubectl get services</span><br><span class=\"line\">NAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class=\"line\">kubernetes            ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP          12m</span><br><span class=\"line\">nginx                 NodePort    10.109.107.109   &lt;none&gt;        80:31482/TCP   5m1s</span><br></pre></td></tr></table></figure>\n<p>查看详情：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl describe services nginx</span><br><span class=\"line\">Name:                     nginx</span><br><span class=\"line\">Namespace:                default</span><br><span class=\"line\">Labels:                   run=nginx</span><br><span class=\"line\">Annotations:              &lt;none&gt;</span><br><span class=\"line\">Selector:                 run=nginx</span><br><span class=\"line\">Type:                     NodePort</span><br><span class=\"line\">IP:                       10.109.107.109</span><br><span class=\"line\">Port:                     &lt;unset&gt;  80/TCP</span><br><span class=\"line\">TargetPort:               80/TCP</span><br><span class=\"line\">NodePort:                 &lt;unset&gt;  31482/TCP</span><br><span class=\"line\">Endpoints:                10.244.2.2:80</span><br><span class=\"line\">Session Affinity:         None</span><br><span class=\"line\">External Traffic Policy:  Cluster</span><br><span class=\"line\">Events:                   &lt;none&gt;</span><br></pre></td></tr></table></figure>\n<p>默认情况下，<code>service</code>名称和<code>deployment</code>名称保持一致，其他参数：</p>\n<ul>\n<li>Selector：<code>service</code>通过<code>Selector</code>选择来匹配对应的<code>pod</code>，k8s会通过<code>Endpoints Controller</code>来定期更新健康的符合<code>Selector</code>匹配规则的<code>pod</code>路由表，在这里nginx service将寻找所有labels为run=nginx的<code>pod</code>作为路由对象</li>\n<li>IP：<code>service</code>在集群中的唯一ip地址</li>\n</ul>\n<p><code>service</code>的<code>NodePort</code>是31482，因此我们可以直接在本机使用localhost访问这个nginx服务了：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ curl localhost:31482</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;</span><br><span class=\"line\">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class=\"line\">&lt;style&gt;</span><br><span class=\"line\">    body &#123;</span><br><span class=\"line\">        width: 35em;</span><br><span class=\"line\">        margin: 0 auto;</span><br><span class=\"line\">        font-family: Tahoma, Verdana, Arial, sans-serif;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&lt;/style&gt;</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>至此已经成功发布nginx service</p>\n<p><code>Service</code>和<code>Deployment</code>,<code>Replica Set</code>还有<code>Pod</code>之间的关系：</p>\n<p><img src=\"\\blog\\images\\image.png\" alt=\"upload successful\"></p>\n<p>一个<code>deployment</code>可以创建多个<code>replica set</code>和<code>pod</code>以及<code>service</code>，<code>replica set</code>和<code>service</code>通过<code>Selector</code>指定的值来匹配带有相关<code>Labels</code>的<code>pod</code></p>\n<h4 id=\"k8s内部的服务发现\"><a href=\"#k8s内部的服务发现\" class=\"headerlink\" title=\"k8s内部的服务发现\"></a>k8s内部的服务发现</h4><p>k8s内部通过何种方式发现我们发布的<code>nginx service</code> ?</p>\n<p>目前有三种方式：</p>\n<ol>\n<li><p><code>NodePort方式</code>：即上面通过<code>node ip + node port</code>将访问路径固定，这种方式不够灵活，通常只能用于外界调试</p>\n</li>\n<li><p><code>环境变量方式</code>：k8s默认会在每个 pod 启动时候会把所有服务的 IP 和 port 信息配置到当前pod的环境变量中，这样 pod 中的应用可以通过读取环境变量来获取依赖服务的地址信息。这种方式服务和环境变量的匹配关系有一定的规范，使用起来也相对简单，但是有个很大的问题：依赖的服务必须在 pod 启动之前就存在，不然是不会出现在环境变量中的。</p>\n</li>\n<li><p><code>kube-dns</code>方式：k8s官方推荐通过<code>kubeDNS + dnsmasq</code>的方式配置kube-dns插件，kube-dns可以缓存所有已经存在的<code>service</code>信息供服务调用方发现并调用服务，其他服务可以直接使用以下方式调用nginx服务：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://&lt;service_name&gt;.&lt;namespace&gt;.svc.&lt;domain&gt;:80/</span><br></pre></td></tr></table></figure>\n<p><code>service_name</code>：即服务名nginx</p>\n<p><code>namespace</code>：k8s命名空间，创建deployment时不特别指定的话，<code>namespace</code>均为”default”</p>\n<p><code>domain</code>：域名后缀，默认为<code>cluster.local</code></p>\n<p>在 <code>pod</code> 中访问也可以使用缩写 <code>service_name.namespace</code>，如果 pod 和 service 在同一个 <code>namespace</code>，可以直接使用 <code>service_name</code>，因此如果同一个<code>namespace</code>有其他服务要访问nginx，则直接使用<code>nginx</code>作为域名即可：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://nginx:80/</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h5 id=\"测试服务发现\"><a href=\"#测试服务发现\" class=\"headerlink\" title=\"测试服务发现\"></a>测试服务发现</h5><p>手动测试<code>service</code>的服务发现需要进入到<code>pod</code>内部，执行以下命令进入<code>pod</code>内部环境，进入到<code>pod</code>后可以通过curl命令访问<code>http://nginx:80/</code> (镜像没有安装curl，可用yum进行安装)：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl get pods</span><br><span class=\"line\">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">curl-6bf6db5c4f-4mkxk    1/1     Running   0          22h</span><br><span class=\"line\">nginx-5ff9d6cc77-5nxpn   1/1     Running   0          59m</span><br><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl exec nginx-5ff9d6cc77-5nxpn -it -- /bin/bash</span><br><span class=\"line\">root@nginx-5ff9d6cc77-5nxpn:/# curl nginx:80/</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;</span><br><span class=\"line\">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class=\"line\">&lt;style&gt;</span><br><span class=\"line\">    body &#123;</span><br><span class=\"line\">        width: 35em;</span><br><span class=\"line\">        margin: 0 auto;</span><br><span class=\"line\">        font-family: Tahoma, Verdana, Arial, sans-serif;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&lt;/style&gt;</span><br><span class=\"line\">......</span><br></pre></td></tr></table></figure>\n<p>使用<code>Ctrl P + Ctrl Q</code>命令退出<code>pod</code>环境</p>\n<h4 id=\"删除service和deployment\"><a href=\"#删除service和deployment\" class=\"headerlink\" title=\"删除service和deployment\"></a>删除service和deployment</h4><p><code>kubectl</code>工具提供一键式删除<code>service</code>和<code>deployment</code>，当<code>deployment</code>被删除后，对应的<code>pod</code>同时被回收</p>\n<p>使用以下命令删除nginx service:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl delete services nginx</span><br><span class=\"line\">service \"nginx\" deleted</span><br></pre></td></tr></table></figure>\n<p>使用以下命令删除nginx deployment:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[irteam@dev-ncc-client-ncl ~]$ kubectl delete deployments nginx</span><br><span class=\"line\">deployment.extensions \"nginx\" deleted</span><br></pre></td></tr></table></figure>\n<p>随后再查看<code>pod</code>可以发现之前创建的<code>pod</code>均被删除</p>"},{"title":"Yarn初探","author":"天渊","date":"2019-05-05T15:15:00.000Z","_content":"Yarn (Yet Another Resource Manager) 是Hadoop 2.0引入的集群计算资源管理系统，最初是为了改善MapReduce任务调度过程，同时也可以支持其他多种分布式计算模式，Yarn不与任何一种计算框架耦合，只参与集群计算资源（CPU，内存等）的分配以及计算任务的调度\n\n探究MapReduce任务从调用`submit()`提交任务到Yarn运行任务的整个过程是件很有意思的事\n\n<!--more-->\n\n### 初始化任务\n\n初始化任务包括以下四个阶段：\n\n1. `申请任务`：主要是向Yarn申请`jobId`\n2. `保存job执行文件`：保存job配置信息，分片信息和Jar包等文件\n3. `加入任务队列`：向`ResourceManager`提交任务，加入任务队列\n\n#### 申请任务\n\nMapReduce的Client在调用`job.submit()`后，交由`JobSubmitter`进行任务提交，调用`submitJobInternal`方法首先申请一个`jobId`:\n\n```java\n//... 略\nJobID jobId = submitClient.getNewJobID();\njob.setJobID(jobId);\n//... 并行度切分，保存Job执行文件，提交任务等\n```\n\n其中`submitClient`是mapreduce的RPC client，有两种实现\n\n- `LocalJobRunner`： 用于提交本地运行的任务，本地环境测试就是使用的这个client\n- `YARNRunner`：用于向Yarn集群提交任务\n\n如果配置Job时设置配置项`mapreduce.framework.name`为`yarn`，mapreduce将采用`YARNRunner`作为client进行任务提交工作，`YARNRunner`为当前Job分配一个`jobId`作为本次任务的唯一ID\n\n#### 保存Job执行文件\n\nJob执行文件包括job.splits, job.xml和job的Jar包等文件，mapreduce向文件系统（本地文件系统或者hdfs）申请一块区域用于存放执行文件：\n\n```java\n//... \nPath submitJobDir = new Path(jobStagingArea, jobId.toString());\n//...\nPath submitJobFile = JobSubmissionFiles.getJobConfPath(submitJobDir);\n```\n\n`submitJobDir`是用于保存Job执行文件的目录，`submitJobFile`即为当前Job文件的目录，格式为`.../staging/jobId`\n\n#### 加入任务队列\n\n使用`submitClient`向Yarn集群（在这里为`ResourceManager`节点）发起RPC请求提交任务：\n\n```java\nstatus = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());\n```\n\n`ResourceManager`会把当前Job加入到任务执行队列中待有可执行任务的资源可用后启动该任务\n\n### 运行Job\n\n集群中能够运行Job的资源是有限的，队列中待执行的Job想要运行需要满足一定的条件，目前Yarn提供了三种任务调度策略：`FIFO调度`，`容量调度`，`公平调度`，日后再分析\n\n#### 启动Container\n\n`ResourceManager`会定期接收各个`NodeManager`发来的节点资源使用信息，某个Job满足运行条件后首先需要申请一个可以运行任务的`NodeManager`，在之上启动一个“容器”：`Container`\n\n> 如何理解Yarn的Container？\n>\n> 可以理解为Yarn为Job运行而启动的一个运行环境，这个运行环境包含运行资源（程序运行所需要的数据，内存占用，还有Vcores虚拟核数，CPU占用的一个虚拟量化指标）\n\n如果Job配置了本地限制（即任务所需的优先需要加载本地HDFS资源，或者同一机架的HDFS副本），`ResourceManager`申请容器运行的节点时会优先申请存储有所需副本的节点，如果实在找不到再基于hadoop网络拓扑模型寻找当前机架的其他节点或者其他机架的节点，使得Job运行时所需要的数据尽量为本地数据，降低对集群带宽的依赖\n\n#### 启动MrAppMaster\n\n启动`Container`后，client会申请在这个“容器”中启动`MrAppMaster`，这个`MrAppMaster`读取Job执行文件，获取Job的配置文件和splits等信息，然后根据这些配置文件进行接下来的任务（直接运行任务，或者申请更多的`Container`并行启动任务）\n\n根据splits规划，如果需要申请更多节点运行并行任务，`MrAppMaster`会向`ResourceManager`申请启动更多的`Container`，然后在这些`Container`中启动mapTask（或者reduceTask），这些task进程在Yarn环境中统一称为`YarnChild`\n\n#### 启动Task\n\n`MrAppMaster`启动完成后，根据splits启动多个mapTask，待mapTask均完成后，再根据该job配置的reduce数目启动多个reduceTask，启动流程与mapTask完全一样，Yarn并不关心具体执行的什么任务，它只需要接收`MrAppMaster`的资源分配请求然后申请启动相应数量的`Container`即可，启动完成后任务内部的交互也不由Yarn负责，当Job完成后再向client返回任务执行结果\n\n### Yarn的特点\n\nYarn作为通用性很强的分布式计算资源调度框架，能够很好地和多种计算框架如MapReduce, Spark, Storm等进行集成，计算框架专注于计算逻辑的实现，Yarn则专注于集群资源的分配和调度\n\n对于除了MapReduce以外的其他计算框架，把上述的`MrAppMaster`替换为任何一种Master进程，把mapTask或者reduceTask替换为任何一个work进程，对于Yarn来说都没有问题，只要实现了Yarn的规范和api，都可以在Yarn上面运行\n\n","source":"_posts/Yarn初探.md","raw":"title: Yarn初探\nauthor: 天渊\ntags:\n  - Hadoop\n  - Yarn\ncategories:\n  - 大数据\ndate: 2019-05-05 23:15:00\n---\nYarn (Yet Another Resource Manager) 是Hadoop 2.0引入的集群计算资源管理系统，最初是为了改善MapReduce任务调度过程，同时也可以支持其他多种分布式计算模式，Yarn不与任何一种计算框架耦合，只参与集群计算资源（CPU，内存等）的分配以及计算任务的调度\n\n探究MapReduce任务从调用`submit()`提交任务到Yarn运行任务的整个过程是件很有意思的事\n\n<!--more-->\n\n### 初始化任务\n\n初始化任务包括以下四个阶段：\n\n1. `申请任务`：主要是向Yarn申请`jobId`\n2. `保存job执行文件`：保存job配置信息，分片信息和Jar包等文件\n3. `加入任务队列`：向`ResourceManager`提交任务，加入任务队列\n\n#### 申请任务\n\nMapReduce的Client在调用`job.submit()`后，交由`JobSubmitter`进行任务提交，调用`submitJobInternal`方法首先申请一个`jobId`:\n\n```java\n//... 略\nJobID jobId = submitClient.getNewJobID();\njob.setJobID(jobId);\n//... 并行度切分，保存Job执行文件，提交任务等\n```\n\n其中`submitClient`是mapreduce的RPC client，有两种实现\n\n- `LocalJobRunner`： 用于提交本地运行的任务，本地环境测试就是使用的这个client\n- `YARNRunner`：用于向Yarn集群提交任务\n\n如果配置Job时设置配置项`mapreduce.framework.name`为`yarn`，mapreduce将采用`YARNRunner`作为client进行任务提交工作，`YARNRunner`为当前Job分配一个`jobId`作为本次任务的唯一ID\n\n#### 保存Job执行文件\n\nJob执行文件包括job.splits, job.xml和job的Jar包等文件，mapreduce向文件系统（本地文件系统或者hdfs）申请一块区域用于存放执行文件：\n\n```java\n//... \nPath submitJobDir = new Path(jobStagingArea, jobId.toString());\n//...\nPath submitJobFile = JobSubmissionFiles.getJobConfPath(submitJobDir);\n```\n\n`submitJobDir`是用于保存Job执行文件的目录，`submitJobFile`即为当前Job文件的目录，格式为`.../staging/jobId`\n\n#### 加入任务队列\n\n使用`submitClient`向Yarn集群（在这里为`ResourceManager`节点）发起RPC请求提交任务：\n\n```java\nstatus = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());\n```\n\n`ResourceManager`会把当前Job加入到任务执行队列中待有可执行任务的资源可用后启动该任务\n\n### 运行Job\n\n集群中能够运行Job的资源是有限的，队列中待执行的Job想要运行需要满足一定的条件，目前Yarn提供了三种任务调度策略：`FIFO调度`，`容量调度`，`公平调度`，日后再分析\n\n#### 启动Container\n\n`ResourceManager`会定期接收各个`NodeManager`发来的节点资源使用信息，某个Job满足运行条件后首先需要申请一个可以运行任务的`NodeManager`，在之上启动一个“容器”：`Container`\n\n> 如何理解Yarn的Container？\n>\n> 可以理解为Yarn为Job运行而启动的一个运行环境，这个运行环境包含运行资源（程序运行所需要的数据，内存占用，还有Vcores虚拟核数，CPU占用的一个虚拟量化指标）\n\n如果Job配置了本地限制（即任务所需的优先需要加载本地HDFS资源，或者同一机架的HDFS副本），`ResourceManager`申请容器运行的节点时会优先申请存储有所需副本的节点，如果实在找不到再基于hadoop网络拓扑模型寻找当前机架的其他节点或者其他机架的节点，使得Job运行时所需要的数据尽量为本地数据，降低对集群带宽的依赖\n\n#### 启动MrAppMaster\n\n启动`Container`后，client会申请在这个“容器”中启动`MrAppMaster`，这个`MrAppMaster`读取Job执行文件，获取Job的配置文件和splits等信息，然后根据这些配置文件进行接下来的任务（直接运行任务，或者申请更多的`Container`并行启动任务）\n\n根据splits规划，如果需要申请更多节点运行并行任务，`MrAppMaster`会向`ResourceManager`申请启动更多的`Container`，然后在这些`Container`中启动mapTask（或者reduceTask），这些task进程在Yarn环境中统一称为`YarnChild`\n\n#### 启动Task\n\n`MrAppMaster`启动完成后，根据splits启动多个mapTask，待mapTask均完成后，再根据该job配置的reduce数目启动多个reduceTask，启动流程与mapTask完全一样，Yarn并不关心具体执行的什么任务，它只需要接收`MrAppMaster`的资源分配请求然后申请启动相应数量的`Container`即可，启动完成后任务内部的交互也不由Yarn负责，当Job完成后再向client返回任务执行结果\n\n### Yarn的特点\n\nYarn作为通用性很强的分布式计算资源调度框架，能够很好地和多种计算框架如MapReduce, Spark, Storm等进行集成，计算框架专注于计算逻辑的实现，Yarn则专注于集群资源的分配和调度\n\n对于除了MapReduce以外的其他计算框架，把上述的`MrAppMaster`替换为任何一种Master进程，把mapTask或者reduceTask替换为任何一个work进程，对于Yarn来说都没有问题，只要实现了Yarn的规范和api，都可以在Yarn上面运行\n\n","slug":"Yarn初探","published":1,"updated":"2019-05-05T15:16:31.806Z","_id":"ckf0h31hl000lactsvd1z8o9x","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Yarn (Yet Another Resource Manager) 是Hadoop 2.0引入的集群计算资源管理系统，最初是为了改善MapReduce任务调度过程，同时也可以支持其他多种分布式计算模式，Yarn不与任何一种计算框架耦合，只参与集群计算资源（CPU，内存等）的分配以及计算任务的调度</p>\n<p>探究MapReduce任务从调用<code>submit()</code>提交任务到Yarn运行任务的整个过程是件很有意思的事</p>\n<a id=\"more\"></a>\n<h3 id=\"初始化任务\"><a href=\"#初始化任务\" class=\"headerlink\" title=\"初始化任务\"></a>初始化任务</h3><p>初始化任务包括以下四个阶段：</p>\n<ol>\n<li><code>申请任务</code>：主要是向Yarn申请<code>jobId</code></li>\n<li><code>保存job执行文件</code>：保存job配置信息，分片信息和Jar包等文件</li>\n<li><code>加入任务队列</code>：向<code>ResourceManager</code>提交任务，加入任务队列</li>\n</ol>\n<h4 id=\"申请任务\"><a href=\"#申请任务\" class=\"headerlink\" title=\"申请任务\"></a>申请任务</h4><p>MapReduce的Client在调用<code>job.submit()</code>后，交由<code>JobSubmitter</code>进行任务提交，调用<code>submitJobInternal</code>方法首先申请一个<code>jobId</code>:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//... 略</span></span><br><span class=\"line\">JobID jobId = submitClient.getNewJobID();</span><br><span class=\"line\">job.setJobID(jobId);</span><br><span class=\"line\"><span class=\"comment\">//... 并行度切分，保存Job执行文件，提交任务等</span></span><br></pre></td></tr></table></figure>\n<p>其中<code>submitClient</code>是mapreduce的RPC client，有两种实现</p>\n<ul>\n<li><code>LocalJobRunner</code>： 用于提交本地运行的任务，本地环境测试就是使用的这个client</li>\n<li><code>YARNRunner</code>：用于向Yarn集群提交任务</li>\n</ul>\n<p>如果配置Job时设置配置项<code>mapreduce.framework.name</code>为<code>yarn</code>，mapreduce将采用<code>YARNRunner</code>作为client进行任务提交工作，<code>YARNRunner</code>为当前Job分配一个<code>jobId</code>作为本次任务的唯一ID</p>\n<h4 id=\"保存Job执行文件\"><a href=\"#保存Job执行文件\" class=\"headerlink\" title=\"保存Job执行文件\"></a>保存Job执行文件</h4><p>Job执行文件包括job.splits, job.xml和job的Jar包等文件，mapreduce向文件系统（本地文件系统或者hdfs）申请一块区域用于存放执行文件：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//... </span></span><br><span class=\"line\">Path submitJobDir = <span class=\"keyword\">new</span> Path(jobStagingArea, jobId.toString());</span><br><span class=\"line\"><span class=\"comment\">//...</span></span><br><span class=\"line\">Path submitJobFile = JobSubmissionFiles.getJobConfPath(submitJobDir);</span><br></pre></td></tr></table></figure>\n<p><code>submitJobDir</code>是用于保存Job执行文件的目录，<code>submitJobFile</code>即为当前Job文件的目录，格式为<code>.../staging/jobId</code></p>\n<h4 id=\"加入任务队列\"><a href=\"#加入任务队列\" class=\"headerlink\" title=\"加入任务队列\"></a>加入任务队列</h4><p>使用<code>submitClient</code>向Yarn集群（在这里为<code>ResourceManager</code>节点）发起RPC请求提交任务：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br></pre></td></tr></table></figure>\n<p><code>ResourceManager</code>会把当前Job加入到任务执行队列中待有可执行任务的资源可用后启动该任务</p>\n<h3 id=\"运行Job\"><a href=\"#运行Job\" class=\"headerlink\" title=\"运行Job\"></a>运行Job</h3><p>集群中能够运行Job的资源是有限的，队列中待执行的Job想要运行需要满足一定的条件，目前Yarn提供了三种任务调度策略：<code>FIFO调度</code>，<code>容量调度</code>，<code>公平调度</code>，日后再分析</p>\n<h4 id=\"启动Container\"><a href=\"#启动Container\" class=\"headerlink\" title=\"启动Container\"></a>启动Container</h4><p><code>ResourceManager</code>会定期接收各个<code>NodeManager</code>发来的节点资源使用信息，某个Job满足运行条件后首先需要申请一个可以运行任务的<code>NodeManager</code>，在之上启动一个“容器”：<code>Container</code></p>\n<blockquote>\n<p>如何理解Yarn的Container？</p>\n<p>可以理解为Yarn为Job运行而启动的一个运行环境，这个运行环境包含运行资源（程序运行所需要的数据，内存占用，还有Vcores虚拟核数，CPU占用的一个虚拟量化指标）</p>\n</blockquote>\n<p>如果Job配置了本地限制（即任务所需的优先需要加载本地HDFS资源，或者同一机架的HDFS副本），<code>ResourceManager</code>申请容器运行的节点时会优先申请存储有所需副本的节点，如果实在找不到再基于hadoop网络拓扑模型寻找当前机架的其他节点或者其他机架的节点，使得Job运行时所需要的数据尽量为本地数据，降低对集群带宽的依赖</p>\n<h4 id=\"启动MrAppMaster\"><a href=\"#启动MrAppMaster\" class=\"headerlink\" title=\"启动MrAppMaster\"></a>启动MrAppMaster</h4><p>启动<code>Container</code>后，client会申请在这个“容器”中启动<code>MrAppMaster</code>，这个<code>MrAppMaster</code>读取Job执行文件，获取Job的配置文件和splits等信息，然后根据这些配置文件进行接下来的任务（直接运行任务，或者申请更多的<code>Container</code>并行启动任务）</p>\n<p>根据splits规划，如果需要申请更多节点运行并行任务，<code>MrAppMaster</code>会向<code>ResourceManager</code>申请启动更多的<code>Container</code>，然后在这些<code>Container</code>中启动mapTask（或者reduceTask），这些task进程在Yarn环境中统一称为<code>YarnChild</code></p>\n<h4 id=\"启动Task\"><a href=\"#启动Task\" class=\"headerlink\" title=\"启动Task\"></a>启动Task</h4><p><code>MrAppMaster</code>启动完成后，根据splits启动多个mapTask，待mapTask均完成后，再根据该job配置的reduce数目启动多个reduceTask，启动流程与mapTask完全一样，Yarn并不关心具体执行的什么任务，它只需要接收<code>MrAppMaster</code>的资源分配请求然后申请启动相应数量的<code>Container</code>即可，启动完成后任务内部的交互也不由Yarn负责，当Job完成后再向client返回任务执行结果</p>\n<h3 id=\"Yarn的特点\"><a href=\"#Yarn的特点\" class=\"headerlink\" title=\"Yarn的特点\"></a>Yarn的特点</h3><p>Yarn作为通用性很强的分布式计算资源调度框架，能够很好地和多种计算框架如MapReduce, Spark, Storm等进行集成，计算框架专注于计算逻辑的实现，Yarn则专注于集群资源的分配和调度</p>\n<p>对于除了MapReduce以外的其他计算框架，把上述的<code>MrAppMaster</code>替换为任何一种Master进程，把mapTask或者reduceTask替换为任何一个work进程，对于Yarn来说都没有问题，只要实现了Yarn的规范和api，都可以在Yarn上面运行</p>\n","site":{"data":{}},"excerpt":"<p>Yarn (Yet Another Resource Manager) 是Hadoop 2.0引入的集群计算资源管理系统，最初是为了改善MapReduce任务调度过程，同时也可以支持其他多种分布式计算模式，Yarn不与任何一种计算框架耦合，只参与集群计算资源（CPU，内存等）的分配以及计算任务的调度</p>\n<p>探究MapReduce任务从调用<code>submit()</code>提交任务到Yarn运行任务的整个过程是件很有意思的事</p>","more":"<h3 id=\"初始化任务\"><a href=\"#初始化任务\" class=\"headerlink\" title=\"初始化任务\"></a>初始化任务</h3><p>初始化任务包括以下四个阶段：</p>\n<ol>\n<li><code>申请任务</code>：主要是向Yarn申请<code>jobId</code></li>\n<li><code>保存job执行文件</code>：保存job配置信息，分片信息和Jar包等文件</li>\n<li><code>加入任务队列</code>：向<code>ResourceManager</code>提交任务，加入任务队列</li>\n</ol>\n<h4 id=\"申请任务\"><a href=\"#申请任务\" class=\"headerlink\" title=\"申请任务\"></a>申请任务</h4><p>MapReduce的Client在调用<code>job.submit()</code>后，交由<code>JobSubmitter</code>进行任务提交，调用<code>submitJobInternal</code>方法首先申请一个<code>jobId</code>:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//... 略</span></span><br><span class=\"line\">JobID jobId = submitClient.getNewJobID();</span><br><span class=\"line\">job.setJobID(jobId);</span><br><span class=\"line\"><span class=\"comment\">//... 并行度切分，保存Job执行文件，提交任务等</span></span><br></pre></td></tr></table></figure>\n<p>其中<code>submitClient</code>是mapreduce的RPC client，有两种实现</p>\n<ul>\n<li><code>LocalJobRunner</code>： 用于提交本地运行的任务，本地环境测试就是使用的这个client</li>\n<li><code>YARNRunner</code>：用于向Yarn集群提交任务</li>\n</ul>\n<p>如果配置Job时设置配置项<code>mapreduce.framework.name</code>为<code>yarn</code>，mapreduce将采用<code>YARNRunner</code>作为client进行任务提交工作，<code>YARNRunner</code>为当前Job分配一个<code>jobId</code>作为本次任务的唯一ID</p>\n<h4 id=\"保存Job执行文件\"><a href=\"#保存Job执行文件\" class=\"headerlink\" title=\"保存Job执行文件\"></a>保存Job执行文件</h4><p>Job执行文件包括job.splits, job.xml和job的Jar包等文件，mapreduce向文件系统（本地文件系统或者hdfs）申请一块区域用于存放执行文件：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//... </span></span><br><span class=\"line\">Path submitJobDir = <span class=\"keyword\">new</span> Path(jobStagingArea, jobId.toString());</span><br><span class=\"line\"><span class=\"comment\">//...</span></span><br><span class=\"line\">Path submitJobFile = JobSubmissionFiles.getJobConfPath(submitJobDir);</span><br></pre></td></tr></table></figure>\n<p><code>submitJobDir</code>是用于保存Job执行文件的目录，<code>submitJobFile</code>即为当前Job文件的目录，格式为<code>.../staging/jobId</code></p>\n<h4 id=\"加入任务队列\"><a href=\"#加入任务队列\" class=\"headerlink\" title=\"加入任务队列\"></a>加入任务队列</h4><p>使用<code>submitClient</code>向Yarn集群（在这里为<code>ResourceManager</code>节点）发起RPC请求提交任务：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br></pre></td></tr></table></figure>\n<p><code>ResourceManager</code>会把当前Job加入到任务执行队列中待有可执行任务的资源可用后启动该任务</p>\n<h3 id=\"运行Job\"><a href=\"#运行Job\" class=\"headerlink\" title=\"运行Job\"></a>运行Job</h3><p>集群中能够运行Job的资源是有限的，队列中待执行的Job想要运行需要满足一定的条件，目前Yarn提供了三种任务调度策略：<code>FIFO调度</code>，<code>容量调度</code>，<code>公平调度</code>，日后再分析</p>\n<h4 id=\"启动Container\"><a href=\"#启动Container\" class=\"headerlink\" title=\"启动Container\"></a>启动Container</h4><p><code>ResourceManager</code>会定期接收各个<code>NodeManager</code>发来的节点资源使用信息，某个Job满足运行条件后首先需要申请一个可以运行任务的<code>NodeManager</code>，在之上启动一个“容器”：<code>Container</code></p>\n<blockquote>\n<p>如何理解Yarn的Container？</p>\n<p>可以理解为Yarn为Job运行而启动的一个运行环境，这个运行环境包含运行资源（程序运行所需要的数据，内存占用，还有Vcores虚拟核数，CPU占用的一个虚拟量化指标）</p>\n</blockquote>\n<p>如果Job配置了本地限制（即任务所需的优先需要加载本地HDFS资源，或者同一机架的HDFS副本），<code>ResourceManager</code>申请容器运行的节点时会优先申请存储有所需副本的节点，如果实在找不到再基于hadoop网络拓扑模型寻找当前机架的其他节点或者其他机架的节点，使得Job运行时所需要的数据尽量为本地数据，降低对集群带宽的依赖</p>\n<h4 id=\"启动MrAppMaster\"><a href=\"#启动MrAppMaster\" class=\"headerlink\" title=\"启动MrAppMaster\"></a>启动MrAppMaster</h4><p>启动<code>Container</code>后，client会申请在这个“容器”中启动<code>MrAppMaster</code>，这个<code>MrAppMaster</code>读取Job执行文件，获取Job的配置文件和splits等信息，然后根据这些配置文件进行接下来的任务（直接运行任务，或者申请更多的<code>Container</code>并行启动任务）</p>\n<p>根据splits规划，如果需要申请更多节点运行并行任务，<code>MrAppMaster</code>会向<code>ResourceManager</code>申请启动更多的<code>Container</code>，然后在这些<code>Container</code>中启动mapTask（或者reduceTask），这些task进程在Yarn环境中统一称为<code>YarnChild</code></p>\n<h4 id=\"启动Task\"><a href=\"#启动Task\" class=\"headerlink\" title=\"启动Task\"></a>启动Task</h4><p><code>MrAppMaster</code>启动完成后，根据splits启动多个mapTask，待mapTask均完成后，再根据该job配置的reduce数目启动多个reduceTask，启动流程与mapTask完全一样，Yarn并不关心具体执行的什么任务，它只需要接收<code>MrAppMaster</code>的资源分配请求然后申请启动相应数量的<code>Container</code>即可，启动完成后任务内部的交互也不由Yarn负责，当Job完成后再向client返回任务执行结果</p>\n<h3 id=\"Yarn的特点\"><a href=\"#Yarn的特点\" class=\"headerlink\" title=\"Yarn的特点\"></a>Yarn的特点</h3><p>Yarn作为通用性很强的分布式计算资源调度框架，能够很好地和多种计算框架如MapReduce, Spark, Storm等进行集成，计算框架专注于计算逻辑的实现，Yarn则专注于集群资源的分配和调度</p>\n<p>对于除了MapReduce以外的其他计算框架，把上述的<code>MrAppMaster</code>替换为任何一种Master进程，把mapTask或者reduceTask替换为任何一个work进程，对于Yarn来说都没有问题，只要实现了Yarn的规范和api，都可以在Yarn上面运行</p>"},{"title":"vim快捷键（1）","author":"天渊","date":"2019-01-21T03:18:00.000Z","_content":"vim编辑器有三个模式：一般模式，编辑模式，命令模式：\n<!--more-->\n\n- 一般模式：默认模式，可以新增删除复制粘贴，按Esc从当前模式转换到普通模式\n- 编辑模式：按i,o,a等字符进入编辑模式，可以编辑文本内容\n- 命令模式：按:,/,?三个字符中的一个进入命令模式，可以读取、查找数据、大量替换字符等操作\n\n### 基本操作\nvi+文件名 进入文档，按命令键进入编辑或者命令模式，Esc回到一般模式（命令模式和编辑模式不能相互转换），输入:w保存文档，输入:wq保存并离开文档，使用:wq!在没有权限的情况下强制写入，输入:q不保存并退出\n\n#### 文本浏览\n\n- 重新载入文件：\n\n  ```shell\n  :e\n  :e! #放弃当前修改，强制重新载入\n  :bufdo e 或者 :bufdo :e! #重新载入所有打开的文件\n  ```\n\n- 光标移动\n\n  ```shell\n  0  #数字0）移动光标至本行开头\n  $  #移动光标至本行末尾\n  ^  #移动光标至本行第一个非空字符\n  w  #向前移动一个词\n  W  #向前移动一个词 （以空格分隔的词）\n  5w  #向前移动5个词\n  b  #向后移动一个词\n  B  #向后移动一个词 （以空格分隔的词）\n  5b  #向后移动5个词\n  G  #移动至文件末尾\n  gg #移动至文件开头\n  ```\n\n- 搜索和替换\n\n  ```shell\n  :/search_text  #在文档后面部分检索search_text这个内容\n  :?search_text  #在文档前面部分检索search_text这个内容\n  n  #移动到后一个检索结果\n  N  #移动到前一个检索结果\n  :%s/original/replacement  #将第一个检索到的original替换为replacement\n  :%s/original/replacement/g\t#将所有original替换为replacement\n  :%s/original/replacement/gc\t #将所有original替换为replacement，但会先询问\n  ```","source":"_posts/Vim编辑器.md","raw":"title: vim快捷键（1）\ntags:\n  - vim\ncategories:\n  - 工具使用\nauthor: 天渊\ndate: 2019-01-21 11:18:00\n---\nvim编辑器有三个模式：一般模式，编辑模式，命令模式：\n<!--more-->\n\n- 一般模式：默认模式，可以新增删除复制粘贴，按Esc从当前模式转换到普通模式\n- 编辑模式：按i,o,a等字符进入编辑模式，可以编辑文本内容\n- 命令模式：按:,/,?三个字符中的一个进入命令模式，可以读取、查找数据、大量替换字符等操作\n\n### 基本操作\nvi+文件名 进入文档，按命令键进入编辑或者命令模式，Esc回到一般模式（命令模式和编辑模式不能相互转换），输入:w保存文档，输入:wq保存并离开文档，使用:wq!在没有权限的情况下强制写入，输入:q不保存并退出\n\n#### 文本浏览\n\n- 重新载入文件：\n\n  ```shell\n  :e\n  :e! #放弃当前修改，强制重新载入\n  :bufdo e 或者 :bufdo :e! #重新载入所有打开的文件\n  ```\n\n- 光标移动\n\n  ```shell\n  0  #数字0）移动光标至本行开头\n  $  #移动光标至本行末尾\n  ^  #移动光标至本行第一个非空字符\n  w  #向前移动一个词\n  W  #向前移动一个词 （以空格分隔的词）\n  5w  #向前移动5个词\n  b  #向后移动一个词\n  B  #向后移动一个词 （以空格分隔的词）\n  5b  #向后移动5个词\n  G  #移动至文件末尾\n  gg #移动至文件开头\n  ```\n\n- 搜索和替换\n\n  ```shell\n  :/search_text  #在文档后面部分检索search_text这个内容\n  :?search_text  #在文档前面部分检索search_text这个内容\n  n  #移动到后一个检索结果\n  N  #移动到前一个检索结果\n  :%s/original/replacement  #将第一个检索到的original替换为replacement\n  :%s/original/replacement/g\t#将所有original替换为replacement\n  :%s/original/replacement/gc\t #将所有original替换为replacement，但会先询问\n  ```","slug":"Vim编辑器","published":1,"updated":"2021-05-31T03:06:33.196Z","_id":"ckf0h31hn000pactsuk76qwb8","comments":1,"layout":"post","photos":[],"link":"","content":"<p>vim编辑器有三个模式：一般模式，编辑模式，命令模式：<br><a id=\"more\"></a></p>\n<ul>\n<li>一般模式：默认模式，可以新增删除复制粘贴，按Esc从当前模式转换到普通模式</li>\n<li>编辑模式：按i,o,a等字符进入编辑模式，可以编辑文本内容</li>\n<li>命令模式：按:,/,?三个字符中的一个进入命令模式，可以读取、查找数据、大量替换字符等操作</li>\n</ul>\n<h3 id=\"基本操作\"><a href=\"#基本操作\" class=\"headerlink\" title=\"基本操作\"></a>基本操作</h3><p>vi+文件名 进入文档，按命令键进入编辑或者命令模式，Esc回到一般模式（命令模式和编辑模式不能相互转换），输入:w保存文档，输入:wq保存并离开文档，使用:wq!在没有权限的情况下强制写入，输入:q不保存并退出</p>\n<h4 id=\"文本浏览\"><a href=\"#文本浏览\" class=\"headerlink\" title=\"文本浏览\"></a>文本浏览</h4><ul>\n<li><p>重新载入文件：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:e</span><br><span class=\"line\">:e! #放弃当前修改，强制重新载入</span><br><span class=\"line\">:bufdo e 或者 :bufdo :e! #重新载入所有打开的文件</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>光标移动</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">0  #数字0）移动光标至本行开头</span><br><span class=\"line\"><span class=\"meta\">$</span>  #移动光标至本行末尾</span><br><span class=\"line\">^  #移动光标至本行第一个非空字符</span><br><span class=\"line\">w  #向前移动一个词</span><br><span class=\"line\">W  #向前移动一个词 （以空格分隔的词）</span><br><span class=\"line\">5w  #向前移动5个词</span><br><span class=\"line\">b  #向后移动一个词</span><br><span class=\"line\">B  #向后移动一个词 （以空格分隔的词）</span><br><span class=\"line\">5b  #向后移动5个词</span><br><span class=\"line\">G  #移动至文件末尾</span><br><span class=\"line\">gg #移动至文件开头</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>搜索和替换</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:/search_text  #在文档后面部分检索search_text这个内容</span><br><span class=\"line\">:?search_text  #在文档前面部分检索search_text这个内容</span><br><span class=\"line\">n  #移动到后一个检索结果</span><br><span class=\"line\">N  #移动到前一个检索结果</span><br><span class=\"line\">:%s/original/replacement  #将第一个检索到的original替换为replacement</span><br><span class=\"line\">:%s/original/replacement/g\t#将所有original替换为replacement</span><br><span class=\"line\">:%s/original/replacement/gc\t #将所有original替换为replacement，但会先询问</span><br></pre></td></tr></table></figure></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>vim编辑器有三个模式：一般模式，编辑模式，命令模式：<br>","more":"</p>\n<ul>\n<li>一般模式：默认模式，可以新增删除复制粘贴，按Esc从当前模式转换到普通模式</li>\n<li>编辑模式：按i,o,a等字符进入编辑模式，可以编辑文本内容</li>\n<li>命令模式：按:,/,?三个字符中的一个进入命令模式，可以读取、查找数据、大量替换字符等操作</li>\n</ul>\n<h3 id=\"基本操作\"><a href=\"#基本操作\" class=\"headerlink\" title=\"基本操作\"></a>基本操作</h3><p>vi+文件名 进入文档，按命令键进入编辑或者命令模式，Esc回到一般模式（命令模式和编辑模式不能相互转换），输入:w保存文档，输入:wq保存并离开文档，使用:wq!在没有权限的情况下强制写入，输入:q不保存并退出</p>\n<h4 id=\"文本浏览\"><a href=\"#文本浏览\" class=\"headerlink\" title=\"文本浏览\"></a>文本浏览</h4><ul>\n<li><p>重新载入文件：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:e</span><br><span class=\"line\">:e! #放弃当前修改，强制重新载入</span><br><span class=\"line\">:bufdo e 或者 :bufdo :e! #重新载入所有打开的文件</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>光标移动</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">0  #数字0）移动光标至本行开头</span><br><span class=\"line\"><span class=\"meta\">$</span>  #移动光标至本行末尾</span><br><span class=\"line\">^  #移动光标至本行第一个非空字符</span><br><span class=\"line\">w  #向前移动一个词</span><br><span class=\"line\">W  #向前移动一个词 （以空格分隔的词）</span><br><span class=\"line\">5w  #向前移动5个词</span><br><span class=\"line\">b  #向后移动一个词</span><br><span class=\"line\">B  #向后移动一个词 （以空格分隔的词）</span><br><span class=\"line\">5b  #向后移动5个词</span><br><span class=\"line\">G  #移动至文件末尾</span><br><span class=\"line\">gg #移动至文件开头</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>搜索和替换</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:/search_text  #在文档后面部分检索search_text这个内容</span><br><span class=\"line\">:?search_text  #在文档前面部分检索search_text这个内容</span><br><span class=\"line\">n  #移动到后一个检索结果</span><br><span class=\"line\">N  #移动到前一个检索结果</span><br><span class=\"line\">:%s/original/replacement  #将第一个检索到的original替换为replacement</span><br><span class=\"line\">:%s/original/replacement/g\t#将所有original替换为replacement</span><br><span class=\"line\">:%s/original/replacement/gc\t #将所有original替换为replacement，但会先询问</span><br></pre></td></tr></table></figure></li>\n</ul>"},{"title":"Yarn任务调度机制探析","author":"天渊","date":"2019-06-04T12:54:00.000Z","_content":"yarn作为hadoop任务调度组件，具有良好的可扩展性、高可用性以及其独特的“多租户”特性，它为不同的作业场景提供了几种特性各异的任务调度机制：`FIFO调度器`，`Capacity调度器`，`Fair调度器`\n<!-- more -->\n\n### FIFO调度器\n\nFIFO调度器采用一个先进先出队列对提交的任务执行顺序进行调度，按照提交的顺序首先为第一个任务的请求分配资源，第一个应用的请求被满足后，再依次为队列中下一个应用分配资源\n\nFIFO调度器的好处是实现简单，无需任务额外配置，但是缺点也很明显，不适合那种大型任务和小型任务穿插执行的共享集群，因为大型任务可能会独占集群中的全部计算资源，并且任务执行时间会很长，yarn短时间为无法为其他任务分配资源，因此只能阻塞在队列中等待大型任务执行完成释放资源：\n\n![1559481447073](\\blog\\images\\1559481447073.png)\n\n如图，横轴表示集群资源利用情况，当job1执行时，由于集群资源有限，job2必须等待job1执行完成后才能执行\n\n### Capacity调度器\n\n容量调度器可以为不同体量的任务提供一个或多个专用的等待队列，保证小型任务一旦提交就可以分配资源启动执行，因此解决了FIFO调度无法兼顾大型任务和小型任务的问题，大型任务的执行不会造成小型任务的长时间等待\n\n不过容量调度器也有自己的缺点，由于yarn要专门为小型任务预留一部分集群资源，分配给大型任务的资源就会相应减少，执行时间也就变长了：\n\n![1559482380158](\\blog\\images\\1559482380158.png)\n\n如图，queue B配置为小型任务服务，分配的资源较少，queue A配置为大型任务服务，分配的集群资源更多，保证大型任务和小型任务能够在集群中共存而不会相互阻塞\n\n配置容量调度器时，可以根据实际需要配置多个队列，每个队列分配不同数额的集群资源，不过如果某个队列的任务在执行过程中分配的集群资源不够用，为了不让该任务等待其他队列释放资源，需要为队列设置`maximun-capacity`，能够在资源不够用时进行动态扩容，如果集群中有空闲资源，则会为这个队列分配更多的资源，这种方式称为`队列弹性`，扩容后的资源总量保证不超过`maximun-capacity`即可\n\n提交map-reduce任务时，通过指定`mapreduce.job.<queue-name>`来指定当前任务分配给哪一个队列\n\n### Fair调度器\n\n即公平调度器，目的是为所有运行的任务公平分配集群资源，在容量调度器的基础上进行了改进，能够在不同任务之间**动态**地调度集群资源：\n\n![1559568139040](\\blog\\images\\1559568139040.png)\n\n如图，在公平调度器模式下，与容量调度类似，根据实际需要分配多个队列用于执行任务：\n\n1. job1率先提交，当前集群中没有其他任务共享资源，因为job1独享集群中queue A和queue B的全部资源\n\n2. job1执行过程中，job2提交，此时job1享有queue A为其分配的资源，而job2享有queue B为其分配的资源，job1和job2共享集群资源\n\n3. job2独享queue B的资源时，job3同样提交到queue B中执行，此时job2和job3共享queue B的资源\n\n4. 待job2执行完成后，job3独享queue B的资源\n\n可以看出，相比于容量调度器，公平调度模式下几乎不会出现饥饿情况（即有任务长期无法分配到集群资源而长时间处于阻塞状态），在满足一定的分配权重和调度策略的情况下，每个任务都能分享到一定数量的集群资源\n\nhadoop默认使用容量调度器，如果要在yarn中启用公平调度器，需要在`yarn-site.xml`作以下配置\n\n```xml\n<property>\n  <name>yarn.resourcemanager.scheduler.class</name>\n  <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>\n</property>\n```\n\n#### Fair调度器的队列放置策略\n\n与容量调度器相似，公平调度器也可以执行某个任务提交到特定的队列中执行，也可以执行任务放置到以任务提交的用户名为队列名的队列下进行执行\n\n在yarn-site.xml中配置`yarn.scheduler.fair.allocation.file`执行队列分配文件，在队列分配文件中制定任务的队列分配策略(来自[hadoop官网yarn-FairScheduler文档](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/FairScheduler.html))：\n\n```xml\n<?xml version=\"1.0\"?>\n<allocations>\n    <queue name=\"sample_queue\">\n        <minResources>10000 mb,0vcores</minResources>\n        <maxResources>90000 mb,0vcores</maxResources>\n        <maxRunningApps>50</maxRunningApps>\n        <maxAMShare>0.1</maxAMShare>\n        <weight>2.0</weight>\n        <schedulingPolicy>fair</schedulingPolicy>\n        <queue name=\"sample_sub_queue\">\n            <aclSubmitApps>charlie</aclSubmitApps>\n            <minResources>5000 mb,0vcores</minResources>\n        </queue>\n        <queue name=\"sample_reservable_queue\">\n            <reservation></reservation>\n        </queue>\n    </queue>\n\n    <queueMaxAMShareDefault>0.5</queueMaxAMShareDefault>\n    <queueMaxResourcesDefault>40000 mb,0vcores</queueMaxResourcesDefault>\n\n    <queue name=\"secondary_group_queue\" type=\"parent\">\n        <weight>3.0</weight>\n        <maxChildResources>4096 mb,4vcores</maxChildResources>\n    </queue>\n\n    <user name=\"sample_user\">\n        <maxRunningApps>30</maxRunningApps>\n    </user>\n    <userMaxAppsDefault>5</userMaxAppsDefault>\n\n    <queuePlacementPolicy>\n        <rule name=\"specified\" />\n        <rule name=\"primaryGroup\" create=\"false\" />\n        <rule name=\"nestedUserQueue\">\n            <rule name=\"secondaryGroupExistingQueue\" create=\"false\" />\n        </rule>\n        <rule name=\"default\" queue=\"sample_queue\"/>\n    </queuePlacementPolicy>\n</allocations>\n```\n\n如上队列分配文件，分配了多个队列，每个队列还可在其内部指定多个叶子队列\n\n最外层隐藏的最顶级队列是root队列，这里面配置的所有队列都是root队列的叶子队列，如果完全没有指定队列分配文件，则所有任务都会默认提交到root队列中执行\n\n队列中可以指定最小和最大分配资源数以及最大可运行的任务数，权重weight值（为同层级队列指定资源分配比例），指定权限用户（aclSubmitApps，拥有这个权限的用户可以提交和杀死这个队列中的任务，需要注意root队列的acl是`*`，即每个用户都有权限），调度策略（schedulingPolicy，在一个队列中一共有三种调度策略），最重要的是队列放置策略`queuePlacementPolicy`：\n\n```xml\n<queuePlacementPolicy>\n    <rule name=\"specified\" create=\"true\"/>\n    <rule name=\"user\" create=\"false\" />\n    <rule name=\"primaryGroup\" create=\"false\" />\n    <rule name=\"nestedUserQueue\">\n        <rule name=\"secondaryGroupExistingQueue\" create=\"false\" />\n    </rule>\n    <rule name=\"default\" queue=\"sample_queue\"/>\n</queuePlacementPolicy>\n```\n\n这是一个规则列表：\n\n- 首先如果specified为true，当前提交任务若指定了队列名则放置于指定队列执行，否则进行下一级判断\n- 如果user为true，则寻找以当前用户名为队列名的队列，若未创建则创建该队列；在这里user为false，就跳过这条判断\n- 如果primaryGroup为true，则寻找以当前用户的主group名命名的队列\n- nestedUserQueue：嵌套用户队列，与primaryGroup不同之处在于，user是应用到root队列的，而nestedUserQueue则会为任务寻找type为parent的队列，在这个队列下再去寻找有没有以任务用户名命名的队列\n- secondaryGroupExistingQueue：寻找以用户的Secondary group名字命名的队列；上面的配置中，yarn会在parent队列下寻找符合要求的嵌套队列\n- 最终如果没有找到匹配以上规则的队列，则执行提交到default队列，这里即为sample_queue队列\n\n##### Fair调度器的三种调度策略\n\n不同于FIFO调度器和容量调度器固定的调度策略，对于所有提交到某个队列中的任务，公平调度器为这个队列提供了三种调度策略，即：默认的`fair调度策略`，传统模式的`FIFO调度策略`，还有一种是`Dominant Resource Fairness(drf)策略`\n\n##### 抢占\n\n公平调度器中，当一个新的任务提交到一个队列，而该队列并没有空闲资源分配给它，这时该任务需要等待其他任务完成一部分container计算然后释放资源给新任务，以达到公平运行的目的\n\n为了使作业从提交到执行所需的时间可控，可以设置抢占模式，当等待时间超过一定阈值时即启动抢占，强迫队列中其他任务立刻让出一部分资源给新任务，达到强行公平运行的目的\n\nyarn-site.xml中将`yarn.scheduler.fair.preemption`设置为true即可打开抢占模式，并至少配置以下两个参数中的一个：\n\n- 最小资源抢占超时时间`minSharePreemptionTimeout`：若指定等待时间内未获得承诺的最小共享资源则会启动抢占\n- 公平资源抢占超时时间`fairSharePreemptionTimeout`：若指定等待时间内未获得承诺的公平共享资源则会启动抢占；承诺的公平共享资源由公平资源抢占阈值`fairSharePreemptionThreshold`和队列公平资源分配值的乘积决定，例如，当前队列一共提交了2个job，job1独占了队列资源，job2的公平资源理应为当前队列的0.5倍资源，若`fairSharePreemptionThreshold`为0.8，则承诺给这个任务的队列资源为0.4；该阈值默认是0.5\n\n以上两个参数均可以设置root队列级别的默认值：`defaultFairSharePreemptionThreshold `，`defaultMinSharePreemptionTimeout `\n\n##### 延迟调度\n\nyarn的资源管理器为任务分配节点的原则是基于任务所需数据先本地后远程，本地如果有资源就优先分配本地节点，如果本地没有资源再寻找远程节点\n\n不过有些时候稍微等待一些时间，待本地节点释放后就可以直接在本地启动任务了，不需要再寻找远程节点，这种行为称为`延迟调度`，容量调度器和公平调度器都支持这种方式\n\n- 对于容量调度器，设置`yarn.scheduler.capacity.node-locality-delay`开启本地延迟，该值为正整数，表示等待本地资源释放期间最多错过多少个远程资源释放的机会，比如设置为3，则表示最多等待3次远程资源释放的信息后，如果本地节点的资源仍然没释放，就直接寻找远程节点的资源，不再等本地了\n- 对于公平调度器，实现稍有不同，是将`yarn.scheduler.fair.locality.threshold.node`设置某个值，比如0.5，表示等待集群中最多半数节点给过资源释放信息后，再考虑远程节点，否则在这之前都将等待本地节点释放\n\n##### 主导资源公平性\n\n对于容量调度或公平调度，都是基于“资源”这一概念进行策略的，资源为内存或者cpu资源的抽象，两种调度模式都是基于某种资源的分配进行调度（内存或者cpu）\n\n不过如果某些任务对于内存或者cpu的依赖各异，这时候分配起来就比较复杂了，往往需要`Dominant Resource Fairness(drf)策略`进行支持\n\n**Dominant Resource Fairness(drf)，主导资源公平策略**：首先观察任务的主导资源（Dominant Resource）是内存还是cpu，选出主导资源，然后根据任务之间主导资源的占比来分配资源\n\n例如：\n\n- job1所需内存资源占集群总内存3%，所需cpu资源占集群总cpu1%，因此job1的主导资源是内存，占比3%\n- job2所需内存资源占2%，所需cpu资源占6%，job2的主导资源是cpu，占比6%\n- 因此job1和job2申请资源比例为`3% : 6%`，也就是1：2，job2分配的container数量为job1的两倍","source":"_posts/Yarn任务调度机制探析.md","raw":"title: Yarn任务调度机制探析\nauthor: 天渊\ntags:\n  - yarn\n  - hadoop\ncategories:\n  - 大数据\ndate: 2019-06-04 20:54:00\n---\nyarn作为hadoop任务调度组件，具有良好的可扩展性、高可用性以及其独特的“多租户”特性，它为不同的作业场景提供了几种特性各异的任务调度机制：`FIFO调度器`，`Capacity调度器`，`Fair调度器`\n<!-- more -->\n\n### FIFO调度器\n\nFIFO调度器采用一个先进先出队列对提交的任务执行顺序进行调度，按照提交的顺序首先为第一个任务的请求分配资源，第一个应用的请求被满足后，再依次为队列中下一个应用分配资源\n\nFIFO调度器的好处是实现简单，无需任务额外配置，但是缺点也很明显，不适合那种大型任务和小型任务穿插执行的共享集群，因为大型任务可能会独占集群中的全部计算资源，并且任务执行时间会很长，yarn短时间为无法为其他任务分配资源，因此只能阻塞在队列中等待大型任务执行完成释放资源：\n\n![1559481447073](\\blog\\images\\1559481447073.png)\n\n如图，横轴表示集群资源利用情况，当job1执行时，由于集群资源有限，job2必须等待job1执行完成后才能执行\n\n### Capacity调度器\n\n容量调度器可以为不同体量的任务提供一个或多个专用的等待队列，保证小型任务一旦提交就可以分配资源启动执行，因此解决了FIFO调度无法兼顾大型任务和小型任务的问题，大型任务的执行不会造成小型任务的长时间等待\n\n不过容量调度器也有自己的缺点，由于yarn要专门为小型任务预留一部分集群资源，分配给大型任务的资源就会相应减少，执行时间也就变长了：\n\n![1559482380158](\\blog\\images\\1559482380158.png)\n\n如图，queue B配置为小型任务服务，分配的资源较少，queue A配置为大型任务服务，分配的集群资源更多，保证大型任务和小型任务能够在集群中共存而不会相互阻塞\n\n配置容量调度器时，可以根据实际需要配置多个队列，每个队列分配不同数额的集群资源，不过如果某个队列的任务在执行过程中分配的集群资源不够用，为了不让该任务等待其他队列释放资源，需要为队列设置`maximun-capacity`，能够在资源不够用时进行动态扩容，如果集群中有空闲资源，则会为这个队列分配更多的资源，这种方式称为`队列弹性`，扩容后的资源总量保证不超过`maximun-capacity`即可\n\n提交map-reduce任务时，通过指定`mapreduce.job.<queue-name>`来指定当前任务分配给哪一个队列\n\n### Fair调度器\n\n即公平调度器，目的是为所有运行的任务公平分配集群资源，在容量调度器的基础上进行了改进，能够在不同任务之间**动态**地调度集群资源：\n\n![1559568139040](\\blog\\images\\1559568139040.png)\n\n如图，在公平调度器模式下，与容量调度类似，根据实际需要分配多个队列用于执行任务：\n\n1. job1率先提交，当前集群中没有其他任务共享资源，因为job1独享集群中queue A和queue B的全部资源\n\n2. job1执行过程中，job2提交，此时job1享有queue A为其分配的资源，而job2享有queue B为其分配的资源，job1和job2共享集群资源\n\n3. job2独享queue B的资源时，job3同样提交到queue B中执行，此时job2和job3共享queue B的资源\n\n4. 待job2执行完成后，job3独享queue B的资源\n\n可以看出，相比于容量调度器，公平调度模式下几乎不会出现饥饿情况（即有任务长期无法分配到集群资源而长时间处于阻塞状态），在满足一定的分配权重和调度策略的情况下，每个任务都能分享到一定数量的集群资源\n\nhadoop默认使用容量调度器，如果要在yarn中启用公平调度器，需要在`yarn-site.xml`作以下配置\n\n```xml\n<property>\n  <name>yarn.resourcemanager.scheduler.class</name>\n  <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>\n</property>\n```\n\n#### Fair调度器的队列放置策略\n\n与容量调度器相似，公平调度器也可以执行某个任务提交到特定的队列中执行，也可以执行任务放置到以任务提交的用户名为队列名的队列下进行执行\n\n在yarn-site.xml中配置`yarn.scheduler.fair.allocation.file`执行队列分配文件，在队列分配文件中制定任务的队列分配策略(来自[hadoop官网yarn-FairScheduler文档](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/FairScheduler.html))：\n\n```xml\n<?xml version=\"1.0\"?>\n<allocations>\n    <queue name=\"sample_queue\">\n        <minResources>10000 mb,0vcores</minResources>\n        <maxResources>90000 mb,0vcores</maxResources>\n        <maxRunningApps>50</maxRunningApps>\n        <maxAMShare>0.1</maxAMShare>\n        <weight>2.0</weight>\n        <schedulingPolicy>fair</schedulingPolicy>\n        <queue name=\"sample_sub_queue\">\n            <aclSubmitApps>charlie</aclSubmitApps>\n            <minResources>5000 mb,0vcores</minResources>\n        </queue>\n        <queue name=\"sample_reservable_queue\">\n            <reservation></reservation>\n        </queue>\n    </queue>\n\n    <queueMaxAMShareDefault>0.5</queueMaxAMShareDefault>\n    <queueMaxResourcesDefault>40000 mb,0vcores</queueMaxResourcesDefault>\n\n    <queue name=\"secondary_group_queue\" type=\"parent\">\n        <weight>3.0</weight>\n        <maxChildResources>4096 mb,4vcores</maxChildResources>\n    </queue>\n\n    <user name=\"sample_user\">\n        <maxRunningApps>30</maxRunningApps>\n    </user>\n    <userMaxAppsDefault>5</userMaxAppsDefault>\n\n    <queuePlacementPolicy>\n        <rule name=\"specified\" />\n        <rule name=\"primaryGroup\" create=\"false\" />\n        <rule name=\"nestedUserQueue\">\n            <rule name=\"secondaryGroupExistingQueue\" create=\"false\" />\n        </rule>\n        <rule name=\"default\" queue=\"sample_queue\"/>\n    </queuePlacementPolicy>\n</allocations>\n```\n\n如上队列分配文件，分配了多个队列，每个队列还可在其内部指定多个叶子队列\n\n最外层隐藏的最顶级队列是root队列，这里面配置的所有队列都是root队列的叶子队列，如果完全没有指定队列分配文件，则所有任务都会默认提交到root队列中执行\n\n队列中可以指定最小和最大分配资源数以及最大可运行的任务数，权重weight值（为同层级队列指定资源分配比例），指定权限用户（aclSubmitApps，拥有这个权限的用户可以提交和杀死这个队列中的任务，需要注意root队列的acl是`*`，即每个用户都有权限），调度策略（schedulingPolicy，在一个队列中一共有三种调度策略），最重要的是队列放置策略`queuePlacementPolicy`：\n\n```xml\n<queuePlacementPolicy>\n    <rule name=\"specified\" create=\"true\"/>\n    <rule name=\"user\" create=\"false\" />\n    <rule name=\"primaryGroup\" create=\"false\" />\n    <rule name=\"nestedUserQueue\">\n        <rule name=\"secondaryGroupExistingQueue\" create=\"false\" />\n    </rule>\n    <rule name=\"default\" queue=\"sample_queue\"/>\n</queuePlacementPolicy>\n```\n\n这是一个规则列表：\n\n- 首先如果specified为true，当前提交任务若指定了队列名则放置于指定队列执行，否则进行下一级判断\n- 如果user为true，则寻找以当前用户名为队列名的队列，若未创建则创建该队列；在这里user为false，就跳过这条判断\n- 如果primaryGroup为true，则寻找以当前用户的主group名命名的队列\n- nestedUserQueue：嵌套用户队列，与primaryGroup不同之处在于，user是应用到root队列的，而nestedUserQueue则会为任务寻找type为parent的队列，在这个队列下再去寻找有没有以任务用户名命名的队列\n- secondaryGroupExistingQueue：寻找以用户的Secondary group名字命名的队列；上面的配置中，yarn会在parent队列下寻找符合要求的嵌套队列\n- 最终如果没有找到匹配以上规则的队列，则执行提交到default队列，这里即为sample_queue队列\n\n##### Fair调度器的三种调度策略\n\n不同于FIFO调度器和容量调度器固定的调度策略，对于所有提交到某个队列中的任务，公平调度器为这个队列提供了三种调度策略，即：默认的`fair调度策略`，传统模式的`FIFO调度策略`，还有一种是`Dominant Resource Fairness(drf)策略`\n\n##### 抢占\n\n公平调度器中，当一个新的任务提交到一个队列，而该队列并没有空闲资源分配给它，这时该任务需要等待其他任务完成一部分container计算然后释放资源给新任务，以达到公平运行的目的\n\n为了使作业从提交到执行所需的时间可控，可以设置抢占模式，当等待时间超过一定阈值时即启动抢占，强迫队列中其他任务立刻让出一部分资源给新任务，达到强行公平运行的目的\n\nyarn-site.xml中将`yarn.scheduler.fair.preemption`设置为true即可打开抢占模式，并至少配置以下两个参数中的一个：\n\n- 最小资源抢占超时时间`minSharePreemptionTimeout`：若指定等待时间内未获得承诺的最小共享资源则会启动抢占\n- 公平资源抢占超时时间`fairSharePreemptionTimeout`：若指定等待时间内未获得承诺的公平共享资源则会启动抢占；承诺的公平共享资源由公平资源抢占阈值`fairSharePreemptionThreshold`和队列公平资源分配值的乘积决定，例如，当前队列一共提交了2个job，job1独占了队列资源，job2的公平资源理应为当前队列的0.5倍资源，若`fairSharePreemptionThreshold`为0.8，则承诺给这个任务的队列资源为0.4；该阈值默认是0.5\n\n以上两个参数均可以设置root队列级别的默认值：`defaultFairSharePreemptionThreshold `，`defaultMinSharePreemptionTimeout `\n\n##### 延迟调度\n\nyarn的资源管理器为任务分配节点的原则是基于任务所需数据先本地后远程，本地如果有资源就优先分配本地节点，如果本地没有资源再寻找远程节点\n\n不过有些时候稍微等待一些时间，待本地节点释放后就可以直接在本地启动任务了，不需要再寻找远程节点，这种行为称为`延迟调度`，容量调度器和公平调度器都支持这种方式\n\n- 对于容量调度器，设置`yarn.scheduler.capacity.node-locality-delay`开启本地延迟，该值为正整数，表示等待本地资源释放期间最多错过多少个远程资源释放的机会，比如设置为3，则表示最多等待3次远程资源释放的信息后，如果本地节点的资源仍然没释放，就直接寻找远程节点的资源，不再等本地了\n- 对于公平调度器，实现稍有不同，是将`yarn.scheduler.fair.locality.threshold.node`设置某个值，比如0.5，表示等待集群中最多半数节点给过资源释放信息后，再考虑远程节点，否则在这之前都将等待本地节点释放\n\n##### 主导资源公平性\n\n对于容量调度或公平调度，都是基于“资源”这一概念进行策略的，资源为内存或者cpu资源的抽象，两种调度模式都是基于某种资源的分配进行调度（内存或者cpu）\n\n不过如果某些任务对于内存或者cpu的依赖各异，这时候分配起来就比较复杂了，往往需要`Dominant Resource Fairness(drf)策略`进行支持\n\n**Dominant Resource Fairness(drf)，主导资源公平策略**：首先观察任务的主导资源（Dominant Resource）是内存还是cpu，选出主导资源，然后根据任务之间主导资源的占比来分配资源\n\n例如：\n\n- job1所需内存资源占集群总内存3%，所需cpu资源占集群总cpu1%，因此job1的主导资源是内存，占比3%\n- job2所需内存资源占2%，所需cpu资源占6%，job2的主导资源是cpu，占比6%\n- 因此job1和job2申请资源比例为`3% : 6%`，也就是1：2，job2分配的container数量为job1的两倍","slug":"Yarn任务调度机制探析","published":1,"updated":"2019-06-04T13:03:35.249Z","_id":"ckf0h31ho000sactsltrfk8ha","comments":1,"layout":"post","photos":[],"link":"","content":"<p>yarn作为hadoop任务调度组件，具有良好的可扩展性、高可用性以及其独特的“多租户”特性，它为不同的作业场景提供了几种特性各异的任务调度机制：<code>FIFO调度器</code>，<code>Capacity调度器</code>，<code>Fair调度器</code><br><a id=\"more\"></a></p>\n<h3 id=\"FIFO调度器\"><a href=\"#FIFO调度器\" class=\"headerlink\" title=\"FIFO调度器\"></a>FIFO调度器</h3><p>FIFO调度器采用一个先进先出队列对提交的任务执行顺序进行调度，按照提交的顺序首先为第一个任务的请求分配资源，第一个应用的请求被满足后，再依次为队列中下一个应用分配资源</p>\n<p>FIFO调度器的好处是实现简单，无需任务额外配置，但是缺点也很明显，不适合那种大型任务和小型任务穿插执行的共享集群，因为大型任务可能会独占集群中的全部计算资源，并且任务执行时间会很长，yarn短时间为无法为其他任务分配资源，因此只能阻塞在队列中等待大型任务执行完成释放资源：</p>\n<p><img src=\"\\blog\\images\\1559481447073.png\" alt=\"1559481447073\"></p>\n<p>如图，横轴表示集群资源利用情况，当job1执行时，由于集群资源有限，job2必须等待job1执行完成后才能执行</p>\n<h3 id=\"Capacity调度器\"><a href=\"#Capacity调度器\" class=\"headerlink\" title=\"Capacity调度器\"></a>Capacity调度器</h3><p>容量调度器可以为不同体量的任务提供一个或多个专用的等待队列，保证小型任务一旦提交就可以分配资源启动执行，因此解决了FIFO调度无法兼顾大型任务和小型任务的问题，大型任务的执行不会造成小型任务的长时间等待</p>\n<p>不过容量调度器也有自己的缺点，由于yarn要专门为小型任务预留一部分集群资源，分配给大型任务的资源就会相应减少，执行时间也就变长了：</p>\n<p><img src=\"\\blog\\images\\1559482380158.png\" alt=\"1559482380158\"></p>\n<p>如图，queue B配置为小型任务服务，分配的资源较少，queue A配置为大型任务服务，分配的集群资源更多，保证大型任务和小型任务能够在集群中共存而不会相互阻塞</p>\n<p>配置容量调度器时，可以根据实际需要配置多个队列，每个队列分配不同数额的集群资源，不过如果某个队列的任务在执行过程中分配的集群资源不够用，为了不让该任务等待其他队列释放资源，需要为队列设置<code>maximun-capacity</code>，能够在资源不够用时进行动态扩容，如果集群中有空闲资源，则会为这个队列分配更多的资源，这种方式称为<code>队列弹性</code>，扩容后的资源总量保证不超过<code>maximun-capacity</code>即可</p>\n<p>提交map-reduce任务时，通过指定<code>mapreduce.job.&lt;queue-name&gt;</code>来指定当前任务分配给哪一个队列</p>\n<h3 id=\"Fair调度器\"><a href=\"#Fair调度器\" class=\"headerlink\" title=\"Fair调度器\"></a>Fair调度器</h3><p>即公平调度器，目的是为所有运行的任务公平分配集群资源，在容量调度器的基础上进行了改进，能够在不同任务之间<strong>动态</strong>地调度集群资源：</p>\n<p><img src=\"\\blog\\images\\1559568139040.png\" alt=\"1559568139040\"></p>\n<p>如图，在公平调度器模式下，与容量调度类似，根据实际需要分配多个队列用于执行任务：</p>\n<ol>\n<li><p>job1率先提交，当前集群中没有其他任务共享资源，因为job1独享集群中queue A和queue B的全部资源</p>\n</li>\n<li><p>job1执行过程中，job2提交，此时job1享有queue A为其分配的资源，而job2享有queue B为其分配的资源，job1和job2共享集群资源</p>\n</li>\n<li><p>job2独享queue B的资源时，job3同样提交到queue B中执行，此时job2和job3共享queue B的资源</p>\n</li>\n<li><p>待job2执行完成后，job3独享queue B的资源</p>\n</li>\n</ol>\n<p>可以看出，相比于容量调度器，公平调度模式下几乎不会出现饥饿情况（即有任务长期无法分配到集群资源而长时间处于阻塞状态），在满足一定的分配权重和调度策略的情况下，每个任务都能分享到一定数量的集群资源</p>\n<p>hadoop默认使用容量调度器，如果要在yarn中启用公平调度器，需要在<code>yarn-site.xml</code>作以下配置</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"Fair调度器的队列放置策略\"><a href=\"#Fair调度器的队列放置策略\" class=\"headerlink\" title=\"Fair调度器的队列放置策略\"></a>Fair调度器的队列放置策略</h4><p>与容量调度器相似，公平调度器也可以执行某个任务提交到特定的队列中执行，也可以执行任务放置到以任务提交的用户名为队列名的队列下进行执行</p>\n<p>在yarn-site.xml中配置<code>yarn.scheduler.fair.allocation.file</code>执行队列分配文件，在队列分配文件中制定任务的队列分配策略(来自<a href=\"http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/FairScheduler.html\" target=\"_blank\" rel=\"noopener\">hadoop官网yarn-FairScheduler文档</a>)：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;?xml version=\"1.0\"?&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">allocations</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">queue</span> <span class=\"attr\">name</span>=<span class=\"string\">\"sample_queue\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">minResources</span>&gt;</span>10000 mb,0vcores<span class=\"tag\">&lt;/<span class=\"name\">minResources</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">maxResources</span>&gt;</span>90000 mb,0vcores<span class=\"tag\">&lt;/<span class=\"name\">maxResources</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">maxRunningApps</span>&gt;</span>50<span class=\"tag\">&lt;/<span class=\"name\">maxRunningApps</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">maxAMShare</span>&gt;</span>0.1<span class=\"tag\">&lt;/<span class=\"name\">maxAMShare</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">weight</span>&gt;</span>2.0<span class=\"tag\">&lt;/<span class=\"name\">weight</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">schedulingPolicy</span>&gt;</span>fair<span class=\"tag\">&lt;/<span class=\"name\">schedulingPolicy</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">queue</span> <span class=\"attr\">name</span>=<span class=\"string\">\"sample_sub_queue\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">aclSubmitApps</span>&gt;</span>charlie<span class=\"tag\">&lt;/<span class=\"name\">aclSubmitApps</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">minResources</span>&gt;</span>5000 mb,0vcores<span class=\"tag\">&lt;/<span class=\"name\">minResources</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">queue</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">queue</span> <span class=\"attr\">name</span>=<span class=\"string\">\"sample_reservable_queue\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">reservation</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">reservation</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">queue</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">queue</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">queueMaxAMShareDefault</span>&gt;</span>0.5<span class=\"tag\">&lt;/<span class=\"name\">queueMaxAMShareDefault</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">queueMaxResourcesDefault</span>&gt;</span>40000 mb,0vcores<span class=\"tag\">&lt;/<span class=\"name\">queueMaxResourcesDefault</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">queue</span> <span class=\"attr\">name</span>=<span class=\"string\">\"secondary_group_queue\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"parent\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">weight</span>&gt;</span>3.0<span class=\"tag\">&lt;/<span class=\"name\">weight</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">maxChildResources</span>&gt;</span>4096 mb,4vcores<span class=\"tag\">&lt;/<span class=\"name\">maxChildResources</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">queue</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">user</span> <span class=\"attr\">name</span>=<span class=\"string\">\"sample_user\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">maxRunningApps</span>&gt;</span>30<span class=\"tag\">&lt;/<span class=\"name\">maxRunningApps</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">user</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">userMaxAppsDefault</span>&gt;</span>5<span class=\"tag\">&lt;/<span class=\"name\">userMaxAppsDefault</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">queuePlacementPolicy</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"specified\"</span> /&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"primaryGroup\"</span> <span class=\"attr\">create</span>=<span class=\"string\">\"false\"</span> /&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"nestedUserQueue\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"secondaryGroupExistingQueue\"</span> <span class=\"attr\">create</span>=<span class=\"string\">\"false\"</span> /&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">rule</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"default\"</span> <span class=\"attr\">queue</span>=<span class=\"string\">\"sample_queue\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">queuePlacementPolicy</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">allocations</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>如上队列分配文件，分配了多个队列，每个队列还可在其内部指定多个叶子队列</p>\n<p>最外层隐藏的最顶级队列是root队列，这里面配置的所有队列都是root队列的叶子队列，如果完全没有指定队列分配文件，则所有任务都会默认提交到root队列中执行</p>\n<p>队列中可以指定最小和最大分配资源数以及最大可运行的任务数，权重weight值（为同层级队列指定资源分配比例），指定权限用户（aclSubmitApps，拥有这个权限的用户可以提交和杀死这个队列中的任务，需要注意root队列的acl是<code>*</code>，即每个用户都有权限），调度策略（schedulingPolicy，在一个队列中一共有三种调度策略），最重要的是队列放置策略<code>queuePlacementPolicy</code>：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">queuePlacementPolicy</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"specified\"</span> <span class=\"attr\">create</span>=<span class=\"string\">\"true\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"user\"</span> <span class=\"attr\">create</span>=<span class=\"string\">\"false\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"primaryGroup\"</span> <span class=\"attr\">create</span>=<span class=\"string\">\"false\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"nestedUserQueue\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"secondaryGroupExistingQueue\"</span> <span class=\"attr\">create</span>=<span class=\"string\">\"false\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">rule</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"default\"</span> <span class=\"attr\">queue</span>=<span class=\"string\">\"sample_queue\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">queuePlacementPolicy</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>这是一个规则列表：</p>\n<ul>\n<li>首先如果specified为true，当前提交任务若指定了队列名则放置于指定队列执行，否则进行下一级判断</li>\n<li>如果user为true，则寻找以当前用户名为队列名的队列，若未创建则创建该队列；在这里user为false，就跳过这条判断</li>\n<li>如果primaryGroup为true，则寻找以当前用户的主group名命名的队列</li>\n<li>nestedUserQueue：嵌套用户队列，与primaryGroup不同之处在于，user是应用到root队列的，而nestedUserQueue则会为任务寻找type为parent的队列，在这个队列下再去寻找有没有以任务用户名命名的队列</li>\n<li>secondaryGroupExistingQueue：寻找以用户的Secondary group名字命名的队列；上面的配置中，yarn会在parent队列下寻找符合要求的嵌套队列</li>\n<li>最终如果没有找到匹配以上规则的队列，则执行提交到default队列，这里即为sample_queue队列</li>\n</ul>\n<h5 id=\"Fair调度器的三种调度策略\"><a href=\"#Fair调度器的三种调度策略\" class=\"headerlink\" title=\"Fair调度器的三种调度策略\"></a>Fair调度器的三种调度策略</h5><p>不同于FIFO调度器和容量调度器固定的调度策略，对于所有提交到某个队列中的任务，公平调度器为这个队列提供了三种调度策略，即：默认的<code>fair调度策略</code>，传统模式的<code>FIFO调度策略</code>，还有一种是<code>Dominant Resource Fairness(drf)策略</code></p>\n<h5 id=\"抢占\"><a href=\"#抢占\" class=\"headerlink\" title=\"抢占\"></a>抢占</h5><p>公平调度器中，当一个新的任务提交到一个队列，而该队列并没有空闲资源分配给它，这时该任务需要等待其他任务完成一部分container计算然后释放资源给新任务，以达到公平运行的目的</p>\n<p>为了使作业从提交到执行所需的时间可控，可以设置抢占模式，当等待时间超过一定阈值时即启动抢占，强迫队列中其他任务立刻让出一部分资源给新任务，达到强行公平运行的目的</p>\n<p>yarn-site.xml中将<code>yarn.scheduler.fair.preemption</code>设置为true即可打开抢占模式，并至少配置以下两个参数中的一个：</p>\n<ul>\n<li>最小资源抢占超时时间<code>minSharePreemptionTimeout</code>：若指定等待时间内未获得承诺的最小共享资源则会启动抢占</li>\n<li>公平资源抢占超时时间<code>fairSharePreemptionTimeout</code>：若指定等待时间内未获得承诺的公平共享资源则会启动抢占；承诺的公平共享资源由公平资源抢占阈值<code>fairSharePreemptionThreshold</code>和队列公平资源分配值的乘积决定，例如，当前队列一共提交了2个job，job1独占了队列资源，job2的公平资源理应为当前队列的0.5倍资源，若<code>fairSharePreemptionThreshold</code>为0.8，则承诺给这个任务的队列资源为0.4；该阈值默认是0.5</li>\n</ul>\n<p>以上两个参数均可以设置root队列级别的默认值：<code>defaultFairSharePreemptionThreshold</code>，<code>defaultMinSharePreemptionTimeout</code></p>\n<h5 id=\"延迟调度\"><a href=\"#延迟调度\" class=\"headerlink\" title=\"延迟调度\"></a>延迟调度</h5><p>yarn的资源管理器为任务分配节点的原则是基于任务所需数据先本地后远程，本地如果有资源就优先分配本地节点，如果本地没有资源再寻找远程节点</p>\n<p>不过有些时候稍微等待一些时间，待本地节点释放后就可以直接在本地启动任务了，不需要再寻找远程节点，这种行为称为<code>延迟调度</code>，容量调度器和公平调度器都支持这种方式</p>\n<ul>\n<li>对于容量调度器，设置<code>yarn.scheduler.capacity.node-locality-delay</code>开启本地延迟，该值为正整数，表示等待本地资源释放期间最多错过多少个远程资源释放的机会，比如设置为3，则表示最多等待3次远程资源释放的信息后，如果本地节点的资源仍然没释放，就直接寻找远程节点的资源，不再等本地了</li>\n<li>对于公平调度器，实现稍有不同，是将<code>yarn.scheduler.fair.locality.threshold.node</code>设置某个值，比如0.5，表示等待集群中最多半数节点给过资源释放信息后，再考虑远程节点，否则在这之前都将等待本地节点释放</li>\n</ul>\n<h5 id=\"主导资源公平性\"><a href=\"#主导资源公平性\" class=\"headerlink\" title=\"主导资源公平性\"></a>主导资源公平性</h5><p>对于容量调度或公平调度，都是基于“资源”这一概念进行策略的，资源为内存或者cpu资源的抽象，两种调度模式都是基于某种资源的分配进行调度（内存或者cpu）</p>\n<p>不过如果某些任务对于内存或者cpu的依赖各异，这时候分配起来就比较复杂了，往往需要<code>Dominant Resource Fairness(drf)策略</code>进行支持</p>\n<p><strong>Dominant Resource Fairness(drf)，主导资源公平策略</strong>：首先观察任务的主导资源（Dominant Resource）是内存还是cpu，选出主导资源，然后根据任务之间主导资源的占比来分配资源</p>\n<p>例如：</p>\n<ul>\n<li>job1所需内存资源占集群总内存3%，所需cpu资源占集群总cpu1%，因此job1的主导资源是内存，占比3%</li>\n<li>job2所需内存资源占2%，所需cpu资源占6%，job2的主导资源是cpu，占比6%</li>\n<li>因此job1和job2申请资源比例为<code>3% : 6%</code>，也就是1：2，job2分配的container数量为job1的两倍</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>yarn作为hadoop任务调度组件，具有良好的可扩展性、高可用性以及其独特的“多租户”特性，它为不同的作业场景提供了几种特性各异的任务调度机制：<code>FIFO调度器</code>，<code>Capacity调度器</code>，<code>Fair调度器</code><br>","more":"</p>\n<h3 id=\"FIFO调度器\"><a href=\"#FIFO调度器\" class=\"headerlink\" title=\"FIFO调度器\"></a>FIFO调度器</h3><p>FIFO调度器采用一个先进先出队列对提交的任务执行顺序进行调度，按照提交的顺序首先为第一个任务的请求分配资源，第一个应用的请求被满足后，再依次为队列中下一个应用分配资源</p>\n<p>FIFO调度器的好处是实现简单，无需任务额外配置，但是缺点也很明显，不适合那种大型任务和小型任务穿插执行的共享集群，因为大型任务可能会独占集群中的全部计算资源，并且任务执行时间会很长，yarn短时间为无法为其他任务分配资源，因此只能阻塞在队列中等待大型任务执行完成释放资源：</p>\n<p><img src=\"\\blog\\images\\1559481447073.png\" alt=\"1559481447073\"></p>\n<p>如图，横轴表示集群资源利用情况，当job1执行时，由于集群资源有限，job2必须等待job1执行完成后才能执行</p>\n<h3 id=\"Capacity调度器\"><a href=\"#Capacity调度器\" class=\"headerlink\" title=\"Capacity调度器\"></a>Capacity调度器</h3><p>容量调度器可以为不同体量的任务提供一个或多个专用的等待队列，保证小型任务一旦提交就可以分配资源启动执行，因此解决了FIFO调度无法兼顾大型任务和小型任务的问题，大型任务的执行不会造成小型任务的长时间等待</p>\n<p>不过容量调度器也有自己的缺点，由于yarn要专门为小型任务预留一部分集群资源，分配给大型任务的资源就会相应减少，执行时间也就变长了：</p>\n<p><img src=\"\\blog\\images\\1559482380158.png\" alt=\"1559482380158\"></p>\n<p>如图，queue B配置为小型任务服务，分配的资源较少，queue A配置为大型任务服务，分配的集群资源更多，保证大型任务和小型任务能够在集群中共存而不会相互阻塞</p>\n<p>配置容量调度器时，可以根据实际需要配置多个队列，每个队列分配不同数额的集群资源，不过如果某个队列的任务在执行过程中分配的集群资源不够用，为了不让该任务等待其他队列释放资源，需要为队列设置<code>maximun-capacity</code>，能够在资源不够用时进行动态扩容，如果集群中有空闲资源，则会为这个队列分配更多的资源，这种方式称为<code>队列弹性</code>，扩容后的资源总量保证不超过<code>maximun-capacity</code>即可</p>\n<p>提交map-reduce任务时，通过指定<code>mapreduce.job.&lt;queue-name&gt;</code>来指定当前任务分配给哪一个队列</p>\n<h3 id=\"Fair调度器\"><a href=\"#Fair调度器\" class=\"headerlink\" title=\"Fair调度器\"></a>Fair调度器</h3><p>即公平调度器，目的是为所有运行的任务公平分配集群资源，在容量调度器的基础上进行了改进，能够在不同任务之间<strong>动态</strong>地调度集群资源：</p>\n<p><img src=\"\\blog\\images\\1559568139040.png\" alt=\"1559568139040\"></p>\n<p>如图，在公平调度器模式下，与容量调度类似，根据实际需要分配多个队列用于执行任务：</p>\n<ol>\n<li><p>job1率先提交，当前集群中没有其他任务共享资源，因为job1独享集群中queue A和queue B的全部资源</p>\n</li>\n<li><p>job1执行过程中，job2提交，此时job1享有queue A为其分配的资源，而job2享有queue B为其分配的资源，job1和job2共享集群资源</p>\n</li>\n<li><p>job2独享queue B的资源时，job3同样提交到queue B中执行，此时job2和job3共享queue B的资源</p>\n</li>\n<li><p>待job2执行完成后，job3独享queue B的资源</p>\n</li>\n</ol>\n<p>可以看出，相比于容量调度器，公平调度模式下几乎不会出现饥饿情况（即有任务长期无法分配到集群资源而长时间处于阻塞状态），在满足一定的分配权重和调度策略的情况下，每个任务都能分享到一定数量的集群资源</p>\n<p>hadoop默认使用容量调度器，如果要在yarn中启用公平调度器，需要在<code>yarn-site.xml</code>作以下配置</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"Fair调度器的队列放置策略\"><a href=\"#Fair调度器的队列放置策略\" class=\"headerlink\" title=\"Fair调度器的队列放置策略\"></a>Fair调度器的队列放置策略</h4><p>与容量调度器相似，公平调度器也可以执行某个任务提交到特定的队列中执行，也可以执行任务放置到以任务提交的用户名为队列名的队列下进行执行</p>\n<p>在yarn-site.xml中配置<code>yarn.scheduler.fair.allocation.file</code>执行队列分配文件，在队列分配文件中制定任务的队列分配策略(来自<a href=\"http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/FairScheduler.html\" target=\"_blank\" rel=\"noopener\">hadoop官网yarn-FairScheduler文档</a>)：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;?xml version=\"1.0\"?&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">allocations</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">queue</span> <span class=\"attr\">name</span>=<span class=\"string\">\"sample_queue\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">minResources</span>&gt;</span>10000 mb,0vcores<span class=\"tag\">&lt;/<span class=\"name\">minResources</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">maxResources</span>&gt;</span>90000 mb,0vcores<span class=\"tag\">&lt;/<span class=\"name\">maxResources</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">maxRunningApps</span>&gt;</span>50<span class=\"tag\">&lt;/<span class=\"name\">maxRunningApps</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">maxAMShare</span>&gt;</span>0.1<span class=\"tag\">&lt;/<span class=\"name\">maxAMShare</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">weight</span>&gt;</span>2.0<span class=\"tag\">&lt;/<span class=\"name\">weight</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">schedulingPolicy</span>&gt;</span>fair<span class=\"tag\">&lt;/<span class=\"name\">schedulingPolicy</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">queue</span> <span class=\"attr\">name</span>=<span class=\"string\">\"sample_sub_queue\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">aclSubmitApps</span>&gt;</span>charlie<span class=\"tag\">&lt;/<span class=\"name\">aclSubmitApps</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">minResources</span>&gt;</span>5000 mb,0vcores<span class=\"tag\">&lt;/<span class=\"name\">minResources</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">queue</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">queue</span> <span class=\"attr\">name</span>=<span class=\"string\">\"sample_reservable_queue\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">reservation</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">reservation</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">queue</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">queue</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">queueMaxAMShareDefault</span>&gt;</span>0.5<span class=\"tag\">&lt;/<span class=\"name\">queueMaxAMShareDefault</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">queueMaxResourcesDefault</span>&gt;</span>40000 mb,0vcores<span class=\"tag\">&lt;/<span class=\"name\">queueMaxResourcesDefault</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">queue</span> <span class=\"attr\">name</span>=<span class=\"string\">\"secondary_group_queue\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"parent\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">weight</span>&gt;</span>3.0<span class=\"tag\">&lt;/<span class=\"name\">weight</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">maxChildResources</span>&gt;</span>4096 mb,4vcores<span class=\"tag\">&lt;/<span class=\"name\">maxChildResources</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">queue</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">user</span> <span class=\"attr\">name</span>=<span class=\"string\">\"sample_user\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">maxRunningApps</span>&gt;</span>30<span class=\"tag\">&lt;/<span class=\"name\">maxRunningApps</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">user</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">userMaxAppsDefault</span>&gt;</span>5<span class=\"tag\">&lt;/<span class=\"name\">userMaxAppsDefault</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">queuePlacementPolicy</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"specified\"</span> /&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"primaryGroup\"</span> <span class=\"attr\">create</span>=<span class=\"string\">\"false\"</span> /&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"nestedUserQueue\"</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"secondaryGroupExistingQueue\"</span> <span class=\"attr\">create</span>=<span class=\"string\">\"false\"</span> /&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">rule</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"default\"</span> <span class=\"attr\">queue</span>=<span class=\"string\">\"sample_queue\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">queuePlacementPolicy</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">allocations</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>如上队列分配文件，分配了多个队列，每个队列还可在其内部指定多个叶子队列</p>\n<p>最外层隐藏的最顶级队列是root队列，这里面配置的所有队列都是root队列的叶子队列，如果完全没有指定队列分配文件，则所有任务都会默认提交到root队列中执行</p>\n<p>队列中可以指定最小和最大分配资源数以及最大可运行的任务数，权重weight值（为同层级队列指定资源分配比例），指定权限用户（aclSubmitApps，拥有这个权限的用户可以提交和杀死这个队列中的任务，需要注意root队列的acl是<code>*</code>，即每个用户都有权限），调度策略（schedulingPolicy，在一个队列中一共有三种调度策略），最重要的是队列放置策略<code>queuePlacementPolicy</code>：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">queuePlacementPolicy</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"specified\"</span> <span class=\"attr\">create</span>=<span class=\"string\">\"true\"</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"user\"</span> <span class=\"attr\">create</span>=<span class=\"string\">\"false\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"primaryGroup\"</span> <span class=\"attr\">create</span>=<span class=\"string\">\"false\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"nestedUserQueue\"</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"secondaryGroupExistingQueue\"</span> <span class=\"attr\">create</span>=<span class=\"string\">\"false\"</span> /&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">rule</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">rule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"default\"</span> <span class=\"attr\">queue</span>=<span class=\"string\">\"sample_queue\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">queuePlacementPolicy</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>这是一个规则列表：</p>\n<ul>\n<li>首先如果specified为true，当前提交任务若指定了队列名则放置于指定队列执行，否则进行下一级判断</li>\n<li>如果user为true，则寻找以当前用户名为队列名的队列，若未创建则创建该队列；在这里user为false，就跳过这条判断</li>\n<li>如果primaryGroup为true，则寻找以当前用户的主group名命名的队列</li>\n<li>nestedUserQueue：嵌套用户队列，与primaryGroup不同之处在于，user是应用到root队列的，而nestedUserQueue则会为任务寻找type为parent的队列，在这个队列下再去寻找有没有以任务用户名命名的队列</li>\n<li>secondaryGroupExistingQueue：寻找以用户的Secondary group名字命名的队列；上面的配置中，yarn会在parent队列下寻找符合要求的嵌套队列</li>\n<li>最终如果没有找到匹配以上规则的队列，则执行提交到default队列，这里即为sample_queue队列</li>\n</ul>\n<h5 id=\"Fair调度器的三种调度策略\"><a href=\"#Fair调度器的三种调度策略\" class=\"headerlink\" title=\"Fair调度器的三种调度策略\"></a>Fair调度器的三种调度策略</h5><p>不同于FIFO调度器和容量调度器固定的调度策略，对于所有提交到某个队列中的任务，公平调度器为这个队列提供了三种调度策略，即：默认的<code>fair调度策略</code>，传统模式的<code>FIFO调度策略</code>，还有一种是<code>Dominant Resource Fairness(drf)策略</code></p>\n<h5 id=\"抢占\"><a href=\"#抢占\" class=\"headerlink\" title=\"抢占\"></a>抢占</h5><p>公平调度器中，当一个新的任务提交到一个队列，而该队列并没有空闲资源分配给它，这时该任务需要等待其他任务完成一部分container计算然后释放资源给新任务，以达到公平运行的目的</p>\n<p>为了使作业从提交到执行所需的时间可控，可以设置抢占模式，当等待时间超过一定阈值时即启动抢占，强迫队列中其他任务立刻让出一部分资源给新任务，达到强行公平运行的目的</p>\n<p>yarn-site.xml中将<code>yarn.scheduler.fair.preemption</code>设置为true即可打开抢占模式，并至少配置以下两个参数中的一个：</p>\n<ul>\n<li>最小资源抢占超时时间<code>minSharePreemptionTimeout</code>：若指定等待时间内未获得承诺的最小共享资源则会启动抢占</li>\n<li>公平资源抢占超时时间<code>fairSharePreemptionTimeout</code>：若指定等待时间内未获得承诺的公平共享资源则会启动抢占；承诺的公平共享资源由公平资源抢占阈值<code>fairSharePreemptionThreshold</code>和队列公平资源分配值的乘积决定，例如，当前队列一共提交了2个job，job1独占了队列资源，job2的公平资源理应为当前队列的0.5倍资源，若<code>fairSharePreemptionThreshold</code>为0.8，则承诺给这个任务的队列资源为0.4；该阈值默认是0.5</li>\n</ul>\n<p>以上两个参数均可以设置root队列级别的默认值：<code>defaultFairSharePreemptionThreshold</code>，<code>defaultMinSharePreemptionTimeout</code></p>\n<h5 id=\"延迟调度\"><a href=\"#延迟调度\" class=\"headerlink\" title=\"延迟调度\"></a>延迟调度</h5><p>yarn的资源管理器为任务分配节点的原则是基于任务所需数据先本地后远程，本地如果有资源就优先分配本地节点，如果本地没有资源再寻找远程节点</p>\n<p>不过有些时候稍微等待一些时间，待本地节点释放后就可以直接在本地启动任务了，不需要再寻找远程节点，这种行为称为<code>延迟调度</code>，容量调度器和公平调度器都支持这种方式</p>\n<ul>\n<li>对于容量调度器，设置<code>yarn.scheduler.capacity.node-locality-delay</code>开启本地延迟，该值为正整数，表示等待本地资源释放期间最多错过多少个远程资源释放的机会，比如设置为3，则表示最多等待3次远程资源释放的信息后，如果本地节点的资源仍然没释放，就直接寻找远程节点的资源，不再等本地了</li>\n<li>对于公平调度器，实现稍有不同，是将<code>yarn.scheduler.fair.locality.threshold.node</code>设置某个值，比如0.5，表示等待集群中最多半数节点给过资源释放信息后，再考虑远程节点，否则在这之前都将等待本地节点释放</li>\n</ul>\n<h5 id=\"主导资源公平性\"><a href=\"#主导资源公平性\" class=\"headerlink\" title=\"主导资源公平性\"></a>主导资源公平性</h5><p>对于容量调度或公平调度，都是基于“资源”这一概念进行策略的，资源为内存或者cpu资源的抽象，两种调度模式都是基于某种资源的分配进行调度（内存或者cpu）</p>\n<p>不过如果某些任务对于内存或者cpu的依赖各异，这时候分配起来就比较复杂了，往往需要<code>Dominant Resource Fairness(drf)策略</code>进行支持</p>\n<p><strong>Dominant Resource Fairness(drf)，主导资源公平策略</strong>：首先观察任务的主导资源（Dominant Resource）是内存还是cpu，选出主导资源，然后根据任务之间主导资源的占比来分配资源</p>\n<p>例如：</p>\n<ul>\n<li>job1所需内存资源占集群总内存3%，所需cpu资源占集群总cpu1%，因此job1的主导资源是内存，占比3%</li>\n<li>job2所需内存资源占2%，所需cpu资源占6%，job2的主导资源是cpu，占比6%</li>\n<li>因此job1和job2申请资源比例为<code>3% : 6%</code>，也就是1：2，job2分配的container数量为job1的两倍</li>\n</ul>"},{"title":"ElasticSearch分布式原理探究 —— 节点和分片","author":"天渊","date":"2019-09-09T09:21:00.000Z","_content":"ElasticSearch `节点`和`分片`原理浅析\n<!--more-->\n\n### Node（节点）\n\n一个运行中的 Elasticsearch 实例称为一个` 节点`，而集群是由一个或者多个拥有相同 `cluster.name` 配置的节点组成\n\nElasticsearch 集群的节点类型：\n\n`Master eligible`：可用于选举master的节点，这种节点可参加master选主流程；通过`node.master`配置项开启，每个节点默认都是开启的\n\n`Master`：master节点，也就是集群主节点，只有主节点才能修改集群状态信息（集群节点信息，所有索引信息，分片路由信息）\n\n`Data Node`：数据节点，用于保存分片数据，集群可以随时增加数据节点用于动态扩容；通过`node.data`配置项开启，每个节点默认都是开启的\n\n`Coordinating Node`：协调节点，接收client的请求并将请求分发到合适的节点，将各个节点返回的数据进行汇总并返回给client；集群中每个节点都具有协调节点的职责\n\n`Client Node`：客户端节点，如果`node.master`和`node.data`都设置为false时，该节点就是个只拥有响应和转发功能的协调节点，专门用于响应client请求\n\n`Hot & Warm Node`：冷热节点，通过对不同硬件配置的节点设置冷热节点\n\n开发环境中一个node可以有多个职责，生产环境下还是推荐单个node具有各自的职责，比如master node就不要负责data node数据保存和修改的职责\n\n![](http://img.mantian.site/201909051623_337.png)\n\n### 分片（Primary Shard & Replica Shard）\n\nElasticsearch 为每个index配置了多个分片（`shard`），用以提高集群读写吞吐量，将index数据分布到多个node上，客户端通过`routing`参数（默认是文档id）来决定当前文档的请求路由到哪个`shard`上：\n\n```\nshard = hash(routing) % number_of_primary_shards\n```\n\n一个分片是一个运行的Lucence实例，并且分片数在创建索引后即确定，不允许修改\n\n`副本（replica）`：为了解决index数据高可用的问题，可以为每个shard配备多个冗余备份，即副本`replica`，`replica`数目可以动态调整；副本数越多，写数据的性能会受影响，但会提高读数据的吞吐量；每个sharding都有一个主分片，其他都为`replica`\n\n![](http://img.mantian.site/201909051653_788.png)\n\n如上，该集群有一个index，这个index被分为了两个shard，即shard 0和shard 1，每个shard又有两个replica，其中shard 0的主分片就是P0，副本就是两个R0，同理sharding 1的主分片是P1，副本是两个R1\n\n>**新建index如何分配shard和replica？**\n>\n>Elasticsearch 在各个data node上分布shard和replica时，会尽量保证单个index的主shard均衡分布不同的node，并且单个shard的主shard和replica分布于不同的node上\n>\n>每当集群有新加入data node，集群都会重新分配各个shard\n\n**默认配置**：7.0版本中，新增index时默认shard数为1，每个shard默认有1个replica\n\n#### shard规划的原则\n\n- 分片数不宜设置过小：过小会导致后续无法有效地通过增加node进行横向扩容，并且单个shard数据量过多也会导致数据重新分派耗时太多\n- 分片数也不宜设置过大：过大的话，也会影响搜索结果汇总时相关性打分的准确性，并且如果单个节点分片过多的话也会导致资源浪费，无法在多个节点间有效地平衡请求负载\n\n#### 文档写操作\n\n对文档的写操作包括`新增`,`索引（修改）`和`删除`等请求，写操作必须作用在主分片上，主分片数据更新完成后才能被复制到各个replica上：\n\n![](http://img.mantian.site/201909051735_122.png)\n\n1. 客户端发送某个写请求到node1，node1此时就是该请求的协调节点\n2. node1通过id（或者routing字段）判断该请求对应shard0，由于shard0的主分片位于node3，因此将请求转发给node3\n3. node3收到请求，修改主分片P0，修改成功后并行地将该请求转发给两个replica：R0\n4. 两个replica数据修改成功后向node3报告修改成功，最后node3再向协调节点node1报告请求成功\n5. node1向客户端反馈请求成功\n\n可以看出，如果一个shard的replica越多，写操作的性能也就越低，因为它要保证所有replica都成功更新数据后才会告诉客户端当前请求成功了\n\n此外还有两个影响写操作的配置项，通过降低安全性为代价提高写入性能：\n\n- 修改`consistency`模式：`consistency`一致性，即至少需要多少个shard副本处于活跃状态才能允许写操作，默认`quorum`模式，即需要保证多于半数的副本能够成功写入数据：\n\n  ```\n  int( (primary + number_of_replicas) / 2 ) + 1\n  ```\n\n  例如shard有1个主shard和2个replica，此时仅需要主shard和其中1个replica处于活跃状态，协调节点就可以开始写操作，否则反馈客户端当前请求失败\n\n  此外`consistency`还可以配置为`ALL`或者`ONE`，即所有副本都处于active状态或者仅主节点active\n\n- 修改`timeout`：即等待副本恢复活跃状态的超时时间，如果设置为100ms，协调节点只会等待100ms，如果等待100ms后活跃副本数目仍未达到规定数量，则直接进行写操作\n\n#### 文档读操作\n\n当向es执行读操作获取某个文档时，协调节点会向保存了该文档的任意一个副本分片发起请求：\n\n![](http://img.mantian.site/201909091005_698.png)\n\n如图，此时node1是协调节点：\n\n1. 客户端向node1发起读请求，node1通过`_id`或者`routing`字段判断所请求的文档在shard1上\n2. 协调节点node1每次读请求都会通过轮询的方式向一个shard的所有副本发送请求，实现负载均衡，本次请求发往node2的副本R0\n3. node2将文档返回给node1，最后由node1返回给客户端\n\n#### 多文档更新\n\n可以使用`mget`请求批量获取多个文档，也可以使用`bulk`请求批量插入或修改多个文档\n\n##### mget\n\n`mget`请求与普通的`get`读请求原理上是一致的，区别在于`mget`需要为多个分片构建多文档请求，然后再将这些请求并行转发到各个节点上，最后将结果汇总返回给客户端\n\n##### bulk\n\n`bulk`请求即批量更新请求，一次性修改多个文档\n\n![](http://img.mantian.site/201909091115_343.png)\n\n步骤如下：\n\n1. node1作为协调节点收到客户端请求\n2. node1构建针对各个分片的多个批量请求，并行地向shard1的主分片P1（保管于当前协调节点node1）和shard0的主分片P0（node3）发起批量请求\n3. 各个shard的主分片更新并同步完成后，向协调节点报告更新结果，最后协调节点node1将结果收集整理并返还给客户端","source":"_posts/ElasticSearch分布式原理探究-——-节点和分片.md","raw":"title: ElasticSearch分布式原理探究 —— 节点和分片\nauthor: 天渊\ntags:\n  - elasticsearch\ncategories: []\ndate: 2019-09-09 17:21:00\n---\nElasticSearch `节点`和`分片`原理浅析\n<!--more-->\n\n### Node（节点）\n\n一个运行中的 Elasticsearch 实例称为一个` 节点`，而集群是由一个或者多个拥有相同 `cluster.name` 配置的节点组成\n\nElasticsearch 集群的节点类型：\n\n`Master eligible`：可用于选举master的节点，这种节点可参加master选主流程；通过`node.master`配置项开启，每个节点默认都是开启的\n\n`Master`：master节点，也就是集群主节点，只有主节点才能修改集群状态信息（集群节点信息，所有索引信息，分片路由信息）\n\n`Data Node`：数据节点，用于保存分片数据，集群可以随时增加数据节点用于动态扩容；通过`node.data`配置项开启，每个节点默认都是开启的\n\n`Coordinating Node`：协调节点，接收client的请求并将请求分发到合适的节点，将各个节点返回的数据进行汇总并返回给client；集群中每个节点都具有协调节点的职责\n\n`Client Node`：客户端节点，如果`node.master`和`node.data`都设置为false时，该节点就是个只拥有响应和转发功能的协调节点，专门用于响应client请求\n\n`Hot & Warm Node`：冷热节点，通过对不同硬件配置的节点设置冷热节点\n\n开发环境中一个node可以有多个职责，生产环境下还是推荐单个node具有各自的职责，比如master node就不要负责data node数据保存和修改的职责\n\n![](http://img.mantian.site/201909051623_337.png)\n\n### 分片（Primary Shard & Replica Shard）\n\nElasticsearch 为每个index配置了多个分片（`shard`），用以提高集群读写吞吐量，将index数据分布到多个node上，客户端通过`routing`参数（默认是文档id）来决定当前文档的请求路由到哪个`shard`上：\n\n```\nshard = hash(routing) % number_of_primary_shards\n```\n\n一个分片是一个运行的Lucence实例，并且分片数在创建索引后即确定，不允许修改\n\n`副本（replica）`：为了解决index数据高可用的问题，可以为每个shard配备多个冗余备份，即副本`replica`，`replica`数目可以动态调整；副本数越多，写数据的性能会受影响，但会提高读数据的吞吐量；每个sharding都有一个主分片，其他都为`replica`\n\n![](http://img.mantian.site/201909051653_788.png)\n\n如上，该集群有一个index，这个index被分为了两个shard，即shard 0和shard 1，每个shard又有两个replica，其中shard 0的主分片就是P0，副本就是两个R0，同理sharding 1的主分片是P1，副本是两个R1\n\n>**新建index如何分配shard和replica？**\n>\n>Elasticsearch 在各个data node上分布shard和replica时，会尽量保证单个index的主shard均衡分布不同的node，并且单个shard的主shard和replica分布于不同的node上\n>\n>每当集群有新加入data node，集群都会重新分配各个shard\n\n**默认配置**：7.0版本中，新增index时默认shard数为1，每个shard默认有1个replica\n\n#### shard规划的原则\n\n- 分片数不宜设置过小：过小会导致后续无法有效地通过增加node进行横向扩容，并且单个shard数据量过多也会导致数据重新分派耗时太多\n- 分片数也不宜设置过大：过大的话，也会影响搜索结果汇总时相关性打分的准确性，并且如果单个节点分片过多的话也会导致资源浪费，无法在多个节点间有效地平衡请求负载\n\n#### 文档写操作\n\n对文档的写操作包括`新增`,`索引（修改）`和`删除`等请求，写操作必须作用在主分片上，主分片数据更新完成后才能被复制到各个replica上：\n\n![](http://img.mantian.site/201909051735_122.png)\n\n1. 客户端发送某个写请求到node1，node1此时就是该请求的协调节点\n2. node1通过id（或者routing字段）判断该请求对应shard0，由于shard0的主分片位于node3，因此将请求转发给node3\n3. node3收到请求，修改主分片P0，修改成功后并行地将该请求转发给两个replica：R0\n4. 两个replica数据修改成功后向node3报告修改成功，最后node3再向协调节点node1报告请求成功\n5. node1向客户端反馈请求成功\n\n可以看出，如果一个shard的replica越多，写操作的性能也就越低，因为它要保证所有replica都成功更新数据后才会告诉客户端当前请求成功了\n\n此外还有两个影响写操作的配置项，通过降低安全性为代价提高写入性能：\n\n- 修改`consistency`模式：`consistency`一致性，即至少需要多少个shard副本处于活跃状态才能允许写操作，默认`quorum`模式，即需要保证多于半数的副本能够成功写入数据：\n\n  ```\n  int( (primary + number_of_replicas) / 2 ) + 1\n  ```\n\n  例如shard有1个主shard和2个replica，此时仅需要主shard和其中1个replica处于活跃状态，协调节点就可以开始写操作，否则反馈客户端当前请求失败\n\n  此外`consistency`还可以配置为`ALL`或者`ONE`，即所有副本都处于active状态或者仅主节点active\n\n- 修改`timeout`：即等待副本恢复活跃状态的超时时间，如果设置为100ms，协调节点只会等待100ms，如果等待100ms后活跃副本数目仍未达到规定数量，则直接进行写操作\n\n#### 文档读操作\n\n当向es执行读操作获取某个文档时，协调节点会向保存了该文档的任意一个副本分片发起请求：\n\n![](http://img.mantian.site/201909091005_698.png)\n\n如图，此时node1是协调节点：\n\n1. 客户端向node1发起读请求，node1通过`_id`或者`routing`字段判断所请求的文档在shard1上\n2. 协调节点node1每次读请求都会通过轮询的方式向一个shard的所有副本发送请求，实现负载均衡，本次请求发往node2的副本R0\n3. node2将文档返回给node1，最后由node1返回给客户端\n\n#### 多文档更新\n\n可以使用`mget`请求批量获取多个文档，也可以使用`bulk`请求批量插入或修改多个文档\n\n##### mget\n\n`mget`请求与普通的`get`读请求原理上是一致的，区别在于`mget`需要为多个分片构建多文档请求，然后再将这些请求并行转发到各个节点上，最后将结果汇总返回给客户端\n\n##### bulk\n\n`bulk`请求即批量更新请求，一次性修改多个文档\n\n![](http://img.mantian.site/201909091115_343.png)\n\n步骤如下：\n\n1. node1作为协调节点收到客户端请求\n2. node1构建针对各个分片的多个批量请求，并行地向shard1的主分片P1（保管于当前协调节点node1）和shard0的主分片P0（node3）发起批量请求\n3. 各个shard的主分片更新并同步完成后，向协调节点报告更新结果，最后协调节点node1将结果收集整理并返还给客户端","slug":"ElasticSearch分布式原理探究-——-节点和分片","published":1,"updated":"2020-05-24T13:00:00.618Z","_id":"ckf0h31hq000wactsg4mimn5q","comments":1,"layout":"post","photos":[],"link":"","content":"<p>ElasticSearch <code>节点</code>和<code>分片</code>原理浅析<br><a id=\"more\"></a></p>\n<h3 id=\"Node（节点）\"><a href=\"#Node（节点）\" class=\"headerlink\" title=\"Node（节点）\"></a>Node（节点）</h3><p>一个运行中的 Elasticsearch 实例称为一个<code>节点</code>，而集群是由一个或者多个拥有相同 <code>cluster.name</code> 配置的节点组成</p>\n<p>Elasticsearch 集群的节点类型：</p>\n<p><code>Master eligible</code>：可用于选举master的节点，这种节点可参加master选主流程；通过<code>node.master</code>配置项开启，每个节点默认都是开启的</p>\n<p><code>Master</code>：master节点，也就是集群主节点，只有主节点才能修改集群状态信息（集群节点信息，所有索引信息，分片路由信息）</p>\n<p><code>Data Node</code>：数据节点，用于保存分片数据，集群可以随时增加数据节点用于动态扩容；通过<code>node.data</code>配置项开启，每个节点默认都是开启的</p>\n<p><code>Coordinating Node</code>：协调节点，接收client的请求并将请求分发到合适的节点，将各个节点返回的数据进行汇总并返回给client；集群中每个节点都具有协调节点的职责</p>\n<p><code>Client Node</code>：客户端节点，如果<code>node.master</code>和<code>node.data</code>都设置为false时，该节点就是个只拥有响应和转发功能的协调节点，专门用于响应client请求</p>\n<p><code>Hot &amp; Warm Node</code>：冷热节点，通过对不同硬件配置的节点设置冷热节点</p>\n<p>开发环境中一个node可以有多个职责，生产环境下还是推荐单个node具有各自的职责，比如master node就不要负责data node数据保存和修改的职责</p>\n<p><img src=\"http://img.mantian.site/201909051623_337.png\" alt></p>\n<h3 id=\"分片（Primary-Shard-amp-Replica-Shard）\"><a href=\"#分片（Primary-Shard-amp-Replica-Shard）\" class=\"headerlink\" title=\"分片（Primary Shard &amp; Replica Shard）\"></a>分片（Primary Shard &amp; Replica Shard）</h3><p>Elasticsearch 为每个index配置了多个分片（<code>shard</code>），用以提高集群读写吞吐量，将index数据分布到多个node上，客户端通过<code>routing</code>参数（默认是文档id）来决定当前文档的请求路由到哪个<code>shard</code>上：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">shard = hash(routing) % number_of_primary_shards</span><br></pre></td></tr></table></figure>\n<p>一个分片是一个运行的Lucence实例，并且分片数在创建索引后即确定，不允许修改</p>\n<p><code>副本（replica）</code>：为了解决index数据高可用的问题，可以为每个shard配备多个冗余备份，即副本<code>replica</code>，<code>replica</code>数目可以动态调整；副本数越多，写数据的性能会受影响，但会提高读数据的吞吐量；每个sharding都有一个主分片，其他都为<code>replica</code></p>\n<p><img src=\"http://img.mantian.site/201909051653_788.png\" alt></p>\n<p>如上，该集群有一个index，这个index被分为了两个shard，即shard 0和shard 1，每个shard又有两个replica，其中shard 0的主分片就是P0，副本就是两个R0，同理sharding 1的主分片是P1，副本是两个R1</p>\n<blockquote>\n<p><strong>新建index如何分配shard和replica？</strong></p>\n<p>Elasticsearch 在各个data node上分布shard和replica时，会尽量保证单个index的主shard均衡分布不同的node，并且单个shard的主shard和replica分布于不同的node上</p>\n<p>每当集群有新加入data node，集群都会重新分配各个shard</p>\n</blockquote>\n<p><strong>默认配置</strong>：7.0版本中，新增index时默认shard数为1，每个shard默认有1个replica</p>\n<h4 id=\"shard规划的原则\"><a href=\"#shard规划的原则\" class=\"headerlink\" title=\"shard规划的原则\"></a>shard规划的原则</h4><ul>\n<li>分片数不宜设置过小：过小会导致后续无法有效地通过增加node进行横向扩容，并且单个shard数据量过多也会导致数据重新分派耗时太多</li>\n<li>分片数也不宜设置过大：过大的话，也会影响搜索结果汇总时相关性打分的准确性，并且如果单个节点分片过多的话也会导致资源浪费，无法在多个节点间有效地平衡请求负载</li>\n</ul>\n<h4 id=\"文档写操作\"><a href=\"#文档写操作\" class=\"headerlink\" title=\"文档写操作\"></a>文档写操作</h4><p>对文档的写操作包括<code>新增</code>,<code>索引（修改）</code>和<code>删除</code>等请求，写操作必须作用在主分片上，主分片数据更新完成后才能被复制到各个replica上：</p>\n<p><img src=\"http://img.mantian.site/201909051735_122.png\" alt></p>\n<ol>\n<li>客户端发送某个写请求到node1，node1此时就是该请求的协调节点</li>\n<li>node1通过id（或者routing字段）判断该请求对应shard0，由于shard0的主分片位于node3，因此将请求转发给node3</li>\n<li>node3收到请求，修改主分片P0，修改成功后并行地将该请求转发给两个replica：R0</li>\n<li>两个replica数据修改成功后向node3报告修改成功，最后node3再向协调节点node1报告请求成功</li>\n<li>node1向客户端反馈请求成功</li>\n</ol>\n<p>可以看出，如果一个shard的replica越多，写操作的性能也就越低，因为它要保证所有replica都成功更新数据后才会告诉客户端当前请求成功了</p>\n<p>此外还有两个影响写操作的配置项，通过降低安全性为代价提高写入性能：</p>\n<ul>\n<li><p>修改<code>consistency</code>模式：<code>consistency</code>一致性，即至少需要多少个shard副本处于活跃状态才能允许写操作，默认<code>quorum</code>模式，即需要保证多于半数的副本能够成功写入数据：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int( (primary + number_of_replicas) / 2 ) + 1</span><br></pre></td></tr></table></figure>\n<p>例如shard有1个主shard和2个replica，此时仅需要主shard和其中1个replica处于活跃状态，协调节点就可以开始写操作，否则反馈客户端当前请求失败</p>\n<p>此外<code>consistency</code>还可以配置为<code>ALL</code>或者<code>ONE</code>，即所有副本都处于active状态或者仅主节点active</p>\n</li>\n<li><p>修改<code>timeout</code>：即等待副本恢复活跃状态的超时时间，如果设置为100ms，协调节点只会等待100ms，如果等待100ms后活跃副本数目仍未达到规定数量，则直接进行写操作</p>\n</li>\n</ul>\n<h4 id=\"文档读操作\"><a href=\"#文档读操作\" class=\"headerlink\" title=\"文档读操作\"></a>文档读操作</h4><p>当向es执行读操作获取某个文档时，协调节点会向保存了该文档的任意一个副本分片发起请求：</p>\n<p><img src=\"http://img.mantian.site/201909091005_698.png\" alt></p>\n<p>如图，此时node1是协调节点：</p>\n<ol>\n<li>客户端向node1发起读请求，node1通过<code>_id</code>或者<code>routing</code>字段判断所请求的文档在shard1上</li>\n<li>协调节点node1每次读请求都会通过轮询的方式向一个shard的所有副本发送请求，实现负载均衡，本次请求发往node2的副本R0</li>\n<li>node2将文档返回给node1，最后由node1返回给客户端</li>\n</ol>\n<h4 id=\"多文档更新\"><a href=\"#多文档更新\" class=\"headerlink\" title=\"多文档更新\"></a>多文档更新</h4><p>可以使用<code>mget</code>请求批量获取多个文档，也可以使用<code>bulk</code>请求批量插入或修改多个文档</p>\n<h5 id=\"mget\"><a href=\"#mget\" class=\"headerlink\" title=\"mget\"></a>mget</h5><p><code>mget</code>请求与普通的<code>get</code>读请求原理上是一致的，区别在于<code>mget</code>需要为多个分片构建多文档请求，然后再将这些请求并行转发到各个节点上，最后将结果汇总返回给客户端</p>\n<h5 id=\"bulk\"><a href=\"#bulk\" class=\"headerlink\" title=\"bulk\"></a>bulk</h5><p><code>bulk</code>请求即批量更新请求，一次性修改多个文档</p>\n<p><img src=\"http://img.mantian.site/201909091115_343.png\" alt></p>\n<p>步骤如下：</p>\n<ol>\n<li>node1作为协调节点收到客户端请求</li>\n<li>node1构建针对各个分片的多个批量请求，并行地向shard1的主分片P1（保管于当前协调节点node1）和shard0的主分片P0（node3）发起批量请求</li>\n<li>各个shard的主分片更新并同步完成后，向协调节点报告更新结果，最后协调节点node1将结果收集整理并返还给客户端</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>ElasticSearch <code>节点</code>和<code>分片</code>原理浅析<br>","more":"</p>\n<h3 id=\"Node（节点）\"><a href=\"#Node（节点）\" class=\"headerlink\" title=\"Node（节点）\"></a>Node（节点）</h3><p>一个运行中的 Elasticsearch 实例称为一个<code>节点</code>，而集群是由一个或者多个拥有相同 <code>cluster.name</code> 配置的节点组成</p>\n<p>Elasticsearch 集群的节点类型：</p>\n<p><code>Master eligible</code>：可用于选举master的节点，这种节点可参加master选主流程；通过<code>node.master</code>配置项开启，每个节点默认都是开启的</p>\n<p><code>Master</code>：master节点，也就是集群主节点，只有主节点才能修改集群状态信息（集群节点信息，所有索引信息，分片路由信息）</p>\n<p><code>Data Node</code>：数据节点，用于保存分片数据，集群可以随时增加数据节点用于动态扩容；通过<code>node.data</code>配置项开启，每个节点默认都是开启的</p>\n<p><code>Coordinating Node</code>：协调节点，接收client的请求并将请求分发到合适的节点，将各个节点返回的数据进行汇总并返回给client；集群中每个节点都具有协调节点的职责</p>\n<p><code>Client Node</code>：客户端节点，如果<code>node.master</code>和<code>node.data</code>都设置为false时，该节点就是个只拥有响应和转发功能的协调节点，专门用于响应client请求</p>\n<p><code>Hot &amp; Warm Node</code>：冷热节点，通过对不同硬件配置的节点设置冷热节点</p>\n<p>开发环境中一个node可以有多个职责，生产环境下还是推荐单个node具有各自的职责，比如master node就不要负责data node数据保存和修改的职责</p>\n<p><img src=\"http://img.mantian.site/201909051623_337.png\" alt></p>\n<h3 id=\"分片（Primary-Shard-amp-Replica-Shard）\"><a href=\"#分片（Primary-Shard-amp-Replica-Shard）\" class=\"headerlink\" title=\"分片（Primary Shard &amp; Replica Shard）\"></a>分片（Primary Shard &amp; Replica Shard）</h3><p>Elasticsearch 为每个index配置了多个分片（<code>shard</code>），用以提高集群读写吞吐量，将index数据分布到多个node上，客户端通过<code>routing</code>参数（默认是文档id）来决定当前文档的请求路由到哪个<code>shard</code>上：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">shard = hash(routing) % number_of_primary_shards</span><br></pre></td></tr></table></figure>\n<p>一个分片是一个运行的Lucence实例，并且分片数在创建索引后即确定，不允许修改</p>\n<p><code>副本（replica）</code>：为了解决index数据高可用的问题，可以为每个shard配备多个冗余备份，即副本<code>replica</code>，<code>replica</code>数目可以动态调整；副本数越多，写数据的性能会受影响，但会提高读数据的吞吐量；每个sharding都有一个主分片，其他都为<code>replica</code></p>\n<p><img src=\"http://img.mantian.site/201909051653_788.png\" alt></p>\n<p>如上，该集群有一个index，这个index被分为了两个shard，即shard 0和shard 1，每个shard又有两个replica，其中shard 0的主分片就是P0，副本就是两个R0，同理sharding 1的主分片是P1，副本是两个R1</p>\n<blockquote>\n<p><strong>新建index如何分配shard和replica？</strong></p>\n<p>Elasticsearch 在各个data node上分布shard和replica时，会尽量保证单个index的主shard均衡分布不同的node，并且单个shard的主shard和replica分布于不同的node上</p>\n<p>每当集群有新加入data node，集群都会重新分配各个shard</p>\n</blockquote>\n<p><strong>默认配置</strong>：7.0版本中，新增index时默认shard数为1，每个shard默认有1个replica</p>\n<h4 id=\"shard规划的原则\"><a href=\"#shard规划的原则\" class=\"headerlink\" title=\"shard规划的原则\"></a>shard规划的原则</h4><ul>\n<li>分片数不宜设置过小：过小会导致后续无法有效地通过增加node进行横向扩容，并且单个shard数据量过多也会导致数据重新分派耗时太多</li>\n<li>分片数也不宜设置过大：过大的话，也会影响搜索结果汇总时相关性打分的准确性，并且如果单个节点分片过多的话也会导致资源浪费，无法在多个节点间有效地平衡请求负载</li>\n</ul>\n<h4 id=\"文档写操作\"><a href=\"#文档写操作\" class=\"headerlink\" title=\"文档写操作\"></a>文档写操作</h4><p>对文档的写操作包括<code>新增</code>,<code>索引（修改）</code>和<code>删除</code>等请求，写操作必须作用在主分片上，主分片数据更新完成后才能被复制到各个replica上：</p>\n<p><img src=\"http://img.mantian.site/201909051735_122.png\" alt></p>\n<ol>\n<li>客户端发送某个写请求到node1，node1此时就是该请求的协调节点</li>\n<li>node1通过id（或者routing字段）判断该请求对应shard0，由于shard0的主分片位于node3，因此将请求转发给node3</li>\n<li>node3收到请求，修改主分片P0，修改成功后并行地将该请求转发给两个replica：R0</li>\n<li>两个replica数据修改成功后向node3报告修改成功，最后node3再向协调节点node1报告请求成功</li>\n<li>node1向客户端反馈请求成功</li>\n</ol>\n<p>可以看出，如果一个shard的replica越多，写操作的性能也就越低，因为它要保证所有replica都成功更新数据后才会告诉客户端当前请求成功了</p>\n<p>此外还有两个影响写操作的配置项，通过降低安全性为代价提高写入性能：</p>\n<ul>\n<li><p>修改<code>consistency</code>模式：<code>consistency</code>一致性，即至少需要多少个shard副本处于活跃状态才能允许写操作，默认<code>quorum</code>模式，即需要保证多于半数的副本能够成功写入数据：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int( (primary + number_of_replicas) / 2 ) + 1</span><br></pre></td></tr></table></figure>\n<p>例如shard有1个主shard和2个replica，此时仅需要主shard和其中1个replica处于活跃状态，协调节点就可以开始写操作，否则反馈客户端当前请求失败</p>\n<p>此外<code>consistency</code>还可以配置为<code>ALL</code>或者<code>ONE</code>，即所有副本都处于active状态或者仅主节点active</p>\n</li>\n<li><p>修改<code>timeout</code>：即等待副本恢复活跃状态的超时时间，如果设置为100ms，协调节点只会等待100ms，如果等待100ms后活跃副本数目仍未达到规定数量，则直接进行写操作</p>\n</li>\n</ul>\n<h4 id=\"文档读操作\"><a href=\"#文档读操作\" class=\"headerlink\" title=\"文档读操作\"></a>文档读操作</h4><p>当向es执行读操作获取某个文档时，协调节点会向保存了该文档的任意一个副本分片发起请求：</p>\n<p><img src=\"http://img.mantian.site/201909091005_698.png\" alt></p>\n<p>如图，此时node1是协调节点：</p>\n<ol>\n<li>客户端向node1发起读请求，node1通过<code>_id</code>或者<code>routing</code>字段判断所请求的文档在shard1上</li>\n<li>协调节点node1每次读请求都会通过轮询的方式向一个shard的所有副本发送请求，实现负载均衡，本次请求发往node2的副本R0</li>\n<li>node2将文档返回给node1，最后由node1返回给客户端</li>\n</ol>\n<h4 id=\"多文档更新\"><a href=\"#多文档更新\" class=\"headerlink\" title=\"多文档更新\"></a>多文档更新</h4><p>可以使用<code>mget</code>请求批量获取多个文档，也可以使用<code>bulk</code>请求批量插入或修改多个文档</p>\n<h5 id=\"mget\"><a href=\"#mget\" class=\"headerlink\" title=\"mget\"></a>mget</h5><p><code>mget</code>请求与普通的<code>get</code>读请求原理上是一致的，区别在于<code>mget</code>需要为多个分片构建多文档请求，然后再将这些请求并行转发到各个节点上，最后将结果汇总返回给客户端</p>\n<h5 id=\"bulk\"><a href=\"#bulk\" class=\"headerlink\" title=\"bulk\"></a>bulk</h5><p><code>bulk</code>请求即批量更新请求，一次性修改多个文档</p>\n<p><img src=\"http://img.mantian.site/201909091115_343.png\" alt></p>\n<p>步骤如下：</p>\n<ol>\n<li>node1作为协调节点收到客户端请求</li>\n<li>node1构建针对各个分片的多个批量请求，并行地向shard1的主分片P1（保管于当前协调节点node1）和shard0的主分片P0（node3）发起批量请求</li>\n<li>各个shard的主分片更新并同步完成后，向协调节点报告更新结果，最后协调节点node1将结果收集整理并返还给客户端</li>\n</ol>"},{"title":"ElasticSearch启动配置注意事项","author":"天渊","date":"2019-09-05T03:12:00.000Z","_content":"配置es集群有两个非常重要的选项，这两个选项关系到es集群节点之间互相发现和master选举：<br>\n<!--more-->\n#### discovery.seed_hosts:\n启动es进程后，该进程默认情况下会监听9200和9300两个端口，9200端口作为与外界通信的rest api接口，9300作为es集群节点间进行通信的接口。\n\n如果不对`discovery.seed_hosts`这个选项作配置，es会检测本机9300~9305这个区间内的端口地址，并将其加入到同一个集群内。如果需要手动配置其他集群节点，则需要把所有节点可用的ip地址（或者ip:port）加入到`discovery.seed_hosts`中，该选项默认是`[\"127.0.0.1\", \"[::1]\"]`即只检测本机的9300~9305端口。\n\n例如将本地局域网的三台服务器加入到集群通信中，配置如下：<br>\n\n```yml\ndiscovery.seed_hosts: [\"192.168.0.1:9300\", \"192.168.0.2:9300\", \"192.168.0.3\"]\n```\n注意，`192.168.0.3`这台服务器没有指定端口，则会直接检测9300~9305端口区间\n\n#### cluster.initial_master_nodes:\n只配置`discovery.seed_hosts`还不行，还需要配置`cluster.initial_master_nodes`选项，将检测到的节点加入到选举流程中。这个过程还关系到`node.name`这个选项，只有在每个节点的es配置文件中指定唯一的`node.name`，才能和`cluster.initial_master_nodes`配合工作 （如果不手动指定`node.name`，则默认是节点hostName）：\n\n上述三个节点的`node.name`均已指定：\n\n```yml\ncluster.initial_master_nodes: [\"node-1\", \"node-2\", \"node-3\"]\n```\n\n关于es集群启动过程的细节问题参阅：<br>\n[官网文档：启动es集群](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-bootstrap-cluster.html)<br>\n[elasticsearch初学终极教程: 把Elastic Search在本地跑起来](https://kalasearch.cn/blog/chapter2-run-elastic-search-locally/)","source":"_posts/ElasticSearch启动配置注意事项.md","raw":"title: ElasticSearch启动配置注意事项\nauthor: 天渊\ntags:\n  - elasticsearch\ncategories: []\ndate: 2019-09-05 11:12:00\n---\n配置es集群有两个非常重要的选项，这两个选项关系到es集群节点之间互相发现和master选举：<br>\n<!--more-->\n#### discovery.seed_hosts:\n启动es进程后，该进程默认情况下会监听9200和9300两个端口，9200端口作为与外界通信的rest api接口，9300作为es集群节点间进行通信的接口。\n\n如果不对`discovery.seed_hosts`这个选项作配置，es会检测本机9300~9305这个区间内的端口地址，并将其加入到同一个集群内。如果需要手动配置其他集群节点，则需要把所有节点可用的ip地址（或者ip:port）加入到`discovery.seed_hosts`中，该选项默认是`[\"127.0.0.1\", \"[::1]\"]`即只检测本机的9300~9305端口。\n\n例如将本地局域网的三台服务器加入到集群通信中，配置如下：<br>\n\n```yml\ndiscovery.seed_hosts: [\"192.168.0.1:9300\", \"192.168.0.2:9300\", \"192.168.0.3\"]\n```\n注意，`192.168.0.3`这台服务器没有指定端口，则会直接检测9300~9305端口区间\n\n#### cluster.initial_master_nodes:\n只配置`discovery.seed_hosts`还不行，还需要配置`cluster.initial_master_nodes`选项，将检测到的节点加入到选举流程中。这个过程还关系到`node.name`这个选项，只有在每个节点的es配置文件中指定唯一的`node.name`，才能和`cluster.initial_master_nodes`配合工作 （如果不手动指定`node.name`，则默认是节点hostName）：\n\n上述三个节点的`node.name`均已指定：\n\n```yml\ncluster.initial_master_nodes: [\"node-1\", \"node-2\", \"node-3\"]\n```\n\n关于es集群启动过程的细节问题参阅：<br>\n[官网文档：启动es集群](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-bootstrap-cluster.html)<br>\n[elasticsearch初学终极教程: 把Elastic Search在本地跑起来](https://kalasearch.cn/blog/chapter2-run-elastic-search-locally/)","slug":"ElasticSearch启动配置注意事项","published":1,"updated":"2020-05-24T13:02:29.579Z","_id":"ckf0h31hs000zacts3ghkmnjt","comments":1,"layout":"post","photos":[],"link":"","content":"<p>配置es集群有两个非常重要的选项，这两个选项关系到es集群节点之间互相发现和master选举：<br><br><a id=\"more\"></a></p>\n<h4 id=\"discovery-seed-hosts\"><a href=\"#discovery-seed-hosts\" class=\"headerlink\" title=\"discovery.seed_hosts:\"></a>discovery.seed_hosts:</h4><p>启动es进程后，该进程默认情况下会监听9200和9300两个端口，9200端口作为与外界通信的rest api接口，9300作为es集群节点间进行通信的接口。</p>\n<p>如果不对<code>discovery.seed_hosts</code>这个选项作配置，es会检测本机9300~9305这个区间内的端口地址，并将其加入到同一个集群内。如果需要手动配置其他集群节点，则需要把所有节点可用的ip地址（或者ip:port）加入到<code>discovery.seed_hosts</code>中，该选项默认是<code>[&quot;127.0.0.1&quot;, &quot;[::1]&quot;]</code>即只检测本机的9300~9305端口。</p>\n<p>例如将本地局域网的三台服务器加入到集群通信中，配置如下：<br></p>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">discovery.seed_hosts:</span> <span class=\"string\">[\"192.168.0.1:9300\",</span> <span class=\"string\">\"192.168.0.2:9300\"</span><span class=\"string\">,</span> <span class=\"string\">\"192.168.0.3\"</span><span class=\"string\">]</span></span><br></pre></td></tr></table></figure>\n<p>注意，<code>192.168.0.3</code>这台服务器没有指定端口，则会直接检测9300~9305端口区间</p>\n<h4 id=\"cluster-initial-master-nodes\"><a href=\"#cluster-initial-master-nodes\" class=\"headerlink\" title=\"cluster.initial_master_nodes:\"></a>cluster.initial_master_nodes:</h4><p>只配置<code>discovery.seed_hosts</code>还不行，还需要配置<code>cluster.initial_master_nodes</code>选项，将检测到的节点加入到选举流程中。这个过程还关系到<code>node.name</code>这个选项，只有在每个节点的es配置文件中指定唯一的<code>node.name</code>，才能和<code>cluster.initial_master_nodes</code>配合工作 （如果不手动指定<code>node.name</code>，则默认是节点hostName）：</p>\n<p>上述三个节点的<code>node.name</code>均已指定：</p>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">cluster.initial_master_nodes:</span> <span class=\"string\">[\"node-1\",</span> <span class=\"string\">\"node-2\"</span><span class=\"string\">,</span> <span class=\"string\">\"node-3\"</span><span class=\"string\">]</span></span><br></pre></td></tr></table></figure>\n<p>关于es集群启动过程的细节问题参阅：<br><br><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-bootstrap-cluster.html\" target=\"_blank\" rel=\"noopener\">官网文档：启动es集群</a><br><br><a href=\"https://kalasearch.cn/blog/chapter2-run-elastic-search-locally/\" target=\"_blank\" rel=\"noopener\">elasticsearch初学终极教程: 把Elastic Search在本地跑起来</a></p>\n","site":{"data":{}},"excerpt":"<p>配置es集群有两个非常重要的选项，这两个选项关系到es集群节点之间互相发现和master选举：<br><br>","more":"</p>\n<h4 id=\"discovery-seed-hosts\"><a href=\"#discovery-seed-hosts\" class=\"headerlink\" title=\"discovery.seed_hosts:\"></a>discovery.seed_hosts:</h4><p>启动es进程后，该进程默认情况下会监听9200和9300两个端口，9200端口作为与外界通信的rest api接口，9300作为es集群节点间进行通信的接口。</p>\n<p>如果不对<code>discovery.seed_hosts</code>这个选项作配置，es会检测本机9300~9305这个区间内的端口地址，并将其加入到同一个集群内。如果需要手动配置其他集群节点，则需要把所有节点可用的ip地址（或者ip:port）加入到<code>discovery.seed_hosts</code>中，该选项默认是<code>[&quot;127.0.0.1&quot;, &quot;[::1]&quot;]</code>即只检测本机的9300~9305端口。</p>\n<p>例如将本地局域网的三台服务器加入到集群通信中，配置如下：<br></p>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">discovery.seed_hosts:</span> <span class=\"string\">[\"192.168.0.1:9300\",</span> <span class=\"string\">\"192.168.0.2:9300\"</span><span class=\"string\">,</span> <span class=\"string\">\"192.168.0.3\"</span><span class=\"string\">]</span></span><br></pre></td></tr></table></figure>\n<p>注意，<code>192.168.0.3</code>这台服务器没有指定端口，则会直接检测9300~9305端口区间</p>\n<h4 id=\"cluster-initial-master-nodes\"><a href=\"#cluster-initial-master-nodes\" class=\"headerlink\" title=\"cluster.initial_master_nodes:\"></a>cluster.initial_master_nodes:</h4><p>只配置<code>discovery.seed_hosts</code>还不行，还需要配置<code>cluster.initial_master_nodes</code>选项，将检测到的节点加入到选举流程中。这个过程还关系到<code>node.name</code>这个选项，只有在每个节点的es配置文件中指定唯一的<code>node.name</code>，才能和<code>cluster.initial_master_nodes</code>配合工作 （如果不手动指定<code>node.name</code>，则默认是节点hostName）：</p>\n<p>上述三个节点的<code>node.name</code>均已指定：</p>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">cluster.initial_master_nodes:</span> <span class=\"string\">[\"node-1\",</span> <span class=\"string\">\"node-2\"</span><span class=\"string\">,</span> <span class=\"string\">\"node-3\"</span><span class=\"string\">]</span></span><br></pre></td></tr></table></figure>\n<p>关于es集群启动过程的细节问题参阅：<br><br><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-bootstrap-cluster.html\" target=\"_blank\" rel=\"noopener\">官网文档：启动es集群</a><br><br><a href=\"https://kalasearch.cn/blog/chapter2-run-elastic-search-locally/\" target=\"_blank\" rel=\"noopener\">elasticsearch初学终极教程: 把Elastic Search在本地跑起来</a></p>"},{"title":"java线程池源码分析 --- submit()的过程","author":"天渊hyominnLover","date":"2019-01-23T05:49:00.000Z","_content":"在jdk线程池中，`submit()`是`ExecutorService`的基础api，用于提交新任务给线程池进行执行，现对`submit()`执行过程一探究竟，这里主要对`AbstractExecutorService`及其子类`ThreadPoolExecutor`的实现进行讨论。\n<!-- more -->\n### submit()\n\njdk 8中，submit()有三个重载，分别是：\n\n```JAVA\n<T> Future<T> submit(Callable<T> task);\n<T> Future<T> submit(Runnable task, T result);\nFuture<?> submit(Runnable task);\n```\n\n三者大同小异，最终都会返回`Future`对象来获取异步执行结果，即便传进来的是Runnable对象，也会包装为Callable进行执行，下面仅探讨第一个重载，源码如下：\n\n```JAVA\npublic <T> Future<T> submit(Callable<T> task) {\n    if (task == null) throw new NullPointerException();\n    RunnableFuture<T> ftask = newTaskFor(task);\n    execute(ftask);\n    return ftask;\n}\n```\n\n任务提交进来后，调用`newTaskFor`方法构建了一个`RunnableFuture`对象，最终会调用`execute`方法提交这个RunnableFuture，其实`RunnableFuture`是一个同时继承了`Runnable`和`Future`的接口，同时具有这两者的功能，在`submit()`中构建的是其实现类：`FutureTask`：\n\n```JAVA\npublic FutureTask(Callable<V> callable) {\n    if (callable == null)\n        throw new NullPointerException();\n    this.callable = callable;\n    this.state = NEW;       // ensure visibility of callable\n}\n```\n\n这个对象是线程池的主要操作对象，是客户提交的任务的执行载体，其中封装了客户提交的callable (Runnable)任务\n\n任务提交进来后会统一交给`execute()`方法进行执行，这个方法`AbstractExecutorService`交给了子类去实现\n\n### execute()\n\n在`ThreadPoolExecutor`中，源码如下：\n\n```JAVA\npublic void execute(Runnable command) {\n    if (command == null)\n        throw new NullPointerException();\n    // 获取ctl值，ctl对同时对线程池的两个状态进行控制：\n    // 1. 当前线程池状态 2. 存活的工作线程总数（即worker数）\n    int c = ctl.get();\n    // 通过ctl获取当前工作线程数目\n    if (workerCountOf(c) < corePoolSize) {\n        // 如果小于核心线程数则增加worker，增加并提交任务成功则直接返回\n        // 本次使用核心线程数来判断worker能否增加成功\n        if (addWorker(command, true))\n            return;\n        // 增加失败，继续获取当前ctl值\n        c = ctl.get();\n    }\n    // 检查当前线程池状态是否为RUNNING，并向workQueue缓存当前任务\n    if (isRunning(c) && workQueue.offer(command)) {\n        int recheck = ctl.get();\n        // 如果当前状态不为RUNNING，尝试从workQueue移除本次任务\n        // 移除成功后执行拒绝策略\n        if (! isRunning(recheck) && remove(command))\n            reject(command);\n        // 如果当前存活worker总数为0则继续尝试增加worker\n        else if (workerCountOf(recheck) == 0)\n            // 第二个参数为false，说明本次使用最大线程数来判断worker能否增加成功\n            addWorker(null, false);\n    }\n    // 若当前状态不为RUNNING或者向workQueue缓存当前任务失败，则尝试增加worker\n    // 若增加worker失败（通常为已达到最大线程数）\n    else if (!addWorker(command, false))\n        reject(command);\n}\n```\n\n整个execute()的过程很复杂，涉及到线程池中各组件比较复杂的交互过程，参考官方注释的说法，整个过程分为三步：\n\n1. 如果worker数量少于**核心线程数**，则尝试增加worker并把当前任务作为新worker的firstTask并执行\n2. 如果以上路线走不通，则尝试向`workqueue`缓存任务，待空闲的worker取任务，在这个过程中对ctl进行双重检查，防止ctl出现不一致（因为以上过程中并没有做同步处理），如果ctl状态不为RUNNING则将刚才的任务弹出workqueue并执行拒绝策略；若成功缓存任务后，且当前worker数为0，则尝试继续增加worker，用**最大线程数**来判断worker能否增加成功\n3. 如果第2步走不通（比如状态非RUNNING或者缓存任务失败），尝试继续增加worker，用**最大线程数**来判断worker能否增加成功，如果这一步都走不通，那直接进行拒绝策略，整个过程结束\n\n可以看出，整个过程非常依赖`addWorker`这个方法，主要用于新建worker并且提交firstTask，该方法执行成功与否直接关系到整个流程的走向，以下情况会导致增加worker失败：\n\n`状态为Stop、Tidying或者Terminate`\n\n`状态为Shutdown，提交任务为null并且workqueue为空`\n\n`达到核心线程数或者最大线程数，或最大容量限制(2的29次方减1)`\n\n`创建新worker时出现其他异常`\n\n### addWorker\n\n`addWorker`是整个任务提交过程中最重要的方法，以下是源码：\n\n```JAVA\nprivate boolean addWorker(Runnable firstTask, boolean core) {\n    retry:\n    for (;;) {\n        int c = ctl.get();\n        int rs = runStateOf(c);\n        // 以下条件判断能否增加worker\n        if (rs >= SHUTDOWN &&\n            ! (rs == SHUTDOWN &&\n               firstTask == null &&\n               ! workQueue.isEmpty()))\n            return false;\n\t\t// 内嵌循环，\n        // 每一次循环都要重新判断worker数目，worker达到数量限制则直接返回false\n        for (;;) {\n            int wc = workerCountOf(c);\n            if (wc >= CAPACITY ||\n                wc >= (core ? corePoolSize : maximumPoolSize))\n                return false;\n            // cas方式增加worker数目，成功后直接退出外层循环\n            if (compareAndIncrementWorkerCount(c))\n                break retry;\n            c = ctl.get();  // Re-read ctl\n            // 若内嵌循环过程中状态改变，则推出内嵌循环开始外层循环\n            if (runStateOf(c) != rs)\n                continue retry;\n            // 如果仅仅是因为worker数目改变导致cas失败，则仅进行内嵌循环\n            // 不需要进行外层循环重新获取ctl状态\n        }\n    }\n\n    boolean workerStarted = false;\n    boolean workerAdded = false;\n    Worker w = null;\n    try {\n        // 新建worker对象并将任务作为其firstTask\n        w = new Worker(firstTask);\n        final Thread t = w.thread;\n        if (t != null) {\n            // 同步操作\n            final ReentrantLock mainLock = this.mainLock;\n            mainLock.lock();\n            try {\n                // 重新获取ctl状态\n                int rs = runStateOf(ctl.get());\n\t\t\t\t// 仅当状态为RUNNING或者为SHUTDOWN时提交的任务是null，才继续执行\n                if (rs < SHUTDOWN ||\n                    (rs == SHUTDOWN && firstTask == null)) {\n                    // 若该worker线程已经启动则抛出异常\n                    if (t.isAlive())\n                        throw new IllegalThreadStateException();\n                    workers.add(w);\n                    int s = workers.size();\n                    // 增加largestPoolSize，仅作为统计用处\n                    if (s > largestPoolSize)\n                        largestPoolSize = s;\n                    workerAdded = true;\n                }\n            } finally {\n                mainLock.unlock();\n            }\n            if (workerAdded) {\n                // 若增加worker成功则启动其线程，执行的是Worker对象的run方法\n                t.start();\n                workerStarted = true;\n            }\n        }\n    } finally {\n        if (! workerStarted)\n            addWorkerFailed(w);\n    }\n    return workerStarted;\n}\n```\n\n该方法第一部分的for循环略微有些绕，总的说来就是对线程池状态有可能随时变化作出的双重保障，内层循环服务于增加worker数目的cas操作，外层循环在此基础上加上了对ctl状态的重新获取及判断。\n\n可以看出，整个submit过程离不开对线程池ctl状态的多次核查，保证了线程池的顺利运行，接下来对worker启动后做的工作进行简要分析\n\n### Worker\n\nWorker类继承了Runnable以及`AQS(AbstractQueuedSynchronizer)`，在他的run方法中调用了线程池对象的`runWorker`方法：\n\n```JAVA\nfinal void runWorker(Worker w) {\n    Thread wt = Thread.currentThread();\n    // 这个task变量很重要，是worker本次执行中的主要执行对象\n    // 首先将worker的firstTask赋值给他\n    // 赋值完后将worker的firstTask置为null\n    Runnable task = w.firstTask;\n    w.firstTask = null;\n    w.unlock(); // allow interrupts\n    boolean completedAbruptly = true;\n    try {\n        // 进入循环，执行任务，如果任务为null则从workqueue里面取\n        while (task != null || (task = getTask()) != null) {\n            // 对当前worker执行同步\n            w.lock();\n            // 如果当前worker线程未被打断，且状态为STOP及其以上（Tyding或者terminated），\n            // 则将当前worker线程中断\n            if ((runStateAtLeast(ctl.get(), STOP) ||\n                 (Thread.interrupted() &&\n                  runStateAtLeast(ctl.get(), STOP))) &&\n                !wt.isInterrupted())\n                wt.interrupt();\n            try {\n                // 执行前预处理，留给子类定制，通常用来对资源进行初始化，或者打印日志\n                beforeExecute(wt, task);\n                Throwable thrown = null;\n                try {\n                    // 真正执行任务\n                    task.run();\n                } catch (RuntimeException x) {\n                    thrown = x; throw x;\n                } catch (Error x) {\n                    thrown = x; throw x;\n                } catch (Throwable x) {\n                    thrown = x; throw new Error(x);\n                } finally {\n                    // 跟beforeExecute类似，也是执行资源释放或打印错误日志\n                    afterExecute(task, thrown);\n                }\n            } finally {\n                // 将task重置为null\n                task = null;\n                // 统计当前worker的执行任务数目\n                w.completedTasks++;\n                // 释放worker同步\n                w.unlock();\n            }\n        }\n        // 如果推出了该循环，则将completedAbruptly参数置为false\n        completedAbruptly = false;\n    } finally {\n        // 执行worker退出操作\n        processWorkerExit(w, completedAbruptly);\n    }\n}\n```\n\n整个过程大致分为以下几个步骤\n\n1. 初始化，将firstTask作为初始任务\n2. worker执行unlock()，调整AQS状态使其可以被打断\n3. 进入循环，执行任务，如果任务为null则从workqueue里面取：`task = getTask()`\n4. 判断是否需要将当前worker打断，满足条件则interrupt该worker的线程\n5. 执行任务\n6. worker循环执行任务，直到无任务可以执行，则正常退出循环，将completedAbruptly置为false；又或者执行了打断线程操作等原因抛出了异常，属于非正常推出循环，这时候completedAbruptly仍为true\n7. 执行worker退出操作\n\n其中最重要的两项操作分别是`getTask()`和`processWorkerExit(w, completedAbruptly)`，worker会持续尝试从`workQueue`中拿任务，worker拿不到任务或者非正常退出时则会执行退出操作，退出操作也比较重要，直接决定接下来线程池中是否保留以及保留多少个worker，现在对`getTask()`进行分析\n\n### getTask()\n\n源码如下：\n\n```JAVA\nprivate Runnable getTask() {\n    boolean timedOut = false; // 判断poll()获取任务的过程是否超时\n    for (;;) {\n        int c = ctl.get();\n        int rs = runStateOf(c);\n        // 若状态不为Running，并且workQueue为空或者状态为Stop，表明已经不需要执行任何任务了\n        // 这时会直接减少workerCount并直接返回null，本次getTask提前结束\n        if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {\n            decrementWorkerCount();\n            return null;\n        }\n        // 重新计算workerCount\n        int wc = workerCountOf(c);\n        // Are workers subject to culling?\n        // 官方注释的意思是，用timer参数标记当前worker是否需要保留，timed为true则不需要保留\n        boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;\n        // 如果workQueue为空或者workerCount大于1，有两种情况当前worker不需要保留：\n        // 1. workerCount已经超出了最大线程数\n        // 2. 获取任务超时并且不需要保留为核心线程\n        if ((wc > maximumPoolSize || (timed && timedOut))\n            && (wc > 1 || workQueue.isEmpty())) {\n            // cas方式减少workerCount，如果cas失败则循环重试\n            if (compareAndDecrementWorkerCount(c))\n                return null;\n            continue;\n        }\n        try {\n            // 从workQueue取任务，根据timed不同又分为两种情况\n            // 1. timed为true，当前worker在keepAliveTime时间内拿不到任务则会被抛弃\n            // 2. timed为false，则当前worker作为核心线程保留下来并尝试拿任务\n            // 由于workQueue是BlockingQueue，所以执行take()拿不到任务的话会阻塞直到队列中有任务可用\n            // take()和poll()的过程都是可以被interrupt的\n            Runnable r = timed ?\n                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :\n            workQueue.take();\n            // 如果拿到任务后会返回，拿不到任务则将timedOut标记为true\n            if (r != null)\n                return r;\n            // 拿不到任务，说明poll()超时了\n            timedOut = true;\n        } catch (InterruptedException retry) {\n            // 说明拿任务的过程被interrupt了，将timedOut标记为false\n            // 表明并不是因为poll()超时而获取不了任务\n            timedOut = false;\n        }\n    }\n}\n```\n\n`getTask()`成功与否直接关系到该worker是否会被抛弃，其中，`timed`这个boolean变量对worker是否需要保留为核心线程进行标记，还涉及到`allowCoreThreadTimeOut`这个属性，分为两种情况：\n\n`allowCoreThreadTimeOut为false`：默认情况，线程池种会保留`corePoolSize`数量的线程作为核心线程，从上述代码种可以看出，只要当前workerCount不大于corePoolSize，那该worker就可以作为核心线程保留下来，取任务时调用`workQueue.take()`，持续阻塞直到有任务可以执行\n\n`allowCoreThreadTimeOut为true`：需要手动调用`allowCoreThreadTimeOut(boolean value)`方法进行设置，这种情况下线程池不会保留核心线程，所有worker在取任务时均会调用`workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS)`方法，在`keepAliveTime`时间后若还未取到任务则会被抛弃\n\n以下几种情况会导致getTask方法返回null，即该worker无任务可以执行，将被抛弃：\n\n1. 线程池状态不为Running，并且workQueue为空\n2. 线程池状态为Stop\n3. 线程池状态为Running，workQueue为空，并且workerCount已经超出了最大线程数\n4. 线程池状态为Running，workQueue为空，获取任务超时并且当前worker不需要保留为核心线程\n\n整个流程走下来，以上4种情况下该worker会被抛弃，进行下面的退出操作`processWorkerExit`，这种情况worker均为正常退出，`completedAbruptly`为false\n\n### processWorkerExit\n\nprocessWorkerExit源码如下：\n\n```JAVA\nprivate void processWorkerExit(Worker w, boolean completedAbruptly) {\n    // 如果worker是非正常退出任务执行循环，则减少workerCount\n    // 若是正常退出，则worker在getTask获取任务失败退出后已经减少了workerCount，可以正常移除该worker了\n    if (completedAbruptly)\n        decrementWorkerCount();\n    final ReentrantLock mainLock = this.mainLock;\n    mainLock.lock();\n    try {\n        completedTaskCount += w.completedTasks;\n        // 移除worker\n        workers.remove(w);\n    } finally {\n        mainLock.unlock();\n    }\n    // 尝试执行终止操作\n    tryTerminate();\n    int c = ctl.get();\n    // 如果当前状态为Running或者Shutdown，则执行以下流程\n    if (runStateLessThan(c, STOP)) {\n        // 若worker为正常退出任务执行循环，则需要额外判断是否需要新增worker\n        // 分两种情况：\n        // 1. 若需要将核心线程在一定闲置时间后被移除，则当前worker最多保留一个\n        // 2. 如果不需要将核心线程闲置一段时间后移除，则可以保留不超过核心线程数的worker\n        if (!completedAbruptly) {\n            int min = allowCoreThreadTimeOut ? 0 : corePoolSize;\n            if (min == 0 && ! workQueue.isEmpty())\n                min = 1;\n            // 如果worker已经够用了就不用addWorker了\n            if (workerCountOf(c) >= min)\n                return; // replacement not needed\n        }\n        // 执行以上判断后依然需要增加worker的话就调用addWorker，不传入任何task\n        addWorker(null, false);\n    }\n}\n```\n\n逻辑相对比较复杂，总结来说，根据`completedAbruptly`参数将退出操作分为两条路线：\n\n`正常退出任务执行循环：`\n\n1. 不需要减少worker数目\n2. 将当前worker移除，并尝试执行终止操作\n3. 如果当前状态为`Running`或者`Shutdown`，表示如果`workQueue`里面还有任务要执行的话，是需要继续执行的，那么接下来尝试新增worker\n4. 计算当前需要保留的worker数目（min变量），如果`workerCount`已经满足需求则不额外增加worker了（这里依然使用`allowCoreThreadTimeOut`判断是否保留一定数量的核心线程，如果为true，则worker最多保留一个），直接退出\n5. 如果`workerCount`数目不满足需求，则新增一个worker然后让他去`workQueue`里面取任务执行\n\n`非正常退出任务执行循环`\n\n1. 减少worker数目\n2. 移除当前worker并尝试执行终止操作，如果当前状态为`Running`或者`Shutdown`，则直接新增worker\n\n至于为什么将worker退出操作分为正常和非正常，我是这么理解的：\n\n`正常退出`：说明worker调用`getTask()`没有成功取到任务，将被抛弃，`getTask`方法已经对`workCount`进行了扣减，这里就不需要对`workerCount`作任何变动，此外需要判断当前`workerCount`数目够不够\n\n`非正常退出`：这种情况下需要对`workerCount`进行扣减并立即补充一个worker，当然如果当前状态为`Stop`或者`Tyding`甚至`Terminated`的话就没必要补充了","source":"_posts/java线程池源码分析--submit-的过程.md","raw":"title: java线程池源码分析 --- submit()的过程\nauthor: 天渊hyominnLover\ntags:\n\n  - Java\n  - 多线程\n  - Java并发包\ncategories: [基础知识]\ndate: 2019-01-23 13:49:00\n---\n在jdk线程池中，`submit()`是`ExecutorService`的基础api，用于提交新任务给线程池进行执行，现对`submit()`执行过程一探究竟，这里主要对`AbstractExecutorService`及其子类`ThreadPoolExecutor`的实现进行讨论。\n<!-- more -->\n### submit()\n\njdk 8中，submit()有三个重载，分别是：\n\n```JAVA\n<T> Future<T> submit(Callable<T> task);\n<T> Future<T> submit(Runnable task, T result);\nFuture<?> submit(Runnable task);\n```\n\n三者大同小异，最终都会返回`Future`对象来获取异步执行结果，即便传进来的是Runnable对象，也会包装为Callable进行执行，下面仅探讨第一个重载，源码如下：\n\n```JAVA\npublic <T> Future<T> submit(Callable<T> task) {\n    if (task == null) throw new NullPointerException();\n    RunnableFuture<T> ftask = newTaskFor(task);\n    execute(ftask);\n    return ftask;\n}\n```\n\n任务提交进来后，调用`newTaskFor`方法构建了一个`RunnableFuture`对象，最终会调用`execute`方法提交这个RunnableFuture，其实`RunnableFuture`是一个同时继承了`Runnable`和`Future`的接口，同时具有这两者的功能，在`submit()`中构建的是其实现类：`FutureTask`：\n\n```JAVA\npublic FutureTask(Callable<V> callable) {\n    if (callable == null)\n        throw new NullPointerException();\n    this.callable = callable;\n    this.state = NEW;       // ensure visibility of callable\n}\n```\n\n这个对象是线程池的主要操作对象，是客户提交的任务的执行载体，其中封装了客户提交的callable (Runnable)任务\n\n任务提交进来后会统一交给`execute()`方法进行执行，这个方法`AbstractExecutorService`交给了子类去实现\n\n### execute()\n\n在`ThreadPoolExecutor`中，源码如下：\n\n```JAVA\npublic void execute(Runnable command) {\n    if (command == null)\n        throw new NullPointerException();\n    // 获取ctl值，ctl对同时对线程池的两个状态进行控制：\n    // 1. 当前线程池状态 2. 存活的工作线程总数（即worker数）\n    int c = ctl.get();\n    // 通过ctl获取当前工作线程数目\n    if (workerCountOf(c) < corePoolSize) {\n        // 如果小于核心线程数则增加worker，增加并提交任务成功则直接返回\n        // 本次使用核心线程数来判断worker能否增加成功\n        if (addWorker(command, true))\n            return;\n        // 增加失败，继续获取当前ctl值\n        c = ctl.get();\n    }\n    // 检查当前线程池状态是否为RUNNING，并向workQueue缓存当前任务\n    if (isRunning(c) && workQueue.offer(command)) {\n        int recheck = ctl.get();\n        // 如果当前状态不为RUNNING，尝试从workQueue移除本次任务\n        // 移除成功后执行拒绝策略\n        if (! isRunning(recheck) && remove(command))\n            reject(command);\n        // 如果当前存活worker总数为0则继续尝试增加worker\n        else if (workerCountOf(recheck) == 0)\n            // 第二个参数为false，说明本次使用最大线程数来判断worker能否增加成功\n            addWorker(null, false);\n    }\n    // 若当前状态不为RUNNING或者向workQueue缓存当前任务失败，则尝试增加worker\n    // 若增加worker失败（通常为已达到最大线程数）\n    else if (!addWorker(command, false))\n        reject(command);\n}\n```\n\n整个execute()的过程很复杂，涉及到线程池中各组件比较复杂的交互过程，参考官方注释的说法，整个过程分为三步：\n\n1. 如果worker数量少于**核心线程数**，则尝试增加worker并把当前任务作为新worker的firstTask并执行\n2. 如果以上路线走不通，则尝试向`workqueue`缓存任务，待空闲的worker取任务，在这个过程中对ctl进行双重检查，防止ctl出现不一致（因为以上过程中并没有做同步处理），如果ctl状态不为RUNNING则将刚才的任务弹出workqueue并执行拒绝策略；若成功缓存任务后，且当前worker数为0，则尝试继续增加worker，用**最大线程数**来判断worker能否增加成功\n3. 如果第2步走不通（比如状态非RUNNING或者缓存任务失败），尝试继续增加worker，用**最大线程数**来判断worker能否增加成功，如果这一步都走不通，那直接进行拒绝策略，整个过程结束\n\n可以看出，整个过程非常依赖`addWorker`这个方法，主要用于新建worker并且提交firstTask，该方法执行成功与否直接关系到整个流程的走向，以下情况会导致增加worker失败：\n\n`状态为Stop、Tidying或者Terminate`\n\n`状态为Shutdown，提交任务为null并且workqueue为空`\n\n`达到核心线程数或者最大线程数，或最大容量限制(2的29次方减1)`\n\n`创建新worker时出现其他异常`\n\n### addWorker\n\n`addWorker`是整个任务提交过程中最重要的方法，以下是源码：\n\n```JAVA\nprivate boolean addWorker(Runnable firstTask, boolean core) {\n    retry:\n    for (;;) {\n        int c = ctl.get();\n        int rs = runStateOf(c);\n        // 以下条件判断能否增加worker\n        if (rs >= SHUTDOWN &&\n            ! (rs == SHUTDOWN &&\n               firstTask == null &&\n               ! workQueue.isEmpty()))\n            return false;\n\t\t// 内嵌循环，\n        // 每一次循环都要重新判断worker数目，worker达到数量限制则直接返回false\n        for (;;) {\n            int wc = workerCountOf(c);\n            if (wc >= CAPACITY ||\n                wc >= (core ? corePoolSize : maximumPoolSize))\n                return false;\n            // cas方式增加worker数目，成功后直接退出外层循环\n            if (compareAndIncrementWorkerCount(c))\n                break retry;\n            c = ctl.get();  // Re-read ctl\n            // 若内嵌循环过程中状态改变，则推出内嵌循环开始外层循环\n            if (runStateOf(c) != rs)\n                continue retry;\n            // 如果仅仅是因为worker数目改变导致cas失败，则仅进行内嵌循环\n            // 不需要进行外层循环重新获取ctl状态\n        }\n    }\n\n    boolean workerStarted = false;\n    boolean workerAdded = false;\n    Worker w = null;\n    try {\n        // 新建worker对象并将任务作为其firstTask\n        w = new Worker(firstTask);\n        final Thread t = w.thread;\n        if (t != null) {\n            // 同步操作\n            final ReentrantLock mainLock = this.mainLock;\n            mainLock.lock();\n            try {\n                // 重新获取ctl状态\n                int rs = runStateOf(ctl.get());\n\t\t\t\t// 仅当状态为RUNNING或者为SHUTDOWN时提交的任务是null，才继续执行\n                if (rs < SHUTDOWN ||\n                    (rs == SHUTDOWN && firstTask == null)) {\n                    // 若该worker线程已经启动则抛出异常\n                    if (t.isAlive())\n                        throw new IllegalThreadStateException();\n                    workers.add(w);\n                    int s = workers.size();\n                    // 增加largestPoolSize，仅作为统计用处\n                    if (s > largestPoolSize)\n                        largestPoolSize = s;\n                    workerAdded = true;\n                }\n            } finally {\n                mainLock.unlock();\n            }\n            if (workerAdded) {\n                // 若增加worker成功则启动其线程，执行的是Worker对象的run方法\n                t.start();\n                workerStarted = true;\n            }\n        }\n    } finally {\n        if (! workerStarted)\n            addWorkerFailed(w);\n    }\n    return workerStarted;\n}\n```\n\n该方法第一部分的for循环略微有些绕，总的说来就是对线程池状态有可能随时变化作出的双重保障，内层循环服务于增加worker数目的cas操作，外层循环在此基础上加上了对ctl状态的重新获取及判断。\n\n可以看出，整个submit过程离不开对线程池ctl状态的多次核查，保证了线程池的顺利运行，接下来对worker启动后做的工作进行简要分析\n\n### Worker\n\nWorker类继承了Runnable以及`AQS(AbstractQueuedSynchronizer)`，在他的run方法中调用了线程池对象的`runWorker`方法：\n\n```JAVA\nfinal void runWorker(Worker w) {\n    Thread wt = Thread.currentThread();\n    // 这个task变量很重要，是worker本次执行中的主要执行对象\n    // 首先将worker的firstTask赋值给他\n    // 赋值完后将worker的firstTask置为null\n    Runnable task = w.firstTask;\n    w.firstTask = null;\n    w.unlock(); // allow interrupts\n    boolean completedAbruptly = true;\n    try {\n        // 进入循环，执行任务，如果任务为null则从workqueue里面取\n        while (task != null || (task = getTask()) != null) {\n            // 对当前worker执行同步\n            w.lock();\n            // 如果当前worker线程未被打断，且状态为STOP及其以上（Tyding或者terminated），\n            // 则将当前worker线程中断\n            if ((runStateAtLeast(ctl.get(), STOP) ||\n                 (Thread.interrupted() &&\n                  runStateAtLeast(ctl.get(), STOP))) &&\n                !wt.isInterrupted())\n                wt.interrupt();\n            try {\n                // 执行前预处理，留给子类定制，通常用来对资源进行初始化，或者打印日志\n                beforeExecute(wt, task);\n                Throwable thrown = null;\n                try {\n                    // 真正执行任务\n                    task.run();\n                } catch (RuntimeException x) {\n                    thrown = x; throw x;\n                } catch (Error x) {\n                    thrown = x; throw x;\n                } catch (Throwable x) {\n                    thrown = x; throw new Error(x);\n                } finally {\n                    // 跟beforeExecute类似，也是执行资源释放或打印错误日志\n                    afterExecute(task, thrown);\n                }\n            } finally {\n                // 将task重置为null\n                task = null;\n                // 统计当前worker的执行任务数目\n                w.completedTasks++;\n                // 释放worker同步\n                w.unlock();\n            }\n        }\n        // 如果推出了该循环，则将completedAbruptly参数置为false\n        completedAbruptly = false;\n    } finally {\n        // 执行worker退出操作\n        processWorkerExit(w, completedAbruptly);\n    }\n}\n```\n\n整个过程大致分为以下几个步骤\n\n1. 初始化，将firstTask作为初始任务\n2. worker执行unlock()，调整AQS状态使其可以被打断\n3. 进入循环，执行任务，如果任务为null则从workqueue里面取：`task = getTask()`\n4. 判断是否需要将当前worker打断，满足条件则interrupt该worker的线程\n5. 执行任务\n6. worker循环执行任务，直到无任务可以执行，则正常退出循环，将completedAbruptly置为false；又或者执行了打断线程操作等原因抛出了异常，属于非正常推出循环，这时候completedAbruptly仍为true\n7. 执行worker退出操作\n\n其中最重要的两项操作分别是`getTask()`和`processWorkerExit(w, completedAbruptly)`，worker会持续尝试从`workQueue`中拿任务，worker拿不到任务或者非正常退出时则会执行退出操作，退出操作也比较重要，直接决定接下来线程池中是否保留以及保留多少个worker，现在对`getTask()`进行分析\n\n### getTask()\n\n源码如下：\n\n```JAVA\nprivate Runnable getTask() {\n    boolean timedOut = false; // 判断poll()获取任务的过程是否超时\n    for (;;) {\n        int c = ctl.get();\n        int rs = runStateOf(c);\n        // 若状态不为Running，并且workQueue为空或者状态为Stop，表明已经不需要执行任何任务了\n        // 这时会直接减少workerCount并直接返回null，本次getTask提前结束\n        if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {\n            decrementWorkerCount();\n            return null;\n        }\n        // 重新计算workerCount\n        int wc = workerCountOf(c);\n        // Are workers subject to culling?\n        // 官方注释的意思是，用timer参数标记当前worker是否需要保留，timed为true则不需要保留\n        boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;\n        // 如果workQueue为空或者workerCount大于1，有两种情况当前worker不需要保留：\n        // 1. workerCount已经超出了最大线程数\n        // 2. 获取任务超时并且不需要保留为核心线程\n        if ((wc > maximumPoolSize || (timed && timedOut))\n            && (wc > 1 || workQueue.isEmpty())) {\n            // cas方式减少workerCount，如果cas失败则循环重试\n            if (compareAndDecrementWorkerCount(c))\n                return null;\n            continue;\n        }\n        try {\n            // 从workQueue取任务，根据timed不同又分为两种情况\n            // 1. timed为true，当前worker在keepAliveTime时间内拿不到任务则会被抛弃\n            // 2. timed为false，则当前worker作为核心线程保留下来并尝试拿任务\n            // 由于workQueue是BlockingQueue，所以执行take()拿不到任务的话会阻塞直到队列中有任务可用\n            // take()和poll()的过程都是可以被interrupt的\n            Runnable r = timed ?\n                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :\n            workQueue.take();\n            // 如果拿到任务后会返回，拿不到任务则将timedOut标记为true\n            if (r != null)\n                return r;\n            // 拿不到任务，说明poll()超时了\n            timedOut = true;\n        } catch (InterruptedException retry) {\n            // 说明拿任务的过程被interrupt了，将timedOut标记为false\n            // 表明并不是因为poll()超时而获取不了任务\n            timedOut = false;\n        }\n    }\n}\n```\n\n`getTask()`成功与否直接关系到该worker是否会被抛弃，其中，`timed`这个boolean变量对worker是否需要保留为核心线程进行标记，还涉及到`allowCoreThreadTimeOut`这个属性，分为两种情况：\n\n`allowCoreThreadTimeOut为false`：默认情况，线程池种会保留`corePoolSize`数量的线程作为核心线程，从上述代码种可以看出，只要当前workerCount不大于corePoolSize，那该worker就可以作为核心线程保留下来，取任务时调用`workQueue.take()`，持续阻塞直到有任务可以执行\n\n`allowCoreThreadTimeOut为true`：需要手动调用`allowCoreThreadTimeOut(boolean value)`方法进行设置，这种情况下线程池不会保留核心线程，所有worker在取任务时均会调用`workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS)`方法，在`keepAliveTime`时间后若还未取到任务则会被抛弃\n\n以下几种情况会导致getTask方法返回null，即该worker无任务可以执行，将被抛弃：\n\n1. 线程池状态不为Running，并且workQueue为空\n2. 线程池状态为Stop\n3. 线程池状态为Running，workQueue为空，并且workerCount已经超出了最大线程数\n4. 线程池状态为Running，workQueue为空，获取任务超时并且当前worker不需要保留为核心线程\n\n整个流程走下来，以上4种情况下该worker会被抛弃，进行下面的退出操作`processWorkerExit`，这种情况worker均为正常退出，`completedAbruptly`为false\n\n### processWorkerExit\n\nprocessWorkerExit源码如下：\n\n```JAVA\nprivate void processWorkerExit(Worker w, boolean completedAbruptly) {\n    // 如果worker是非正常退出任务执行循环，则减少workerCount\n    // 若是正常退出，则worker在getTask获取任务失败退出后已经减少了workerCount，可以正常移除该worker了\n    if (completedAbruptly)\n        decrementWorkerCount();\n    final ReentrantLock mainLock = this.mainLock;\n    mainLock.lock();\n    try {\n        completedTaskCount += w.completedTasks;\n        // 移除worker\n        workers.remove(w);\n    } finally {\n        mainLock.unlock();\n    }\n    // 尝试执行终止操作\n    tryTerminate();\n    int c = ctl.get();\n    // 如果当前状态为Running或者Shutdown，则执行以下流程\n    if (runStateLessThan(c, STOP)) {\n        // 若worker为正常退出任务执行循环，则需要额外判断是否需要新增worker\n        // 分两种情况：\n        // 1. 若需要将核心线程在一定闲置时间后被移除，则当前worker最多保留一个\n        // 2. 如果不需要将核心线程闲置一段时间后移除，则可以保留不超过核心线程数的worker\n        if (!completedAbruptly) {\n            int min = allowCoreThreadTimeOut ? 0 : corePoolSize;\n            if (min == 0 && ! workQueue.isEmpty())\n                min = 1;\n            // 如果worker已经够用了就不用addWorker了\n            if (workerCountOf(c) >= min)\n                return; // replacement not needed\n        }\n        // 执行以上判断后依然需要增加worker的话就调用addWorker，不传入任何task\n        addWorker(null, false);\n    }\n}\n```\n\n逻辑相对比较复杂，总结来说，根据`completedAbruptly`参数将退出操作分为两条路线：\n\n`正常退出任务执行循环：`\n\n1. 不需要减少worker数目\n2. 将当前worker移除，并尝试执行终止操作\n3. 如果当前状态为`Running`或者`Shutdown`，表示如果`workQueue`里面还有任务要执行的话，是需要继续执行的，那么接下来尝试新增worker\n4. 计算当前需要保留的worker数目（min变量），如果`workerCount`已经满足需求则不额外增加worker了（这里依然使用`allowCoreThreadTimeOut`判断是否保留一定数量的核心线程，如果为true，则worker最多保留一个），直接退出\n5. 如果`workerCount`数目不满足需求，则新增一个worker然后让他去`workQueue`里面取任务执行\n\n`非正常退出任务执行循环`\n\n1. 减少worker数目\n2. 移除当前worker并尝试执行终止操作，如果当前状态为`Running`或者`Shutdown`，则直接新增worker\n\n至于为什么将worker退出操作分为正常和非正常，我是这么理解的：\n\n`正常退出`：说明worker调用`getTask()`没有成功取到任务，将被抛弃，`getTask`方法已经对`workCount`进行了扣减，这里就不需要对`workerCount`作任何变动，此外需要判断当前`workerCount`数目够不够\n\n`非正常退出`：这种情况下需要对`workerCount`进行扣减并立即补充一个worker，当然如果当前状态为`Stop`或者`Tyding`甚至`Terminated`的话就没必要补充了","slug":"java线程池源码分析--submit-的过程","published":1,"updated":"2021-05-31T03:06:33.197Z","_id":"ckf0h31ht0012actscz3mdswv","comments":1,"layout":"post","photos":[],"link":"","content":"<p>在jdk线程池中，<code>submit()</code>是<code>ExecutorService</code>的基础api，用于提交新任务给线程池进行执行，现对<code>submit()</code>执行过程一探究竟，这里主要对<code>AbstractExecutorService</code>及其子类<code>ThreadPoolExecutor</code>的实现进行讨论。<br><a id=\"more\"></a></p>\n<h3 id=\"submit\"><a href=\"#submit\" class=\"headerlink\" title=\"submit()\"></a>submit()</h3><p>jdk 8中，submit()有三个重载，分别是：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;T&gt; <span class=\"function\">Future&lt;T&gt; <span class=\"title\">submit</span><span class=\"params\">(Callable&lt;T&gt; task)</span></span>;</span><br><span class=\"line\">&lt;T&gt; <span class=\"function\">Future&lt;T&gt; <span class=\"title\">submit</span><span class=\"params\">(Runnable task, T result)</span></span>;</span><br><span class=\"line\">Future&lt;?&gt; submit(Runnable task);</span><br></pre></td></tr></table></figure>\n<p>三者大同小异，最终都会返回<code>Future</code>对象来获取异步执行结果，即便传进来的是Runnable对象，也会包装为Callable进行执行，下面仅探讨第一个重载，源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> &lt;T&gt; <span class=\"function\">Future&lt;T&gt; <span class=\"title\">submit</span><span class=\"params\">(Callable&lt;T&gt; task)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (task == <span class=\"keyword\">null</span>) <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> NullPointerException();</span><br><span class=\"line\">    RunnableFuture&lt;T&gt; ftask = newTaskFor(task);</span><br><span class=\"line\">    execute(ftask);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ftask;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>任务提交进来后，调用<code>newTaskFor</code>方法构建了一个<code>RunnableFuture</code>对象，最终会调用<code>execute</code>方法提交这个RunnableFuture，其实<code>RunnableFuture</code>是一个同时继承了<code>Runnable</code>和<code>Future</code>的接口，同时具有这两者的功能，在<code>submit()</code>中构建的是其实现类：<code>FutureTask</code>：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">FutureTask</span><span class=\"params\">(Callable&lt;V&gt; callable)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (callable == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> NullPointerException();</span><br><span class=\"line\">    <span class=\"keyword\">this</span>.callable = callable;</span><br><span class=\"line\">    <span class=\"keyword\">this</span>.state = NEW;       <span class=\"comment\">// ensure visibility of callable</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这个对象是线程池的主要操作对象，是客户提交的任务的执行载体，其中封装了客户提交的callable (Runnable)任务</p>\n<p>任务提交进来后会统一交给<code>execute()</code>方法进行执行，这个方法<code>AbstractExecutorService</code>交给了子类去实现</p>\n<h3 id=\"execute\"><a href=\"#execute\" class=\"headerlink\" title=\"execute()\"></a>execute()</h3><p>在<code>ThreadPoolExecutor</code>中，源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">execute</span><span class=\"params\">(Runnable command)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (command == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> NullPointerException();</span><br><span class=\"line\">    <span class=\"comment\">// 获取ctl值，ctl对同时对线程池的两个状态进行控制：</span></span><br><span class=\"line\">    <span class=\"comment\">// 1. 当前线程池状态 2. 存活的工作线程总数（即worker数）</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> c = ctl.get();</span><br><span class=\"line\">    <span class=\"comment\">// 通过ctl获取当前工作线程数目</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (workerCountOf(c) &lt; corePoolSize) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 如果小于核心线程数则增加worker，增加并提交任务成功则直接返回</span></span><br><span class=\"line\">        <span class=\"comment\">// 本次使用核心线程数来判断worker能否增加成功</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (addWorker(command, <span class=\"keyword\">true</span>))</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"comment\">// 增加失败，继续获取当前ctl值</span></span><br><span class=\"line\">        c = ctl.get();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 检查当前线程池状态是否为RUNNING，并向workQueue缓存当前任务</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> recheck = ctl.get();</span><br><span class=\"line\">        <span class=\"comment\">// 如果当前状态不为RUNNING，尝试从workQueue移除本次任务</span></span><br><span class=\"line\">        <span class=\"comment\">// 移除成功后执行拒绝策略</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (! isRunning(recheck) &amp;&amp; remove(command))</span><br><span class=\"line\">            reject(command);</span><br><span class=\"line\">        <span class=\"comment\">// 如果当前存活worker总数为0则继续尝试增加worker</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (workerCountOf(recheck) == <span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"comment\">// 第二个参数为false，说明本次使用最大线程数来判断worker能否增加成功</span></span><br><span class=\"line\">            addWorker(<span class=\"keyword\">null</span>, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 若当前状态不为RUNNING或者向workQueue缓存当前任务失败，则尝试增加worker</span></span><br><span class=\"line\">    <span class=\"comment\">// 若增加worker失败（通常为已达到最大线程数）</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (!addWorker(command, <span class=\"keyword\">false</span>))</span><br><span class=\"line\">        reject(command);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>整个execute()的过程很复杂，涉及到线程池中各组件比较复杂的交互过程，参考官方注释的说法，整个过程分为三步：</p>\n<ol>\n<li>如果worker数量少于<strong>核心线程数</strong>，则尝试增加worker并把当前任务作为新worker的firstTask并执行</li>\n<li>如果以上路线走不通，则尝试向<code>workqueue</code>缓存任务，待空闲的worker取任务，在这个过程中对ctl进行双重检查，防止ctl出现不一致（因为以上过程中并没有做同步处理），如果ctl状态不为RUNNING则将刚才的任务弹出workqueue并执行拒绝策略；若成功缓存任务后，且当前worker数为0，则尝试继续增加worker，用<strong>最大线程数</strong>来判断worker能否增加成功</li>\n<li>如果第2步走不通（比如状态非RUNNING或者缓存任务失败），尝试继续增加worker，用<strong>最大线程数</strong>来判断worker能否增加成功，如果这一步都走不通，那直接进行拒绝策略，整个过程结束</li>\n</ol>\n<p>可以看出，整个过程非常依赖<code>addWorker</code>这个方法，主要用于新建worker并且提交firstTask，该方法执行成功与否直接关系到整个流程的走向，以下情况会导致增加worker失败：</p>\n<p><code>状态为Stop、Tidying或者Terminate</code></p>\n<p><code>状态为Shutdown，提交任务为null并且workqueue为空</code></p>\n<p><code>达到核心线程数或者最大线程数，或最大容量限制(2的29次方减1)</code></p>\n<p><code>创建新worker时出现其他异常</code></p>\n<h3 id=\"addWorker\"><a href=\"#addWorker\" class=\"headerlink\" title=\"addWorker\"></a>addWorker</h3><p><code>addWorker</code>是整个任务提交过程中最重要的方法，以下是源码：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">boolean</span> <span class=\"title\">addWorker</span><span class=\"params\">(Runnable firstTask, <span class=\"keyword\">boolean</span> core)</span> </span>&#123;</span><br><span class=\"line\">    retry:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> c = ctl.get();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rs = runStateOf(c);</span><br><span class=\"line\">        <span class=\"comment\">// 以下条件判断能否增加worker</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (rs &gt;= SHUTDOWN &amp;&amp;</span><br><span class=\"line\">            ! (rs == SHUTDOWN &amp;&amp;</span><br><span class=\"line\">               firstTask == <span class=\"keyword\">null</span> &amp;&amp;</span><br><span class=\"line\">               ! workQueue.isEmpty()))</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">\t\t<span class=\"comment\">// 内嵌循环，</span></span><br><span class=\"line\">        <span class=\"comment\">// 每一次循环都要重新判断worker数目，worker达到数量限制则直接返回false</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> wc = workerCountOf(c);</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (wc &gt;= CAPACITY ||</span><br><span class=\"line\">                wc &gt;= (core ? corePoolSize : maximumPoolSize))</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">            <span class=\"comment\">// cas方式增加worker数目，成功后直接退出外层循环</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (compareAndIncrementWorkerCount(c))</span><br><span class=\"line\">                <span class=\"keyword\">break</span> retry;</span><br><span class=\"line\">            c = ctl.get();  <span class=\"comment\">// Re-read ctl</span></span><br><span class=\"line\">            <span class=\"comment\">// 若内嵌循环过程中状态改变，则推出内嵌循环开始外层循环</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (runStateOf(c) != rs)</span><br><span class=\"line\">                <span class=\"keyword\">continue</span> retry;</span><br><span class=\"line\">            <span class=\"comment\">// 如果仅仅是因为worker数目改变导致cas失败，则仅进行内嵌循环</span></span><br><span class=\"line\">            <span class=\"comment\">// 不需要进行外层循环重新获取ctl状态</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> workerStarted = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> workerAdded = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    Worker w = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 新建worker对象并将任务作为其firstTask</span></span><br><span class=\"line\">        w = <span class=\"keyword\">new</span> Worker(firstTask);</span><br><span class=\"line\">        <span class=\"keyword\">final</span> Thread t = w.thread;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (t != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 同步操作</span></span><br><span class=\"line\">            <span class=\"keyword\">final</span> ReentrantLock mainLock = <span class=\"keyword\">this</span>.mainLock;</span><br><span class=\"line\">            mainLock.lock();</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 重新获取ctl状态</span></span><br><span class=\"line\">                <span class=\"keyword\">int</span> rs = runStateOf(ctl.get());</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">// 仅当状态为RUNNING或者为SHUTDOWN时提交的任务是null，才继续执行</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (rs &lt; SHUTDOWN ||</span><br><span class=\"line\">                    (rs == SHUTDOWN &amp;&amp; firstTask == <span class=\"keyword\">null</span>)) &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 若该worker线程已经启动则抛出异常</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (t.isAlive())</span><br><span class=\"line\">                        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalThreadStateException();</span><br><span class=\"line\">                    workers.add(w);</span><br><span class=\"line\">                    <span class=\"keyword\">int</span> s = workers.size();</span><br><span class=\"line\">                    <span class=\"comment\">// 增加largestPoolSize，仅作为统计用处</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (s &gt; largestPoolSize)</span><br><span class=\"line\">                        largestPoolSize = s;</span><br><span class=\"line\">                    workerAdded = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                mainLock.unlock();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (workerAdded) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 若增加worker成功则启动其线程，执行的是Worker对象的run方法</span></span><br><span class=\"line\">                t.start();</span><br><span class=\"line\">                workerStarted = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (! workerStarted)</span><br><span class=\"line\">            addWorkerFailed(w);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> workerStarted;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>该方法第一部分的for循环略微有些绕，总的说来就是对线程池状态有可能随时变化作出的双重保障，内层循环服务于增加worker数目的cas操作，外层循环在此基础上加上了对ctl状态的重新获取及判断。</p>\n<p>可以看出，整个submit过程离不开对线程池ctl状态的多次核查，保证了线程池的顺利运行，接下来对worker启动后做的工作进行简要分析</p>\n<h3 id=\"Worker\"><a href=\"#Worker\" class=\"headerlink\" title=\"Worker\"></a>Worker</h3><p>Worker类继承了Runnable以及<code>AQS(AbstractQueuedSynchronizer)</code>，在他的run方法中调用了线程池对象的<code>runWorker</code>方法：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">runWorker</span><span class=\"params\">(Worker w)</span> </span>&#123;</span><br><span class=\"line\">    Thread wt = Thread.currentThread();</span><br><span class=\"line\">    <span class=\"comment\">// 这个task变量很重要，是worker本次执行中的主要执行对象</span></span><br><span class=\"line\">    <span class=\"comment\">// 首先将worker的firstTask赋值给他</span></span><br><span class=\"line\">    <span class=\"comment\">// 赋值完后将worker的firstTask置为null</span></span><br><span class=\"line\">    Runnable task = w.firstTask;</span><br><span class=\"line\">    w.firstTask = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    w.unlock(); <span class=\"comment\">// allow interrupts</span></span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> completedAbruptly = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 进入循环，执行任务，如果任务为null则从workqueue里面取</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (task != <span class=\"keyword\">null</span> || (task = getTask()) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 对当前worker执行同步</span></span><br><span class=\"line\">            w.lock();</span><br><span class=\"line\">            <span class=\"comment\">// 如果当前worker线程未被打断，且状态为STOP及其以上（Tyding或者terminated），</span></span><br><span class=\"line\">            <span class=\"comment\">// 则将当前worker线程中断</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> ((runStateAtLeast(ctl.get(), STOP) ||</span><br><span class=\"line\">                 (Thread.interrupted() &amp;&amp;</span><br><span class=\"line\">                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;</span><br><span class=\"line\">                !wt.isInterrupted())</span><br><span class=\"line\">                wt.interrupt();</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 执行前预处理，留给子类定制，通常用来对资源进行初始化，或者打印日志</span></span><br><span class=\"line\">                beforeExecute(wt, task);</span><br><span class=\"line\">                Throwable thrown = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 真正执行任务</span></span><br><span class=\"line\">                    task.run();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (RuntimeException x) &#123;</span><br><span class=\"line\">                    thrown = x; <span class=\"keyword\">throw</span> x;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Error x) &#123;</span><br><span class=\"line\">                    thrown = x; <span class=\"keyword\">throw</span> x;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Throwable x) &#123;</span><br><span class=\"line\">                    thrown = x; <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> Error(x);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 跟beforeExecute类似，也是执行资源释放或打印错误日志</span></span><br><span class=\"line\">                    afterExecute(task, thrown);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 将task重置为null</span></span><br><span class=\"line\">                task = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                <span class=\"comment\">// 统计当前worker的执行任务数目</span></span><br><span class=\"line\">                w.completedTasks++;</span><br><span class=\"line\">                <span class=\"comment\">// 释放worker同步</span></span><br><span class=\"line\">                w.unlock();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 如果推出了该循环，则将completedAbruptly参数置为false</span></span><br><span class=\"line\">        completedAbruptly = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 执行worker退出操作</span></span><br><span class=\"line\">        processWorkerExit(w, completedAbruptly);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>整个过程大致分为以下几个步骤</p>\n<ol>\n<li>初始化，将firstTask作为初始任务</li>\n<li>worker执行unlock()，调整AQS状态使其可以被打断</li>\n<li>进入循环，执行任务，如果任务为null则从workqueue里面取：<code>task = getTask()</code></li>\n<li>判断是否需要将当前worker打断，满足条件则interrupt该worker的线程</li>\n<li>执行任务</li>\n<li>worker循环执行任务，直到无任务可以执行，则正常退出循环，将completedAbruptly置为false；又或者执行了打断线程操作等原因抛出了异常，属于非正常推出循环，这时候completedAbruptly仍为true</li>\n<li>执行worker退出操作</li>\n</ol>\n<p>其中最重要的两项操作分别是<code>getTask()</code>和<code>processWorkerExit(w, completedAbruptly)</code>，worker会持续尝试从<code>workQueue</code>中拿任务，worker拿不到任务或者非正常退出时则会执行退出操作，退出操作也比较重要，直接决定接下来线程池中是否保留以及保留多少个worker，现在对<code>getTask()</code>进行分析</p>\n<h3 id=\"getTask\"><a href=\"#getTask\" class=\"headerlink\" title=\"getTask()\"></a>getTask()</h3><p>源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> Runnable <span class=\"title\">getTask</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> timedOut = <span class=\"keyword\">false</span>; <span class=\"comment\">// 判断poll()获取任务的过程是否超时</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> c = ctl.get();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rs = runStateOf(c);</span><br><span class=\"line\">        <span class=\"comment\">// 若状态不为Running，并且workQueue为空或者状态为Stop，表明已经不需要执行任何任务了</span></span><br><span class=\"line\">        <span class=\"comment\">// 这时会直接减少workerCount并直接返回null，本次getTask提前结束</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123;</span><br><span class=\"line\">            decrementWorkerCount();</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 重新计算workerCount</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> wc = workerCountOf(c);</span><br><span class=\"line\">        <span class=\"comment\">// Are workers subject to culling?</span></span><br><span class=\"line\">        <span class=\"comment\">// 官方注释的意思是，用timer参数标记当前worker是否需要保留，timed为true则不需要保留</span></span><br><span class=\"line\">        <span class=\"keyword\">boolean</span> timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;</span><br><span class=\"line\">        <span class=\"comment\">// 如果workQueue为空或者workerCount大于1，有两种情况当前worker不需要保留：</span></span><br><span class=\"line\">        <span class=\"comment\">// 1. workerCount已经超出了最大线程数</span></span><br><span class=\"line\">        <span class=\"comment\">// 2. 获取任务超时并且不需要保留为核心线程</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))</span><br><span class=\"line\">            &amp;&amp; (wc &gt; <span class=\"number\">1</span> || workQueue.isEmpty())) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// cas方式减少workerCount，如果cas失败则循环重试</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (compareAndDecrementWorkerCount(c))</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">            <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 从workQueue取任务，根据timed不同又分为两种情况</span></span><br><span class=\"line\">            <span class=\"comment\">// 1. timed为true，当前worker在keepAliveTime时间内拿不到任务则会被抛弃</span></span><br><span class=\"line\">            <span class=\"comment\">// 2. timed为false，则当前worker作为核心线程保留下来并尝试拿任务</span></span><br><span class=\"line\">            <span class=\"comment\">// 由于workQueue是BlockingQueue，所以执行take()拿不到任务的话会阻塞直到队列中有任务可用</span></span><br><span class=\"line\">            <span class=\"comment\">// take()和poll()的过程都是可以被interrupt的</span></span><br><span class=\"line\">            Runnable r = timed ?</span><br><span class=\"line\">                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :</span><br><span class=\"line\">            workQueue.take();</span><br><span class=\"line\">            <span class=\"comment\">// 如果拿到任务后会返回，拿不到任务则将timedOut标记为true</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (r != <span class=\"keyword\">null</span>)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> r;</span><br><span class=\"line\">            <span class=\"comment\">// 拿不到任务，说明poll()超时了</span></span><br><span class=\"line\">            timedOut = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (InterruptedException retry) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 说明拿任务的过程被interrupt了，将timedOut标记为false</span></span><br><span class=\"line\">            <span class=\"comment\">// 表明并不是因为poll()超时而获取不了任务</span></span><br><span class=\"line\">            timedOut = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>getTask()</code>成功与否直接关系到该worker是否会被抛弃，其中，<code>timed</code>这个boolean变量对worker是否需要保留为核心线程进行标记，还涉及到<code>allowCoreThreadTimeOut</code>这个属性，分为两种情况：</p>\n<p><code>allowCoreThreadTimeOut为false</code>：默认情况，线程池种会保留<code>corePoolSize</code>数量的线程作为核心线程，从上述代码种可以看出，只要当前workerCount不大于corePoolSize，那该worker就可以作为核心线程保留下来，取任务时调用<code>workQueue.take()</code>，持续阻塞直到有任务可以执行</p>\n<p><code>allowCoreThreadTimeOut为true</code>：需要手动调用<code>allowCoreThreadTimeOut(boolean value)</code>方法进行设置，这种情况下线程池不会保留核心线程，所有worker在取任务时均会调用<code>workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS)</code>方法，在<code>keepAliveTime</code>时间后若还未取到任务则会被抛弃</p>\n<p>以下几种情况会导致getTask方法返回null，即该worker无任务可以执行，将被抛弃：</p>\n<ol>\n<li>线程池状态不为Running，并且workQueue为空</li>\n<li>线程池状态为Stop</li>\n<li>线程池状态为Running，workQueue为空，并且workerCount已经超出了最大线程数</li>\n<li>线程池状态为Running，workQueue为空，获取任务超时并且当前worker不需要保留为核心线程</li>\n</ol>\n<p>整个流程走下来，以上4种情况下该worker会被抛弃，进行下面的退出操作<code>processWorkerExit</code>，这种情况worker均为正常退出，<code>completedAbruptly</code>为false</p>\n<h3 id=\"processWorkerExit\"><a href=\"#processWorkerExit\" class=\"headerlink\" title=\"processWorkerExit\"></a>processWorkerExit</h3><p>processWorkerExit源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">processWorkerExit</span><span class=\"params\">(Worker w, <span class=\"keyword\">boolean</span> completedAbruptly)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 如果worker是非正常退出任务执行循环，则减少workerCount</span></span><br><span class=\"line\">    <span class=\"comment\">// 若是正常退出，则worker在getTask获取任务失败退出后已经减少了workerCount，可以正常移除该worker了</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (completedAbruptly)</span><br><span class=\"line\">        decrementWorkerCount();</span><br><span class=\"line\">    <span class=\"keyword\">final</span> ReentrantLock mainLock = <span class=\"keyword\">this</span>.mainLock;</span><br><span class=\"line\">    mainLock.lock();</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        completedTaskCount += w.completedTasks;</span><br><span class=\"line\">        <span class=\"comment\">// 移除worker</span></span><br><span class=\"line\">        workers.remove(w);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        mainLock.unlock();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 尝试执行终止操作</span></span><br><span class=\"line\">    tryTerminate();</span><br><span class=\"line\">    <span class=\"keyword\">int</span> c = ctl.get();</span><br><span class=\"line\">    <span class=\"comment\">// 如果当前状态为Running或者Shutdown，则执行以下流程</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (runStateLessThan(c, STOP)) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 若worker为正常退出任务执行循环，则需要额外判断是否需要新增worker</span></span><br><span class=\"line\">        <span class=\"comment\">// 分两种情况：</span></span><br><span class=\"line\">        <span class=\"comment\">// 1. 若需要将核心线程在一定闲置时间后被移除，则当前worker最多保留一个</span></span><br><span class=\"line\">        <span class=\"comment\">// 2. 如果不需要将核心线程闲置一段时间后移除，则可以保留不超过核心线程数的worker</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!completedAbruptly) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> min = allowCoreThreadTimeOut ? <span class=\"number\">0</span> : corePoolSize;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (min == <span class=\"number\">0</span> &amp;&amp; ! workQueue.isEmpty())</span><br><span class=\"line\">                min = <span class=\"number\">1</span>;</span><br><span class=\"line\">            <span class=\"comment\">// 如果worker已经够用了就不用addWorker了</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (workerCountOf(c) &gt;= min)</span><br><span class=\"line\">                <span class=\"keyword\">return</span>; <span class=\"comment\">// replacement not needed</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 执行以上判断后依然需要增加worker的话就调用addWorker，不传入任何task</span></span><br><span class=\"line\">        addWorker(<span class=\"keyword\">null</span>, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>逻辑相对比较复杂，总结来说，根据<code>completedAbruptly</code>参数将退出操作分为两条路线：</p>\n<p><code>正常退出任务执行循环：</code></p>\n<ol>\n<li>不需要减少worker数目</li>\n<li>将当前worker移除，并尝试执行终止操作</li>\n<li>如果当前状态为<code>Running</code>或者<code>Shutdown</code>，表示如果<code>workQueue</code>里面还有任务要执行的话，是需要继续执行的，那么接下来尝试新增worker</li>\n<li>计算当前需要保留的worker数目（min变量），如果<code>workerCount</code>已经满足需求则不额外增加worker了（这里依然使用<code>allowCoreThreadTimeOut</code>判断是否保留一定数量的核心线程，如果为true，则worker最多保留一个），直接退出</li>\n<li>如果<code>workerCount</code>数目不满足需求，则新增一个worker然后让他去<code>workQueue</code>里面取任务执行</li>\n</ol>\n<p><code>非正常退出任务执行循环</code></p>\n<ol>\n<li>减少worker数目</li>\n<li>移除当前worker并尝试执行终止操作，如果当前状态为<code>Running</code>或者<code>Shutdown</code>，则直接新增worker</li>\n</ol>\n<p>至于为什么将worker退出操作分为正常和非正常，我是这么理解的：</p>\n<p><code>正常退出</code>：说明worker调用<code>getTask()</code>没有成功取到任务，将被抛弃，<code>getTask</code>方法已经对<code>workCount</code>进行了扣减，这里就不需要对<code>workerCount</code>作任何变动，此外需要判断当前<code>workerCount</code>数目够不够</p>\n<p><code>非正常退出</code>：这种情况下需要对<code>workerCount</code>进行扣减并立即补充一个worker，当然如果当前状态为<code>Stop</code>或者<code>Tyding</code>甚至<code>Terminated</code>的话就没必要补充了</p>\n","site":{"data":{}},"excerpt":"<p>在jdk线程池中，<code>submit()</code>是<code>ExecutorService</code>的基础api，用于提交新任务给线程池进行执行，现对<code>submit()</code>执行过程一探究竟，这里主要对<code>AbstractExecutorService</code>及其子类<code>ThreadPoolExecutor</code>的实现进行讨论。<br>","more":"</p>\n<h3 id=\"submit\"><a href=\"#submit\" class=\"headerlink\" title=\"submit()\"></a>submit()</h3><p>jdk 8中，submit()有三个重载，分别是：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;T&gt; <span class=\"function\">Future&lt;T&gt; <span class=\"title\">submit</span><span class=\"params\">(Callable&lt;T&gt; task)</span></span>;</span><br><span class=\"line\">&lt;T&gt; <span class=\"function\">Future&lt;T&gt; <span class=\"title\">submit</span><span class=\"params\">(Runnable task, T result)</span></span>;</span><br><span class=\"line\">Future&lt;?&gt; submit(Runnable task);</span><br></pre></td></tr></table></figure>\n<p>三者大同小异，最终都会返回<code>Future</code>对象来获取异步执行结果，即便传进来的是Runnable对象，也会包装为Callable进行执行，下面仅探讨第一个重载，源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> &lt;T&gt; <span class=\"function\">Future&lt;T&gt; <span class=\"title\">submit</span><span class=\"params\">(Callable&lt;T&gt; task)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (task == <span class=\"keyword\">null</span>) <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> NullPointerException();</span><br><span class=\"line\">    RunnableFuture&lt;T&gt; ftask = newTaskFor(task);</span><br><span class=\"line\">    execute(ftask);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ftask;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>任务提交进来后，调用<code>newTaskFor</code>方法构建了一个<code>RunnableFuture</code>对象，最终会调用<code>execute</code>方法提交这个RunnableFuture，其实<code>RunnableFuture</code>是一个同时继承了<code>Runnable</code>和<code>Future</code>的接口，同时具有这两者的功能，在<code>submit()</code>中构建的是其实现类：<code>FutureTask</code>：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">FutureTask</span><span class=\"params\">(Callable&lt;V&gt; callable)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (callable == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> NullPointerException();</span><br><span class=\"line\">    <span class=\"keyword\">this</span>.callable = callable;</span><br><span class=\"line\">    <span class=\"keyword\">this</span>.state = NEW;       <span class=\"comment\">// ensure visibility of callable</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这个对象是线程池的主要操作对象，是客户提交的任务的执行载体，其中封装了客户提交的callable (Runnable)任务</p>\n<p>任务提交进来后会统一交给<code>execute()</code>方法进行执行，这个方法<code>AbstractExecutorService</code>交给了子类去实现</p>\n<h3 id=\"execute\"><a href=\"#execute\" class=\"headerlink\" title=\"execute()\"></a>execute()</h3><p>在<code>ThreadPoolExecutor</code>中，源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">execute</span><span class=\"params\">(Runnable command)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (command == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> NullPointerException();</span><br><span class=\"line\">    <span class=\"comment\">// 获取ctl值，ctl对同时对线程池的两个状态进行控制：</span></span><br><span class=\"line\">    <span class=\"comment\">// 1. 当前线程池状态 2. 存活的工作线程总数（即worker数）</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> c = ctl.get();</span><br><span class=\"line\">    <span class=\"comment\">// 通过ctl获取当前工作线程数目</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (workerCountOf(c) &lt; corePoolSize) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 如果小于核心线程数则增加worker，增加并提交任务成功则直接返回</span></span><br><span class=\"line\">        <span class=\"comment\">// 本次使用核心线程数来判断worker能否增加成功</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (addWorker(command, <span class=\"keyword\">true</span>))</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"comment\">// 增加失败，继续获取当前ctl值</span></span><br><span class=\"line\">        c = ctl.get();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 检查当前线程池状态是否为RUNNING，并向workQueue缓存当前任务</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> recheck = ctl.get();</span><br><span class=\"line\">        <span class=\"comment\">// 如果当前状态不为RUNNING，尝试从workQueue移除本次任务</span></span><br><span class=\"line\">        <span class=\"comment\">// 移除成功后执行拒绝策略</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (! isRunning(recheck) &amp;&amp; remove(command))</span><br><span class=\"line\">            reject(command);</span><br><span class=\"line\">        <span class=\"comment\">// 如果当前存活worker总数为0则继续尝试增加worker</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (workerCountOf(recheck) == <span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"comment\">// 第二个参数为false，说明本次使用最大线程数来判断worker能否增加成功</span></span><br><span class=\"line\">            addWorker(<span class=\"keyword\">null</span>, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 若当前状态不为RUNNING或者向workQueue缓存当前任务失败，则尝试增加worker</span></span><br><span class=\"line\">    <span class=\"comment\">// 若增加worker失败（通常为已达到最大线程数）</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (!addWorker(command, <span class=\"keyword\">false</span>))</span><br><span class=\"line\">        reject(command);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>整个execute()的过程很复杂，涉及到线程池中各组件比较复杂的交互过程，参考官方注释的说法，整个过程分为三步：</p>\n<ol>\n<li>如果worker数量少于<strong>核心线程数</strong>，则尝试增加worker并把当前任务作为新worker的firstTask并执行</li>\n<li>如果以上路线走不通，则尝试向<code>workqueue</code>缓存任务，待空闲的worker取任务，在这个过程中对ctl进行双重检查，防止ctl出现不一致（因为以上过程中并没有做同步处理），如果ctl状态不为RUNNING则将刚才的任务弹出workqueue并执行拒绝策略；若成功缓存任务后，且当前worker数为0，则尝试继续增加worker，用<strong>最大线程数</strong>来判断worker能否增加成功</li>\n<li>如果第2步走不通（比如状态非RUNNING或者缓存任务失败），尝试继续增加worker，用<strong>最大线程数</strong>来判断worker能否增加成功，如果这一步都走不通，那直接进行拒绝策略，整个过程结束</li>\n</ol>\n<p>可以看出，整个过程非常依赖<code>addWorker</code>这个方法，主要用于新建worker并且提交firstTask，该方法执行成功与否直接关系到整个流程的走向，以下情况会导致增加worker失败：</p>\n<p><code>状态为Stop、Tidying或者Terminate</code></p>\n<p><code>状态为Shutdown，提交任务为null并且workqueue为空</code></p>\n<p><code>达到核心线程数或者最大线程数，或最大容量限制(2的29次方减1)</code></p>\n<p><code>创建新worker时出现其他异常</code></p>\n<h3 id=\"addWorker\"><a href=\"#addWorker\" class=\"headerlink\" title=\"addWorker\"></a>addWorker</h3><p><code>addWorker</code>是整个任务提交过程中最重要的方法，以下是源码：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">boolean</span> <span class=\"title\">addWorker</span><span class=\"params\">(Runnable firstTask, <span class=\"keyword\">boolean</span> core)</span> </span>&#123;</span><br><span class=\"line\">    retry:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> c = ctl.get();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rs = runStateOf(c);</span><br><span class=\"line\">        <span class=\"comment\">// 以下条件判断能否增加worker</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (rs &gt;= SHUTDOWN &amp;&amp;</span><br><span class=\"line\">            ! (rs == SHUTDOWN &amp;&amp;</span><br><span class=\"line\">               firstTask == <span class=\"keyword\">null</span> &amp;&amp;</span><br><span class=\"line\">               ! workQueue.isEmpty()))</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">\t\t<span class=\"comment\">// 内嵌循环，</span></span><br><span class=\"line\">        <span class=\"comment\">// 每一次循环都要重新判断worker数目，worker达到数量限制则直接返回false</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> wc = workerCountOf(c);</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (wc &gt;= CAPACITY ||</span><br><span class=\"line\">                wc &gt;= (core ? corePoolSize : maximumPoolSize))</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">            <span class=\"comment\">// cas方式增加worker数目，成功后直接退出外层循环</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (compareAndIncrementWorkerCount(c))</span><br><span class=\"line\">                <span class=\"keyword\">break</span> retry;</span><br><span class=\"line\">            c = ctl.get();  <span class=\"comment\">// Re-read ctl</span></span><br><span class=\"line\">            <span class=\"comment\">// 若内嵌循环过程中状态改变，则推出内嵌循环开始外层循环</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (runStateOf(c) != rs)</span><br><span class=\"line\">                <span class=\"keyword\">continue</span> retry;</span><br><span class=\"line\">            <span class=\"comment\">// 如果仅仅是因为worker数目改变导致cas失败，则仅进行内嵌循环</span></span><br><span class=\"line\">            <span class=\"comment\">// 不需要进行外层循环重新获取ctl状态</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> workerStarted = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> workerAdded = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    Worker w = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 新建worker对象并将任务作为其firstTask</span></span><br><span class=\"line\">        w = <span class=\"keyword\">new</span> Worker(firstTask);</span><br><span class=\"line\">        <span class=\"keyword\">final</span> Thread t = w.thread;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (t != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 同步操作</span></span><br><span class=\"line\">            <span class=\"keyword\">final</span> ReentrantLock mainLock = <span class=\"keyword\">this</span>.mainLock;</span><br><span class=\"line\">            mainLock.lock();</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 重新获取ctl状态</span></span><br><span class=\"line\">                <span class=\"keyword\">int</span> rs = runStateOf(ctl.get());</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">// 仅当状态为RUNNING或者为SHUTDOWN时提交的任务是null，才继续执行</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (rs &lt; SHUTDOWN ||</span><br><span class=\"line\">                    (rs == SHUTDOWN &amp;&amp; firstTask == <span class=\"keyword\">null</span>)) &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 若该worker线程已经启动则抛出异常</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (t.isAlive())</span><br><span class=\"line\">                        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalThreadStateException();</span><br><span class=\"line\">                    workers.add(w);</span><br><span class=\"line\">                    <span class=\"keyword\">int</span> s = workers.size();</span><br><span class=\"line\">                    <span class=\"comment\">// 增加largestPoolSize，仅作为统计用处</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (s &gt; largestPoolSize)</span><br><span class=\"line\">                        largestPoolSize = s;</span><br><span class=\"line\">                    workerAdded = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                mainLock.unlock();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (workerAdded) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 若增加worker成功则启动其线程，执行的是Worker对象的run方法</span></span><br><span class=\"line\">                t.start();</span><br><span class=\"line\">                workerStarted = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (! workerStarted)</span><br><span class=\"line\">            addWorkerFailed(w);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> workerStarted;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>该方法第一部分的for循环略微有些绕，总的说来就是对线程池状态有可能随时变化作出的双重保障，内层循环服务于增加worker数目的cas操作，外层循环在此基础上加上了对ctl状态的重新获取及判断。</p>\n<p>可以看出，整个submit过程离不开对线程池ctl状态的多次核查，保证了线程池的顺利运行，接下来对worker启动后做的工作进行简要分析</p>\n<h3 id=\"Worker\"><a href=\"#Worker\" class=\"headerlink\" title=\"Worker\"></a>Worker</h3><p>Worker类继承了Runnable以及<code>AQS(AbstractQueuedSynchronizer)</code>，在他的run方法中调用了线程池对象的<code>runWorker</code>方法：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">runWorker</span><span class=\"params\">(Worker w)</span> </span>&#123;</span><br><span class=\"line\">    Thread wt = Thread.currentThread();</span><br><span class=\"line\">    <span class=\"comment\">// 这个task变量很重要，是worker本次执行中的主要执行对象</span></span><br><span class=\"line\">    <span class=\"comment\">// 首先将worker的firstTask赋值给他</span></span><br><span class=\"line\">    <span class=\"comment\">// 赋值完后将worker的firstTask置为null</span></span><br><span class=\"line\">    Runnable task = w.firstTask;</span><br><span class=\"line\">    w.firstTask = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    w.unlock(); <span class=\"comment\">// allow interrupts</span></span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> completedAbruptly = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 进入循环，执行任务，如果任务为null则从workqueue里面取</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (task != <span class=\"keyword\">null</span> || (task = getTask()) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 对当前worker执行同步</span></span><br><span class=\"line\">            w.lock();</span><br><span class=\"line\">            <span class=\"comment\">// 如果当前worker线程未被打断，且状态为STOP及其以上（Tyding或者terminated），</span></span><br><span class=\"line\">            <span class=\"comment\">// 则将当前worker线程中断</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> ((runStateAtLeast(ctl.get(), STOP) ||</span><br><span class=\"line\">                 (Thread.interrupted() &amp;&amp;</span><br><span class=\"line\">                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;</span><br><span class=\"line\">                !wt.isInterrupted())</span><br><span class=\"line\">                wt.interrupt();</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 执行前预处理，留给子类定制，通常用来对资源进行初始化，或者打印日志</span></span><br><span class=\"line\">                beforeExecute(wt, task);</span><br><span class=\"line\">                Throwable thrown = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 真正执行任务</span></span><br><span class=\"line\">                    task.run();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (RuntimeException x) &#123;</span><br><span class=\"line\">                    thrown = x; <span class=\"keyword\">throw</span> x;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Error x) &#123;</span><br><span class=\"line\">                    thrown = x; <span class=\"keyword\">throw</span> x;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Throwable x) &#123;</span><br><span class=\"line\">                    thrown = x; <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> Error(x);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 跟beforeExecute类似，也是执行资源释放或打印错误日志</span></span><br><span class=\"line\">                    afterExecute(task, thrown);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 将task重置为null</span></span><br><span class=\"line\">                task = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                <span class=\"comment\">// 统计当前worker的执行任务数目</span></span><br><span class=\"line\">                w.completedTasks++;</span><br><span class=\"line\">                <span class=\"comment\">// 释放worker同步</span></span><br><span class=\"line\">                w.unlock();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 如果推出了该循环，则将completedAbruptly参数置为false</span></span><br><span class=\"line\">        completedAbruptly = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 执行worker退出操作</span></span><br><span class=\"line\">        processWorkerExit(w, completedAbruptly);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>整个过程大致分为以下几个步骤</p>\n<ol>\n<li>初始化，将firstTask作为初始任务</li>\n<li>worker执行unlock()，调整AQS状态使其可以被打断</li>\n<li>进入循环，执行任务，如果任务为null则从workqueue里面取：<code>task = getTask()</code></li>\n<li>判断是否需要将当前worker打断，满足条件则interrupt该worker的线程</li>\n<li>执行任务</li>\n<li>worker循环执行任务，直到无任务可以执行，则正常退出循环，将completedAbruptly置为false；又或者执行了打断线程操作等原因抛出了异常，属于非正常推出循环，这时候completedAbruptly仍为true</li>\n<li>执行worker退出操作</li>\n</ol>\n<p>其中最重要的两项操作分别是<code>getTask()</code>和<code>processWorkerExit(w, completedAbruptly)</code>，worker会持续尝试从<code>workQueue</code>中拿任务，worker拿不到任务或者非正常退出时则会执行退出操作，退出操作也比较重要，直接决定接下来线程池中是否保留以及保留多少个worker，现在对<code>getTask()</code>进行分析</p>\n<h3 id=\"getTask\"><a href=\"#getTask\" class=\"headerlink\" title=\"getTask()\"></a>getTask()</h3><p>源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> Runnable <span class=\"title\">getTask</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> timedOut = <span class=\"keyword\">false</span>; <span class=\"comment\">// 判断poll()获取任务的过程是否超时</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> c = ctl.get();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rs = runStateOf(c);</span><br><span class=\"line\">        <span class=\"comment\">// 若状态不为Running，并且workQueue为空或者状态为Stop，表明已经不需要执行任何任务了</span></span><br><span class=\"line\">        <span class=\"comment\">// 这时会直接减少workerCount并直接返回null，本次getTask提前结束</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123;</span><br><span class=\"line\">            decrementWorkerCount();</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 重新计算workerCount</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> wc = workerCountOf(c);</span><br><span class=\"line\">        <span class=\"comment\">// Are workers subject to culling?</span></span><br><span class=\"line\">        <span class=\"comment\">// 官方注释的意思是，用timer参数标记当前worker是否需要保留，timed为true则不需要保留</span></span><br><span class=\"line\">        <span class=\"keyword\">boolean</span> timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;</span><br><span class=\"line\">        <span class=\"comment\">// 如果workQueue为空或者workerCount大于1，有两种情况当前worker不需要保留：</span></span><br><span class=\"line\">        <span class=\"comment\">// 1. workerCount已经超出了最大线程数</span></span><br><span class=\"line\">        <span class=\"comment\">// 2. 获取任务超时并且不需要保留为核心线程</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))</span><br><span class=\"line\">            &amp;&amp; (wc &gt; <span class=\"number\">1</span> || workQueue.isEmpty())) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// cas方式减少workerCount，如果cas失败则循环重试</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (compareAndDecrementWorkerCount(c))</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">            <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 从workQueue取任务，根据timed不同又分为两种情况</span></span><br><span class=\"line\">            <span class=\"comment\">// 1. timed为true，当前worker在keepAliveTime时间内拿不到任务则会被抛弃</span></span><br><span class=\"line\">            <span class=\"comment\">// 2. timed为false，则当前worker作为核心线程保留下来并尝试拿任务</span></span><br><span class=\"line\">            <span class=\"comment\">// 由于workQueue是BlockingQueue，所以执行take()拿不到任务的话会阻塞直到队列中有任务可用</span></span><br><span class=\"line\">            <span class=\"comment\">// take()和poll()的过程都是可以被interrupt的</span></span><br><span class=\"line\">            Runnable r = timed ?</span><br><span class=\"line\">                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :</span><br><span class=\"line\">            workQueue.take();</span><br><span class=\"line\">            <span class=\"comment\">// 如果拿到任务后会返回，拿不到任务则将timedOut标记为true</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (r != <span class=\"keyword\">null</span>)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> r;</span><br><span class=\"line\">            <span class=\"comment\">// 拿不到任务，说明poll()超时了</span></span><br><span class=\"line\">            timedOut = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (InterruptedException retry) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 说明拿任务的过程被interrupt了，将timedOut标记为false</span></span><br><span class=\"line\">            <span class=\"comment\">// 表明并不是因为poll()超时而获取不了任务</span></span><br><span class=\"line\">            timedOut = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>getTask()</code>成功与否直接关系到该worker是否会被抛弃，其中，<code>timed</code>这个boolean变量对worker是否需要保留为核心线程进行标记，还涉及到<code>allowCoreThreadTimeOut</code>这个属性，分为两种情况：</p>\n<p><code>allowCoreThreadTimeOut为false</code>：默认情况，线程池种会保留<code>corePoolSize</code>数量的线程作为核心线程，从上述代码种可以看出，只要当前workerCount不大于corePoolSize，那该worker就可以作为核心线程保留下来，取任务时调用<code>workQueue.take()</code>，持续阻塞直到有任务可以执行</p>\n<p><code>allowCoreThreadTimeOut为true</code>：需要手动调用<code>allowCoreThreadTimeOut(boolean value)</code>方法进行设置，这种情况下线程池不会保留核心线程，所有worker在取任务时均会调用<code>workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS)</code>方法，在<code>keepAliveTime</code>时间后若还未取到任务则会被抛弃</p>\n<p>以下几种情况会导致getTask方法返回null，即该worker无任务可以执行，将被抛弃：</p>\n<ol>\n<li>线程池状态不为Running，并且workQueue为空</li>\n<li>线程池状态为Stop</li>\n<li>线程池状态为Running，workQueue为空，并且workerCount已经超出了最大线程数</li>\n<li>线程池状态为Running，workQueue为空，获取任务超时并且当前worker不需要保留为核心线程</li>\n</ol>\n<p>整个流程走下来，以上4种情况下该worker会被抛弃，进行下面的退出操作<code>processWorkerExit</code>，这种情况worker均为正常退出，<code>completedAbruptly</code>为false</p>\n<h3 id=\"processWorkerExit\"><a href=\"#processWorkerExit\" class=\"headerlink\" title=\"processWorkerExit\"></a>processWorkerExit</h3><p>processWorkerExit源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">processWorkerExit</span><span class=\"params\">(Worker w, <span class=\"keyword\">boolean</span> completedAbruptly)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 如果worker是非正常退出任务执行循环，则减少workerCount</span></span><br><span class=\"line\">    <span class=\"comment\">// 若是正常退出，则worker在getTask获取任务失败退出后已经减少了workerCount，可以正常移除该worker了</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (completedAbruptly)</span><br><span class=\"line\">        decrementWorkerCount();</span><br><span class=\"line\">    <span class=\"keyword\">final</span> ReentrantLock mainLock = <span class=\"keyword\">this</span>.mainLock;</span><br><span class=\"line\">    mainLock.lock();</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        completedTaskCount += w.completedTasks;</span><br><span class=\"line\">        <span class=\"comment\">// 移除worker</span></span><br><span class=\"line\">        workers.remove(w);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        mainLock.unlock();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 尝试执行终止操作</span></span><br><span class=\"line\">    tryTerminate();</span><br><span class=\"line\">    <span class=\"keyword\">int</span> c = ctl.get();</span><br><span class=\"line\">    <span class=\"comment\">// 如果当前状态为Running或者Shutdown，则执行以下流程</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (runStateLessThan(c, STOP)) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 若worker为正常退出任务执行循环，则需要额外判断是否需要新增worker</span></span><br><span class=\"line\">        <span class=\"comment\">// 分两种情况：</span></span><br><span class=\"line\">        <span class=\"comment\">// 1. 若需要将核心线程在一定闲置时间后被移除，则当前worker最多保留一个</span></span><br><span class=\"line\">        <span class=\"comment\">// 2. 如果不需要将核心线程闲置一段时间后移除，则可以保留不超过核心线程数的worker</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!completedAbruptly) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> min = allowCoreThreadTimeOut ? <span class=\"number\">0</span> : corePoolSize;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (min == <span class=\"number\">0</span> &amp;&amp; ! workQueue.isEmpty())</span><br><span class=\"line\">                min = <span class=\"number\">1</span>;</span><br><span class=\"line\">            <span class=\"comment\">// 如果worker已经够用了就不用addWorker了</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (workerCountOf(c) &gt;= min)</span><br><span class=\"line\">                <span class=\"keyword\">return</span>; <span class=\"comment\">// replacement not needed</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 执行以上判断后依然需要增加worker的话就调用addWorker，不传入任何task</span></span><br><span class=\"line\">        addWorker(<span class=\"keyword\">null</span>, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>逻辑相对比较复杂，总结来说，根据<code>completedAbruptly</code>参数将退出操作分为两条路线：</p>\n<p><code>正常退出任务执行循环：</code></p>\n<ol>\n<li>不需要减少worker数目</li>\n<li>将当前worker移除，并尝试执行终止操作</li>\n<li>如果当前状态为<code>Running</code>或者<code>Shutdown</code>，表示如果<code>workQueue</code>里面还有任务要执行的话，是需要继续执行的，那么接下来尝试新增worker</li>\n<li>计算当前需要保留的worker数目（min变量），如果<code>workerCount</code>已经满足需求则不额外增加worker了（这里依然使用<code>allowCoreThreadTimeOut</code>判断是否保留一定数量的核心线程，如果为true，则worker最多保留一个），直接退出</li>\n<li>如果<code>workerCount</code>数目不满足需求，则新增一个worker然后让他去<code>workQueue</code>里面取任务执行</li>\n</ol>\n<p><code>非正常退出任务执行循环</code></p>\n<ol>\n<li>减少worker数目</li>\n<li>移除当前worker并尝试执行终止操作，如果当前状态为<code>Running</code>或者<code>Shutdown</code>，则直接新增worker</li>\n</ol>\n<p>至于为什么将worker退出操作分为正常和非正常，我是这么理解的：</p>\n<p><code>正常退出</code>：说明worker调用<code>getTask()</code>没有成功取到任务，将被抛弃，<code>getTask</code>方法已经对<code>workCount</code>进行了扣减，这里就不需要对<code>workerCount</code>作任何变动，此外需要判断当前<code>workerCount</code>数目够不够</p>\n<p><code>非正常退出</code>：这种情况下需要对<code>workerCount</code>进行扣减并立即补充一个worker，当然如果当前状态为<code>Stop</code>或者<code>Tyding</code>甚至<code>Terminated</code>的话就没必要补充了</p>"},{"title":"kafka学习笔记（1）—— 基础知识","author":"天渊","date":"2019-02-13T08:31:00.000Z","_content":"Kafka是由LinkedIn开发并开源的分布式发布/订阅模式的消息队列系统，因其分布式及高吞吐率而被广泛使用，目前在大数据处理领域占有很重要的地位，能够很方便地与Hadoop, Spark, Storm, Flink和Flume等大数据处理工具进行集成\n<!--more-->\n\n### Kafka主要特点\n\nKafka有三个主要的作用：`传统意义上的消息系统`，`分布式存储`，`流处理工具`\n\n**Kafka最重要的作用就是企业级消息队列服务**：\n\n- 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能\n- Server间的topic分区（partition）消费，保证了高吞吐率，同时保证每个分区内的消息顺序传输\n- 发布/订阅模式中，单个topic支持多consumer，并支持consumer-group自动负载均衡\n\n- 不同于RabbitMQ等传统消息队列，kafka不会删除历史数据\n- 支持数据备份（repliaction），通过master-slave方式保证数据一致性以及高可用\n\n**Kafka-stream**：\n\nKafka Stream是Apache Kafka从0.10版本引入的一个新Feature，它提供了对存储于Kafka内的数据进行流式处理和分析的功能。\n\n### Kafka架构\n\nKafka涉及到的一些专用名词\n\n- **Broker**\n  　　Kafka集群包含一个或多个服务器，这种服务器被称为broker\n- **Topic**\n  　　每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）\n- **Partition**\n  　　分片，每个Topic包含一个或多个Partition.\n- **repliaction**\n  　　复制集，每个partition包含一个或多个repliaction，其中有一个master多个slave\n- **Producer**\n  　　消息发布者，负责发布消息到Kafka broker\n- **Consumer**\n  　　消息消费者，通过拉取的方式向Kafka broker读取消息\n- **Consumer Group**\n  　　每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。\n\nkafka集群拓扑：\n\n![](/blog/images/kafka.png)\n- Kafka集群中包含若干Producer，使用push模式将消息**批量**发布到broker\n- 包含若干broker，支持水平扩展，broker数量越多，集群吞吐率越高，新建的topic-partition及其复制集均分到各个broker上\n- 由Consumer Group管理consumer实例，单个consumer实例可以订阅多个topic，若同一个Consumer Group中的多个consumer实例订阅了同一个topic，则由kafka集群自动进行负载均衡，统一协调分配partition进行消费\n- kafka强依赖Zookeeper集群，通过Zookeeper管理集群配置，保存元数据，选举partition leader，以及在Consumer Group发生变化时进行rebalance\n\n### Kafka与常用MQ对比\n\n- RabbitMQ：支持多种协议栈（AMQP，XMPP, SMTP等），功能更加强大（推拉消费，延迟消费，优先消费等），安全性和可靠性要优于kafka，相比较之下Kafka设计更加简单，吞吐量更高，更加适用于大规模日志数据处理\n- RocketMQ：阿里开源的消息队列，最早思路来源于kafka，具有高吞吐量、高可用性、适合大规模分布式系统应用的特点，相比于kafka在可靠性和稳定性方面均有提升，而且支持事务消息\n- ZeroMQ：号称最快的消息队列系统，具有超高吞吐量，但作用场景有限，大部分情况下作为数据流传输模块嵌入到各个中间件中\n\n### Kafka文件存储方式\n\nKafka以顺序I/O的方式将消息存入磁盘进行持久化，保证了足够的刷盘速度:\n\n- Kafka存储的每条消息数据称为`Message`，每条`Message`数据包含四个属性：`offset`，`MessageSize`，`data`，`timestamp`时间戳即时间戳类型\n\n- Kafka的消息队列在逻辑上是由`partition`的方式存在的，每个`partition`的`repliaction`在物理上由多个`segment`分段组成，每个`segment`数据文件以该段中最小的 offset 命名，文件扩展名为`.log`，查找指定 offset 的 Message 的时候，使用二分查找定位到该 Message 在哪个 `segment` 数据文件；写入消息时直接将消息添加到最新`segment`文件的末尾\n\n- 每个`segment`分段都有自己的索引文件，扩展名为`.index`，索引文件采用稀疏索引的方式建立索引，每隔一定字节的数据建立一条索引，这样避免了索引文件占用过多的空间，从而可以将索引文件保留在内存中\n\n![upload successful](\\blog\\images\\pasted-0.png)\n\n  `log.dirs=/home1/irteam/apps/kafka/data/kafka/kafka-logs`\n\n  在该文件夹中，每个topic的partition都有自己单独的文件夹进行存放，比如`resource-v1-APIGateway-Api`这个topic编号为0的partition放如下位置：\n\n  `/home1/irteam/apps/kafka/data/kafka/kafka-logs/resource-v1-APIGateway-Api-0/`\n  \n![upload successful](\\blog\\images\\pasted-1.png)\n  其中`.index`，`.log`，`.timestamp`三个文件分别对应`分段索引文件`，`分段数据`和`时间索引`\n    \n  **时间索引**：`.timeindex`文件用于保存当前分段中消息发布时间与offset的稀疏索引，用于定期删除消息（`log.retention.hours`参数）\n    \n    \n### Kafka搭建集群即基本操作\n\n1. 前期工作\n\n   首先保证当前主机安装有jdk，推荐jdk 8 及其以上版本\n\n   Kafka发行版自带zookeeper，无需单独安装zookeeper集群，当然也可以自己另外搭建zookeeper集群\n\n   最新版kafka发行版下载地址：\n\n   https://www.apache.org/dyn/closer.cgi?path=/kafka/2.1.0/kafka_2.11-2.1.0.tgz\n\n   下载到本地并解压tar文件得到`kafka_2.11-2.1.0`文件夹 （2.11是kafka源码的scala版本，2.1.0是kafka实际发行版本）：\n   \n2. 初始化配置\n\n   为了简便起见这里就只配置单点broker；进入`config`文件夹，`server.properties`是kafka集群的主配置文件，大部分配置都可以选择默认，部分配置需要注意一下：\n\n   ```properties\n   # 当前主机id，也是集群中唯一id，将保存于zookeeper中\n   broker.id=0\n   # 监听地址和端口，如果没有配置的话默认当前主机名；端口默认9092\n   listeners = PLAINTEXT://your.host.name:9092\n   # 给生产者和消费者的广播地址，如果没设置的话默认采用上面的listeners属性\n   advertised.listeners=PLAINTEXT://your.host.name:9092\n   # kafka数据存放路径\n   log.dirs=/tmp/kafka-logs\n   # topic默认的分片数，创建topic的适合可以单独指定该属性\n   # 理论上，分区数量越多，吞吐量越大，但会造成更严重的资源消耗\n   num.partitions=1\n   # 是否允许自动创建topic（当producer或者consumer发布/订阅某个不存在的topic时）\n   auto.create.topics.enable=true\n   # 是否允许删除topic（删除topic后需要重启broker，不过即使这样也无法完全删除topic数据，需要进入zookeeper删除topic元数据，不过很危险，不推荐）\n   delete.topic.enable=true\n   # kafka采取异步刷盘的方式将内存中收到的消息序列化到硬盘上，下面两个条件任意满足一项即开启刷盘\n   # 每收到10000条消息刷盘一次\n   log.flush.interval.messages=10000\n   # 每隔1000ms刷盘一次\n   log.flush.interval.ms=1000\n   # 消息删除策略，保存消息的最长时间\n   log.retention.hours=168\n   # 单个分区保留消息的最大容量，默认就是1G\n   log.retention.bytes=1073741824\n   # segment分段的最大容量，单个segment超出这个容量后将创建一个新的segment继续保存消息\n   log.segment.bytes=1073741824\n   # 可接收的消息最大大小（压缩后的大小）\n   message.max.bytes=1048576\n   # zookeeper配置\n   zookeeper.connect=localhost:2181\n   zookeeper.connection.timeout.ms=6000\n   ```\n\n   关于kafka broker更详细的配置策略请参考官网：https://kafka.apache.org/documentation/#brokerconfigs\n\n3. 配置完成后，首先启动zookeeper，如果启动的是kafka默认自带的zookeeper的话，进入kafka安装目录，按照以下方式启动：\n\n   ```shell\n   > ./bin/zookeeper-server-start.sh ./config/zookeeper.properties\n   ```\n\n   再执行以下命令可以进入zookeeper，即可查看zookeeper启动状态和执行各种zookeeper相关命令，输入quit退出：\n\n   ```shell\n   > ./bin/zookeeper-shell.sh localhost:2181\n   ```\n\n\n4. zookeeper启动完成后，启动kafka broker （-daemon 参数指定kafka进程后台运行）\n\n   ```shell\n   > ./bin/kafka-server-start.sh -daemon ./config/server.properties\n   ```\n\n   kafka运行日志存放于`安装路径/logs/server.log`中，可以查看运行状态和报错信息\n\n5. 启动完成后进入zookeeper控制台输入`ls /brokers/ids`命令即可查看注册的kafka broker信息\n\n\n### 基本操作\n\n再控制台中进行一些基本操作，包括创建topic，发布和消费数据\n\n#### 创建topic\n\n输入以下命令创建一个名为test_topic_1的topic：\n\n```shell\n> ./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test_topic_1\n```\n\n每次执行kafka脚本都需要指定zookeeper；指定topic的`replication-factor`即复制集数量为1，分片数量`partitions`为1，名称为test_topic_1，然后通过以下命令查看当前所有topic：\n\n```shell\n> ./bin/kafka-topics.sh --list --zookeeper localhost:2181\n```\n\n执行以下命令查看某个topic的状态，包含分片信息，复制集信息，分片leader以及`Isr`：\n\n```shell\n> ./bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test_topic_1\n```\n\n需要注意的是， 创建topic时，`replication-factor`不能大于集群中broker的数量，因为每个partition的replication将会均匀分布到不同的broker上；以下是一个partition为2，replication为1的topic信息：\n\n![upload successful](\\blog\\images\\pasted-2.png)\n\n（`Isr`：repliaction副本存活列表，用于leader进行复制集数据同步，这个集合中的所有节点都是存活状态，并且跟leader同步，长时间未与leader进行同步的副本将被踢出该列表）\n\n#### 发布/订阅消息\n\n使用以下命令向`test_topic_1`进入producer控制台，发布消息：\n\n```shell\n./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test_topic_1\n```\n\n另外再开一个session，使用以下命令进入consumer消费`test_topic_1`的消息：\n\n```shell\n./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test_topic_1\n```","source":"_posts/kafka学习笔记（1）——-kafka基本特点以及与其他mq的对比-2.md","raw":"title: kafka学习笔记（1）—— 基础知识\nauthor: 天渊\ntags:\n  - Kafka\n  - 大数据\ncategories:\n  - 基础知识\ndate: 2019-02-13 16:31:00\n---\nKafka是由LinkedIn开发并开源的分布式发布/订阅模式的消息队列系统，因其分布式及高吞吐率而被广泛使用，目前在大数据处理领域占有很重要的地位，能够很方便地与Hadoop, Spark, Storm, Flink和Flume等大数据处理工具进行集成\n<!--more-->\n\n### Kafka主要特点\n\nKafka有三个主要的作用：`传统意义上的消息系统`，`分布式存储`，`流处理工具`\n\n**Kafka最重要的作用就是企业级消息队列服务**：\n\n- 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能\n- Server间的topic分区（partition）消费，保证了高吞吐率，同时保证每个分区内的消息顺序传输\n- 发布/订阅模式中，单个topic支持多consumer，并支持consumer-group自动负载均衡\n\n- 不同于RabbitMQ等传统消息队列，kafka不会删除历史数据\n- 支持数据备份（repliaction），通过master-slave方式保证数据一致性以及高可用\n\n**Kafka-stream**：\n\nKafka Stream是Apache Kafka从0.10版本引入的一个新Feature，它提供了对存储于Kafka内的数据进行流式处理和分析的功能。\n\n### Kafka架构\n\nKafka涉及到的一些专用名词\n\n- **Broker**\n  　　Kafka集群包含一个或多个服务器，这种服务器被称为broker\n- **Topic**\n  　　每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）\n- **Partition**\n  　　分片，每个Topic包含一个或多个Partition.\n- **repliaction**\n  　　复制集，每个partition包含一个或多个repliaction，其中有一个master多个slave\n- **Producer**\n  　　消息发布者，负责发布消息到Kafka broker\n- **Consumer**\n  　　消息消费者，通过拉取的方式向Kafka broker读取消息\n- **Consumer Group**\n  　　每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。\n\nkafka集群拓扑：\n\n![](/blog/images/kafka.png)\n- Kafka集群中包含若干Producer，使用push模式将消息**批量**发布到broker\n- 包含若干broker，支持水平扩展，broker数量越多，集群吞吐率越高，新建的topic-partition及其复制集均分到各个broker上\n- 由Consumer Group管理consumer实例，单个consumer实例可以订阅多个topic，若同一个Consumer Group中的多个consumer实例订阅了同一个topic，则由kafka集群自动进行负载均衡，统一协调分配partition进行消费\n- kafka强依赖Zookeeper集群，通过Zookeeper管理集群配置，保存元数据，选举partition leader，以及在Consumer Group发生变化时进行rebalance\n\n### Kafka与常用MQ对比\n\n- RabbitMQ：支持多种协议栈（AMQP，XMPP, SMTP等），功能更加强大（推拉消费，延迟消费，优先消费等），安全性和可靠性要优于kafka，相比较之下Kafka设计更加简单，吞吐量更高，更加适用于大规模日志数据处理\n- RocketMQ：阿里开源的消息队列，最早思路来源于kafka，具有高吞吐量、高可用性、适合大规模分布式系统应用的特点，相比于kafka在可靠性和稳定性方面均有提升，而且支持事务消息\n- ZeroMQ：号称最快的消息队列系统，具有超高吞吐量，但作用场景有限，大部分情况下作为数据流传输模块嵌入到各个中间件中\n\n### Kafka文件存储方式\n\nKafka以顺序I/O的方式将消息存入磁盘进行持久化，保证了足够的刷盘速度:\n\n- Kafka存储的每条消息数据称为`Message`，每条`Message`数据包含四个属性：`offset`，`MessageSize`，`data`，`timestamp`时间戳即时间戳类型\n\n- Kafka的消息队列在逻辑上是由`partition`的方式存在的，每个`partition`的`repliaction`在物理上由多个`segment`分段组成，每个`segment`数据文件以该段中最小的 offset 命名，文件扩展名为`.log`，查找指定 offset 的 Message 的时候，使用二分查找定位到该 Message 在哪个 `segment` 数据文件；写入消息时直接将消息添加到最新`segment`文件的末尾\n\n- 每个`segment`分段都有自己的索引文件，扩展名为`.index`，索引文件采用稀疏索引的方式建立索引，每隔一定字节的数据建立一条索引，这样避免了索引文件占用过多的空间，从而可以将索引文件保留在内存中\n\n![upload successful](\\blog\\images\\pasted-0.png)\n\n  `log.dirs=/home1/irteam/apps/kafka/data/kafka/kafka-logs`\n\n  在该文件夹中，每个topic的partition都有自己单独的文件夹进行存放，比如`resource-v1-APIGateway-Api`这个topic编号为0的partition放如下位置：\n\n  `/home1/irteam/apps/kafka/data/kafka/kafka-logs/resource-v1-APIGateway-Api-0/`\n  \n![upload successful](\\blog\\images\\pasted-1.png)\n  其中`.index`，`.log`，`.timestamp`三个文件分别对应`分段索引文件`，`分段数据`和`时间索引`\n    \n  **时间索引**：`.timeindex`文件用于保存当前分段中消息发布时间与offset的稀疏索引，用于定期删除消息（`log.retention.hours`参数）\n    \n    \n### Kafka搭建集群即基本操作\n\n1. 前期工作\n\n   首先保证当前主机安装有jdk，推荐jdk 8 及其以上版本\n\n   Kafka发行版自带zookeeper，无需单独安装zookeeper集群，当然也可以自己另外搭建zookeeper集群\n\n   最新版kafka发行版下载地址：\n\n   https://www.apache.org/dyn/closer.cgi?path=/kafka/2.1.0/kafka_2.11-2.1.0.tgz\n\n   下载到本地并解压tar文件得到`kafka_2.11-2.1.0`文件夹 （2.11是kafka源码的scala版本，2.1.0是kafka实际发行版本）：\n   \n2. 初始化配置\n\n   为了简便起见这里就只配置单点broker；进入`config`文件夹，`server.properties`是kafka集群的主配置文件，大部分配置都可以选择默认，部分配置需要注意一下：\n\n   ```properties\n   # 当前主机id，也是集群中唯一id，将保存于zookeeper中\n   broker.id=0\n   # 监听地址和端口，如果没有配置的话默认当前主机名；端口默认9092\n   listeners = PLAINTEXT://your.host.name:9092\n   # 给生产者和消费者的广播地址，如果没设置的话默认采用上面的listeners属性\n   advertised.listeners=PLAINTEXT://your.host.name:9092\n   # kafka数据存放路径\n   log.dirs=/tmp/kafka-logs\n   # topic默认的分片数，创建topic的适合可以单独指定该属性\n   # 理论上，分区数量越多，吞吐量越大，但会造成更严重的资源消耗\n   num.partitions=1\n   # 是否允许自动创建topic（当producer或者consumer发布/订阅某个不存在的topic时）\n   auto.create.topics.enable=true\n   # 是否允许删除topic（删除topic后需要重启broker，不过即使这样也无法完全删除topic数据，需要进入zookeeper删除topic元数据，不过很危险，不推荐）\n   delete.topic.enable=true\n   # kafka采取异步刷盘的方式将内存中收到的消息序列化到硬盘上，下面两个条件任意满足一项即开启刷盘\n   # 每收到10000条消息刷盘一次\n   log.flush.interval.messages=10000\n   # 每隔1000ms刷盘一次\n   log.flush.interval.ms=1000\n   # 消息删除策略，保存消息的最长时间\n   log.retention.hours=168\n   # 单个分区保留消息的最大容量，默认就是1G\n   log.retention.bytes=1073741824\n   # segment分段的最大容量，单个segment超出这个容量后将创建一个新的segment继续保存消息\n   log.segment.bytes=1073741824\n   # 可接收的消息最大大小（压缩后的大小）\n   message.max.bytes=1048576\n   # zookeeper配置\n   zookeeper.connect=localhost:2181\n   zookeeper.connection.timeout.ms=6000\n   ```\n\n   关于kafka broker更详细的配置策略请参考官网：https://kafka.apache.org/documentation/#brokerconfigs\n\n3. 配置完成后，首先启动zookeeper，如果启动的是kafka默认自带的zookeeper的话，进入kafka安装目录，按照以下方式启动：\n\n   ```shell\n   > ./bin/zookeeper-server-start.sh ./config/zookeeper.properties\n   ```\n\n   再执行以下命令可以进入zookeeper，即可查看zookeeper启动状态和执行各种zookeeper相关命令，输入quit退出：\n\n   ```shell\n   > ./bin/zookeeper-shell.sh localhost:2181\n   ```\n\n\n4. zookeeper启动完成后，启动kafka broker （-daemon 参数指定kafka进程后台运行）\n\n   ```shell\n   > ./bin/kafka-server-start.sh -daemon ./config/server.properties\n   ```\n\n   kafka运行日志存放于`安装路径/logs/server.log`中，可以查看运行状态和报错信息\n\n5. 启动完成后进入zookeeper控制台输入`ls /brokers/ids`命令即可查看注册的kafka broker信息\n\n\n### 基本操作\n\n再控制台中进行一些基本操作，包括创建topic，发布和消费数据\n\n#### 创建topic\n\n输入以下命令创建一个名为test_topic_1的topic：\n\n```shell\n> ./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test_topic_1\n```\n\n每次执行kafka脚本都需要指定zookeeper；指定topic的`replication-factor`即复制集数量为1，分片数量`partitions`为1，名称为test_topic_1，然后通过以下命令查看当前所有topic：\n\n```shell\n> ./bin/kafka-topics.sh --list --zookeeper localhost:2181\n```\n\n执行以下命令查看某个topic的状态，包含分片信息，复制集信息，分片leader以及`Isr`：\n\n```shell\n> ./bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test_topic_1\n```\n\n需要注意的是， 创建topic时，`replication-factor`不能大于集群中broker的数量，因为每个partition的replication将会均匀分布到不同的broker上；以下是一个partition为2，replication为1的topic信息：\n\n![upload successful](\\blog\\images\\pasted-2.png)\n\n（`Isr`：repliaction副本存活列表，用于leader进行复制集数据同步，这个集合中的所有节点都是存活状态，并且跟leader同步，长时间未与leader进行同步的副本将被踢出该列表）\n\n#### 发布/订阅消息\n\n使用以下命令向`test_topic_1`进入producer控制台，发布消息：\n\n```shell\n./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test_topic_1\n```\n\n另外再开一个session，使用以下命令进入consumer消费`test_topic_1`的消息：\n\n```shell\n./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test_topic_1\n```","slug":"kafka学习笔记（1）——-kafka基本特点以及与其他mq的对比-2","published":1,"updated":"2021-05-31T03:06:33.197Z","_id":"ckf0h31hv0015actsd5thluzv","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Kafka是由LinkedIn开发并开源的分布式发布/订阅模式的消息队列系统，因其分布式及高吞吐率而被广泛使用，目前在大数据处理领域占有很重要的地位，能够很方便地与Hadoop, Spark, Storm, Flink和Flume等大数据处理工具进行集成<br><a id=\"more\"></a></p>\n<h3 id=\"Kafka主要特点\"><a href=\"#Kafka主要特点\" class=\"headerlink\" title=\"Kafka主要特点\"></a>Kafka主要特点</h3><p>Kafka有三个主要的作用：<code>传统意义上的消息系统</code>，<code>分布式存储</code>，<code>流处理工具</code></p>\n<p><strong>Kafka最重要的作用就是企业级消息队列服务</strong>：</p>\n<ul>\n<li>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能</li>\n<li>Server间的topic分区（partition）消费，保证了高吞吐率，同时保证每个分区内的消息顺序传输</li>\n<li><p>发布/订阅模式中，单个topic支持多consumer，并支持consumer-group自动负载均衡</p>\n</li>\n<li><p>不同于RabbitMQ等传统消息队列，kafka不会删除历史数据</p>\n</li>\n<li>支持数据备份（repliaction），通过master-slave方式保证数据一致性以及高可用</li>\n</ul>\n<p><strong>Kafka-stream</strong>：</p>\n<p>Kafka Stream是Apache Kafka从0.10版本引入的一个新Feature，它提供了对存储于Kafka内的数据进行流式处理和分析的功能。</p>\n<h3 id=\"Kafka架构\"><a href=\"#Kafka架构\" class=\"headerlink\" title=\"Kafka架构\"></a>Kafka架构</h3><p>Kafka涉及到的一些专用名词</p>\n<ul>\n<li><strong>Broker</strong><br>　　Kafka集群包含一个或多个服务器，这种服务器被称为broker</li>\n<li><strong>Topic</strong><br>　　每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</li>\n<li><strong>Partition</strong><br>　　分片，每个Topic包含一个或多个Partition.</li>\n<li><strong>repliaction</strong><br>　　复制集，每个partition包含一个或多个repliaction，其中有一个master多个slave</li>\n<li><strong>Producer</strong><br>　　消息发布者，负责发布消息到Kafka broker</li>\n<li><strong>Consumer</strong><br>　　消息消费者，通过拉取的方式向Kafka broker读取消息</li>\n<li><strong>Consumer Group</strong><br>　　每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</li>\n</ul>\n<p>kafka集群拓扑：</p>\n<p><img src=\"/blog/images/kafka.png\" alt></p>\n<ul>\n<li>Kafka集群中包含若干Producer，使用push模式将消息<strong>批量</strong>发布到broker</li>\n<li>包含若干broker，支持水平扩展，broker数量越多，集群吞吐率越高，新建的topic-partition及其复制集均分到各个broker上</li>\n<li>由Consumer Group管理consumer实例，单个consumer实例可以订阅多个topic，若同一个Consumer Group中的多个consumer实例订阅了同一个topic，则由kafka集群自动进行负载均衡，统一协调分配partition进行消费</li>\n<li>kafka强依赖Zookeeper集群，通过Zookeeper管理集群配置，保存元数据，选举partition leader，以及在Consumer Group发生变化时进行rebalance</li>\n</ul>\n<h3 id=\"Kafka与常用MQ对比\"><a href=\"#Kafka与常用MQ对比\" class=\"headerlink\" title=\"Kafka与常用MQ对比\"></a>Kafka与常用MQ对比</h3><ul>\n<li>RabbitMQ：支持多种协议栈（AMQP，XMPP, SMTP等），功能更加强大（推拉消费，延迟消费，优先消费等），安全性和可靠性要优于kafka，相比较之下Kafka设计更加简单，吞吐量更高，更加适用于大规模日志数据处理</li>\n<li>RocketMQ：阿里开源的消息队列，最早思路来源于kafka，具有高吞吐量、高可用性、适合大规模分布式系统应用的特点，相比于kafka在可靠性和稳定性方面均有提升，而且支持事务消息</li>\n<li>ZeroMQ：号称最快的消息队列系统，具有超高吞吐量，但作用场景有限，大部分情况下作为数据流传输模块嵌入到各个中间件中</li>\n</ul>\n<h3 id=\"Kafka文件存储方式\"><a href=\"#Kafka文件存储方式\" class=\"headerlink\" title=\"Kafka文件存储方式\"></a>Kafka文件存储方式</h3><p>Kafka以顺序I/O的方式将消息存入磁盘进行持久化，保证了足够的刷盘速度:</p>\n<ul>\n<li><p>Kafka存储的每条消息数据称为<code>Message</code>，每条<code>Message</code>数据包含四个属性：<code>offset</code>，<code>MessageSize</code>，<code>data</code>，<code>timestamp</code>时间戳即时间戳类型</p>\n</li>\n<li><p>Kafka的消息队列在逻辑上是由<code>partition</code>的方式存在的，每个<code>partition</code>的<code>repliaction</code>在物理上由多个<code>segment</code>分段组成，每个<code>segment</code>数据文件以该段中最小的 offset 命名，文件扩展名为<code>.log</code>，查找指定 offset 的 Message 的时候，使用二分查找定位到该 Message 在哪个 <code>segment</code> 数据文件；写入消息时直接将消息添加到最新<code>segment</code>文件的末尾</p>\n</li>\n<li><p>每个<code>segment</code>分段都有自己的索引文件，扩展名为<code>.index</code>，索引文件采用稀疏索引的方式建立索引，每隔一定字节的数据建立一条索引，这样避免了索引文件占用过多的空间，从而可以将索引文件保留在内存中</p>\n</li>\n</ul>\n<p><img src=\"\\blog\\images\\pasted-0.png\" alt=\"upload successful\"></p>\n<p>  <code>log.dirs=/home1/irteam/apps/kafka/data/kafka/kafka-logs</code></p>\n<p>  在该文件夹中，每个topic的partition都有自己单独的文件夹进行存放，比如<code>resource-v1-APIGateway-Api</code>这个topic编号为0的partition放如下位置：</p>\n<p>  <code>/home1/irteam/apps/kafka/data/kafka/kafka-logs/resource-v1-APIGateway-Api-0/</code></p>\n<p><img src=\"\\blog\\images\\pasted-1.png\" alt=\"upload successful\"><br>  其中<code>.index</code>，<code>.log</code>，<code>.timestamp</code>三个文件分别对应<code>分段索引文件</code>，<code>分段数据</code>和<code>时间索引</code></p>\n<p>  <strong>时间索引</strong>：<code>.timeindex</code>文件用于保存当前分段中消息发布时间与offset的稀疏索引，用于定期删除消息（<code>log.retention.hours</code>参数）</p>\n<h3 id=\"Kafka搭建集群即基本操作\"><a href=\"#Kafka搭建集群即基本操作\" class=\"headerlink\" title=\"Kafka搭建集群即基本操作\"></a>Kafka搭建集群即基本操作</h3><ol>\n<li><p>前期工作</p>\n<p>首先保证当前主机安装有jdk，推荐jdk 8 及其以上版本</p>\n<p>Kafka发行版自带zookeeper，无需单独安装zookeeper集群，当然也可以自己另外搭建zookeeper集群</p>\n<p>最新版kafka发行版下载地址：</p>\n<p><a href=\"https://www.apache.org/dyn/closer.cgi?path=/kafka/2.1.0/kafka_2.11-2.1.0.tgz\" target=\"_blank\" rel=\"noopener\">https://www.apache.org/dyn/closer.cgi?path=/kafka/2.1.0/kafka_2.11-2.1.0.tgz</a></p>\n<p>下载到本地并解压tar文件得到<code>kafka_2.11-2.1.0</code>文件夹 （2.11是kafka源码的scala版本，2.1.0是kafka实际发行版本）：</p>\n</li>\n<li><p>初始化配置</p>\n<p>为了简便起见这里就只配置单点broker；进入<code>config</code>文件夹，<code>server.properties</code>是kafka集群的主配置文件，大部分配置都可以选择默认，部分配置需要注意一下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 当前主机id，也是集群中唯一id，将保存于zookeeper中</span><br><span class=\"line\">broker.id=0</span><br><span class=\"line\"># 监听地址和端口，如果没有配置的话默认当前主机名；端口默认9092</span><br><span class=\"line\">listeners = PLAINTEXT://your.host.name:9092</span><br><span class=\"line\"># 给生产者和消费者的广播地址，如果没设置的话默认采用上面的listeners属性</span><br><span class=\"line\">advertised.listeners=PLAINTEXT://your.host.name:9092</span><br><span class=\"line\"># kafka数据存放路径</span><br><span class=\"line\">log.dirs=/tmp/kafka-logs</span><br><span class=\"line\"># topic默认的分片数，创建topic的适合可以单独指定该属性</span><br><span class=\"line\"># 理论上，分区数量越多，吞吐量越大，但会造成更严重的资源消耗</span><br><span class=\"line\">num.partitions=1</span><br><span class=\"line\"># 是否允许自动创建topic（当producer或者consumer发布/订阅某个不存在的topic时）</span><br><span class=\"line\">auto.create.topics.enable=true</span><br><span class=\"line\"># 是否允许删除topic（删除topic后需要重启broker，不过即使这样也无法完全删除topic数据，需要进入zookeeper删除topic元数据，不过很危险，不推荐）</span><br><span class=\"line\">delete.topic.enable=true</span><br><span class=\"line\"># kafka采取异步刷盘的方式将内存中收到的消息序列化到硬盘上，下面两个条件任意满足一项即开启刷盘</span><br><span class=\"line\"># 每收到10000条消息刷盘一次</span><br><span class=\"line\">log.flush.interval.messages=10000</span><br><span class=\"line\"># 每隔1000ms刷盘一次</span><br><span class=\"line\">log.flush.interval.ms=1000</span><br><span class=\"line\"># 消息删除策略，保存消息的最长时间</span><br><span class=\"line\">log.retention.hours=168</span><br><span class=\"line\"># 单个分区保留消息的最大容量，默认就是1G</span><br><span class=\"line\">log.retention.bytes=1073741824</span><br><span class=\"line\"># segment分段的最大容量，单个segment超出这个容量后将创建一个新的segment继续保存消息</span><br><span class=\"line\">log.segment.bytes=1073741824</span><br><span class=\"line\"># 可接收的消息最大大小（压缩后的大小）</span><br><span class=\"line\">message.max.bytes=1048576</span><br><span class=\"line\"># zookeeper配置</span><br><span class=\"line\">zookeeper.connect=localhost:2181</span><br><span class=\"line\">zookeeper.connection.timeout.ms=6000</span><br></pre></td></tr></table></figure>\n<p>关于kafka broker更详细的配置策略请参考官网：<a href=\"https://kafka.apache.org/documentation/#brokerconfigs\" target=\"_blank\" rel=\"noopener\">https://kafka.apache.org/documentation/#brokerconfigs</a></p>\n</li>\n<li><p>配置完成后，首先启动zookeeper，如果启动的是kafka默认自带的zookeeper的话，进入kafka安装目录，按照以下方式启动：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span> ./bin/zookeeper-server-start.sh ./config/zookeeper.properties</span><br></pre></td></tr></table></figure>\n<p>再执行以下命令可以进入zookeeper，即可查看zookeeper启动状态和执行各种zookeeper相关命令，输入quit退出：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span> ./bin/zookeeper-shell.sh localhost:2181</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>zookeeper启动完成后，启动kafka broker （-daemon 参数指定kafka进程后台运行）</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span> ./bin/kafka-server-start.sh -daemon ./config/server.properties</span><br></pre></td></tr></table></figure>\n<p>kafka运行日志存放于<code>安装路径/logs/server.log</code>中，可以查看运行状态和报错信息</p>\n</li>\n<li><p>启动完成后进入zookeeper控制台输入<code>ls /brokers/ids</code>命令即可查看注册的kafka broker信息</p>\n</li>\n</ol>\n<h3 id=\"基本操作\"><a href=\"#基本操作\" class=\"headerlink\" title=\"基本操作\"></a>基本操作</h3><p>再控制台中进行一些基本操作，包括创建topic，发布和消费数据</p>\n<h4 id=\"创建topic\"><a href=\"#创建topic\" class=\"headerlink\" title=\"创建topic\"></a>创建topic</h4><p>输入以下命令创建一个名为test_topic_1的topic：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span> ./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test_topic_1</span><br></pre></td></tr></table></figure>\n<p>每次执行kafka脚本都需要指定zookeeper；指定topic的<code>replication-factor</code>即复制集数量为1，分片数量<code>partitions</code>为1，名称为test_topic_1，然后通过以下命令查看当前所有topic：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span> ./bin/kafka-topics.sh --list --zookeeper localhost:2181</span><br></pre></td></tr></table></figure>\n<p>执行以下命令查看某个topic的状态，包含分片信息，复制集信息，分片leader以及<code>Isr</code>：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span> ./bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test_topic_1</span><br></pre></td></tr></table></figure>\n<p>需要注意的是， 创建topic时，<code>replication-factor</code>不能大于集群中broker的数量，因为每个partition的replication将会均匀分布到不同的broker上；以下是一个partition为2，replication为1的topic信息：</p>\n<p><img src=\"\\blog\\images\\pasted-2.png\" alt=\"upload successful\"></p>\n<p>（<code>Isr</code>：repliaction副本存活列表，用于leader进行复制集数据同步，这个集合中的所有节点都是存活状态，并且跟leader同步，长时间未与leader进行同步的副本将被踢出该列表）</p>\n<h4 id=\"发布-订阅消息\"><a href=\"#发布-订阅消息\" class=\"headerlink\" title=\"发布/订阅消息\"></a>发布/订阅消息</h4><p>使用以下命令向<code>test_topic_1</code>进入producer控制台，发布消息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test_topic_1</span><br></pre></td></tr></table></figure>\n<p>另外再开一个session，使用以下命令进入consumer消费<code>test_topic_1</code>的消息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test_topic_1</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<p>Kafka是由LinkedIn开发并开源的分布式发布/订阅模式的消息队列系统，因其分布式及高吞吐率而被广泛使用，目前在大数据处理领域占有很重要的地位，能够很方便地与Hadoop, Spark, Storm, Flink和Flume等大数据处理工具进行集成<br>","more":"</p>\n<h3 id=\"Kafka主要特点\"><a href=\"#Kafka主要特点\" class=\"headerlink\" title=\"Kafka主要特点\"></a>Kafka主要特点</h3><p>Kafka有三个主要的作用：<code>传统意义上的消息系统</code>，<code>分布式存储</code>，<code>流处理工具</code></p>\n<p><strong>Kafka最重要的作用就是企业级消息队列服务</strong>：</p>\n<ul>\n<li>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能</li>\n<li>Server间的topic分区（partition）消费，保证了高吞吐率，同时保证每个分区内的消息顺序传输</li>\n<li><p>发布/订阅模式中，单个topic支持多consumer，并支持consumer-group自动负载均衡</p>\n</li>\n<li><p>不同于RabbitMQ等传统消息队列，kafka不会删除历史数据</p>\n</li>\n<li>支持数据备份（repliaction），通过master-slave方式保证数据一致性以及高可用</li>\n</ul>\n<p><strong>Kafka-stream</strong>：</p>\n<p>Kafka Stream是Apache Kafka从0.10版本引入的一个新Feature，它提供了对存储于Kafka内的数据进行流式处理和分析的功能。</p>\n<h3 id=\"Kafka架构\"><a href=\"#Kafka架构\" class=\"headerlink\" title=\"Kafka架构\"></a>Kafka架构</h3><p>Kafka涉及到的一些专用名词</p>\n<ul>\n<li><strong>Broker</strong><br>　　Kafka集群包含一个或多个服务器，这种服务器被称为broker</li>\n<li><strong>Topic</strong><br>　　每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</li>\n<li><strong>Partition</strong><br>　　分片，每个Topic包含一个或多个Partition.</li>\n<li><strong>repliaction</strong><br>　　复制集，每个partition包含一个或多个repliaction，其中有一个master多个slave</li>\n<li><strong>Producer</strong><br>　　消息发布者，负责发布消息到Kafka broker</li>\n<li><strong>Consumer</strong><br>　　消息消费者，通过拉取的方式向Kafka broker读取消息</li>\n<li><strong>Consumer Group</strong><br>　　每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</li>\n</ul>\n<p>kafka集群拓扑：</p>\n<p><img src=\"/blog/images/kafka.png\" alt></p>\n<ul>\n<li>Kafka集群中包含若干Producer，使用push模式将消息<strong>批量</strong>发布到broker</li>\n<li>包含若干broker，支持水平扩展，broker数量越多，集群吞吐率越高，新建的topic-partition及其复制集均分到各个broker上</li>\n<li>由Consumer Group管理consumer实例，单个consumer实例可以订阅多个topic，若同一个Consumer Group中的多个consumer实例订阅了同一个topic，则由kafka集群自动进行负载均衡，统一协调分配partition进行消费</li>\n<li>kafka强依赖Zookeeper集群，通过Zookeeper管理集群配置，保存元数据，选举partition leader，以及在Consumer Group发生变化时进行rebalance</li>\n</ul>\n<h3 id=\"Kafka与常用MQ对比\"><a href=\"#Kafka与常用MQ对比\" class=\"headerlink\" title=\"Kafka与常用MQ对比\"></a>Kafka与常用MQ对比</h3><ul>\n<li>RabbitMQ：支持多种协议栈（AMQP，XMPP, SMTP等），功能更加强大（推拉消费，延迟消费，优先消费等），安全性和可靠性要优于kafka，相比较之下Kafka设计更加简单，吞吐量更高，更加适用于大规模日志数据处理</li>\n<li>RocketMQ：阿里开源的消息队列，最早思路来源于kafka，具有高吞吐量、高可用性、适合大规模分布式系统应用的特点，相比于kafka在可靠性和稳定性方面均有提升，而且支持事务消息</li>\n<li>ZeroMQ：号称最快的消息队列系统，具有超高吞吐量，但作用场景有限，大部分情况下作为数据流传输模块嵌入到各个中间件中</li>\n</ul>\n<h3 id=\"Kafka文件存储方式\"><a href=\"#Kafka文件存储方式\" class=\"headerlink\" title=\"Kafka文件存储方式\"></a>Kafka文件存储方式</h3><p>Kafka以顺序I/O的方式将消息存入磁盘进行持久化，保证了足够的刷盘速度:</p>\n<ul>\n<li><p>Kafka存储的每条消息数据称为<code>Message</code>，每条<code>Message</code>数据包含四个属性：<code>offset</code>，<code>MessageSize</code>，<code>data</code>，<code>timestamp</code>时间戳即时间戳类型</p>\n</li>\n<li><p>Kafka的消息队列在逻辑上是由<code>partition</code>的方式存在的，每个<code>partition</code>的<code>repliaction</code>在物理上由多个<code>segment</code>分段组成，每个<code>segment</code>数据文件以该段中最小的 offset 命名，文件扩展名为<code>.log</code>，查找指定 offset 的 Message 的时候，使用二分查找定位到该 Message 在哪个 <code>segment</code> 数据文件；写入消息时直接将消息添加到最新<code>segment</code>文件的末尾</p>\n</li>\n<li><p>每个<code>segment</code>分段都有自己的索引文件，扩展名为<code>.index</code>，索引文件采用稀疏索引的方式建立索引，每隔一定字节的数据建立一条索引，这样避免了索引文件占用过多的空间，从而可以将索引文件保留在内存中</p>\n</li>\n</ul>\n<p><img src=\"\\blog\\images\\pasted-0.png\" alt=\"upload successful\"></p>\n<p>  <code>log.dirs=/home1/irteam/apps/kafka/data/kafka/kafka-logs</code></p>\n<p>  在该文件夹中，每个topic的partition都有自己单独的文件夹进行存放，比如<code>resource-v1-APIGateway-Api</code>这个topic编号为0的partition放如下位置：</p>\n<p>  <code>/home1/irteam/apps/kafka/data/kafka/kafka-logs/resource-v1-APIGateway-Api-0/</code></p>\n<p><img src=\"\\blog\\images\\pasted-1.png\" alt=\"upload successful\"><br>  其中<code>.index</code>，<code>.log</code>，<code>.timestamp</code>三个文件分别对应<code>分段索引文件</code>，<code>分段数据</code>和<code>时间索引</code></p>\n<p>  <strong>时间索引</strong>：<code>.timeindex</code>文件用于保存当前分段中消息发布时间与offset的稀疏索引，用于定期删除消息（<code>log.retention.hours</code>参数）</p>\n<h3 id=\"Kafka搭建集群即基本操作\"><a href=\"#Kafka搭建集群即基本操作\" class=\"headerlink\" title=\"Kafka搭建集群即基本操作\"></a>Kafka搭建集群即基本操作</h3><ol>\n<li><p>前期工作</p>\n<p>首先保证当前主机安装有jdk，推荐jdk 8 及其以上版本</p>\n<p>Kafka发行版自带zookeeper，无需单独安装zookeeper集群，当然也可以自己另外搭建zookeeper集群</p>\n<p>最新版kafka发行版下载地址：</p>\n<p><a href=\"https://www.apache.org/dyn/closer.cgi?path=/kafka/2.1.0/kafka_2.11-2.1.0.tgz\" target=\"_blank\" rel=\"noopener\">https://www.apache.org/dyn/closer.cgi?path=/kafka/2.1.0/kafka_2.11-2.1.0.tgz</a></p>\n<p>下载到本地并解压tar文件得到<code>kafka_2.11-2.1.0</code>文件夹 （2.11是kafka源码的scala版本，2.1.0是kafka实际发行版本）：</p>\n</li>\n<li><p>初始化配置</p>\n<p>为了简便起见这里就只配置单点broker；进入<code>config</code>文件夹，<code>server.properties</code>是kafka集群的主配置文件，大部分配置都可以选择默认，部分配置需要注意一下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 当前主机id，也是集群中唯一id，将保存于zookeeper中</span><br><span class=\"line\">broker.id=0</span><br><span class=\"line\"># 监听地址和端口，如果没有配置的话默认当前主机名；端口默认9092</span><br><span class=\"line\">listeners = PLAINTEXT://your.host.name:9092</span><br><span class=\"line\"># 给生产者和消费者的广播地址，如果没设置的话默认采用上面的listeners属性</span><br><span class=\"line\">advertised.listeners=PLAINTEXT://your.host.name:9092</span><br><span class=\"line\"># kafka数据存放路径</span><br><span class=\"line\">log.dirs=/tmp/kafka-logs</span><br><span class=\"line\"># topic默认的分片数，创建topic的适合可以单独指定该属性</span><br><span class=\"line\"># 理论上，分区数量越多，吞吐量越大，但会造成更严重的资源消耗</span><br><span class=\"line\">num.partitions=1</span><br><span class=\"line\"># 是否允许自动创建topic（当producer或者consumer发布/订阅某个不存在的topic时）</span><br><span class=\"line\">auto.create.topics.enable=true</span><br><span class=\"line\"># 是否允许删除topic（删除topic后需要重启broker，不过即使这样也无法完全删除topic数据，需要进入zookeeper删除topic元数据，不过很危险，不推荐）</span><br><span class=\"line\">delete.topic.enable=true</span><br><span class=\"line\"># kafka采取异步刷盘的方式将内存中收到的消息序列化到硬盘上，下面两个条件任意满足一项即开启刷盘</span><br><span class=\"line\"># 每收到10000条消息刷盘一次</span><br><span class=\"line\">log.flush.interval.messages=10000</span><br><span class=\"line\"># 每隔1000ms刷盘一次</span><br><span class=\"line\">log.flush.interval.ms=1000</span><br><span class=\"line\"># 消息删除策略，保存消息的最长时间</span><br><span class=\"line\">log.retention.hours=168</span><br><span class=\"line\"># 单个分区保留消息的最大容量，默认就是1G</span><br><span class=\"line\">log.retention.bytes=1073741824</span><br><span class=\"line\"># segment分段的最大容量，单个segment超出这个容量后将创建一个新的segment继续保存消息</span><br><span class=\"line\">log.segment.bytes=1073741824</span><br><span class=\"line\"># 可接收的消息最大大小（压缩后的大小）</span><br><span class=\"line\">message.max.bytes=1048576</span><br><span class=\"line\"># zookeeper配置</span><br><span class=\"line\">zookeeper.connect=localhost:2181</span><br><span class=\"line\">zookeeper.connection.timeout.ms=6000</span><br></pre></td></tr></table></figure>\n<p>关于kafka broker更详细的配置策略请参考官网：<a href=\"https://kafka.apache.org/documentation/#brokerconfigs\" target=\"_blank\" rel=\"noopener\">https://kafka.apache.org/documentation/#brokerconfigs</a></p>\n</li>\n<li><p>配置完成后，首先启动zookeeper，如果启动的是kafka默认自带的zookeeper的话，进入kafka安装目录，按照以下方式启动：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span> ./bin/zookeeper-server-start.sh ./config/zookeeper.properties</span><br></pre></td></tr></table></figure>\n<p>再执行以下命令可以进入zookeeper，即可查看zookeeper启动状态和执行各种zookeeper相关命令，输入quit退出：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span> ./bin/zookeeper-shell.sh localhost:2181</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>zookeeper启动完成后，启动kafka broker （-daemon 参数指定kafka进程后台运行）</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span> ./bin/kafka-server-start.sh -daemon ./config/server.properties</span><br></pre></td></tr></table></figure>\n<p>kafka运行日志存放于<code>安装路径/logs/server.log</code>中，可以查看运行状态和报错信息</p>\n</li>\n<li><p>启动完成后进入zookeeper控制台输入<code>ls /brokers/ids</code>命令即可查看注册的kafka broker信息</p>\n</li>\n</ol>\n<h3 id=\"基本操作\"><a href=\"#基本操作\" class=\"headerlink\" title=\"基本操作\"></a>基本操作</h3><p>再控制台中进行一些基本操作，包括创建topic，发布和消费数据</p>\n<h4 id=\"创建topic\"><a href=\"#创建topic\" class=\"headerlink\" title=\"创建topic\"></a>创建topic</h4><p>输入以下命令创建一个名为test_topic_1的topic：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span> ./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test_topic_1</span><br></pre></td></tr></table></figure>\n<p>每次执行kafka脚本都需要指定zookeeper；指定topic的<code>replication-factor</code>即复制集数量为1，分片数量<code>partitions</code>为1，名称为test_topic_1，然后通过以下命令查看当前所有topic：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span> ./bin/kafka-topics.sh --list --zookeeper localhost:2181</span><br></pre></td></tr></table></figure>\n<p>执行以下命令查看某个topic的状态，包含分片信息，复制集信息，分片leader以及<code>Isr</code>：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span> ./bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test_topic_1</span><br></pre></td></tr></table></figure>\n<p>需要注意的是， 创建topic时，<code>replication-factor</code>不能大于集群中broker的数量，因为每个partition的replication将会均匀分布到不同的broker上；以下是一个partition为2，replication为1的topic信息：</p>\n<p><img src=\"\\blog\\images\\pasted-2.png\" alt=\"upload successful\"></p>\n<p>（<code>Isr</code>：repliaction副本存活列表，用于leader进行复制集数据同步，这个集合中的所有节点都是存活状态，并且跟leader同步，长时间未与leader进行同步的副本将被踢出该列表）</p>\n<h4 id=\"发布-订阅消息\"><a href=\"#发布-订阅消息\" class=\"headerlink\" title=\"发布/订阅消息\"></a>发布/订阅消息</h4><p>使用以下命令向<code>test_topic_1</code>进入producer控制台，发布消息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test_topic_1</span><br></pre></td></tr></table></figure>\n<p>另外再开一个session，使用以下命令进入consumer消费<code>test_topic_1</code>的消息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test_topic_1</span><br></pre></td></tr></table></figure>"},{"title":"kafka学习笔记（2）—— 生产者 producer","author":"天渊","date":"2019-03-18T04:43:00.000Z","_content":"kafka作为大数据日志收集系统，能够接收来自多端的生产者数据，下图是消息经由`kafka-producer-api`向kafka集群发送消息的基本过程：\n<!--more-->\n\n![upload successful](\\blog\\images\\pasted-3.png)\n\n下面用kafka-producer的java api来进行说明\n\n\n### kafka-producer java api\n\n#### KafkaProducer基本操作\n\n项目中引入以下依赖：\n\n```xml\n<dependency>\n    <groupId>org.apache.kafka</groupId>\n    <artifactId>kafka-clients</artifactId>\n    <version>2.1.1</version>\n</dependency>\n```\n\n最新版本的kafka-producer-api取消了同步发送消息的模式，全部默认采用异步发送消息，使用异步线程从发送队列中批量发送消息，然后返回一个`Future`对象\n\n首先创建producer并进行配置，以下三个配置项是必选配置，其他配置都是可选配置：\n\n```java\nMap<String, Object> producerConfig = new HashMap<>();\nproducerConfig.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"10.106.151.187:9092\");\nproducerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\nproducerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\nProducer<String, String> producer = new KafkaProducer<>(producerConfig);\n```\n\n构建record并发送，发送成功后返回topic和partition的元数据：\n\n```java\nProducerRecord<String, String> record = new ProducerRecord<>(\"test-topic-1\", \"it's a msg\");\nFuture<RecordMetadata> future = producer.send(record);\nRecordMetadata recordMetadata = future.get();\nSystem.out.println(\"offset:\" + recordMetadata.offset());\nSystem.out.println(\"partition id: \" + recordMetadata.partition());\nSystem.out.println(\"topic: \" + recordMetadata.topic());\n```\n\n也可以设置回调函数，对Future进行消费：\n\n```java\nCountDownLatch latch = new CountDownLatch(1);\nproducer.send(record, (recordMetadata, e) -> {\n    System.out.println(\"offset:\" + recordMetadata.offset());\n    System.out.println(\"partition id: \" + recordMetadata.partition());\n    System.out.println(\"topic: \" + recordMetadata.topic());\n    if (e != null) {\n        e.printStackTrace();\n    }\n    latch.countDown();\n});\nlatch.await();\n```\n\n#### KafkaProducer配置解析\n\n除了`bootstrap.servers`, `key.serializer`,`value.serializer` 这三个配置项是必选配置，其他配置都是可选的：\n\n```properties\n# 指定目标分区有多少个副本成功收到消息时，producer才会收到消息发送成功的响应\n# 1：leader节点成功收到消息后即认为消息发送成功，一般采用这个\n# all：所有replica节点都成功收到消息后才认为消息发送成功\n# 0：producer无需等待任何发送成功的响应，消息发送完毕后即返回\nacks=1\n# 生产者缓冲区大小，消息发送到broker前可以在producer内存中进行缓冲，如果待发送的消息大小超过该值，后续发送请求则会阻塞\nbuffer.memory=33554432\n# 和上述配置协同工作，当缓冲区不足时后续请求能够阻塞的最大时间，超过该值仍然阻塞则会抛异常\nmax.block.ms=60000\n# 消息压缩方式\n# snappy：cpu消耗低，性能好； gzip：cpu消耗高，压缩比较snappy更高\ncompression.type=snappy\n# 消息发送失败后的重试次数（部分错误像“消息太大”之类的错误默认不重试直接报错）\nretries=3\n# 消息发送失败后每次重试的间隔时间\nretry.backoff.ms=100\n# 消息发送的单个batch大小，把多个消息合并为一个请求可以提高网络利用率，提高吞吐量，但也某种程度造成了消息延迟\nbatch.size=16384\n# 同样服务于消息batch，producer将等待直到消息填满一个batch或者达到linger时间后直接进行发送该批次消息\nlinger.ms=5\n# producer允许的未返回响应的最大请求个数，如果为1，则producer在未收到当前请求的响应前不会发送后续请求\n# 调高该值可以提高吞吐量，前提是对消息发送顺序没要求（如果开启retry的话有可能打乱消息发布的顺序）\nmax.in.flight.requests.per.connection=5\n# producer单次发送的最大容量，保证这个值不超过broker的message.max.bytes属性即可\nmax.request.size=1048576\n# 发布消息的请求响应超时时间，超出该值要么重试要么报错\nrequest.timeout.ms=30000\n```\n\n关于kafka-producer配置的一些问题如下：\n\n1. 如何保证消息发布顺序：如果同时配置了`retries`和`max.in.flight.requests.per.connection`，当后者大于1时，有可能造成消息发布乱序（比如，消息1发布失败，消息2发布成功，紧接着重试发送消息1并成功），所以官方建议如果配置了大于0的`retries`，`max.in.flight.requests.per.connection`最好设置为1\n\n2. 幂等消息：为了避免消息重复发布，支持单个producer对于同一个`Topic,Partition`的`Exactly Once`语义，kafka在`0.11.0.0`后引入了对幂等消息的支持，通过以下配置进行开启：\n\n   ```properties\n   # 开启幂等producer\n   enable.idempotence=true\n   # 如果开启幂等producer，必须对以下配置进行如下的设置\n   acks = all\n   retries = （大于0）\n   max.inflight.requests.per.connection = （小于等于5）\n   ```\n\n3. 事务支持：kafka同时在`0.11.0.0`版本引入了事务支持，支持跨partition幂等发布消息，保证了跨分区发布消息的原子性，通过以下配置进行开启：\n\n   ```properties\n   # 设置一个字符串表示事务id\n   # 开启事务后，enable.idempotence默认设置为true\n   transactional.id=my_tx_id_1\n   ```\n\n\n#### Kafka-producer序列化器\n\nKafka消息队列没有规定具体的消息传输协议和消息格式，队列中统一传输二进制数据流，因此需要用户根据自己消息的协议和格式选取合适的序列化器，或者自定义序列化器\n\nKafka默认提供的常用序列化器有有以下几种，基本上只能用于基本数据类型和字节数组或者ByteBuffer对象的序列化：\n\n```properties\nStringDeserializer\nIntegerSerializer\nByteArraySerializer\nByteBufferSerializer\nDoubleSerializer\nUUIDSerializer\n```\n\n用户自定义序列化器直接实现`Serializer`接口即可，如下实现一个简单的Json格式的序列化器：\n\n```java\npublic class SimpleJsonSerializer implements Serializer {\n\tprivate final Gson gson = new Gson();\n\t@Override\n\tpublic void configure(Map configs, boolean isKey) {\n\t}\n\t@Override\n\tpublic byte[] serialize(String topic, Object data) {\n\t\tString json = gson.toJson(data);\n\t\treturn json.getBytes(Charset.defaultCharset());\n\t}\n\t@Override\n\tpublic void close() {\n\t}\n}\n```\n\n然后在producer中进行配置，即可将java对象序列化为json字节数组了：\n\n```java\nMap<String, Object> producerConfig = new HashMap<>();\nproducerConfig.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"10.106.151.187:9092\");\nproducerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\nproducerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, SimpleJsonSerializer.class);\nproducerConfig.put(ProducerConfig.ACKS_CONFIG, \"1\");\nProducer<String, Person> producer = new KafkaProducer<>(producerConfig);\n\nProducerRecord<String, Person> record = new ProducerRecord<>(\"test-topic-1\", Person.builder().id(0).name(\"liugeng\").build());\n\n```\n\n#### kafka-producer分区器\n\nproducer发送消息时无需手动指定发送到某个partition，producer-api默认的`DefaultPartitioner`会根据消息中有无设置key来进行分区操作：\n\n1. key不为null：计算key的hash值，然后和partition数量取模，映射到不同的partition中\n2. key为null：使用Round-Robin进行轮询映射\n\n如果需要自己实现分区器（例如需要根据key指定特定的分区，或者某个key的消息需要占用多个分区），可以实现`Partitioner`接口，以下是一个例子，将key为`last`的record映射到最后一个partition上，剩下的record通过hash映射到其他partition：\n\n```java\npublic class SimpleCustomerPartitioner implements Partitioner {\n\t@Override\n\tpublic int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n\t\tList<PartitionInfo> partitionInfoList = cluster.availablePartitionsForTopic(topic);\n\t\tint partitionNum = partitionInfoList.size();\n\t\tif (keyBytes == null || !(key instanceof String)) {\n\t\t\tthrow new InvalidRecordException(\"the key is necessary !\");\n\t\t}\n\t\tif (\"last\".equals(key)) {\n\t\t\treturn partitionNum - 1;\n\t\t}\n\t\treturn Math.abs(Utils.murmur2(keyBytes)) % (partitionNum -1);\n\t}\n\t@Override\n\tpublic void close() {\n\t}\n\t@Override\n\tpublic void configure(Map<String, ?> configs) {\n\t}\n}\n```\n\n分区器的`partition`方法返回指定partition的id，需要注意的是partition的id是从0开始的\n","source":"_posts/kafka学习笔记（2）——-生产者-producer.md","raw":"title: kafka学习笔记（2）—— 生产者 producer\nauthor: 天渊\ntags:\n  - Kafka\n  - 大数据\ncategories:\n  - 基础知识\ndate: 2019-03-18 12:43:00\n---\nkafka作为大数据日志收集系统，能够接收来自多端的生产者数据，下图是消息经由`kafka-producer-api`向kafka集群发送消息的基本过程：\n<!--more-->\n\n![upload successful](\\blog\\images\\pasted-3.png)\n\n下面用kafka-producer的java api来进行说明\n\n\n### kafka-producer java api\n\n#### KafkaProducer基本操作\n\n项目中引入以下依赖：\n\n```xml\n<dependency>\n    <groupId>org.apache.kafka</groupId>\n    <artifactId>kafka-clients</artifactId>\n    <version>2.1.1</version>\n</dependency>\n```\n\n最新版本的kafka-producer-api取消了同步发送消息的模式，全部默认采用异步发送消息，使用异步线程从发送队列中批量发送消息，然后返回一个`Future`对象\n\n首先创建producer并进行配置，以下三个配置项是必选配置，其他配置都是可选配置：\n\n```java\nMap<String, Object> producerConfig = new HashMap<>();\nproducerConfig.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"10.106.151.187:9092\");\nproducerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\nproducerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\nProducer<String, String> producer = new KafkaProducer<>(producerConfig);\n```\n\n构建record并发送，发送成功后返回topic和partition的元数据：\n\n```java\nProducerRecord<String, String> record = new ProducerRecord<>(\"test-topic-1\", \"it's a msg\");\nFuture<RecordMetadata> future = producer.send(record);\nRecordMetadata recordMetadata = future.get();\nSystem.out.println(\"offset:\" + recordMetadata.offset());\nSystem.out.println(\"partition id: \" + recordMetadata.partition());\nSystem.out.println(\"topic: \" + recordMetadata.topic());\n```\n\n也可以设置回调函数，对Future进行消费：\n\n```java\nCountDownLatch latch = new CountDownLatch(1);\nproducer.send(record, (recordMetadata, e) -> {\n    System.out.println(\"offset:\" + recordMetadata.offset());\n    System.out.println(\"partition id: \" + recordMetadata.partition());\n    System.out.println(\"topic: \" + recordMetadata.topic());\n    if (e != null) {\n        e.printStackTrace();\n    }\n    latch.countDown();\n});\nlatch.await();\n```\n\n#### KafkaProducer配置解析\n\n除了`bootstrap.servers`, `key.serializer`,`value.serializer` 这三个配置项是必选配置，其他配置都是可选的：\n\n```properties\n# 指定目标分区有多少个副本成功收到消息时，producer才会收到消息发送成功的响应\n# 1：leader节点成功收到消息后即认为消息发送成功，一般采用这个\n# all：所有replica节点都成功收到消息后才认为消息发送成功\n# 0：producer无需等待任何发送成功的响应，消息发送完毕后即返回\nacks=1\n# 生产者缓冲区大小，消息发送到broker前可以在producer内存中进行缓冲，如果待发送的消息大小超过该值，后续发送请求则会阻塞\nbuffer.memory=33554432\n# 和上述配置协同工作，当缓冲区不足时后续请求能够阻塞的最大时间，超过该值仍然阻塞则会抛异常\nmax.block.ms=60000\n# 消息压缩方式\n# snappy：cpu消耗低，性能好； gzip：cpu消耗高，压缩比较snappy更高\ncompression.type=snappy\n# 消息发送失败后的重试次数（部分错误像“消息太大”之类的错误默认不重试直接报错）\nretries=3\n# 消息发送失败后每次重试的间隔时间\nretry.backoff.ms=100\n# 消息发送的单个batch大小，把多个消息合并为一个请求可以提高网络利用率，提高吞吐量，但也某种程度造成了消息延迟\nbatch.size=16384\n# 同样服务于消息batch，producer将等待直到消息填满一个batch或者达到linger时间后直接进行发送该批次消息\nlinger.ms=5\n# producer允许的未返回响应的最大请求个数，如果为1，则producer在未收到当前请求的响应前不会发送后续请求\n# 调高该值可以提高吞吐量，前提是对消息发送顺序没要求（如果开启retry的话有可能打乱消息发布的顺序）\nmax.in.flight.requests.per.connection=5\n# producer单次发送的最大容量，保证这个值不超过broker的message.max.bytes属性即可\nmax.request.size=1048576\n# 发布消息的请求响应超时时间，超出该值要么重试要么报错\nrequest.timeout.ms=30000\n```\n\n关于kafka-producer配置的一些问题如下：\n\n1. 如何保证消息发布顺序：如果同时配置了`retries`和`max.in.flight.requests.per.connection`，当后者大于1时，有可能造成消息发布乱序（比如，消息1发布失败，消息2发布成功，紧接着重试发送消息1并成功），所以官方建议如果配置了大于0的`retries`，`max.in.flight.requests.per.connection`最好设置为1\n\n2. 幂等消息：为了避免消息重复发布，支持单个producer对于同一个`Topic,Partition`的`Exactly Once`语义，kafka在`0.11.0.0`后引入了对幂等消息的支持，通过以下配置进行开启：\n\n   ```properties\n   # 开启幂等producer\n   enable.idempotence=true\n   # 如果开启幂等producer，必须对以下配置进行如下的设置\n   acks = all\n   retries = （大于0）\n   max.inflight.requests.per.connection = （小于等于5）\n   ```\n\n3. 事务支持：kafka同时在`0.11.0.0`版本引入了事务支持，支持跨partition幂等发布消息，保证了跨分区发布消息的原子性，通过以下配置进行开启：\n\n   ```properties\n   # 设置一个字符串表示事务id\n   # 开启事务后，enable.idempotence默认设置为true\n   transactional.id=my_tx_id_1\n   ```\n\n\n#### Kafka-producer序列化器\n\nKafka消息队列没有规定具体的消息传输协议和消息格式，队列中统一传输二进制数据流，因此需要用户根据自己消息的协议和格式选取合适的序列化器，或者自定义序列化器\n\nKafka默认提供的常用序列化器有有以下几种，基本上只能用于基本数据类型和字节数组或者ByteBuffer对象的序列化：\n\n```properties\nStringDeserializer\nIntegerSerializer\nByteArraySerializer\nByteBufferSerializer\nDoubleSerializer\nUUIDSerializer\n```\n\n用户自定义序列化器直接实现`Serializer`接口即可，如下实现一个简单的Json格式的序列化器：\n\n```java\npublic class SimpleJsonSerializer implements Serializer {\n\tprivate final Gson gson = new Gson();\n\t@Override\n\tpublic void configure(Map configs, boolean isKey) {\n\t}\n\t@Override\n\tpublic byte[] serialize(String topic, Object data) {\n\t\tString json = gson.toJson(data);\n\t\treturn json.getBytes(Charset.defaultCharset());\n\t}\n\t@Override\n\tpublic void close() {\n\t}\n}\n```\n\n然后在producer中进行配置，即可将java对象序列化为json字节数组了：\n\n```java\nMap<String, Object> producerConfig = new HashMap<>();\nproducerConfig.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"10.106.151.187:9092\");\nproducerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\nproducerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, SimpleJsonSerializer.class);\nproducerConfig.put(ProducerConfig.ACKS_CONFIG, \"1\");\nProducer<String, Person> producer = new KafkaProducer<>(producerConfig);\n\nProducerRecord<String, Person> record = new ProducerRecord<>(\"test-topic-1\", Person.builder().id(0).name(\"liugeng\").build());\n\n```\n\n#### kafka-producer分区器\n\nproducer发送消息时无需手动指定发送到某个partition，producer-api默认的`DefaultPartitioner`会根据消息中有无设置key来进行分区操作：\n\n1. key不为null：计算key的hash值，然后和partition数量取模，映射到不同的partition中\n2. key为null：使用Round-Robin进行轮询映射\n\n如果需要自己实现分区器（例如需要根据key指定特定的分区，或者某个key的消息需要占用多个分区），可以实现`Partitioner`接口，以下是一个例子，将key为`last`的record映射到最后一个partition上，剩下的record通过hash映射到其他partition：\n\n```java\npublic class SimpleCustomerPartitioner implements Partitioner {\n\t@Override\n\tpublic int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n\t\tList<PartitionInfo> partitionInfoList = cluster.availablePartitionsForTopic(topic);\n\t\tint partitionNum = partitionInfoList.size();\n\t\tif (keyBytes == null || !(key instanceof String)) {\n\t\t\tthrow new InvalidRecordException(\"the key is necessary !\");\n\t\t}\n\t\tif (\"last\".equals(key)) {\n\t\t\treturn partitionNum - 1;\n\t\t}\n\t\treturn Math.abs(Utils.murmur2(keyBytes)) % (partitionNum -1);\n\t}\n\t@Override\n\tpublic void close() {\n\t}\n\t@Override\n\tpublic void configure(Map<String, ?> configs) {\n\t}\n}\n```\n\n分区器的`partition`方法返回指定partition的id，需要注意的是partition的id是从0开始的\n","slug":"kafka学习笔记（2）——-生产者-producer","published":1,"updated":"2021-05-31T03:06:33.198Z","_id":"ckf0h31hx0017acts2mugr2el","comments":1,"layout":"post","photos":[],"link":"","content":"<p>kafka作为大数据日志收集系统，能够接收来自多端的生产者数据，下图是消息经由<code>kafka-producer-api</code>向kafka集群发送消息的基本过程：<br><a id=\"more\"></a></p>\n<p><img src=\"\\blog\\images\\pasted-3.png\" alt=\"upload successful\"></p>\n<p>下面用kafka-producer的java api来进行说明</p>\n<h3 id=\"kafka-producer-java-api\"><a href=\"#kafka-producer-java-api\" class=\"headerlink\" title=\"kafka-producer java api\"></a>kafka-producer java api</h3><h4 id=\"KafkaProducer基本操作\"><a href=\"#KafkaProducer基本操作\" class=\"headerlink\" title=\"KafkaProducer基本操作\"></a>KafkaProducer基本操作</h4><p>项目中引入以下依赖：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.kafka<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>kafka-clients<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.1.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>最新版本的kafka-producer-api取消了同步发送消息的模式，全部默认采用异步发送消息，使用异步线程从发送队列中批量发送消息，然后返回一个<code>Future</code>对象</p>\n<p>首先创建producer并进行配置，以下三个配置项是必选配置，其他配置都是可选配置：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Map&lt;String, Object&gt; producerConfig = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">producerConfig.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class=\"string\">\"10.106.151.187:9092\"</span>);</span><br><span class=\"line\">producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class=\"line\">producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class=\"line\">Producer&lt;String, String&gt; producer = <span class=\"keyword\">new</span> KafkaProducer&lt;&gt;(producerConfig);</span><br></pre></td></tr></table></figure>\n<p>构建record并发送，发送成功后返回topic和partition的元数据：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ProducerRecord&lt;String, String&gt; record = <span class=\"keyword\">new</span> ProducerRecord&lt;&gt;(<span class=\"string\">\"test-topic-1\"</span>, <span class=\"string\">\"it's a msg\"</span>);</span><br><span class=\"line\">Future&lt;RecordMetadata&gt; future = producer.send(record);</span><br><span class=\"line\">RecordMetadata recordMetadata = future.get();</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"offset:\"</span> + recordMetadata.offset());</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"partition id: \"</span> + recordMetadata.partition());</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"topic: \"</span> + recordMetadata.topic());</span><br></pre></td></tr></table></figure>\n<p>也可以设置回调函数，对Future进行消费：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CountDownLatch latch = <span class=\"keyword\">new</span> CountDownLatch(<span class=\"number\">1</span>);</span><br><span class=\"line\">producer.send(record, (recordMetadata, e) -&gt; &#123;</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"offset:\"</span> + recordMetadata.offset());</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"partition id: \"</span> + recordMetadata.partition());</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"topic: \"</span> + recordMetadata.topic());</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (e != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    latch.countDown();</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">latch.await();</span><br></pre></td></tr></table></figure>\n<h4 id=\"KafkaProducer配置解析\"><a href=\"#KafkaProducer配置解析\" class=\"headerlink\" title=\"KafkaProducer配置解析\"></a>KafkaProducer配置解析</h4><p>除了<code>bootstrap.servers</code>, <code>key.serializer</code>,<code>value.serializer</code> 这三个配置项是必选配置，其他配置都是可选的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 指定目标分区有多少个副本成功收到消息时，producer才会收到消息发送成功的响应</span><br><span class=\"line\"># 1：leader节点成功收到消息后即认为消息发送成功，一般采用这个</span><br><span class=\"line\"># all：所有replica节点都成功收到消息后才认为消息发送成功</span><br><span class=\"line\"># 0：producer无需等待任何发送成功的响应，消息发送完毕后即返回</span><br><span class=\"line\">acks=1</span><br><span class=\"line\"># 生产者缓冲区大小，消息发送到broker前可以在producer内存中进行缓冲，如果待发送的消息大小超过该值，后续发送请求则会阻塞</span><br><span class=\"line\">buffer.memory=33554432</span><br><span class=\"line\"># 和上述配置协同工作，当缓冲区不足时后续请求能够阻塞的最大时间，超过该值仍然阻塞则会抛异常</span><br><span class=\"line\">max.block.ms=60000</span><br><span class=\"line\"># 消息压缩方式</span><br><span class=\"line\"># snappy：cpu消耗低，性能好； gzip：cpu消耗高，压缩比较snappy更高</span><br><span class=\"line\">compression.type=snappy</span><br><span class=\"line\"># 消息发送失败后的重试次数（部分错误像“消息太大”之类的错误默认不重试直接报错）</span><br><span class=\"line\">retries=3</span><br><span class=\"line\"># 消息发送失败后每次重试的间隔时间</span><br><span class=\"line\">retry.backoff.ms=100</span><br><span class=\"line\"># 消息发送的单个batch大小，把多个消息合并为一个请求可以提高网络利用率，提高吞吐量，但也某种程度造成了消息延迟</span><br><span class=\"line\">batch.size=16384</span><br><span class=\"line\"># 同样服务于消息batch，producer将等待直到消息填满一个batch或者达到linger时间后直接进行发送该批次消息</span><br><span class=\"line\">linger.ms=5</span><br><span class=\"line\"># producer允许的未返回响应的最大请求个数，如果为1，则producer在未收到当前请求的响应前不会发送后续请求</span><br><span class=\"line\"># 调高该值可以提高吞吐量，前提是对消息发送顺序没要求（如果开启retry的话有可能打乱消息发布的顺序）</span><br><span class=\"line\">max.in.flight.requests.per.connection=5</span><br><span class=\"line\"># producer单次发送的最大容量，保证这个值不超过broker的message.max.bytes属性即可</span><br><span class=\"line\">max.request.size=1048576</span><br><span class=\"line\"># 发布消息的请求响应超时时间，超出该值要么重试要么报错</span><br><span class=\"line\">request.timeout.ms=30000</span><br></pre></td></tr></table></figure>\n<p>关于kafka-producer配置的一些问题如下：</p>\n<ol>\n<li><p>如何保证消息发布顺序：如果同时配置了<code>retries</code>和<code>max.in.flight.requests.per.connection</code>，当后者大于1时，有可能造成消息发布乱序（比如，消息1发布失败，消息2发布成功，紧接着重试发送消息1并成功），所以官方建议如果配置了大于0的<code>retries</code>，<code>max.in.flight.requests.per.connection</code>最好设置为1</p>\n</li>\n<li><p>幂等消息：为了避免消息重复发布，支持单个producer对于同一个<code>Topic,Partition</code>的<code>Exactly Once</code>语义，kafka在<code>0.11.0.0</code>后引入了对幂等消息的支持，通过以下配置进行开启：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 开启幂等producer</span><br><span class=\"line\">enable.idempotence=true</span><br><span class=\"line\"># 如果开启幂等producer，必须对以下配置进行如下的设置</span><br><span class=\"line\">acks = all</span><br><span class=\"line\">retries = （大于0）</span><br><span class=\"line\">max.inflight.requests.per.connection = （小于等于5）</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>事务支持：kafka同时在<code>0.11.0.0</code>版本引入了事务支持，支持跨partition幂等发布消息，保证了跨分区发布消息的原子性，通过以下配置进行开启：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置一个字符串表示事务id</span><br><span class=\"line\"># 开启事务后，enable.idempotence默认设置为true</span><br><span class=\"line\">transactional.id=my_tx_id_1</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h4 id=\"Kafka-producer序列化器\"><a href=\"#Kafka-producer序列化器\" class=\"headerlink\" title=\"Kafka-producer序列化器\"></a>Kafka-producer序列化器</h4><p>Kafka消息队列没有规定具体的消息传输协议和消息格式，队列中统一传输二进制数据流，因此需要用户根据自己消息的协议和格式选取合适的序列化器，或者自定义序列化器</p>\n<p>Kafka默认提供的常用序列化器有有以下几种，基本上只能用于基本数据类型和字节数组或者ByteBuffer对象的序列化：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">StringDeserializer</span><br><span class=\"line\">IntegerSerializer</span><br><span class=\"line\">ByteArraySerializer</span><br><span class=\"line\">ByteBufferSerializer</span><br><span class=\"line\">DoubleSerializer</span><br><span class=\"line\">UUIDSerializer</span><br></pre></td></tr></table></figure>\n<p>用户自定义序列化器直接实现<code>Serializer</code>接口即可，如下实现一个简单的Json格式的序列化器：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SimpleJsonSerializer</span> <span class=\"keyword\">implements</span> <span class=\"title\">Serializer</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">final</span> Gson gson = <span class=\"keyword\">new</span> Gson();</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">configure</span><span class=\"params\">(Map configs, <span class=\"keyword\">boolean</span> isKey)</span> </span>&#123;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"keyword\">byte</span>[] serialize(String topic, Object data) &#123;</span><br><span class=\"line\">\t\tString json = gson.toJson(data);</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> json.getBytes(Charset.defaultCharset());</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">close</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>然后在producer中进行配置，即可将java对象序列化为json字节数组了：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Map&lt;String, Object&gt; producerConfig = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">producerConfig.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class=\"string\">\"10.106.151.187:9092\"</span>);</span><br><span class=\"line\">producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class=\"line\">producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, SimpleJsonSerializer.class);</span><br><span class=\"line\">producerConfig.put(ProducerConfig.ACKS_CONFIG, <span class=\"string\">\"1\"</span>);</span><br><span class=\"line\">Producer&lt;String, Person&gt; producer = <span class=\"keyword\">new</span> KafkaProducer&lt;&gt;(producerConfig);</span><br><span class=\"line\"></span><br><span class=\"line\">ProducerRecord&lt;String, Person&gt; record = <span class=\"keyword\">new</span> ProducerRecord&lt;&gt;(<span class=\"string\">\"test-topic-1\"</span>, Person.builder().id(<span class=\"number\">0</span>).name(<span class=\"string\">\"liugeng\"</span>).build());</span><br></pre></td></tr></table></figure>\n<h4 id=\"kafka-producer分区器\"><a href=\"#kafka-producer分区器\" class=\"headerlink\" title=\"kafka-producer分区器\"></a>kafka-producer分区器</h4><p>producer发送消息时无需手动指定发送到某个partition，producer-api默认的<code>DefaultPartitioner</code>会根据消息中有无设置key来进行分区操作：</p>\n<ol>\n<li>key不为null：计算key的hash值，然后和partition数量取模，映射到不同的partition中</li>\n<li>key为null：使用Round-Robin进行轮询映射</li>\n</ol>\n<p>如果需要自己实现分区器（例如需要根据key指定特定的分区，或者某个key的消息需要占用多个分区），可以实现<code>Partitioner</code>接口，以下是一个例子，将key为<code>last</code>的record映射到最后一个partition上，剩下的record通过hash映射到其他partition：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SimpleCustomerPartitioner</span> <span class=\"keyword\">implements</span> <span class=\"title\">Partitioner</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">int</span> <span class=\"title\">partition</span><span class=\"params\">(String topic, Object key, <span class=\"keyword\">byte</span>[] keyBytes, Object value, <span class=\"keyword\">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class=\"line\">\t\tList&lt;PartitionInfo&gt; partitionInfoList = cluster.availablePartitionsForTopic(topic);</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> partitionNum = partitionInfoList.size();</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (keyBytes == <span class=\"keyword\">null</span> || !(key <span class=\"keyword\">instanceof</span> String)) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> InvalidRecordException(<span class=\"string\">\"the key is necessary !\"</span>);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (<span class=\"string\">\"last\"</span>.equals(key)) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> partitionNum - <span class=\"number\">1</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> Math.abs(Utils.murmur2(keyBytes)) % (partitionNum -<span class=\"number\">1</span>);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">close</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">configure</span><span class=\"params\">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>分区器的<code>partition</code>方法返回指定partition的id，需要注意的是partition的id是从0开始的</p>\n","site":{"data":{}},"excerpt":"<p>kafka作为大数据日志收集系统，能够接收来自多端的生产者数据，下图是消息经由<code>kafka-producer-api</code>向kafka集群发送消息的基本过程：<br>","more":"</p>\n<p><img src=\"\\blog\\images\\pasted-3.png\" alt=\"upload successful\"></p>\n<p>下面用kafka-producer的java api来进行说明</p>\n<h3 id=\"kafka-producer-java-api\"><a href=\"#kafka-producer-java-api\" class=\"headerlink\" title=\"kafka-producer java api\"></a>kafka-producer java api</h3><h4 id=\"KafkaProducer基本操作\"><a href=\"#KafkaProducer基本操作\" class=\"headerlink\" title=\"KafkaProducer基本操作\"></a>KafkaProducer基本操作</h4><p>项目中引入以下依赖：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.kafka<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>kafka-clients<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.1.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>最新版本的kafka-producer-api取消了同步发送消息的模式，全部默认采用异步发送消息，使用异步线程从发送队列中批量发送消息，然后返回一个<code>Future</code>对象</p>\n<p>首先创建producer并进行配置，以下三个配置项是必选配置，其他配置都是可选配置：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Map&lt;String, Object&gt; producerConfig = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">producerConfig.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class=\"string\">\"10.106.151.187:9092\"</span>);</span><br><span class=\"line\">producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class=\"line\">producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class=\"line\">Producer&lt;String, String&gt; producer = <span class=\"keyword\">new</span> KafkaProducer&lt;&gt;(producerConfig);</span><br></pre></td></tr></table></figure>\n<p>构建record并发送，发送成功后返回topic和partition的元数据：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ProducerRecord&lt;String, String&gt; record = <span class=\"keyword\">new</span> ProducerRecord&lt;&gt;(<span class=\"string\">\"test-topic-1\"</span>, <span class=\"string\">\"it's a msg\"</span>);</span><br><span class=\"line\">Future&lt;RecordMetadata&gt; future = producer.send(record);</span><br><span class=\"line\">RecordMetadata recordMetadata = future.get();</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"offset:\"</span> + recordMetadata.offset());</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"partition id: \"</span> + recordMetadata.partition());</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"topic: \"</span> + recordMetadata.topic());</span><br></pre></td></tr></table></figure>\n<p>也可以设置回调函数，对Future进行消费：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CountDownLatch latch = <span class=\"keyword\">new</span> CountDownLatch(<span class=\"number\">1</span>);</span><br><span class=\"line\">producer.send(record, (recordMetadata, e) -&gt; &#123;</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"offset:\"</span> + recordMetadata.offset());</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"partition id: \"</span> + recordMetadata.partition());</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"topic: \"</span> + recordMetadata.topic());</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (e != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    latch.countDown();</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">latch.await();</span><br></pre></td></tr></table></figure>\n<h4 id=\"KafkaProducer配置解析\"><a href=\"#KafkaProducer配置解析\" class=\"headerlink\" title=\"KafkaProducer配置解析\"></a>KafkaProducer配置解析</h4><p>除了<code>bootstrap.servers</code>, <code>key.serializer</code>,<code>value.serializer</code> 这三个配置项是必选配置，其他配置都是可选的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 指定目标分区有多少个副本成功收到消息时，producer才会收到消息发送成功的响应</span><br><span class=\"line\"># 1：leader节点成功收到消息后即认为消息发送成功，一般采用这个</span><br><span class=\"line\"># all：所有replica节点都成功收到消息后才认为消息发送成功</span><br><span class=\"line\"># 0：producer无需等待任何发送成功的响应，消息发送完毕后即返回</span><br><span class=\"line\">acks=1</span><br><span class=\"line\"># 生产者缓冲区大小，消息发送到broker前可以在producer内存中进行缓冲，如果待发送的消息大小超过该值，后续发送请求则会阻塞</span><br><span class=\"line\">buffer.memory=33554432</span><br><span class=\"line\"># 和上述配置协同工作，当缓冲区不足时后续请求能够阻塞的最大时间，超过该值仍然阻塞则会抛异常</span><br><span class=\"line\">max.block.ms=60000</span><br><span class=\"line\"># 消息压缩方式</span><br><span class=\"line\"># snappy：cpu消耗低，性能好； gzip：cpu消耗高，压缩比较snappy更高</span><br><span class=\"line\">compression.type=snappy</span><br><span class=\"line\"># 消息发送失败后的重试次数（部分错误像“消息太大”之类的错误默认不重试直接报错）</span><br><span class=\"line\">retries=3</span><br><span class=\"line\"># 消息发送失败后每次重试的间隔时间</span><br><span class=\"line\">retry.backoff.ms=100</span><br><span class=\"line\"># 消息发送的单个batch大小，把多个消息合并为一个请求可以提高网络利用率，提高吞吐量，但也某种程度造成了消息延迟</span><br><span class=\"line\">batch.size=16384</span><br><span class=\"line\"># 同样服务于消息batch，producer将等待直到消息填满一个batch或者达到linger时间后直接进行发送该批次消息</span><br><span class=\"line\">linger.ms=5</span><br><span class=\"line\"># producer允许的未返回响应的最大请求个数，如果为1，则producer在未收到当前请求的响应前不会发送后续请求</span><br><span class=\"line\"># 调高该值可以提高吞吐量，前提是对消息发送顺序没要求（如果开启retry的话有可能打乱消息发布的顺序）</span><br><span class=\"line\">max.in.flight.requests.per.connection=5</span><br><span class=\"line\"># producer单次发送的最大容量，保证这个值不超过broker的message.max.bytes属性即可</span><br><span class=\"line\">max.request.size=1048576</span><br><span class=\"line\"># 发布消息的请求响应超时时间，超出该值要么重试要么报错</span><br><span class=\"line\">request.timeout.ms=30000</span><br></pre></td></tr></table></figure>\n<p>关于kafka-producer配置的一些问题如下：</p>\n<ol>\n<li><p>如何保证消息发布顺序：如果同时配置了<code>retries</code>和<code>max.in.flight.requests.per.connection</code>，当后者大于1时，有可能造成消息发布乱序（比如，消息1发布失败，消息2发布成功，紧接着重试发送消息1并成功），所以官方建议如果配置了大于0的<code>retries</code>，<code>max.in.flight.requests.per.connection</code>最好设置为1</p>\n</li>\n<li><p>幂等消息：为了避免消息重复发布，支持单个producer对于同一个<code>Topic,Partition</code>的<code>Exactly Once</code>语义，kafka在<code>0.11.0.0</code>后引入了对幂等消息的支持，通过以下配置进行开启：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 开启幂等producer</span><br><span class=\"line\">enable.idempotence=true</span><br><span class=\"line\"># 如果开启幂等producer，必须对以下配置进行如下的设置</span><br><span class=\"line\">acks = all</span><br><span class=\"line\">retries = （大于0）</span><br><span class=\"line\">max.inflight.requests.per.connection = （小于等于5）</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>事务支持：kafka同时在<code>0.11.0.0</code>版本引入了事务支持，支持跨partition幂等发布消息，保证了跨分区发布消息的原子性，通过以下配置进行开启：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置一个字符串表示事务id</span><br><span class=\"line\"># 开启事务后，enable.idempotence默认设置为true</span><br><span class=\"line\">transactional.id=my_tx_id_1</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h4 id=\"Kafka-producer序列化器\"><a href=\"#Kafka-producer序列化器\" class=\"headerlink\" title=\"Kafka-producer序列化器\"></a>Kafka-producer序列化器</h4><p>Kafka消息队列没有规定具体的消息传输协议和消息格式，队列中统一传输二进制数据流，因此需要用户根据自己消息的协议和格式选取合适的序列化器，或者自定义序列化器</p>\n<p>Kafka默认提供的常用序列化器有有以下几种，基本上只能用于基本数据类型和字节数组或者ByteBuffer对象的序列化：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">StringDeserializer</span><br><span class=\"line\">IntegerSerializer</span><br><span class=\"line\">ByteArraySerializer</span><br><span class=\"line\">ByteBufferSerializer</span><br><span class=\"line\">DoubleSerializer</span><br><span class=\"line\">UUIDSerializer</span><br></pre></td></tr></table></figure>\n<p>用户自定义序列化器直接实现<code>Serializer</code>接口即可，如下实现一个简单的Json格式的序列化器：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SimpleJsonSerializer</span> <span class=\"keyword\">implements</span> <span class=\"title\">Serializer</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">final</span> Gson gson = <span class=\"keyword\">new</span> Gson();</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">configure</span><span class=\"params\">(Map configs, <span class=\"keyword\">boolean</span> isKey)</span> </span>&#123;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"keyword\">byte</span>[] serialize(String topic, Object data) &#123;</span><br><span class=\"line\">\t\tString json = gson.toJson(data);</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> json.getBytes(Charset.defaultCharset());</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">close</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>然后在producer中进行配置，即可将java对象序列化为json字节数组了：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Map&lt;String, Object&gt; producerConfig = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">producerConfig.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class=\"string\">\"10.106.151.187:9092\"</span>);</span><br><span class=\"line\">producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class=\"line\">producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, SimpleJsonSerializer.class);</span><br><span class=\"line\">producerConfig.put(ProducerConfig.ACKS_CONFIG, <span class=\"string\">\"1\"</span>);</span><br><span class=\"line\">Producer&lt;String, Person&gt; producer = <span class=\"keyword\">new</span> KafkaProducer&lt;&gt;(producerConfig);</span><br><span class=\"line\"></span><br><span class=\"line\">ProducerRecord&lt;String, Person&gt; record = <span class=\"keyword\">new</span> ProducerRecord&lt;&gt;(<span class=\"string\">\"test-topic-1\"</span>, Person.builder().id(<span class=\"number\">0</span>).name(<span class=\"string\">\"liugeng\"</span>).build());</span><br></pre></td></tr></table></figure>\n<h4 id=\"kafka-producer分区器\"><a href=\"#kafka-producer分区器\" class=\"headerlink\" title=\"kafka-producer分区器\"></a>kafka-producer分区器</h4><p>producer发送消息时无需手动指定发送到某个partition，producer-api默认的<code>DefaultPartitioner</code>会根据消息中有无设置key来进行分区操作：</p>\n<ol>\n<li>key不为null：计算key的hash值，然后和partition数量取模，映射到不同的partition中</li>\n<li>key为null：使用Round-Robin进行轮询映射</li>\n</ol>\n<p>如果需要自己实现分区器（例如需要根据key指定特定的分区，或者某个key的消息需要占用多个分区），可以实现<code>Partitioner</code>接口，以下是一个例子，将key为<code>last</code>的record映射到最后一个partition上，剩下的record通过hash映射到其他partition：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SimpleCustomerPartitioner</span> <span class=\"keyword\">implements</span> <span class=\"title\">Partitioner</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">int</span> <span class=\"title\">partition</span><span class=\"params\">(String topic, Object key, <span class=\"keyword\">byte</span>[] keyBytes, Object value, <span class=\"keyword\">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class=\"line\">\t\tList&lt;PartitionInfo&gt; partitionInfoList = cluster.availablePartitionsForTopic(topic);</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> partitionNum = partitionInfoList.size();</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (keyBytes == <span class=\"keyword\">null</span> || !(key <span class=\"keyword\">instanceof</span> String)) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> InvalidRecordException(<span class=\"string\">\"the key is necessary !\"</span>);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (<span class=\"string\">\"last\"</span>.equals(key)) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> partitionNum - <span class=\"number\">1</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> Math.abs(Utils.murmur2(keyBytes)) % (partitionNum -<span class=\"number\">1</span>);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">close</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">configure</span><span class=\"params\">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>分区器的<code>partition</code>方法返回指定partition的id，需要注意的是partition的id是从0开始的</p>"},{"title":"java线程池源码分析--shutdown, shutdownNow, awaitTermination","date":"2019-01-21T02:31:00.000Z","_content":"谈到jdk线程池的生命周期就不得不说shutdown，shutdownNow和awaitTermination这三个方法，一般用来进行线程池的停止和资源的释放，以下例子主要讨论`ThreadPoolExecutor`的实现\n\n<!-- more -->\n\n### 程序演示\n\n- shutdown\n\n  该方法用于在结束线程池的任务提交后关闭线程池，让线程池拒绝后续的任务提交，以下提交5个任务到线程池，并调用`shutdown`方法，接着尝试再次提交任务：\n\n  ```JAVA\n  @Before\n  public void setup() {\n  \texecutorService = Executors.newFixedThreadPool(5);\n  \trunnable = new Runnable() {\n  \t\tpublic void run() {\n  \t\t\tSystem.out.println(\"Thread: {\" + Thread.currentThread().getName() + \"} start!\");\n  \t\t\ttry {\n  \t\t\t\tThread.sleep(3000);\n  \t\t\t} catch (InterruptedException e) {\n  \t\t\t\te.printStackTrace();\n  \t\t\t}\n  \t\t\tSystem.out.println(\"Thread: {\" + Thread.currentThread().getName() + \"} stop!\");\n  \t\t}\n  \t};\n  \tfor (int i = 0; i < 5; i++) {\n  \t\texecutorService.submit(runnable);\n  \t}\n  }\n  \n  @Test\n  public void test2() throws Exception {\n  \tSystem.out.println(\"try to shutdown threadPool!\");\n  \texecutorService.shutdown();\n  \t// here, jump out RejectedExecutionException\n  \texecutorService.submit(runnable);\n  }\n  ```\n\n  输出结果：\n\n  ![1547708979007](/blog/images/1547708979007.png)\n\n  可以看出，调用`shutdown`后是无法再次提交任务的，资源会被回收，只能重新创建一个新的线程池重新提交任务\n\n- shutdown配合awaitTermination\n\n  通常情况下`shutdown`方法不会独立使用，因为调用这个方法后无法得知立即线程池是否已经停止了，可能还有任务未执行完，官方注释如下：\n\n  ![1547709651604](/blog/images/1547709651604.png)\n\n  > 该方法并不会等待之前提交的任务完成执行，如果想达到这个目的请使用awaitTermination\n\n  这个解释我认为有一点歧义，因为`shutdown`方法是会等待之前提交的任务完成执行的，只不过调用了该方法后并不会留时间给用户一个反馈，而`awaitTermination`会等待一段时间并查看线程池是否已经停止了:\n\n  ```JAVA\n  @Test\n  public void test1() throws Exception {\n  \tSystem.out.println(\"try to shutdown threadPool!\");\n  \t// wait for the tasks which is in execution to finish their work\n  \texecutorService.shutdown();\n  \twhile (!executorService.awaitTermination(1, TimeUnit.SECONDS)) {\n  \t\tSystem.out.println(\"threadPool is not terminated!\");\n  \t}\n  \tSystem.out.println(\"threadPool is terminated!\");\n  }\n  ```\n\n  结果：\n\n  ![1547710015291](/blog/images/1547710015291.png)\n\n  提交5个任务后马上调用`shutdown`, 并不会中止任务，让`awaitTermination`每隔一秒检查一下是否停止，以此达到确认线程池成功停止的目的\n\n\n\n- shutdownNow\n\n  `shutdown`会等到提交过的任务完成执行， 但`shutdownNow`会尝试停止当前所有正在执行的任务\n\n  ```JAVA\n  @Before\n  public void setup() {\n  \texecutorService = Executors.newFixedThreadPool(5);\n  \trunnable = new Runnable() {\n  \t\tpublic void run() {\n  \t\t\tSystem.out.println(\"Thread: {\" + Thread.currentThread().getName() + \"} start!\");\n  \t\t\tboolean isInterrupted = false;\n  \t\t\ttry {\n  \t\t\t\tThread.sleep(3000);\n  \t\t\t} catch (InterruptedException e) {\n  \t\t\t\tisInterrupted = true;\n  \t\t\t}\n  \t\t\tif (!isInterrupted) {\n  \t\t\t\tSystem.out.println(\"Thread: {\" + Thread.currentThread().getName() + \"} stop!\");\n  \t\t\t}\n  \t\t}\n  \t};\n  \tfor (int i = 0; i < 5; i++) {\n  \t\texecutorService.submit(runnable);\n  \t}\n  }\n  \n  @Test\n  public void test3() throws Exception {\n  \tSystem.out.println(\"try to shutdownNow threadPool!\");\n  \t// if the Runnable or Callable can jump out InterruptedException\n  \t// the thread in ThreadPool can be terminated by this method\n  \texecutorService.shutdownNow();\n  }\n  ```\n\n  程序对比之前的例子，做了一些修改，当出现`InterruptedException`则中断线程，结果如下：\n\n  ![1547712156480](/blog/images/1547712156480.png)\n\n  官方文档指出，当调用`shutdownNow`后，每个正在执行任务的线程调用了`interrupt()`方法，但这种方式只有对能正常反馈`InterruptedException`的线程使用，否则正在运行的线程依然无法停止：\n\n  ![1547712312524](/blog/images/1547712312524.png)\n\n\n\n  `shutdownNow`最终会返回还未执行的任务集合，比如如下例子：\n\n  ```JAVA\n  @Test\n  \tpublic void test1() {\n  \t\texecutorService = Executors.newFixedThreadPool(1);\n  \t\trunnable = new Runnable() {\n  \t\t\tpublic void run() {\n  \t\t\t\tSystem.out.println(\"Thread: {\" + Thread.currentThread().getName() + \"} start!\");\n  \t\t\t\tboolean isInterrupted = false;\n  \t\t\t\ttry {\n  \t\t\t\t\tThread.sleep(3000);\n  \t\t\t\t} catch (InterruptedException e) {\n  \t\t\t\t\tisInterrupted = true;\n  \t\t\t\t}\n  \t\t\t\tif (!isInterrupted) {\n  \t\t\t\t\tSystem.out.println(\"Thread: {\" + Thread.currentThread().getName() + \"} stop!\");\n  \t\t\t\t}\n  \t\t\t}\n  \t\t};\n  \t\texecutorService.submit(runnable);\n  \t\texecutorService.submit(runnable);\n  \t\texecutorService.submit(runnable);\n  \t\texecutorService.submit(runnable);\n  \t\texecutorService.submit(runnable);\n  \t\tList<Runnable> noExecutedTasks = executorService.shutdownNow();\n  \t\tSystem.out.println(noExecutedTasks.size());\n  \t}\n  ```\n\n  结果如下：\n\n  ![1547712873168](/blog/images/1547712873168.png)\n\n  线程池最大线程数只有1个，提交5个任务后马上调用`shutdownNow`，正在执行的任务被终止，并导致剩下4个任务没有机会执行，则将这四个任务集合返还给用户\n\n\n\n- isShutdown和isTerminated\n\n  线程池生命周期方法中的`isShutdown`和`isTerminated`也比较重要，前者在线程池调用`shutdown`后返回true，后者在线程池中任务全部执行结束后才返回true：\n\n  ```JAVA\n  @Test\n  public void test4() throws Exception {\n  \tSystem.out.println(\"try to shutdownNow threadPool!\");\n  \texecutorService.shutdown();\n  \t// still RejectedExecutionException\n  \tSystem.out.println(executorService.isShutdown());\n  \tSystem.out.println(executorService.isTerminated());\n  }\n  ```\n\n  ![1547713322805](/blog/images/1547713322805.png)\n\n  调用`isShutdown`后，`isShutdown`为true，但`isTerminated`为false\n\n  ```JAVA\n  @Test\n  public void test5() throws Exception {\n  \tSystem.out.println(\"try to shutdown threadPool!\");\n  \t// wait for the tasks which is in execution to finish their work\n  \texecutorService.shutdown();\n  \tSystem.out.println(executorService.isShutdown());\n  \tSystem.out.println(executorService.isTerminated());\n  \twhile (!executorService.awaitTermination(1, TimeUnit.SECONDS)) {\n  \t\tSystem.out.println(\"threadPool is not terminated!\");\n  \t}\n  \tSystem.out.println(\"threadPool is terminated!\");\n  \tSystem.out.println(executorService.isTerminated());\n  }\n  ```\n\n  ![1547713402558](/blog/images/1547713402558.png)\n\n  第一次调用`isTerminated`，返回false，最后等所有任务都执行完了，该方法便返回true\n\n\n\n### 源码浅析\n\n调用上述几种线程池生命周期方法后，线程池内部做的怎样的实现呢？jdk线程池内部实现机理还是挺复杂的，现在从`isShutdown`入手来一探究竟\n\n- shutdown()\n\n  ```JAVA\n  public void shutdown() {\n      final ReentrantLock mainLock = this.mainLock;\n      mainLock.lock();\n      try {\n          checkShutdownAccess();\n          advanceRunState(SHUTDOWN);\n          interruptIdleWorkers();\n          onShutdown(); // hook for ScheduledThreadPoolExecutor\n      } finally {\n          mainLock.unlock();\n      }\n      tryTerminate();\n  }\n  ```\n\n  `mainLock`用于将线程的停止操作进行同步处理，然后调用`checkShutdownAccess`对用户是否有线程访问权限\n\n- advanceRunState(SHUTDOWN)\n\n  `advanceRunState`方法用于切换线程池状态，调用该方法将线程池状态设置为`SHUTDOWN`\n\n  ```JAVA\n      private void advanceRunState(int targetState) {\n          for (;;) {\n              int c = ctl.get();\n              if (runStateAtLeast(c, targetState) ||\n                  ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c))))\n                  break;\n          }\n      }\n  ```\n\n  内部使用了CAS原子操作来进行状态切换\n\n- interruptIdleWorkers()\n\n  interruptIdleWorkers()方法用来给每个空闲的`worker`线程打上interrupt标记:\n\n  ```JAVA\n      private void interruptIdleWorkers(boolean onlyOne) {\n          final ReentrantLock mainLock = this.mainLock;\n          mainLock.lock();\n          try {\n              for (Worker w : workers) {\n                  Thread t = w.thread;\n                  if (!t.isInterrupted() && w.tryLock()) {\n                      try {\n                          t.interrupt();\n                      } catch (SecurityException ignore) {\n                      } finally {\n                          w.unlock();\n                      }\n                  }\n                  if (onlyOne)\n                      break;\n              }\n          } finally {\n              mainLock.unlock();\n          }\n      }\n  ```\n\n  `!t.isInterrupted() && w.tryLock() `这个判断很重要，首先判断当前worker的执行线程是否已经interrupt，然后判断worker是否能成功获取锁，如果返回true则说明当前worker没有执行任务（），最后执行interrupt()方法并释放work锁和mainLock同步锁\n\n- onShutdown()\n\n- tryTerminate()\n\n  interruptIdleWorkers方法只能保证将空闲的worker线程置为interruptted，但正在工作的worker还是会继续执行任务，这时候需要启用`tryTerminate`方法，进行终止操作：\n\n  ```JAVA\n      final void tryTerminate() {\n          for (;;) {\n              int c = ctl.get();\n              // 以下三种状态不进行终止操作：\n              // 1.RUNNING状态 2.TIDING或者TERMINATED状态 3.SHUTDOWN状态并且workQueue不为空\n              if (isRunning(c) ||\n                  runStateAtLeast(c, TIDYING) ||\n                  (runStateOf(c) == SHUTDOWN && ! workQueue.isEmpty()))\n                  return;\n              // 尝试interrupt空闲的worker，只中断一个\n              if (workerCountOf(c) != 0) { // Eligible to terminate\n                  interruptIdleWorkers(ONLY_ONE);\n                  return;\n              }\n  \t\t\t\n              final ReentrantLock mainLock = this.mainLock;\n              mainLock.lock();\n              try {\n                  // 真正开始终止操作，通过CAS将当前状态置为TIDYNG，即高于STOP的一种状态\n                  if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) {\n                      try {\n                          //终止操作，在ThreadPoolExecutor中啥也没做，留给子类用作额外的资源回收\n                          terminated();\n                      } finally {\n                          //将状态置为TERMINATED\n                          ctl.set(ctlOf(TERMINATED, 0));\n                          //将调用了awaitTermination()的线程唤醒\n                          termination.signalAll();\n                      }\n                      return;\n                  }\n              } finally {\n                  mainLock.unlock();\n              }\n              // else retry on failed CAS\n          }\n      }\n  ```","source":"_posts/java线程池源码分析--shutdown, shutdownNow, awaitTermination.md","raw":"title: 'java线程池源码分析--shutdown, shutdownNow, awaitTermination'\ntags:\n  - 多线程\n  - Java并发包\n  - Java\ncategories:\n  - 基础知识\ndate: 2019-01-21 10:31:00\n---\n谈到jdk线程池的生命周期就不得不说shutdown，shutdownNow和awaitTermination这三个方法，一般用来进行线程池的停止和资源的释放，以下例子主要讨论`ThreadPoolExecutor`的实现\n\n<!-- more -->\n\n### 程序演示\n\n- shutdown\n\n  该方法用于在结束线程池的任务提交后关闭线程池，让线程池拒绝后续的任务提交，以下提交5个任务到线程池，并调用`shutdown`方法，接着尝试再次提交任务：\n\n  ```JAVA\n  @Before\n  public void setup() {\n  \texecutorService = Executors.newFixedThreadPool(5);\n  \trunnable = new Runnable() {\n  \t\tpublic void run() {\n  \t\t\tSystem.out.println(\"Thread: {\" + Thread.currentThread().getName() + \"} start!\");\n  \t\t\ttry {\n  \t\t\t\tThread.sleep(3000);\n  \t\t\t} catch (InterruptedException e) {\n  \t\t\t\te.printStackTrace();\n  \t\t\t}\n  \t\t\tSystem.out.println(\"Thread: {\" + Thread.currentThread().getName() + \"} stop!\");\n  \t\t}\n  \t};\n  \tfor (int i = 0; i < 5; i++) {\n  \t\texecutorService.submit(runnable);\n  \t}\n  }\n  \n  @Test\n  public void test2() throws Exception {\n  \tSystem.out.println(\"try to shutdown threadPool!\");\n  \texecutorService.shutdown();\n  \t// here, jump out RejectedExecutionException\n  \texecutorService.submit(runnable);\n  }\n  ```\n\n  输出结果：\n\n  ![1547708979007](/blog/images/1547708979007.png)\n\n  可以看出，调用`shutdown`后是无法再次提交任务的，资源会被回收，只能重新创建一个新的线程池重新提交任务\n\n- shutdown配合awaitTermination\n\n  通常情况下`shutdown`方法不会独立使用，因为调用这个方法后无法得知立即线程池是否已经停止了，可能还有任务未执行完，官方注释如下：\n\n  ![1547709651604](/blog/images/1547709651604.png)\n\n  > 该方法并不会等待之前提交的任务完成执行，如果想达到这个目的请使用awaitTermination\n\n  这个解释我认为有一点歧义，因为`shutdown`方法是会等待之前提交的任务完成执行的，只不过调用了该方法后并不会留时间给用户一个反馈，而`awaitTermination`会等待一段时间并查看线程池是否已经停止了:\n\n  ```JAVA\n  @Test\n  public void test1() throws Exception {\n  \tSystem.out.println(\"try to shutdown threadPool!\");\n  \t// wait for the tasks which is in execution to finish their work\n  \texecutorService.shutdown();\n  \twhile (!executorService.awaitTermination(1, TimeUnit.SECONDS)) {\n  \t\tSystem.out.println(\"threadPool is not terminated!\");\n  \t}\n  \tSystem.out.println(\"threadPool is terminated!\");\n  }\n  ```\n\n  结果：\n\n  ![1547710015291](/blog/images/1547710015291.png)\n\n  提交5个任务后马上调用`shutdown`, 并不会中止任务，让`awaitTermination`每隔一秒检查一下是否停止，以此达到确认线程池成功停止的目的\n\n\n\n- shutdownNow\n\n  `shutdown`会等到提交过的任务完成执行， 但`shutdownNow`会尝试停止当前所有正在执行的任务\n\n  ```JAVA\n  @Before\n  public void setup() {\n  \texecutorService = Executors.newFixedThreadPool(5);\n  \trunnable = new Runnable() {\n  \t\tpublic void run() {\n  \t\t\tSystem.out.println(\"Thread: {\" + Thread.currentThread().getName() + \"} start!\");\n  \t\t\tboolean isInterrupted = false;\n  \t\t\ttry {\n  \t\t\t\tThread.sleep(3000);\n  \t\t\t} catch (InterruptedException e) {\n  \t\t\t\tisInterrupted = true;\n  \t\t\t}\n  \t\t\tif (!isInterrupted) {\n  \t\t\t\tSystem.out.println(\"Thread: {\" + Thread.currentThread().getName() + \"} stop!\");\n  \t\t\t}\n  \t\t}\n  \t};\n  \tfor (int i = 0; i < 5; i++) {\n  \t\texecutorService.submit(runnable);\n  \t}\n  }\n  \n  @Test\n  public void test3() throws Exception {\n  \tSystem.out.println(\"try to shutdownNow threadPool!\");\n  \t// if the Runnable or Callable can jump out InterruptedException\n  \t// the thread in ThreadPool can be terminated by this method\n  \texecutorService.shutdownNow();\n  }\n  ```\n\n  程序对比之前的例子，做了一些修改，当出现`InterruptedException`则中断线程，结果如下：\n\n  ![1547712156480](/blog/images/1547712156480.png)\n\n  官方文档指出，当调用`shutdownNow`后，每个正在执行任务的线程调用了`interrupt()`方法，但这种方式只有对能正常反馈`InterruptedException`的线程使用，否则正在运行的线程依然无法停止：\n\n  ![1547712312524](/blog/images/1547712312524.png)\n\n\n\n  `shutdownNow`最终会返回还未执行的任务集合，比如如下例子：\n\n  ```JAVA\n  @Test\n  \tpublic void test1() {\n  \t\texecutorService = Executors.newFixedThreadPool(1);\n  \t\trunnable = new Runnable() {\n  \t\t\tpublic void run() {\n  \t\t\t\tSystem.out.println(\"Thread: {\" + Thread.currentThread().getName() + \"} start!\");\n  \t\t\t\tboolean isInterrupted = false;\n  \t\t\t\ttry {\n  \t\t\t\t\tThread.sleep(3000);\n  \t\t\t\t} catch (InterruptedException e) {\n  \t\t\t\t\tisInterrupted = true;\n  \t\t\t\t}\n  \t\t\t\tif (!isInterrupted) {\n  \t\t\t\t\tSystem.out.println(\"Thread: {\" + Thread.currentThread().getName() + \"} stop!\");\n  \t\t\t\t}\n  \t\t\t}\n  \t\t};\n  \t\texecutorService.submit(runnable);\n  \t\texecutorService.submit(runnable);\n  \t\texecutorService.submit(runnable);\n  \t\texecutorService.submit(runnable);\n  \t\texecutorService.submit(runnable);\n  \t\tList<Runnable> noExecutedTasks = executorService.shutdownNow();\n  \t\tSystem.out.println(noExecutedTasks.size());\n  \t}\n  ```\n\n  结果如下：\n\n  ![1547712873168](/blog/images/1547712873168.png)\n\n  线程池最大线程数只有1个，提交5个任务后马上调用`shutdownNow`，正在执行的任务被终止，并导致剩下4个任务没有机会执行，则将这四个任务集合返还给用户\n\n\n\n- isShutdown和isTerminated\n\n  线程池生命周期方法中的`isShutdown`和`isTerminated`也比较重要，前者在线程池调用`shutdown`后返回true，后者在线程池中任务全部执行结束后才返回true：\n\n  ```JAVA\n  @Test\n  public void test4() throws Exception {\n  \tSystem.out.println(\"try to shutdownNow threadPool!\");\n  \texecutorService.shutdown();\n  \t// still RejectedExecutionException\n  \tSystem.out.println(executorService.isShutdown());\n  \tSystem.out.println(executorService.isTerminated());\n  }\n  ```\n\n  ![1547713322805](/blog/images/1547713322805.png)\n\n  调用`isShutdown`后，`isShutdown`为true，但`isTerminated`为false\n\n  ```JAVA\n  @Test\n  public void test5() throws Exception {\n  \tSystem.out.println(\"try to shutdown threadPool!\");\n  \t// wait for the tasks which is in execution to finish their work\n  \texecutorService.shutdown();\n  \tSystem.out.println(executorService.isShutdown());\n  \tSystem.out.println(executorService.isTerminated());\n  \twhile (!executorService.awaitTermination(1, TimeUnit.SECONDS)) {\n  \t\tSystem.out.println(\"threadPool is not terminated!\");\n  \t}\n  \tSystem.out.println(\"threadPool is terminated!\");\n  \tSystem.out.println(executorService.isTerminated());\n  }\n  ```\n\n  ![1547713402558](/blog/images/1547713402558.png)\n\n  第一次调用`isTerminated`，返回false，最后等所有任务都执行完了，该方法便返回true\n\n\n\n### 源码浅析\n\n调用上述几种线程池生命周期方法后，线程池内部做的怎样的实现呢？jdk线程池内部实现机理还是挺复杂的，现在从`isShutdown`入手来一探究竟\n\n- shutdown()\n\n  ```JAVA\n  public void shutdown() {\n      final ReentrantLock mainLock = this.mainLock;\n      mainLock.lock();\n      try {\n          checkShutdownAccess();\n          advanceRunState(SHUTDOWN);\n          interruptIdleWorkers();\n          onShutdown(); // hook for ScheduledThreadPoolExecutor\n      } finally {\n          mainLock.unlock();\n      }\n      tryTerminate();\n  }\n  ```\n\n  `mainLock`用于将线程的停止操作进行同步处理，然后调用`checkShutdownAccess`对用户是否有线程访问权限\n\n- advanceRunState(SHUTDOWN)\n\n  `advanceRunState`方法用于切换线程池状态，调用该方法将线程池状态设置为`SHUTDOWN`\n\n  ```JAVA\n      private void advanceRunState(int targetState) {\n          for (;;) {\n              int c = ctl.get();\n              if (runStateAtLeast(c, targetState) ||\n                  ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c))))\n                  break;\n          }\n      }\n  ```\n\n  内部使用了CAS原子操作来进行状态切换\n\n- interruptIdleWorkers()\n\n  interruptIdleWorkers()方法用来给每个空闲的`worker`线程打上interrupt标记:\n\n  ```JAVA\n      private void interruptIdleWorkers(boolean onlyOne) {\n          final ReentrantLock mainLock = this.mainLock;\n          mainLock.lock();\n          try {\n              for (Worker w : workers) {\n                  Thread t = w.thread;\n                  if (!t.isInterrupted() && w.tryLock()) {\n                      try {\n                          t.interrupt();\n                      } catch (SecurityException ignore) {\n                      } finally {\n                          w.unlock();\n                      }\n                  }\n                  if (onlyOne)\n                      break;\n              }\n          } finally {\n              mainLock.unlock();\n          }\n      }\n  ```\n\n  `!t.isInterrupted() && w.tryLock() `这个判断很重要，首先判断当前worker的执行线程是否已经interrupt，然后判断worker是否能成功获取锁，如果返回true则说明当前worker没有执行任务（），最后执行interrupt()方法并释放work锁和mainLock同步锁\n\n- onShutdown()\n\n- tryTerminate()\n\n  interruptIdleWorkers方法只能保证将空闲的worker线程置为interruptted，但正在工作的worker还是会继续执行任务，这时候需要启用`tryTerminate`方法，进行终止操作：\n\n  ```JAVA\n      final void tryTerminate() {\n          for (;;) {\n              int c = ctl.get();\n              // 以下三种状态不进行终止操作：\n              // 1.RUNNING状态 2.TIDING或者TERMINATED状态 3.SHUTDOWN状态并且workQueue不为空\n              if (isRunning(c) ||\n                  runStateAtLeast(c, TIDYING) ||\n                  (runStateOf(c) == SHUTDOWN && ! workQueue.isEmpty()))\n                  return;\n              // 尝试interrupt空闲的worker，只中断一个\n              if (workerCountOf(c) != 0) { // Eligible to terminate\n                  interruptIdleWorkers(ONLY_ONE);\n                  return;\n              }\n  \t\t\t\n              final ReentrantLock mainLock = this.mainLock;\n              mainLock.lock();\n              try {\n                  // 真正开始终止操作，通过CAS将当前状态置为TIDYNG，即高于STOP的一种状态\n                  if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) {\n                      try {\n                          //终止操作，在ThreadPoolExecutor中啥也没做，留给子类用作额外的资源回收\n                          terminated();\n                      } finally {\n                          //将状态置为TERMINATED\n                          ctl.set(ctlOf(TERMINATED, 0));\n                          //将调用了awaitTermination()的线程唤醒\n                          termination.signalAll();\n                      }\n                      return;\n                  }\n              } finally {\n                  mainLock.unlock();\n              }\n              // else retry on failed CAS\n          }\n      }\n  ```","slug":"java线程池源码分析--shutdown, shutdownNow, awaitTermination","published":1,"updated":"2021-05-31T03:06:33.197Z","_id":"ckf0h31hz001aactsoftdfe39","comments":1,"layout":"post","photos":[],"link":"","content":"<p>谈到jdk线程池的生命周期就不得不说shutdown，shutdownNow和awaitTermination这三个方法，一般用来进行线程池的停止和资源的释放，以下例子主要讨论<code>ThreadPoolExecutor</code>的实现</p>\n<a id=\"more\"></a>\n<h3 id=\"程序演示\"><a href=\"#程序演示\" class=\"headerlink\" title=\"程序演示\"></a>程序演示</h3><ul>\n<li><p>shutdown</p>\n<p>该方法用于在结束线程池的任务提交后关闭线程池，让线程池拒绝后续的任务提交，以下提交5个任务到线程池，并调用<code>shutdown</code>方法，接着尝试再次提交任务：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Before</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setup</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\texecutorService = Executors.newFixedThreadPool(<span class=\"number\">5</span>);</span><br><span class=\"line\">\trunnable = <span class=\"keyword\">new</span> Runnable() &#123;</span><br><span class=\"line\">\t\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\t\tSystem.out.println(<span class=\"string\">\"Thread: &#123;\"</span> + Thread.currentThread().getName() + <span class=\"string\">\"&#125; start!\"</span>);</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t\t\t\tThread.sleep(<span class=\"number\">3000</span>);</span><br><span class=\"line\">\t\t\t&#125; <span class=\"keyword\">catch</span> (InterruptedException e) &#123;</span><br><span class=\"line\">\t\t\t\te.printStackTrace();</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tSystem.out.println(<span class=\"string\">\"Thread: &#123;\"</span> + Thread.currentThread().getName() + <span class=\"string\">\"&#125; stop!\"</span>);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">5</span>; i++) &#123;</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Test</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test2</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"try to shutdown threadPool!\"</span>);</span><br><span class=\"line\">\texecutorService.shutdown();</span><br><span class=\"line\">\t<span class=\"comment\">// here, jump out RejectedExecutionException</span></span><br><span class=\"line\">\texecutorService.submit(runnable);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>输出结果：</p>\n<p><img src=\"/blog/images/1547708979007.png\" alt=\"1547708979007\"></p>\n<p>可以看出，调用<code>shutdown</code>后是无法再次提交任务的，资源会被回收，只能重新创建一个新的线程池重新提交任务</p>\n</li>\n<li><p>shutdown配合awaitTermination</p>\n<p>通常情况下<code>shutdown</code>方法不会独立使用，因为调用这个方法后无法得知立即线程池是否已经停止了，可能还有任务未执行完，官方注释如下：</p>\n<p><img src=\"/blog/images/1547709651604.png\" alt=\"1547709651604\"></p>\n<blockquote>\n<p>该方法并不会等待之前提交的任务完成执行，如果想达到这个目的请使用awaitTermination</p>\n</blockquote>\n<p>这个解释我认为有一点歧义，因为<code>shutdown</code>方法是会等待之前提交的任务完成执行的，只不过调用了该方法后并不会留时间给用户一个反馈，而<code>awaitTermination</code>会等待一段时间并查看线程池是否已经停止了:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Test</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test1</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"try to shutdown threadPool!\"</span>);</span><br><span class=\"line\">\t<span class=\"comment\">// wait for the tasks which is in execution to finish their work</span></span><br><span class=\"line\">\texecutorService.shutdown();</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (!executorService.awaitTermination(<span class=\"number\">1</span>, TimeUnit.SECONDS)) &#123;</span><br><span class=\"line\">\t\tSystem.out.println(<span class=\"string\">\"threadPool is not terminated!\"</span>);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"threadPool is terminated!\"</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>结果：</p>\n<p><img src=\"/blog/images/1547710015291.png\" alt=\"1547710015291\"></p>\n<p>提交5个任务后马上调用<code>shutdown</code>, 并不会中止任务，让<code>awaitTermination</code>每隔一秒检查一下是否停止，以此达到确认线程池成功停止的目的</p>\n</li>\n</ul>\n<ul>\n<li><p>shutdownNow</p>\n<p><code>shutdown</code>会等到提交过的任务完成执行， 但<code>shutdownNow</code>会尝试停止当前所有正在执行的任务</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Before</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setup</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\texecutorService = Executors.newFixedThreadPool(<span class=\"number\">5</span>);</span><br><span class=\"line\">\trunnable = <span class=\"keyword\">new</span> Runnable() &#123;</span><br><span class=\"line\">\t\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\t\tSystem.out.println(<span class=\"string\">\"Thread: &#123;\"</span> + Thread.currentThread().getName() + <span class=\"string\">\"&#125; start!\"</span>);</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">boolean</span> isInterrupted = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t\t\t\tThread.sleep(<span class=\"number\">3000</span>);</span><br><span class=\"line\">\t\t\t&#125; <span class=\"keyword\">catch</span> (InterruptedException e) &#123;</span><br><span class=\"line\">\t\t\t\tisInterrupted = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> (!isInterrupted) &#123;</span><br><span class=\"line\">\t\t\t\tSystem.out.println(<span class=\"string\">\"Thread: &#123;\"</span> + Thread.currentThread().getName() + <span class=\"string\">\"&#125; stop!\"</span>);</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">5</span>; i++) &#123;</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Test</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test3</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"try to shutdownNow threadPool!\"</span>);</span><br><span class=\"line\">\t<span class=\"comment\">// if the Runnable or Callable can jump out InterruptedException</span></span><br><span class=\"line\">\t<span class=\"comment\">// the thread in ThreadPool can be terminated by this method</span></span><br><span class=\"line\">\texecutorService.shutdownNow();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>程序对比之前的例子，做了一些修改，当出现<code>InterruptedException</code>则中断线程，结果如下：</p>\n<p><img src=\"/blog/images/1547712156480.png\" alt=\"1547712156480\"></p>\n<p>官方文档指出，当调用<code>shutdownNow</code>后，每个正在执行任务的线程调用了<code>interrupt()</code>方法，但这种方式只有对能正常反馈<code>InterruptedException</code>的线程使用，否则正在运行的线程依然无法停止：</p>\n<p><img src=\"/blog/images/1547712312524.png\" alt=\"1547712312524\"></p>\n</li>\n</ul>\n<p>  <code>shutdownNow</code>最终会返回还未执行的任务集合，比如如下例子：</p>\n  <figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Test</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test1</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\texecutorService = Executors.newFixedThreadPool(<span class=\"number\">1</span>);</span><br><span class=\"line\">\t\trunnable = <span class=\"keyword\">new</span> Runnable() &#123;</span><br><span class=\"line\">\t\t\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\t\t\tSystem.out.println(<span class=\"string\">\"Thread: &#123;\"</span> + Thread.currentThread().getName() + <span class=\"string\">\"&#125; start!\"</span>);</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">boolean</span> isInterrupted = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t\t\t\t\tThread.sleep(<span class=\"number\">3000</span>);</span><br><span class=\"line\">\t\t\t\t&#125; <span class=\"keyword\">catch</span> (InterruptedException e) &#123;</span><br><span class=\"line\">\t\t\t\t\tisInterrupted = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">if</span> (!isInterrupted) &#123;</span><br><span class=\"line\">\t\t\t\t\tSystem.out.println(<span class=\"string\">\"Thread: &#123;\"</span> + Thread.currentThread().getName() + <span class=\"string\">\"&#125; stop!\"</span>);</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;;</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t\tList&lt;Runnable&gt; noExecutedTasks = executorService.shutdownNow();</span><br><span class=\"line\">\t\tSystem.out.println(noExecutedTasks.size());</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n<p>  结果如下：</p>\n<p>  <img src=\"/blog/images/1547712873168.png\" alt=\"1547712873168\"></p>\n<p>  线程池最大线程数只有1个，提交5个任务后马上调用<code>shutdownNow</code>，正在执行的任务被终止，并导致剩下4个任务没有机会执行，则将这四个任务集合返还给用户</p>\n<ul>\n<li><p>isShutdown和isTerminated</p>\n<p>线程池生命周期方法中的<code>isShutdown</code>和<code>isTerminated</code>也比较重要，前者在线程池调用<code>shutdown</code>后返回true，后者在线程池中任务全部执行结束后才返回true：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Test</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test4</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"try to shutdownNow threadPool!\"</span>);</span><br><span class=\"line\">\texecutorService.shutdown();</span><br><span class=\"line\">\t<span class=\"comment\">// still RejectedExecutionException</span></span><br><span class=\"line\">\tSystem.out.println(executorService.isShutdown());</span><br><span class=\"line\">\tSystem.out.println(executorService.isTerminated());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"/blog/images/1547713322805.png\" alt=\"1547713322805\"></p>\n<p>调用<code>isShutdown</code>后，<code>isShutdown</code>为true，但<code>isTerminated</code>为false</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Test</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test5</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"try to shutdown threadPool!\"</span>);</span><br><span class=\"line\">\t<span class=\"comment\">// wait for the tasks which is in execution to finish their work</span></span><br><span class=\"line\">\texecutorService.shutdown();</span><br><span class=\"line\">\tSystem.out.println(executorService.isShutdown());</span><br><span class=\"line\">\tSystem.out.println(executorService.isTerminated());</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (!executorService.awaitTermination(<span class=\"number\">1</span>, TimeUnit.SECONDS)) &#123;</span><br><span class=\"line\">\t\tSystem.out.println(<span class=\"string\">\"threadPool is not terminated!\"</span>);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"threadPool is terminated!\"</span>);</span><br><span class=\"line\">\tSystem.out.println(executorService.isTerminated());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"/blog/images/1547713402558.png\" alt=\"1547713402558\"></p>\n<p>第一次调用<code>isTerminated</code>，返回false，最后等所有任务都执行完了，该方法便返回true</p>\n</li>\n</ul>\n<h3 id=\"源码浅析\"><a href=\"#源码浅析\" class=\"headerlink\" title=\"源码浅析\"></a>源码浅析</h3><p>调用上述几种线程池生命周期方法后，线程池内部做的怎样的实现呢？jdk线程池内部实现机理还是挺复杂的，现在从<code>isShutdown</code>入手来一探究竟</p>\n<ul>\n<li><p>shutdown()</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">shutdown</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> ReentrantLock mainLock = <span class=\"keyword\">this</span>.mainLock;</span><br><span class=\"line\">    mainLock.lock();</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        checkShutdownAccess();</span><br><span class=\"line\">        advanceRunState(SHUTDOWN);</span><br><span class=\"line\">        interruptIdleWorkers();</span><br><span class=\"line\">        onShutdown(); <span class=\"comment\">// hook for ScheduledThreadPoolExecutor</span></span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        mainLock.unlock();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    tryTerminate();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>mainLock</code>用于将线程的停止操作进行同步处理，然后调用<code>checkShutdownAccess</code>对用户是否有线程访问权限</p>\n</li>\n<li><p>advanceRunState(SHUTDOWN)</p>\n<p><code>advanceRunState</code>方法用于切换线程池状态，调用该方法将线程池状态设置为<code>SHUTDOWN</code></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">advanceRunState</span><span class=\"params\">(<span class=\"keyword\">int</span> targetState)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> c = ctl.get();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (runStateAtLeast(c, targetState) ||</span><br><span class=\"line\">            ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c))))</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>内部使用了CAS原子操作来进行状态切换</p>\n</li>\n<li><p>interruptIdleWorkers()</p>\n<p>interruptIdleWorkers()方法用来给每个空闲的<code>worker</code>线程打上interrupt标记:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">interruptIdleWorkers</span><span class=\"params\">(<span class=\"keyword\">boolean</span> onlyOne)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> ReentrantLock mainLock = <span class=\"keyword\">this</span>.mainLock;</span><br><span class=\"line\">    mainLock.lock();</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (Worker w : workers) &#123;</span><br><span class=\"line\">            Thread t = w.thread;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    t.interrupt();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (SecurityException ignore) &#123;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    w.unlock();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (onlyOne)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        mainLock.unlock();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>!t.isInterrupted() &amp;&amp; w.tryLock()</code>这个判断很重要，首先判断当前worker的执行线程是否已经interrupt，然后判断worker是否能成功获取锁，如果返回true则说明当前worker没有执行任务（），最后执行interrupt()方法并释放work锁和mainLock同步锁</p>\n</li>\n<li><p>onShutdown()</p>\n</li>\n<li><p>tryTerminate()</p>\n<p>interruptIdleWorkers方法只能保证将空闲的worker线程置为interruptted，但正在工作的worker还是会继续执行任务，这时候需要启用<code>tryTerminate</code>方法，进行终止操作：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">tryTerminate</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> c = ctl.get();</span><br><span class=\"line\">        <span class=\"comment\">// 以下三种状态不进行终止操作：</span></span><br><span class=\"line\">        <span class=\"comment\">// 1.RUNNING状态 2.TIDING或者TERMINATED状态 3.SHUTDOWN状态并且workQueue不为空</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (isRunning(c) ||</span><br><span class=\"line\">            runStateAtLeast(c, TIDYING) ||</span><br><span class=\"line\">            (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty()))</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"comment\">// 尝试interrupt空闲的worker，只中断一个</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (workerCountOf(c) != <span class=\"number\">0</span>) &#123; <span class=\"comment\">// Eligible to terminate</span></span><br><span class=\"line\">            interruptIdleWorkers(ONLY_ONE);</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">  \t\t\t</span><br><span class=\"line\">        <span class=\"keyword\">final</span> ReentrantLock mainLock = <span class=\"keyword\">this</span>.mainLock;</span><br><span class=\"line\">        mainLock.lock();</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 真正开始终止操作，通过CAS将当前状态置为TIDYNG，即高于STOP的一种状态</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (ctl.compareAndSet(c, ctlOf(TIDYING, <span class=\"number\">0</span>))) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">//终止操作，在ThreadPoolExecutor中啥也没做，留给子类用作额外的资源回收</span></span><br><span class=\"line\">                    terminated();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">//将状态置为TERMINATED</span></span><br><span class=\"line\">                    ctl.set(ctlOf(TERMINATED, <span class=\"number\">0</span>));</span><br><span class=\"line\">                    <span class=\"comment\">//将调用了awaitTermination()的线程唤醒</span></span><br><span class=\"line\">                    termination.signalAll();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">return</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">            mainLock.unlock();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// else retry on failed CAS</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>谈到jdk线程池的生命周期就不得不说shutdown，shutdownNow和awaitTermination这三个方法，一般用来进行线程池的停止和资源的释放，以下例子主要讨论<code>ThreadPoolExecutor</code>的实现</p>","more":"<h3 id=\"程序演示\"><a href=\"#程序演示\" class=\"headerlink\" title=\"程序演示\"></a>程序演示</h3><ul>\n<li><p>shutdown</p>\n<p>该方法用于在结束线程池的任务提交后关闭线程池，让线程池拒绝后续的任务提交，以下提交5个任务到线程池，并调用<code>shutdown</code>方法，接着尝试再次提交任务：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Before</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setup</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\texecutorService = Executors.newFixedThreadPool(<span class=\"number\">5</span>);</span><br><span class=\"line\">\trunnable = <span class=\"keyword\">new</span> Runnable() &#123;</span><br><span class=\"line\">\t\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\t\tSystem.out.println(<span class=\"string\">\"Thread: &#123;\"</span> + Thread.currentThread().getName() + <span class=\"string\">\"&#125; start!\"</span>);</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t\t\t\tThread.sleep(<span class=\"number\">3000</span>);</span><br><span class=\"line\">\t\t\t&#125; <span class=\"keyword\">catch</span> (InterruptedException e) &#123;</span><br><span class=\"line\">\t\t\t\te.printStackTrace();</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tSystem.out.println(<span class=\"string\">\"Thread: &#123;\"</span> + Thread.currentThread().getName() + <span class=\"string\">\"&#125; stop!\"</span>);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">5</span>; i++) &#123;</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Test</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test2</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"try to shutdown threadPool!\"</span>);</span><br><span class=\"line\">\texecutorService.shutdown();</span><br><span class=\"line\">\t<span class=\"comment\">// here, jump out RejectedExecutionException</span></span><br><span class=\"line\">\texecutorService.submit(runnable);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>输出结果：</p>\n<p><img src=\"/blog/images/1547708979007.png\" alt=\"1547708979007\"></p>\n<p>可以看出，调用<code>shutdown</code>后是无法再次提交任务的，资源会被回收，只能重新创建一个新的线程池重新提交任务</p>\n</li>\n<li><p>shutdown配合awaitTermination</p>\n<p>通常情况下<code>shutdown</code>方法不会独立使用，因为调用这个方法后无法得知立即线程池是否已经停止了，可能还有任务未执行完，官方注释如下：</p>\n<p><img src=\"/blog/images/1547709651604.png\" alt=\"1547709651604\"></p>\n<blockquote>\n<p>该方法并不会等待之前提交的任务完成执行，如果想达到这个目的请使用awaitTermination</p>\n</blockquote>\n<p>这个解释我认为有一点歧义，因为<code>shutdown</code>方法是会等待之前提交的任务完成执行的，只不过调用了该方法后并不会留时间给用户一个反馈，而<code>awaitTermination</code>会等待一段时间并查看线程池是否已经停止了:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Test</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test1</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"try to shutdown threadPool!\"</span>);</span><br><span class=\"line\">\t<span class=\"comment\">// wait for the tasks which is in execution to finish their work</span></span><br><span class=\"line\">\texecutorService.shutdown();</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (!executorService.awaitTermination(<span class=\"number\">1</span>, TimeUnit.SECONDS)) &#123;</span><br><span class=\"line\">\t\tSystem.out.println(<span class=\"string\">\"threadPool is not terminated!\"</span>);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"threadPool is terminated!\"</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>结果：</p>\n<p><img src=\"/blog/images/1547710015291.png\" alt=\"1547710015291\"></p>\n<p>提交5个任务后马上调用<code>shutdown</code>, 并不会中止任务，让<code>awaitTermination</code>每隔一秒检查一下是否停止，以此达到确认线程池成功停止的目的</p>\n</li>\n</ul>\n<ul>\n<li><p>shutdownNow</p>\n<p><code>shutdown</code>会等到提交过的任务完成执行， 但<code>shutdownNow</code>会尝试停止当前所有正在执行的任务</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Before</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setup</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\texecutorService = Executors.newFixedThreadPool(<span class=\"number\">5</span>);</span><br><span class=\"line\">\trunnable = <span class=\"keyword\">new</span> Runnable() &#123;</span><br><span class=\"line\">\t\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\t\tSystem.out.println(<span class=\"string\">\"Thread: &#123;\"</span> + Thread.currentThread().getName() + <span class=\"string\">\"&#125; start!\"</span>);</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">boolean</span> isInterrupted = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t\t\t\tThread.sleep(<span class=\"number\">3000</span>);</span><br><span class=\"line\">\t\t\t&#125; <span class=\"keyword\">catch</span> (InterruptedException e) &#123;</span><br><span class=\"line\">\t\t\t\tisInterrupted = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> (!isInterrupted) &#123;</span><br><span class=\"line\">\t\t\t\tSystem.out.println(<span class=\"string\">\"Thread: &#123;\"</span> + Thread.currentThread().getName() + <span class=\"string\">\"&#125; stop!\"</span>);</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">5</span>; i++) &#123;</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Test</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test3</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"try to shutdownNow threadPool!\"</span>);</span><br><span class=\"line\">\t<span class=\"comment\">// if the Runnable or Callable can jump out InterruptedException</span></span><br><span class=\"line\">\t<span class=\"comment\">// the thread in ThreadPool can be terminated by this method</span></span><br><span class=\"line\">\texecutorService.shutdownNow();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>程序对比之前的例子，做了一些修改，当出现<code>InterruptedException</code>则中断线程，结果如下：</p>\n<p><img src=\"/blog/images/1547712156480.png\" alt=\"1547712156480\"></p>\n<p>官方文档指出，当调用<code>shutdownNow</code>后，每个正在执行任务的线程调用了<code>interrupt()</code>方法，但这种方式只有对能正常反馈<code>InterruptedException</code>的线程使用，否则正在运行的线程依然无法停止：</p>\n<p><img src=\"/blog/images/1547712312524.png\" alt=\"1547712312524\"></p>\n</li>\n</ul>\n<p>  <code>shutdownNow</code>最终会返回还未执行的任务集合，比如如下例子：</p>\n  <figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Test</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test1</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\texecutorService = Executors.newFixedThreadPool(<span class=\"number\">1</span>);</span><br><span class=\"line\">\t\trunnable = <span class=\"keyword\">new</span> Runnable() &#123;</span><br><span class=\"line\">\t\t\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t\t\t\tSystem.out.println(<span class=\"string\">\"Thread: &#123;\"</span> + Thread.currentThread().getName() + <span class=\"string\">\"&#125; start!\"</span>);</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">boolean</span> isInterrupted = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t\t\t\t\tThread.sleep(<span class=\"number\">3000</span>);</span><br><span class=\"line\">\t\t\t\t&#125; <span class=\"keyword\">catch</span> (InterruptedException e) &#123;</span><br><span class=\"line\">\t\t\t\t\tisInterrupted = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">if</span> (!isInterrupted) &#123;</span><br><span class=\"line\">\t\t\t\t\tSystem.out.println(<span class=\"string\">\"Thread: &#123;\"</span> + Thread.currentThread().getName() + <span class=\"string\">\"&#125; stop!\"</span>);</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;;</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t\texecutorService.submit(runnable);</span><br><span class=\"line\">\t\tList&lt;Runnable&gt; noExecutedTasks = executorService.shutdownNow();</span><br><span class=\"line\">\t\tSystem.out.println(noExecutedTasks.size());</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n<p>  结果如下：</p>\n<p>  <img src=\"/blog/images/1547712873168.png\" alt=\"1547712873168\"></p>\n<p>  线程池最大线程数只有1个，提交5个任务后马上调用<code>shutdownNow</code>，正在执行的任务被终止，并导致剩下4个任务没有机会执行，则将这四个任务集合返还给用户</p>\n<ul>\n<li><p>isShutdown和isTerminated</p>\n<p>线程池生命周期方法中的<code>isShutdown</code>和<code>isTerminated</code>也比较重要，前者在线程池调用<code>shutdown</code>后返回true，后者在线程池中任务全部执行结束后才返回true：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Test</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test4</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"try to shutdownNow threadPool!\"</span>);</span><br><span class=\"line\">\texecutorService.shutdown();</span><br><span class=\"line\">\t<span class=\"comment\">// still RejectedExecutionException</span></span><br><span class=\"line\">\tSystem.out.println(executorService.isShutdown());</span><br><span class=\"line\">\tSystem.out.println(executorService.isTerminated());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"/blog/images/1547713322805.png\" alt=\"1547713322805\"></p>\n<p>调用<code>isShutdown</code>后，<code>isShutdown</code>为true，但<code>isTerminated</code>为false</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Test</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test5</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"try to shutdown threadPool!\"</span>);</span><br><span class=\"line\">\t<span class=\"comment\">// wait for the tasks which is in execution to finish their work</span></span><br><span class=\"line\">\texecutorService.shutdown();</span><br><span class=\"line\">\tSystem.out.println(executorService.isShutdown());</span><br><span class=\"line\">\tSystem.out.println(executorService.isTerminated());</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (!executorService.awaitTermination(<span class=\"number\">1</span>, TimeUnit.SECONDS)) &#123;</span><br><span class=\"line\">\t\tSystem.out.println(<span class=\"string\">\"threadPool is not terminated!\"</span>);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tSystem.out.println(<span class=\"string\">\"threadPool is terminated!\"</span>);</span><br><span class=\"line\">\tSystem.out.println(executorService.isTerminated());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"/blog/images/1547713402558.png\" alt=\"1547713402558\"></p>\n<p>第一次调用<code>isTerminated</code>，返回false，最后等所有任务都执行完了，该方法便返回true</p>\n</li>\n</ul>\n<h3 id=\"源码浅析\"><a href=\"#源码浅析\" class=\"headerlink\" title=\"源码浅析\"></a>源码浅析</h3><p>调用上述几种线程池生命周期方法后，线程池内部做的怎样的实现呢？jdk线程池内部实现机理还是挺复杂的，现在从<code>isShutdown</code>入手来一探究竟</p>\n<ul>\n<li><p>shutdown()</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">shutdown</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> ReentrantLock mainLock = <span class=\"keyword\">this</span>.mainLock;</span><br><span class=\"line\">    mainLock.lock();</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        checkShutdownAccess();</span><br><span class=\"line\">        advanceRunState(SHUTDOWN);</span><br><span class=\"line\">        interruptIdleWorkers();</span><br><span class=\"line\">        onShutdown(); <span class=\"comment\">// hook for ScheduledThreadPoolExecutor</span></span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        mainLock.unlock();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    tryTerminate();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>mainLock</code>用于将线程的停止操作进行同步处理，然后调用<code>checkShutdownAccess</code>对用户是否有线程访问权限</p>\n</li>\n<li><p>advanceRunState(SHUTDOWN)</p>\n<p><code>advanceRunState</code>方法用于切换线程池状态，调用该方法将线程池状态设置为<code>SHUTDOWN</code></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">advanceRunState</span><span class=\"params\">(<span class=\"keyword\">int</span> targetState)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> c = ctl.get();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (runStateAtLeast(c, targetState) ||</span><br><span class=\"line\">            ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c))))</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>内部使用了CAS原子操作来进行状态切换</p>\n</li>\n<li><p>interruptIdleWorkers()</p>\n<p>interruptIdleWorkers()方法用来给每个空闲的<code>worker</code>线程打上interrupt标记:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">interruptIdleWorkers</span><span class=\"params\">(<span class=\"keyword\">boolean</span> onlyOne)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> ReentrantLock mainLock = <span class=\"keyword\">this</span>.mainLock;</span><br><span class=\"line\">    mainLock.lock();</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (Worker w : workers) &#123;</span><br><span class=\"line\">            Thread t = w.thread;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    t.interrupt();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (SecurityException ignore) &#123;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    w.unlock();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (onlyOne)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        mainLock.unlock();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>!t.isInterrupted() &amp;&amp; w.tryLock()</code>这个判断很重要，首先判断当前worker的执行线程是否已经interrupt，然后判断worker是否能成功获取锁，如果返回true则说明当前worker没有执行任务（），最后执行interrupt()方法并释放work锁和mainLock同步锁</p>\n</li>\n<li><p>onShutdown()</p>\n</li>\n<li><p>tryTerminate()</p>\n<p>interruptIdleWorkers方法只能保证将空闲的worker线程置为interruptted，但正在工作的worker还是会继续执行任务，这时候需要启用<code>tryTerminate</code>方法，进行终止操作：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">tryTerminate</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> c = ctl.get();</span><br><span class=\"line\">        <span class=\"comment\">// 以下三种状态不进行终止操作：</span></span><br><span class=\"line\">        <span class=\"comment\">// 1.RUNNING状态 2.TIDING或者TERMINATED状态 3.SHUTDOWN状态并且workQueue不为空</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (isRunning(c) ||</span><br><span class=\"line\">            runStateAtLeast(c, TIDYING) ||</span><br><span class=\"line\">            (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty()))</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"comment\">// 尝试interrupt空闲的worker，只中断一个</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (workerCountOf(c) != <span class=\"number\">0</span>) &#123; <span class=\"comment\">// Eligible to terminate</span></span><br><span class=\"line\">            interruptIdleWorkers(ONLY_ONE);</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">  \t\t\t</span><br><span class=\"line\">        <span class=\"keyword\">final</span> ReentrantLock mainLock = <span class=\"keyword\">this</span>.mainLock;</span><br><span class=\"line\">        mainLock.lock();</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 真正开始终止操作，通过CAS将当前状态置为TIDYNG，即高于STOP的一种状态</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (ctl.compareAndSet(c, ctlOf(TIDYING, <span class=\"number\">0</span>))) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">//终止操作，在ThreadPoolExecutor中啥也没做，留给子类用作额外的资源回收</span></span><br><span class=\"line\">                    terminated();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">//将状态置为TERMINATED</span></span><br><span class=\"line\">                    ctl.set(ctlOf(TERMINATED, <span class=\"number\">0</span>));</span><br><span class=\"line\">                    <span class=\"comment\">//将调用了awaitTermination()的线程唤醒</span></span><br><span class=\"line\">                    termination.signalAll();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">return</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">            mainLock.unlock();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// else retry on failed CAS</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n</ul>"},{"title":"Mongodb索引浅析","author":"","date":"2019-01-21T03:16:00.000Z","_content":"mongodb索引数据结果是`b-树`，该数据结构作为索引具有高性能，磁盘io少等特点\n\n### 何为b-树\n\nb-树，又称b树，跟mysql的b+树索引不同，mongodb的b-树索引节点直接与数据绑定，找到索引后直接返回索引对应的document，这种索引适合mongodb这种聚合型nosql数据库：\n\n<!-- more -->\n\n![1547792452619](\\blog\\images\\1547792452619.png)\n\n- b树节点元素个数为k，子节点个数为k+1\n- 如果b树的阶树为m，则`m/2 ≤ k ≤ m`\n- 查询的时间复杂度为O(log n)，单次查询的磁盘io次数为数的高度\n\n### mongodb索引种类\n\nmongodb索引分为如下\n\n- single index: 单个索引，索引字段只有一个：\n\n  ```javascript\n  db.getCollection('user').createIndex({name:1})\n  ```\n\n  score是索引字段，1表示升序索引，-1表示降序索引：\n\n- compound indexex: 混合索引，跟mysql类似，也是由多个字段组成索引：\n\n  ```javascript\n  db.getCollection('user').createIndex({name:1,gender:1})\n  ```\n\n  使用混合索引时，有一些地方需要注意\n\n  - 排序查找的顺序：\n\n    官方文档提到：\n\n    > However, for [compound indexes], sort order can matter in determining whether the index can support a sort operation\n    >\n    > 对于复合索引，排序字段的顺序对于排序操作是否启用索引非常重要\n\n    对于如下索引：\n\n    ```javascript\n    db.getCollection('user').createIndex( { name : 1, gender : -1 } )\n    ```\n\n    对姓名作升序索引，对性别做降序索引，那么在进行以下两种排序时，都会启用索引\n\n    ```javascript\n    db.getCollection('user').find({}).sort({ name : -1, gender : 1 })\n    db.getCollection('user').find({}).sort({ name : 1, gender : -1 })\n    ```\n\n    用`explain(\"allPlansExecution\")`查看执行计划发现，totalKeysExamined是所需结果的数目，说明全部查询均走的索引，执行阶段首先执行IXSCAN即扫描索引确定key的位置，然后执行FETCH去检索指定的document。\n\n    但对以下排序，是不会启用索引的：\n\n    ```javascript\n    db.getCollection('user').find({}).sort({ name : 1, gender : 1 })\n    db.getCollection('user').find({}).sort({ name : -1, gender : -1 })\n    ```\n\n    用`explain(\"allPlansExecution\")`查看执行计划发现，totalKeysExamined是0，执行阶段首先执行COLLSCAN即全表扫描，然后进行排序；说明如果排序查找如果跟索引的排序情况不匹配的话，将放弃启用索引。\n\n  - 左子前缀子集：\n\n    这样的索引：`{ name : 1, gender : 1 }`，包含以下的前缀子集：\n\n    ```javascript\n    { name : 1}\n    { name : 1, gender : 1 }\n    ```\n\n    但不包含以下形式:\n\n    ```javascript\n    { gender : 1}\n    { gender : 1, name : 1 }\n    ```\n\n    使用的时候要特别注意能否匹配上索引的前缀子集\n\n- multikey indexes: 多key型索引，索引字段通常是数组类型\n\n- geospatial indexes: 地理位置索引，包括2dsphere和2d还有geoHaystack三种类型\n\n- text indexex: 全文索引，一个document最多只能有一个全文索引，用于在文档中搜索文本，但创建索引的开销比较大，需要后台或离线创建，综合来说不如elasticsearch等搜索引擎\n\n  在文本中subject和comments两个字段建立了全文索引“text”：\n\n  ```javascript\n  db.reviews.createIndex(\n     {\n       subject: \"text\",\n       comments: \"text\"\n     }\n   )\n  ```\n\n- hashed index：用于分布式collection分片的场景，将不同的document按照某个字段取hash的形式分布到不同的sharding上去：\n\n  > Hashed indexes support [sharding] using hashed shard keys. [Hashed based sharding] uses a hashed index of a field as the shard key to partition data across your sharded cluster.\n\n  对name字段创建一个hashed索引：\n\n  ```javascript\n  db.collection.createIndex( { name: \"hashed\" } )\n  ```\n\n\n\n### mongodb索引属性\n\n建立索引时可以对索引指定属性，有以下几种属性：\n\n- TTL: 对索引设置过期时间shu，有两种方式\n\n  - 延迟时间：在索引创建后延迟特定秒数然后删除该document：\n\n    ```javascript\n    db.collection.createIndex( { \"createAt\": 1 }, { expireAfterSeconds: 3600 } )\n    ```\n\n    createAt字段保存了创建时间，该document会在这个时间的3600秒后被删除\n\n  - 固定时间：在索引创建后延迟特定秒数然后删除该document:\n\n    ```javascript\n    db.collection.createIndex( { \"expireTime\": 1 }, { expireAfterSeconds: 0 } )\n    ```\n\n    该document将在到达expireTime上设置的时间时被删除\n\n- unique index：唯一索引，索引字段唯一，若插入包含相同内容字段的document则会报错\n\n  ```javascript\n  db.getCollection('user').createIndex({name:1}, {unique: true})\n  ```\n\n- spares indexes：稀疏索引，如果设置了稀疏索引，将只对有该索引字段的document启用索引\n\n- partial indexes： 部分索引，跟稀疏索引一样也是非完全索引，在创建索引时可以对索引字段设置一个范围，在这个范围内的才启用索引：\n\n  ```javascript\n  db.restaurants.createIndex(\n     { cuisine: 1, name: 1 },\n     { partialFilterExpression: { rating: { $gt: 5 } } }\n  )\n  ```\n\n  partialFilterExpression表示范围取值，rating是部分索引的索引字段，需要注意的是，进行查询时，查询范围不能超出部分索引的设定范围，不然无法启用索引\n\n- case insensitive indexes\n\n\n\n### mongodb执行计划\n\n通过`explain()`执行计划进行mongodb的性能分析","source":"_posts/mongodb索引类型.md","raw":"title: Mongodb索引浅析\ntags:\n  - mongodb\ncategories: []\nauthor: ''\ndate: 2019-01-21 11:16:00\n---\nmongodb索引数据结果是`b-树`，该数据结构作为索引具有高性能，磁盘io少等特点\n\n### 何为b-树\n\nb-树，又称b树，跟mysql的b+树索引不同，mongodb的b-树索引节点直接与数据绑定，找到索引后直接返回索引对应的document，这种索引适合mongodb这种聚合型nosql数据库：\n\n<!-- more -->\n\n![1547792452619](\\blog\\images\\1547792452619.png)\n\n- b树节点元素个数为k，子节点个数为k+1\n- 如果b树的阶树为m，则`m/2 ≤ k ≤ m`\n- 查询的时间复杂度为O(log n)，单次查询的磁盘io次数为数的高度\n\n### mongodb索引种类\n\nmongodb索引分为如下\n\n- single index: 单个索引，索引字段只有一个：\n\n  ```javascript\n  db.getCollection('user').createIndex({name:1})\n  ```\n\n  score是索引字段，1表示升序索引，-1表示降序索引：\n\n- compound indexex: 混合索引，跟mysql类似，也是由多个字段组成索引：\n\n  ```javascript\n  db.getCollection('user').createIndex({name:1,gender:1})\n  ```\n\n  使用混合索引时，有一些地方需要注意\n\n  - 排序查找的顺序：\n\n    官方文档提到：\n\n    > However, for [compound indexes], sort order can matter in determining whether the index can support a sort operation\n    >\n    > 对于复合索引，排序字段的顺序对于排序操作是否启用索引非常重要\n\n    对于如下索引：\n\n    ```javascript\n    db.getCollection('user').createIndex( { name : 1, gender : -1 } )\n    ```\n\n    对姓名作升序索引，对性别做降序索引，那么在进行以下两种排序时，都会启用索引\n\n    ```javascript\n    db.getCollection('user').find({}).sort({ name : -1, gender : 1 })\n    db.getCollection('user').find({}).sort({ name : 1, gender : -1 })\n    ```\n\n    用`explain(\"allPlansExecution\")`查看执行计划发现，totalKeysExamined是所需结果的数目，说明全部查询均走的索引，执行阶段首先执行IXSCAN即扫描索引确定key的位置，然后执行FETCH去检索指定的document。\n\n    但对以下排序，是不会启用索引的：\n\n    ```javascript\n    db.getCollection('user').find({}).sort({ name : 1, gender : 1 })\n    db.getCollection('user').find({}).sort({ name : -1, gender : -1 })\n    ```\n\n    用`explain(\"allPlansExecution\")`查看执行计划发现，totalKeysExamined是0，执行阶段首先执行COLLSCAN即全表扫描，然后进行排序；说明如果排序查找如果跟索引的排序情况不匹配的话，将放弃启用索引。\n\n  - 左子前缀子集：\n\n    这样的索引：`{ name : 1, gender : 1 }`，包含以下的前缀子集：\n\n    ```javascript\n    { name : 1}\n    { name : 1, gender : 1 }\n    ```\n\n    但不包含以下形式:\n\n    ```javascript\n    { gender : 1}\n    { gender : 1, name : 1 }\n    ```\n\n    使用的时候要特别注意能否匹配上索引的前缀子集\n\n- multikey indexes: 多key型索引，索引字段通常是数组类型\n\n- geospatial indexes: 地理位置索引，包括2dsphere和2d还有geoHaystack三种类型\n\n- text indexex: 全文索引，一个document最多只能有一个全文索引，用于在文档中搜索文本，但创建索引的开销比较大，需要后台或离线创建，综合来说不如elasticsearch等搜索引擎\n\n  在文本中subject和comments两个字段建立了全文索引“text”：\n\n  ```javascript\n  db.reviews.createIndex(\n     {\n       subject: \"text\",\n       comments: \"text\"\n     }\n   )\n  ```\n\n- hashed index：用于分布式collection分片的场景，将不同的document按照某个字段取hash的形式分布到不同的sharding上去：\n\n  > Hashed indexes support [sharding] using hashed shard keys. [Hashed based sharding] uses a hashed index of a field as the shard key to partition data across your sharded cluster.\n\n  对name字段创建一个hashed索引：\n\n  ```javascript\n  db.collection.createIndex( { name: \"hashed\" } )\n  ```\n\n\n\n### mongodb索引属性\n\n建立索引时可以对索引指定属性，有以下几种属性：\n\n- TTL: 对索引设置过期时间shu，有两种方式\n\n  - 延迟时间：在索引创建后延迟特定秒数然后删除该document：\n\n    ```javascript\n    db.collection.createIndex( { \"createAt\": 1 }, { expireAfterSeconds: 3600 } )\n    ```\n\n    createAt字段保存了创建时间，该document会在这个时间的3600秒后被删除\n\n  - 固定时间：在索引创建后延迟特定秒数然后删除该document:\n\n    ```javascript\n    db.collection.createIndex( { \"expireTime\": 1 }, { expireAfterSeconds: 0 } )\n    ```\n\n    该document将在到达expireTime上设置的时间时被删除\n\n- unique index：唯一索引，索引字段唯一，若插入包含相同内容字段的document则会报错\n\n  ```javascript\n  db.getCollection('user').createIndex({name:1}, {unique: true})\n  ```\n\n- spares indexes：稀疏索引，如果设置了稀疏索引，将只对有该索引字段的document启用索引\n\n- partial indexes： 部分索引，跟稀疏索引一样也是非完全索引，在创建索引时可以对索引字段设置一个范围，在这个范围内的才启用索引：\n\n  ```javascript\n  db.restaurants.createIndex(\n     { cuisine: 1, name: 1 },\n     { partialFilterExpression: { rating: { $gt: 5 } } }\n  )\n  ```\n\n  partialFilterExpression表示范围取值，rating是部分索引的索引字段，需要注意的是，进行查询时，查询范围不能超出部分索引的设定范围，不然无法启用索引\n\n- case insensitive indexes\n\n\n\n### mongodb执行计划\n\n通过`explain()`执行计划进行mongodb的性能分析","slug":"mongodb索引类型","published":1,"updated":"2021-05-31T03:06:33.198Z","_id":"ckf0h31i0001cactsl4r3hlvk","comments":1,"layout":"post","photos":[],"link":"","content":"<p>mongodb索引数据结果是<code>b-树</code>，该数据结构作为索引具有高性能，磁盘io少等特点</p>\n<h3 id=\"何为b-树\"><a href=\"#何为b-树\" class=\"headerlink\" title=\"何为b-树\"></a>何为b-树</h3><p>b-树，又称b树，跟mysql的b+树索引不同，mongodb的b-树索引节点直接与数据绑定，找到索引后直接返回索引对应的document，这种索引适合mongodb这种聚合型nosql数据库：</p>\n<a id=\"more\"></a>\n<p><img src=\"\\blog\\images\\1547792452619.png\" alt=\"1547792452619\"></p>\n<ul>\n<li>b树节点元素个数为k，子节点个数为k+1</li>\n<li>如果b树的阶树为m，则<code>m/2 ≤ k ≤ m</code></li>\n<li>查询的时间复杂度为O(log n)，单次查询的磁盘io次数为数的高度</li>\n</ul>\n<h3 id=\"mongodb索引种类\"><a href=\"#mongodb索引种类\" class=\"headerlink\" title=\"mongodb索引种类\"></a>mongodb索引种类</h3><p>mongodb索引分为如下</p>\n<ul>\n<li><p>single index: 单个索引，索引字段只有一个：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).createIndex(&#123;<span class=\"attr\">name</span>:<span class=\"number\">1</span>&#125;)</span><br></pre></td></tr></table></figure>\n<p>score是索引字段，1表示升序索引，-1表示降序索引：</p>\n</li>\n<li><p>compound indexex: 混合索引，跟mysql类似，也是由多个字段组成索引：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).createIndex(&#123;<span class=\"attr\">name</span>:<span class=\"number\">1</span>,<span class=\"attr\">gender</span>:<span class=\"number\">1</span>&#125;)</span><br></pre></td></tr></table></figure>\n<p>使用混合索引时，有一些地方需要注意</p>\n<ul>\n<li><p>排序查找的顺序：</p>\n<p>官方文档提到：</p>\n<blockquote>\n<p>However, for [compound indexes], sort order can matter in determining whether the index can support a sort operation</p>\n<p>对于复合索引，排序字段的顺序对于排序操作是否启用索引非常重要</p>\n</blockquote>\n<p>对于如下索引：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).createIndex( &#123; <span class=\"attr\">name</span> : <span class=\"number\">1</span>, <span class=\"attr\">gender</span> : <span class=\"number\">-1</span> &#125; )</span><br></pre></td></tr></table></figure>\n<p>对姓名作升序索引，对性别做降序索引，那么在进行以下两种排序时，都会启用索引</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).find(&#123;&#125;).sort(&#123; <span class=\"attr\">name</span> : <span class=\"number\">-1</span>, <span class=\"attr\">gender</span> : <span class=\"number\">1</span> &#125;)</span><br><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).find(&#123;&#125;).sort(&#123; <span class=\"attr\">name</span> : <span class=\"number\">1</span>, <span class=\"attr\">gender</span> : <span class=\"number\">-1</span> &#125;)</span><br></pre></td></tr></table></figure>\n<p>用<code>explain(&quot;allPlansExecution&quot;)</code>查看执行计划发现，totalKeysExamined是所需结果的数目，说明全部查询均走的索引，执行阶段首先执行IXSCAN即扫描索引确定key的位置，然后执行FETCH去检索指定的document。</p>\n<p>但对以下排序，是不会启用索引的：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).find(&#123;&#125;).sort(&#123; <span class=\"attr\">name</span> : <span class=\"number\">1</span>, <span class=\"attr\">gender</span> : <span class=\"number\">1</span> &#125;)</span><br><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).find(&#123;&#125;).sort(&#123; <span class=\"attr\">name</span> : <span class=\"number\">-1</span>, <span class=\"attr\">gender</span> : <span class=\"number\">-1</span> &#125;)</span><br></pre></td></tr></table></figure>\n<p>用<code>explain(&quot;allPlansExecution&quot;)</code>查看执行计划发现，totalKeysExamined是0，执行阶段首先执行COLLSCAN即全表扫描，然后进行排序；说明如果排序查找如果跟索引的排序情况不匹配的话，将放弃启用索引。</p>\n</li>\n<li><p>左子前缀子集：</p>\n<p>这样的索引：<code>{ name : 1, gender : 1 }</code>，包含以下的前缀子集：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123; <span class=\"attr\">name</span> : <span class=\"number\">1</span>&#125;</span><br><span class=\"line\">&#123; <span class=\"attr\">name</span> : <span class=\"number\">1</span>, <span class=\"attr\">gender</span> : <span class=\"number\">1</span> &#125;</span><br></pre></td></tr></table></figure>\n<p>但不包含以下形式:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123; <span class=\"attr\">gender</span> : <span class=\"number\">1</span>&#125;</span><br><span class=\"line\">&#123; <span class=\"attr\">gender</span> : <span class=\"number\">1</span>, <span class=\"attr\">name</span> : <span class=\"number\">1</span> &#125;</span><br></pre></td></tr></table></figure>\n<p>使用的时候要特别注意能否匹配上索引的前缀子集</p>\n</li>\n</ul>\n</li>\n<li><p>multikey indexes: 多key型索引，索引字段通常是数组类型</p>\n</li>\n<li><p>geospatial indexes: 地理位置索引，包括2dsphere和2d还有geoHaystack三种类型</p>\n</li>\n<li><p>text indexex: 全文索引，一个document最多只能有一个全文索引，用于在文档中搜索文本，但创建索引的开销比较大，需要后台或离线创建，综合来说不如elasticsearch等搜索引擎</p>\n<p>在文本中subject和comments两个字段建立了全文索引“text”：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.reviews.createIndex(</span><br><span class=\"line\">   &#123;</span><br><span class=\"line\">     subject: <span class=\"string\">\"text\"</span>,</span><br><span class=\"line\">     comments: <span class=\"string\">\"text\"</span></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"> )</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>hashed index：用于分布式collection分片的场景，将不同的document按照某个字段取hash的形式分布到不同的sharding上去：</p>\n<blockquote>\n<p>Hashed indexes support [sharding] using hashed shard keys. [Hashed based sharding] uses a hashed index of a field as the shard key to partition data across your sharded cluster.</p>\n</blockquote>\n<p>对name字段创建一个hashed索引：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.collection.createIndex( &#123; <span class=\"attr\">name</span>: <span class=\"string\">\"hashed\"</span> &#125; )</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"mongodb索引属性\"><a href=\"#mongodb索引属性\" class=\"headerlink\" title=\"mongodb索引属性\"></a>mongodb索引属性</h3><p>建立索引时可以对索引指定属性，有以下几种属性：</p>\n<ul>\n<li><p>TTL: 对索引设置过期时间shu，有两种方式</p>\n<ul>\n<li><p>延迟时间：在索引创建后延迟特定秒数然后删除该document：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.collection.createIndex( &#123; <span class=\"string\">\"createAt\"</span>: <span class=\"number\">1</span> &#125;, &#123; <span class=\"attr\">expireAfterSeconds</span>: <span class=\"number\">3600</span> &#125; )</span><br></pre></td></tr></table></figure>\n<p>createAt字段保存了创建时间，该document会在这个时间的3600秒后被删除</p>\n</li>\n<li><p>固定时间：在索引创建后延迟特定秒数然后删除该document:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.collection.createIndex( &#123; <span class=\"string\">\"expireTime\"</span>: <span class=\"number\">1</span> &#125;, &#123; <span class=\"attr\">expireAfterSeconds</span>: <span class=\"number\">0</span> &#125; )</span><br></pre></td></tr></table></figure>\n<p>该document将在到达expireTime上设置的时间时被删除</p>\n</li>\n</ul>\n</li>\n<li><p>unique index：唯一索引，索引字段唯一，若插入包含相同内容字段的document则会报错</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).createIndex(&#123;<span class=\"attr\">name</span>:<span class=\"number\">1</span>&#125;, &#123;<span class=\"attr\">unique</span>: <span class=\"literal\">true</span>&#125;)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>spares indexes：稀疏索引，如果设置了稀疏索引，将只对有该索引字段的document启用索引</p>\n</li>\n<li><p>partial indexes： 部分索引，跟稀疏索引一样也是非完全索引，在创建索引时可以对索引字段设置一个范围，在这个范围内的才启用索引：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.restaurants.createIndex(</span><br><span class=\"line\">   &#123; <span class=\"attr\">cuisine</span>: <span class=\"number\">1</span>, <span class=\"attr\">name</span>: <span class=\"number\">1</span> &#125;,</span><br><span class=\"line\">   &#123; <span class=\"attr\">partialFilterExpression</span>: &#123; <span class=\"attr\">rating</span>: &#123; <span class=\"attr\">$gt</span>: <span class=\"number\">5</span> &#125; &#125; &#125;</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>partialFilterExpression表示范围取值，rating是部分索引的索引字段，需要注意的是，进行查询时，查询范围不能超出部分索引的设定范围，不然无法启用索引</p>\n</li>\n<li><p>case insensitive indexes</p>\n</li>\n</ul>\n<h3 id=\"mongodb执行计划\"><a href=\"#mongodb执行计划\" class=\"headerlink\" title=\"mongodb执行计划\"></a>mongodb执行计划</h3><p>通过<code>explain()</code>执行计划进行mongodb的性能分析</p>\n","site":{"data":{}},"excerpt":"<p>mongodb索引数据结果是<code>b-树</code>，该数据结构作为索引具有高性能，磁盘io少等特点</p>\n<h3 id=\"何为b-树\"><a href=\"#何为b-树\" class=\"headerlink\" title=\"何为b-树\"></a>何为b-树</h3><p>b-树，又称b树，跟mysql的b+树索引不同，mongodb的b-树索引节点直接与数据绑定，找到索引后直接返回索引对应的document，这种索引适合mongodb这种聚合型nosql数据库：</p>","more":"<p><img src=\"\\blog\\images\\1547792452619.png\" alt=\"1547792452619\"></p>\n<ul>\n<li>b树节点元素个数为k，子节点个数为k+1</li>\n<li>如果b树的阶树为m，则<code>m/2 ≤ k ≤ m</code></li>\n<li>查询的时间复杂度为O(log n)，单次查询的磁盘io次数为数的高度</li>\n</ul>\n<h3 id=\"mongodb索引种类\"><a href=\"#mongodb索引种类\" class=\"headerlink\" title=\"mongodb索引种类\"></a>mongodb索引种类</h3><p>mongodb索引分为如下</p>\n<ul>\n<li><p>single index: 单个索引，索引字段只有一个：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).createIndex(&#123;<span class=\"attr\">name</span>:<span class=\"number\">1</span>&#125;)</span><br></pre></td></tr></table></figure>\n<p>score是索引字段，1表示升序索引，-1表示降序索引：</p>\n</li>\n<li><p>compound indexex: 混合索引，跟mysql类似，也是由多个字段组成索引：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).createIndex(&#123;<span class=\"attr\">name</span>:<span class=\"number\">1</span>,<span class=\"attr\">gender</span>:<span class=\"number\">1</span>&#125;)</span><br></pre></td></tr></table></figure>\n<p>使用混合索引时，有一些地方需要注意</p>\n<ul>\n<li><p>排序查找的顺序：</p>\n<p>官方文档提到：</p>\n<blockquote>\n<p>However, for [compound indexes], sort order can matter in determining whether the index can support a sort operation</p>\n<p>对于复合索引，排序字段的顺序对于排序操作是否启用索引非常重要</p>\n</blockquote>\n<p>对于如下索引：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).createIndex( &#123; <span class=\"attr\">name</span> : <span class=\"number\">1</span>, <span class=\"attr\">gender</span> : <span class=\"number\">-1</span> &#125; )</span><br></pre></td></tr></table></figure>\n<p>对姓名作升序索引，对性别做降序索引，那么在进行以下两种排序时，都会启用索引</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).find(&#123;&#125;).sort(&#123; <span class=\"attr\">name</span> : <span class=\"number\">-1</span>, <span class=\"attr\">gender</span> : <span class=\"number\">1</span> &#125;)</span><br><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).find(&#123;&#125;).sort(&#123; <span class=\"attr\">name</span> : <span class=\"number\">1</span>, <span class=\"attr\">gender</span> : <span class=\"number\">-1</span> &#125;)</span><br></pre></td></tr></table></figure>\n<p>用<code>explain(&quot;allPlansExecution&quot;)</code>查看执行计划发现，totalKeysExamined是所需结果的数目，说明全部查询均走的索引，执行阶段首先执行IXSCAN即扫描索引确定key的位置，然后执行FETCH去检索指定的document。</p>\n<p>但对以下排序，是不会启用索引的：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).find(&#123;&#125;).sort(&#123; <span class=\"attr\">name</span> : <span class=\"number\">1</span>, <span class=\"attr\">gender</span> : <span class=\"number\">1</span> &#125;)</span><br><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).find(&#123;&#125;).sort(&#123; <span class=\"attr\">name</span> : <span class=\"number\">-1</span>, <span class=\"attr\">gender</span> : <span class=\"number\">-1</span> &#125;)</span><br></pre></td></tr></table></figure>\n<p>用<code>explain(&quot;allPlansExecution&quot;)</code>查看执行计划发现，totalKeysExamined是0，执行阶段首先执行COLLSCAN即全表扫描，然后进行排序；说明如果排序查找如果跟索引的排序情况不匹配的话，将放弃启用索引。</p>\n</li>\n<li><p>左子前缀子集：</p>\n<p>这样的索引：<code>{ name : 1, gender : 1 }</code>，包含以下的前缀子集：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123; <span class=\"attr\">name</span> : <span class=\"number\">1</span>&#125;</span><br><span class=\"line\">&#123; <span class=\"attr\">name</span> : <span class=\"number\">1</span>, <span class=\"attr\">gender</span> : <span class=\"number\">1</span> &#125;</span><br></pre></td></tr></table></figure>\n<p>但不包含以下形式:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123; <span class=\"attr\">gender</span> : <span class=\"number\">1</span>&#125;</span><br><span class=\"line\">&#123; <span class=\"attr\">gender</span> : <span class=\"number\">1</span>, <span class=\"attr\">name</span> : <span class=\"number\">1</span> &#125;</span><br></pre></td></tr></table></figure>\n<p>使用的时候要特别注意能否匹配上索引的前缀子集</p>\n</li>\n</ul>\n</li>\n<li><p>multikey indexes: 多key型索引，索引字段通常是数组类型</p>\n</li>\n<li><p>geospatial indexes: 地理位置索引，包括2dsphere和2d还有geoHaystack三种类型</p>\n</li>\n<li><p>text indexex: 全文索引，一个document最多只能有一个全文索引，用于在文档中搜索文本，但创建索引的开销比较大，需要后台或离线创建，综合来说不如elasticsearch等搜索引擎</p>\n<p>在文本中subject和comments两个字段建立了全文索引“text”：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.reviews.createIndex(</span><br><span class=\"line\">   &#123;</span><br><span class=\"line\">     subject: <span class=\"string\">\"text\"</span>,</span><br><span class=\"line\">     comments: <span class=\"string\">\"text\"</span></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"> )</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>hashed index：用于分布式collection分片的场景，将不同的document按照某个字段取hash的形式分布到不同的sharding上去：</p>\n<blockquote>\n<p>Hashed indexes support [sharding] using hashed shard keys. [Hashed based sharding] uses a hashed index of a field as the shard key to partition data across your sharded cluster.</p>\n</blockquote>\n<p>对name字段创建一个hashed索引：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.collection.createIndex( &#123; <span class=\"attr\">name</span>: <span class=\"string\">\"hashed\"</span> &#125; )</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"mongodb索引属性\"><a href=\"#mongodb索引属性\" class=\"headerlink\" title=\"mongodb索引属性\"></a>mongodb索引属性</h3><p>建立索引时可以对索引指定属性，有以下几种属性：</p>\n<ul>\n<li><p>TTL: 对索引设置过期时间shu，有两种方式</p>\n<ul>\n<li><p>延迟时间：在索引创建后延迟特定秒数然后删除该document：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.collection.createIndex( &#123; <span class=\"string\">\"createAt\"</span>: <span class=\"number\">1</span> &#125;, &#123; <span class=\"attr\">expireAfterSeconds</span>: <span class=\"number\">3600</span> &#125; )</span><br></pre></td></tr></table></figure>\n<p>createAt字段保存了创建时间，该document会在这个时间的3600秒后被删除</p>\n</li>\n<li><p>固定时间：在索引创建后延迟特定秒数然后删除该document:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.collection.createIndex( &#123; <span class=\"string\">\"expireTime\"</span>: <span class=\"number\">1</span> &#125;, &#123; <span class=\"attr\">expireAfterSeconds</span>: <span class=\"number\">0</span> &#125; )</span><br></pre></td></tr></table></figure>\n<p>该document将在到达expireTime上设置的时间时被删除</p>\n</li>\n</ul>\n</li>\n<li><p>unique index：唯一索引，索引字段唯一，若插入包含相同内容字段的document则会报错</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.getCollection(<span class=\"string\">'user'</span>).createIndex(&#123;<span class=\"attr\">name</span>:<span class=\"number\">1</span>&#125;, &#123;<span class=\"attr\">unique</span>: <span class=\"literal\">true</span>&#125;)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>spares indexes：稀疏索引，如果设置了稀疏索引，将只对有该索引字段的document启用索引</p>\n</li>\n<li><p>partial indexes： 部分索引，跟稀疏索引一样也是非完全索引，在创建索引时可以对索引字段设置一个范围，在这个范围内的才启用索引：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">db.restaurants.createIndex(</span><br><span class=\"line\">   &#123; <span class=\"attr\">cuisine</span>: <span class=\"number\">1</span>, <span class=\"attr\">name</span>: <span class=\"number\">1</span> &#125;,</span><br><span class=\"line\">   &#123; <span class=\"attr\">partialFilterExpression</span>: &#123; <span class=\"attr\">rating</span>: &#123; <span class=\"attr\">$gt</span>: <span class=\"number\">5</span> &#125; &#125; &#125;</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>partialFilterExpression表示范围取值，rating是部分索引的索引字段，需要注意的是，进行查询时，查询范围不能超出部分索引的设定范围，不然无法启用索引</p>\n</li>\n<li><p>case insensitive indexes</p>\n</li>\n</ul>\n<h3 id=\"mongodb执行计划\"><a href=\"#mongodb执行计划\" class=\"headerlink\" title=\"mongodb执行计划\"></a>mongodb执行计划</h3><p>通过<code>explain()</code>执行计划进行mongodb的性能分析</p>"},{"title":"kafka学习笔记（4）—— 深入集群","author":"天渊","date":"2019-03-18T05:33:00.000Z","_content":"## KafkaController\n\n`KafkaController`其实就是kafka集群中其中一个broker，他是由zookeeper在多个broker选举出来的`leader broker`，肩负`partition assign`，`consumer rebalance`，`partition election`等重任 <!--more-->\n\n![upload successful](\\blog\\images\\pasted-26.png)\n\n### KafkaController选举\n\n- 新加入集群的broker向zookeeper创建临时节点`/controller`，创建成功则为KafkaController，并在当前节点写入以下信息，其他broker节点会监听`/controller`节点的变化情况\n\n  ```json\n  {“version”:1,”brokerid”:1,”timestamp”:”1512018424988”}\n  ```\n\n- 新选出的Controller(leader broker)会在zookeeper的`/controller_epoch`节点上创建递增序列，用于区别不同代的leader，并向zookeeper同步元数据，其他follower broker则会监听当前的`controller_epoch`的值，如果在和某个自称为leader的broker通信时发现他的epoch不是最新值，则会选择忽略本次通信（防止controller脑裂）\n\n![upload successful](\\blog\\images\\pasted-27.png)\n\n### controller主导partition leader选举\n\nKafkaController有一个很重要的功能就是在某个partition的leader出现不可用时，主导这个partition各副本之间的新leader选举，单个partition分为 leader副本和follow副本：\n\n- leader副本：每隔partition都有一个leader和多个follower，所有producer和consumer的请求都得通过leader进行处理\n- follower副本：follower副本不处理客户端的读写请求，唯一任务就是从首领那里同步数据，如果leader发生崩溃（leader副本所在的broker发生down机或者该broker和zookeeper同步超时），controller则会启动该partition的leader选举，并将新选举产生的leader信息同步给zookeeper\n\n![upload successful](\\blog\\images\\pasted-28.png)\n\n## Partition Leader\n\n分区leader负责消息的读写并协调各副本的数据同步\n\n### hight water mark\n\nkafka为了保证消息数据的高可靠性，只有已经被所有副本完全同步的消息才能被consumer消费，这个所谓的“已经被所有副本完全同步的消息”由`high water mark`来标定，只有offset小于`high water mark`的消息才对consumer可见：\n\n![upload successful](\\blog\\images\\pasted-29.png)\n\n如上所示，只有offset < 3的消息才是可被消费的消息\n\n### LEO (log end offset)\n\n日志末端位移，即当前副本日志中下一条消息的offset，上图中Replaca 0的LEO为5，以此类推，Replica的LEO为4，Replica的LEO为3\n\npartition的leader和followers均保留一份自己的LEO值，同时leader保有所有follower的LEO值，follower向leader同步数据时，leader会根据follower当前的LEO值判断需要同步给他的消息范围，并根据follower的LEO值更新`high water mark`\n\n### ISR (insync replicas)\n\n处于同步状态的partition副本列表，partition的leader保留一份，并且在zookeeper也保留一份，这份列表记录了当前有哪些副本处于有效同步状态（包含leader自己）：\n\n- `replica.lag.time.max.ms`：超过这个时间还未与leader同步的follower将会被踢出ISR列表\n- 挂掉的follower重新与leader同步，在同步进度追上leader后重新加入ISR\n- `min.insync.replicas`：最小同步副本数，如果ISR当中的副本数目不足，当前partition则会变为不可用状态，拒绝任何produce和consume请求；该参数用于平衡kafka集群的可用性和一致性\n- ISR与高水位的关系：ISR中副本的最低LEO即为`high water mark`\n- `unclean.leader.election`：不完全的首领选举，如果设置为true，在进行leader选举时可以选举ISR列表以外的副本作为新leader，但这种情况下丢失消息的几率就比较高了\n\n### leader_epoch\n\n当前partition的leader分代标记，用于在某个副本崩溃重启后与当前leader同步消息时，判断当前leader_epoch是否与自己崩溃前保存的leader_epoch信息一致，并根据leader_epoch信息判断是否需要做日志truncate\n\n（关于老版本kafka使用高水位进行truncate风险及kafka丢消息的往事，细节比较复杂，详细请参考这篇文章：[confluence cwiki: use leader epoch rather than high water mark for truncation](https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation) )\n\nleader_epoch的数据结构是一个键值对：`LeaderEpoch -> StartOffset`，其中`LeaderEpoch `是一个单调递增序列号，每次进行leader选举后都会产生一个`LeaderEpoch `序列号，`StartOffset`是该次选举完成后新leader自己的LEO值\n\n## Partition副本同步\n\n为了保证消息一致性，kafka使用了`high water mark`，`ISR`，`LEO`和`leader_epoch`等方式来处理follower和leader间的消息同步，同步流程如下：\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/kafka学习笔记（4）——-深入集群.md","raw":"title: kafka学习笔记（4）—— 深入集群\nauthor: 天渊\ntags:\n  - Kafka\n  - 大数据\ncategories:\n  - 基础知识\ndate: 2019-03-18 13:33:00\n---\n## KafkaController\n\n`KafkaController`其实就是kafka集群中其中一个broker，他是由zookeeper在多个broker选举出来的`leader broker`，肩负`partition assign`，`consumer rebalance`，`partition election`等重任 <!--more-->\n\n![upload successful](\\blog\\images\\pasted-26.png)\n\n### KafkaController选举\n\n- 新加入集群的broker向zookeeper创建临时节点`/controller`，创建成功则为KafkaController，并在当前节点写入以下信息，其他broker节点会监听`/controller`节点的变化情况\n\n  ```json\n  {“version”:1,”brokerid”:1,”timestamp”:”1512018424988”}\n  ```\n\n- 新选出的Controller(leader broker)会在zookeeper的`/controller_epoch`节点上创建递增序列，用于区别不同代的leader，并向zookeeper同步元数据，其他follower broker则会监听当前的`controller_epoch`的值，如果在和某个自称为leader的broker通信时发现他的epoch不是最新值，则会选择忽略本次通信（防止controller脑裂）\n\n![upload successful](\\blog\\images\\pasted-27.png)\n\n### controller主导partition leader选举\n\nKafkaController有一个很重要的功能就是在某个partition的leader出现不可用时，主导这个partition各副本之间的新leader选举，单个partition分为 leader副本和follow副本：\n\n- leader副本：每隔partition都有一个leader和多个follower，所有producer和consumer的请求都得通过leader进行处理\n- follower副本：follower副本不处理客户端的读写请求，唯一任务就是从首领那里同步数据，如果leader发生崩溃（leader副本所在的broker发生down机或者该broker和zookeeper同步超时），controller则会启动该partition的leader选举，并将新选举产生的leader信息同步给zookeeper\n\n![upload successful](\\blog\\images\\pasted-28.png)\n\n## Partition Leader\n\n分区leader负责消息的读写并协调各副本的数据同步\n\n### hight water mark\n\nkafka为了保证消息数据的高可靠性，只有已经被所有副本完全同步的消息才能被consumer消费，这个所谓的“已经被所有副本完全同步的消息”由`high water mark`来标定，只有offset小于`high water mark`的消息才对consumer可见：\n\n![upload successful](\\blog\\images\\pasted-29.png)\n\n如上所示，只有offset < 3的消息才是可被消费的消息\n\n### LEO (log end offset)\n\n日志末端位移，即当前副本日志中下一条消息的offset，上图中Replaca 0的LEO为5，以此类推，Replica的LEO为4，Replica的LEO为3\n\npartition的leader和followers均保留一份自己的LEO值，同时leader保有所有follower的LEO值，follower向leader同步数据时，leader会根据follower当前的LEO值判断需要同步给他的消息范围，并根据follower的LEO值更新`high water mark`\n\n### ISR (insync replicas)\n\n处于同步状态的partition副本列表，partition的leader保留一份，并且在zookeeper也保留一份，这份列表记录了当前有哪些副本处于有效同步状态（包含leader自己）：\n\n- `replica.lag.time.max.ms`：超过这个时间还未与leader同步的follower将会被踢出ISR列表\n- 挂掉的follower重新与leader同步，在同步进度追上leader后重新加入ISR\n- `min.insync.replicas`：最小同步副本数，如果ISR当中的副本数目不足，当前partition则会变为不可用状态，拒绝任何produce和consume请求；该参数用于平衡kafka集群的可用性和一致性\n- ISR与高水位的关系：ISR中副本的最低LEO即为`high water mark`\n- `unclean.leader.election`：不完全的首领选举，如果设置为true，在进行leader选举时可以选举ISR列表以外的副本作为新leader，但这种情况下丢失消息的几率就比较高了\n\n### leader_epoch\n\n当前partition的leader分代标记，用于在某个副本崩溃重启后与当前leader同步消息时，判断当前leader_epoch是否与自己崩溃前保存的leader_epoch信息一致，并根据leader_epoch信息判断是否需要做日志truncate\n\n（关于老版本kafka使用高水位进行truncate风险及kafka丢消息的往事，细节比较复杂，详细请参考这篇文章：[confluence cwiki: use leader epoch rather than high water mark for truncation](https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation) )\n\nleader_epoch的数据结构是一个键值对：`LeaderEpoch -> StartOffset`，其中`LeaderEpoch `是一个单调递增序列号，每次进行leader选举后都会产生一个`LeaderEpoch `序列号，`StartOffset`是该次选举完成后新leader自己的LEO值\n\n## Partition副本同步\n\n为了保证消息一致性，kafka使用了`high water mark`，`ISR`，`LEO`和`leader_epoch`等方式来处理follower和leader间的消息同步，同步流程如下：\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"kafka学习笔记（4）——-深入集群","published":1,"updated":"2021-05-31T03:06:33.198Z","_id":"ckf0h31i2001facts2ii4yuo7","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"KafkaController\"><a href=\"#KafkaController\" class=\"headerlink\" title=\"KafkaController\"></a>KafkaController</h2><p><code>KafkaController</code>其实就是kafka集群中其中一个broker，他是由zookeeper在多个broker选举出来的<code>leader broker</code>，肩负<code>partition assign</code>，<code>consumer rebalance</code>，<code>partition election</code>等重任 <a id=\"more\"></a></p>\n<p><img src=\"\\blog\\images\\pasted-26.png\" alt=\"upload successful\"></p>\n<h3 id=\"KafkaController选举\"><a href=\"#KafkaController选举\" class=\"headerlink\" title=\"KafkaController选举\"></a>KafkaController选举</h3><ul>\n<li><p>新加入集群的broker向zookeeper创建临时节点<code>/controller</code>，创建成功则为KafkaController，并在当前节点写入以下信息，其他broker节点会监听<code>/controller</code>节点的变化情况</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;“version”:1,”brokerid”:1,”timestamp”:”1512018424988”&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>新选出的Controller(leader broker)会在zookeeper的<code>/controller_epoch</code>节点上创建递增序列，用于区别不同代的leader，并向zookeeper同步元数据，其他follower broker则会监听当前的<code>controller_epoch</code>的值，如果在和某个自称为leader的broker通信时发现他的epoch不是最新值，则会选择忽略本次通信（防止controller脑裂）</p>\n</li>\n</ul>\n<p><img src=\"\\blog\\images\\pasted-27.png\" alt=\"upload successful\"></p>\n<h3 id=\"controller主导partition-leader选举\"><a href=\"#controller主导partition-leader选举\" class=\"headerlink\" title=\"controller主导partition leader选举\"></a>controller主导partition leader选举</h3><p>KafkaController有一个很重要的功能就是在某个partition的leader出现不可用时，主导这个partition各副本之间的新leader选举，单个partition分为 leader副本和follow副本：</p>\n<ul>\n<li>leader副本：每隔partition都有一个leader和多个follower，所有producer和consumer的请求都得通过leader进行处理</li>\n<li>follower副本：follower副本不处理客户端的读写请求，唯一任务就是从首领那里同步数据，如果leader发生崩溃（leader副本所在的broker发生down机或者该broker和zookeeper同步超时），controller则会启动该partition的leader选举，并将新选举产生的leader信息同步给zookeeper</li>\n</ul>\n<p><img src=\"\\blog\\images\\pasted-28.png\" alt=\"upload successful\"></p>\n<h2 id=\"Partition-Leader\"><a href=\"#Partition-Leader\" class=\"headerlink\" title=\"Partition Leader\"></a>Partition Leader</h2><p>分区leader负责消息的读写并协调各副本的数据同步</p>\n<h3 id=\"hight-water-mark\"><a href=\"#hight-water-mark\" class=\"headerlink\" title=\"hight water mark\"></a>hight water mark</h3><p>kafka为了保证消息数据的高可靠性，只有已经被所有副本完全同步的消息才能被consumer消费，这个所谓的“已经被所有副本完全同步的消息”由<code>high water mark</code>来标定，只有offset小于<code>high water mark</code>的消息才对consumer可见：</p>\n<p><img src=\"\\blog\\images\\pasted-29.png\" alt=\"upload successful\"></p>\n<p>如上所示，只有offset &lt; 3的消息才是可被消费的消息</p>\n<h3 id=\"LEO-log-end-offset\"><a href=\"#LEO-log-end-offset\" class=\"headerlink\" title=\"LEO (log end offset)\"></a>LEO (log end offset)</h3><p>日志末端位移，即当前副本日志中下一条消息的offset，上图中Replaca 0的LEO为5，以此类推，Replica的LEO为4，Replica的LEO为3</p>\n<p>partition的leader和followers均保留一份自己的LEO值，同时leader保有所有follower的LEO值，follower向leader同步数据时，leader会根据follower当前的LEO值判断需要同步给他的消息范围，并根据follower的LEO值更新<code>high water mark</code></p>\n<h3 id=\"ISR-insync-replicas\"><a href=\"#ISR-insync-replicas\" class=\"headerlink\" title=\"ISR (insync replicas)\"></a>ISR (insync replicas)</h3><p>处于同步状态的partition副本列表，partition的leader保留一份，并且在zookeeper也保留一份，这份列表记录了当前有哪些副本处于有效同步状态（包含leader自己）：</p>\n<ul>\n<li><code>replica.lag.time.max.ms</code>：超过这个时间还未与leader同步的follower将会被踢出ISR列表</li>\n<li>挂掉的follower重新与leader同步，在同步进度追上leader后重新加入ISR</li>\n<li><code>min.insync.replicas</code>：最小同步副本数，如果ISR当中的副本数目不足，当前partition则会变为不可用状态，拒绝任何produce和consume请求；该参数用于平衡kafka集群的可用性和一致性</li>\n<li>ISR与高水位的关系：ISR中副本的最低LEO即为<code>high water mark</code></li>\n<li><code>unclean.leader.election</code>：不完全的首领选举，如果设置为true，在进行leader选举时可以选举ISR列表以外的副本作为新leader，但这种情况下丢失消息的几率就比较高了</li>\n</ul>\n<h3 id=\"leader-epoch\"><a href=\"#leader-epoch\" class=\"headerlink\" title=\"leader_epoch\"></a>leader_epoch</h3><p>当前partition的leader分代标记，用于在某个副本崩溃重启后与当前leader同步消息时，判断当前leader_epoch是否与自己崩溃前保存的leader_epoch信息一致，并根据leader_epoch信息判断是否需要做日志truncate</p>\n<p>（关于老版本kafka使用高水位进行truncate风险及kafka丢消息的往事，细节比较复杂，详细请参考这篇文章：<a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation\" target=\"_blank\" rel=\"noopener\">confluence cwiki: use leader epoch rather than high water mark for truncation</a> )</p>\n<p>leader_epoch的数据结构是一个键值对：<code>LeaderEpoch -&gt; StartOffset</code>，其中<code>LeaderEpoch</code>是一个单调递增序列号，每次进行leader选举后都会产生一个<code>LeaderEpoch</code>序列号，<code>StartOffset</code>是该次选举完成后新leader自己的LEO值</p>\n<h2 id=\"Partition副本同步\"><a href=\"#Partition副本同步\" class=\"headerlink\" title=\"Partition副本同步\"></a>Partition副本同步</h2><p>为了保证消息一致性，kafka使用了<code>high water mark</code>，<code>ISR</code>，<code>LEO</code>和<code>leader_epoch</code>等方式来处理follower和leader间的消息同步，同步流程如下：</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"KafkaController\"><a href=\"#KafkaController\" class=\"headerlink\" title=\"KafkaController\"></a>KafkaController</h2><p><code>KafkaController</code>其实就是kafka集群中其中一个broker，他是由zookeeper在多个broker选举出来的<code>leader broker</code>，肩负<code>partition assign</code>，<code>consumer rebalance</code>，<code>partition election</code>等重任","more":"</p>\n<p><img src=\"\\blog\\images\\pasted-26.png\" alt=\"upload successful\"></p>\n<h3 id=\"KafkaController选举\"><a href=\"#KafkaController选举\" class=\"headerlink\" title=\"KafkaController选举\"></a>KafkaController选举</h3><ul>\n<li><p>新加入集群的broker向zookeeper创建临时节点<code>/controller</code>，创建成功则为KafkaController，并在当前节点写入以下信息，其他broker节点会监听<code>/controller</code>节点的变化情况</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;“version”:1,”brokerid”:1,”timestamp”:”1512018424988”&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>新选出的Controller(leader broker)会在zookeeper的<code>/controller_epoch</code>节点上创建递增序列，用于区别不同代的leader，并向zookeeper同步元数据，其他follower broker则会监听当前的<code>controller_epoch</code>的值，如果在和某个自称为leader的broker通信时发现他的epoch不是最新值，则会选择忽略本次通信（防止controller脑裂）</p>\n</li>\n</ul>\n<p><img src=\"\\blog\\images\\pasted-27.png\" alt=\"upload successful\"></p>\n<h3 id=\"controller主导partition-leader选举\"><a href=\"#controller主导partition-leader选举\" class=\"headerlink\" title=\"controller主导partition leader选举\"></a>controller主导partition leader选举</h3><p>KafkaController有一个很重要的功能就是在某个partition的leader出现不可用时，主导这个partition各副本之间的新leader选举，单个partition分为 leader副本和follow副本：</p>\n<ul>\n<li>leader副本：每隔partition都有一个leader和多个follower，所有producer和consumer的请求都得通过leader进行处理</li>\n<li>follower副本：follower副本不处理客户端的读写请求，唯一任务就是从首领那里同步数据，如果leader发生崩溃（leader副本所在的broker发生down机或者该broker和zookeeper同步超时），controller则会启动该partition的leader选举，并将新选举产生的leader信息同步给zookeeper</li>\n</ul>\n<p><img src=\"\\blog\\images\\pasted-28.png\" alt=\"upload successful\"></p>\n<h2 id=\"Partition-Leader\"><a href=\"#Partition-Leader\" class=\"headerlink\" title=\"Partition Leader\"></a>Partition Leader</h2><p>分区leader负责消息的读写并协调各副本的数据同步</p>\n<h3 id=\"hight-water-mark\"><a href=\"#hight-water-mark\" class=\"headerlink\" title=\"hight water mark\"></a>hight water mark</h3><p>kafka为了保证消息数据的高可靠性，只有已经被所有副本完全同步的消息才能被consumer消费，这个所谓的“已经被所有副本完全同步的消息”由<code>high water mark</code>来标定，只有offset小于<code>high water mark</code>的消息才对consumer可见：</p>\n<p><img src=\"\\blog\\images\\pasted-29.png\" alt=\"upload successful\"></p>\n<p>如上所示，只有offset &lt; 3的消息才是可被消费的消息</p>\n<h3 id=\"LEO-log-end-offset\"><a href=\"#LEO-log-end-offset\" class=\"headerlink\" title=\"LEO (log end offset)\"></a>LEO (log end offset)</h3><p>日志末端位移，即当前副本日志中下一条消息的offset，上图中Replaca 0的LEO为5，以此类推，Replica的LEO为4，Replica的LEO为3</p>\n<p>partition的leader和followers均保留一份自己的LEO值，同时leader保有所有follower的LEO值，follower向leader同步数据时，leader会根据follower当前的LEO值判断需要同步给他的消息范围，并根据follower的LEO值更新<code>high water mark</code></p>\n<h3 id=\"ISR-insync-replicas\"><a href=\"#ISR-insync-replicas\" class=\"headerlink\" title=\"ISR (insync replicas)\"></a>ISR (insync replicas)</h3><p>处于同步状态的partition副本列表，partition的leader保留一份，并且在zookeeper也保留一份，这份列表记录了当前有哪些副本处于有效同步状态（包含leader自己）：</p>\n<ul>\n<li><code>replica.lag.time.max.ms</code>：超过这个时间还未与leader同步的follower将会被踢出ISR列表</li>\n<li>挂掉的follower重新与leader同步，在同步进度追上leader后重新加入ISR</li>\n<li><code>min.insync.replicas</code>：最小同步副本数，如果ISR当中的副本数目不足，当前partition则会变为不可用状态，拒绝任何produce和consume请求；该参数用于平衡kafka集群的可用性和一致性</li>\n<li>ISR与高水位的关系：ISR中副本的最低LEO即为<code>high water mark</code></li>\n<li><code>unclean.leader.election</code>：不完全的首领选举，如果设置为true，在进行leader选举时可以选举ISR列表以外的副本作为新leader，但这种情况下丢失消息的几率就比较高了</li>\n</ul>\n<h3 id=\"leader-epoch\"><a href=\"#leader-epoch\" class=\"headerlink\" title=\"leader_epoch\"></a>leader_epoch</h3><p>当前partition的leader分代标记，用于在某个副本崩溃重启后与当前leader同步消息时，判断当前leader_epoch是否与自己崩溃前保存的leader_epoch信息一致，并根据leader_epoch信息判断是否需要做日志truncate</p>\n<p>（关于老版本kafka使用高水位进行truncate风险及kafka丢消息的往事，细节比较复杂，详细请参考这篇文章：<a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation\" target=\"_blank\" rel=\"noopener\">confluence cwiki: use leader epoch rather than high water mark for truncation</a> )</p>\n<p>leader_epoch的数据结构是一个键值对：<code>LeaderEpoch -&gt; StartOffset</code>，其中<code>LeaderEpoch</code>是一个单调递增序列号，每次进行leader选举后都会产生一个<code>LeaderEpoch</code>序列号，<code>StartOffset</code>是该次选举完成后新leader自己的LEO值</p>\n<h2 id=\"Partition副本同步\"><a href=\"#Partition副本同步\" class=\"headerlink\" title=\"Partition副本同步\"></a>Partition副本同步</h2><p>为了保证消息一致性，kafka使用了<code>high water mark</code>，<code>ISR</code>，<code>LEO</code>和<code>leader_epoch</code>等方式来处理follower和leader间的消息同步，同步流程如下：</p>"},{"title":"kafka学习笔记（3）—— 消费者 consumer","author":"天渊","date":"2019-03-18T05:21:00.000Z","_content":"kafka-consumer作为kafka消息队列的消费者端，通过接收topic的消息进行处理然后输出到下游数据源（数据库，文件系统，或者是另外的消息队列）<!--more-->\n\nkafka-consumer最大的特点是，遵循发布/订阅模型，多个consumer共同订阅同一个topic，通过offset对消息的消费位置进行标记：\n\n![upload successful](\\blog\\images\\pasted-7.png)\n\n**consumer的offset保存在哪里？**：老版本的kafka，offset保存在zookeeper中，但由于consumer的offset数据太过庞大，不适合存放在zookeeper，因此新版本的kafka单独维护了一个保存offset的topic：`__consumer_offsets`，以group-id，topic以及partition做为组合Key对每个consumer的offset进行检索\n\n### consumer消费数据\n\nconsumer以consumer-group（消费者组）为单位向kafka订阅topic并消费数据：\n\n![upload successful](\\blog\\images\\pasted-8.png)\n\nkafka consumer抓取数据基本流程图：\n\n![upload successful](\\blog\\images\\pasted-9.png)\n\n几点特性：\n\n- **partition主从热备**：消息的读/写工作全部交给leader partition来完成，slave partition主动与leader同步，通过LEO和leader epoch等信息同步数据，leader通过ISR列表保存当前存活的slave状态\n- **可靠性**：只有当ISR列表中所有副本都成功收到的消息才能提供给consumer，可以提供给consumer的这部分消息由`high water`来进行控制 (设置`replica.lag.time.max.ms`参数可保证副本同步消息的时间上限)\n- **零拷贝**：kafka通过零拷贝的方式将数据返回给consumer\n\n#### consumer的java api\n\n使用kafka-consumer高级api进行消费操作：\n\n1. 创建单个consumer进行消费：\n\n   ```java\n   public class ConsumerGroupTest {\n       public static void main(String[] args) {\n           Map<String, Object> consumerConfig = new HashMap<>();\n           consumerConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"10.106.151.187:9092\");\n           consumerConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n           consumerConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n           consumerConfig.put(ConsumerConfig.GROUP_ID_CONFIG, \"test-group-1\");\n           runConsumer(consumerConfig);\n       }\n       private static void runConsumer(Map<String, Object> consumerConfig) {\n           Consumer<String, String> consumer = new KafkaConsumer<>(consumerConfig);\n           consumer.subscribe(Collections.singleton(\"test_multi_par_topic_1\"));\n           try {\n               while (true) {\n                   // poll拉取消息，最长等待时间10秒\n                   ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(10));\n                   records.forEach(record -> {\n                       printRecord(record);\n                       print(\"当前consumer实例：\", consumer.toString());\n                       System.out.println();\n                   });\n               }\n           } finally {\n               consumer.close();\n           }\n       }\n       private static void printRecord(ConsumerRecord<String, String> record) {\n           System.out.println(\"当前record：====> \"\n                              + \" topic:\" + record.topic()\n                              + \" partition:\" + record.partition()\n                              + \" offset:\" + record.offset()\n                              + \" value:\" + record.value()\n                             );\n       }\n       private static void print(String name, Object value) {\n           System.out.println(\"KafkaConsumer ====> \" + name + \" is \" + \"{ \" + value + \" }\");\n       }\n   }\n   ```\n\n   单个consumer实例可以订阅多个topic，也可以通过正则表达式订阅topic：\n\n   ```java\n   // 订阅多个topic\n   consumer.subscribe(Arrays.asList(\"test-topic-1\", \"test-topic-2\"));\n   // 通过正则表达式订阅多个topic\n   consumer.subscribe(Pattern.compile(\"test.*\"));\n   ```\n\n2. 创建消费者组订阅包含多个partition的topic：\n\n   创建一个叫做“test-group-1”的消费组，订阅“test_multi_par_topic_1” topic， 该topic包含三个partition：\n\n   ```java\n   public static void main(String[] args) {\n       Map<String, Object> consumerConfig = new HashMap<>();\n       consumerConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"10.106.151.187:9092\");\n       consumerConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n       consumerConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n       consumerConfig.put(ConsumerConfig.GROUP_ID_CONFIG, \"test-group-1\");\n       runConsumerManualCommit(consumerConfig);\n   }\n   \n   private static void runConsumer(Map<String, Object> consumerConfig) {\n       Consumer<String, String> consumer = new KafkaConsumer<>(consumerConfig);\n       consumer.subscribe(Collections.singleton(\"test_multi_par_topic_1\"));\n       try {\n           while (true) {\n               // poll拉取消息，最长等待时间10秒\n               ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(10));\n               records.forEach(record -> {\n                   printRecord(record);\n                   print(\"当前consumer实例：\", consumer.toString());\n                   System.out.println();\n               });\n           }\n       } finally {\n           consumer.close();\n       }\n   }\n   ```\n   \n   首先只启动一个实例，可以看到，当前consumer实例消费了全部的三个partition的数据：\n   \n![upload successful](\\blog\\images\\pasted-10.png)\n\n    \n   向该组加入一个consumer实例，可以看到，之前`@48322fe3`这个consumer实例只分到了partition2，而新加入的`@365ae362`这个实例分到了0和1：：\n   \n![upload successful](\\blog\\images\\pasted-11.png) \n\n![upload successful](\\blog\\images\\pasted-12.png)\n\n继续加consumer实例进来，最早的元老实例1，分到了partition2：\n \n![upload successful](\\blog\\images\\pasted-13.png)\n\t\n之后加入的实例2分到了partition0：\n\n![upload successful](\\blog\\images\\pasted-14.png)\n\n最新加入的实例3 `@345dd14f`，分到了parition1：\n\n![upload successful](\\blog\\images\\pasted-15.png)\n\t\n接下来将元老实例1`@48322fe3`停掉，观察实例2和实例3 （注意观察实例1的最后消费offset），实例1最后消费情况，消费完offset=85就挂掉了：\n   \n![upload successful](\\blog\\images\\pasted-16.png)\n   \n观察实例2可以发现，实例2除了继续消费partition0，还认领了之前实例3消费的partition1的任务\n  \n![upload successful](\\blog\\images\\pasted-17.png)\n\n观察实例3，消费partition1直到offset=91的位置，发生了rebalance，之后partition1的任务分派给了上面实例2，自己分到了因实例1挂掉而无人认领的partition2，并且从实例1最后消费位置即offset=86开始消费\n   \n   \n![upload successful](\\blog\\images\\pasted-18.png)\n\n### consumer-group\n\n单个consumer-group即可以只消费一个topic的消息，也可以同时消费多个topic的消息\n\n#### consumer-group订阅topic\n\n单个consumer-group在订阅某个topic时，如果不特殊指定订阅某个partition，kafka将启用`Coordinator`对consumer-group内的consumer实例进行负载均衡，有以下特点：\n\n1. 组内的一个consumer实例消费全部的partition：\n\n\t![upload successful](\\blog\\images\\pasted-19.png)\n\n2. 组内继续加入consumer实例，一同消费多个partition，消费过程与另外的consumer完全隔离不受影响：\n\n\t![upload successful](\\blog\\images\\pasted-20.png)\n\n3. 组内继续加入consumer，每个consumer实例单独消费一个partition，此时consumer数目与partition数目一致：\n\n\t![upload successful](\\blog\\images\\pasted-21.png)\n\n4. 继续加入consumer，数目超过partition数目，此时多出来的consumer将分不到partition进行消费：\n\n\t![upload successful](\\blog\\images\\pasted-22.png)\n\n如上可以看出，当单个consumer-group订阅topic进行消费时，kafka的Coordinator保证topic的数据能够被均匀分派到组内的各个消费者上，并且topic中的**单个partition只能被单个consumer-group中的其中一个consumer消费**\n\n不过，如果有其他consumer-group的consumer参与消费这个topic，将与之前的consumer-group隔离，Coordinator将单独为这个新的组进行负载均衡：\n\n   ![upload successful](\\blog\\images\\pasted-23.png)\n    \n#### consumer分区再平衡\n\n- 每当一个consumer-group有新成员加入，并且和老成员一起消费同一个topic的时候，Coordinator都将进行分区再平衡（`rebalance`），为了平衡消费能力，老成员消费的partition有可能会被分派给新加入的consumer\n- 当有consumer实例挂掉时，之前分派给他的partition将会重新分派给剩余还活着的consumer（conusmer实例通过发送心跳让kafka集群知道他还活着）\n- 订阅的topic新加入partition也会触发rebalance\n- 通过正则表达式订阅某个类型的topic，当新加入该类型的topic时，也会发生rebalance\n\n#### consumer rebalance的大致流程：\n\n1. Topic/Partition的改变或者新Consumer的加入或者已有Consumer停止，将触发Coordinator注册在Zookeeper上的watch，Coordinator收到通知准备发起Rebalance操作。\n2. Coordinator通过在HeartbeatResponse中返回IllegalGeneration错误码通知各个consumer发起Rebalance操作。\n3. 存活的Consumer向Coordinator发送JoinGroupRequest\n4. Coordinator在Zookeeper中增加Group的Generation ID并将新的Partition分配情况写入Zookeeper\n5. Coordinator向存活的consumer发送JoinGroupResponse\n6. 存活的consumer收到JoinGroupResponse后重新启动新一轮消费\n\n### consumer配置\n\n除了上述`bootstrap.servers`,`key.deserializer`,`value.deserializer`,`group.id`这几个配置项必须进行配置之外，其他的配置项均为可选项：\n\n```properties\n# 单次拉取消息的最小字节数，如果该值不为0，在consumer拉取消息时，如果可消费数据达不到该值，broker将等待一段时间(fetch.max.wait.ms)直到有足够数据或者等待超时，再返回给consumer\nfetch.min.bytes=1024\n# 单次拉取消息的最长等待时间\nfetch.max.wait.ms=500\n# 指定consumer单次poll()从分区中拉取的最大字节数，默认1MB\nmax.partition.fetch.bytes=1048576\n# kafka集群判断consumer连接中断的最长等待时间，默认10秒，如果consumer超过该时间没有发送心跳，则会判断为死亡进而触发rebalance\nsession.timeout.ms=10000\n# 心跳间隔时间，建议不超过session.timeout.ms的1/3\nheartbeat.interval.ms=3000\n# 是否开启自动提交offset，默认是开启的，如果开启，将每隔auto.commit.interval.ms的时间将消费完成但未提交offset的consumer统一向kafka集群提交一次（风险：当consumer消费完成但未提交offset就挂掉时，重启后将造成消息重复消费）\nenable.auto.commit=true\n# 自动统一提交offset的时间间隔\nauto.commit.interval.ms=5000\n# 开始消费的consumer-group（或者该consumer掉线已久，已经丢失有效的offset信息）初始化offset的策略，\n# latest：默认值，默认从最新的有效offset开始消费\n# earliest：从最早的有效offset开始消费\n# none：如果kafka没有保存该consumer-group的offset信息则直接抛异常\nauto.offset.reset=[latest, earliest, none]\n# 分区分派策略类，kafka-clients自带的分区策略有Range和RoundRobin\n# 必须是PartitionAssignor的实现类\npartition.assignment.strategy=class org.apache.kafka.clients.consumer.RangeAssignor\n# 单次poll()拉取的消息数量最大值，默认是500个\nmax.poll.records=500\n```\n\n### kafka consumer的offset提交策略\n\nconsumer每次消费数据完成后需要提交offset给集群以更新自己的消费状态，提交过程非常重要，直接关系到消费过程的稳定性，提交异常的话可能导致以下两种后果：\n\n- 重复消费：一般发生在还没来得及提交offset即被中断消费的情况\n  \n  ![upload successful](\\blog\\images\\pasted-24.png)\n\n- 丢失消费：一般发生在消费过程有耗时操作的情况，如果在此期间提交了当前还没处理完成的消息的offset，会造成消费丢失：\n\n  ![upload successful](\\blog\\images\\pasted-25.png)\n\nkafka提供了`手动commit`和`自动commit`两种提交策略：\n\n1. **自动提交**：将`enable.auto.commit`设置为true并且将`auto.commit.interval.ms`设置为大于0的时间，即可开启自动提交，每次调用`consumer.poll()`方法时都会检查是否达到提交间隔时间，并将上一次拉取消息中最大的一个offset信息发送给集群中的`__consumer_offsets`这个topic\n\n   缺点：自动提交不需要用户手动commit，因此提交过程不可控\n\n2. **手动提交**：手动提交又分为`commitSync()`和`commitAsync()`两种方式，该模式下`enable.auto.commit`必须为false，consumer api任何情况都不会自动帮用户提交offset，一切由用户主动控制：\n\n   `commitSync()`：同步提交，直接提交之前拉取的最新的offset，用户可自己保证在消息处理完毕后直接提交当前offset，缺点是整个提交过程是阻塞的，并且提交失败会进行重试\n\n   `commitAsync()`：异步提交，同样也是提交之前拉取的最新的offset，改善了同步提交过程会产生阻塞的缺点，支持回调函数，提交过程不进行重试\n\n比较好的手动提交方式是`同步和异步组合提交`：\n\n```java\ntry {\n    while (true) {\n        // poll拉取消息，最长等待时间10秒\n        try {\n            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(10));\n            records.forEach(record -> {\n                printRecord(record);\n                print(\"当前consumer实例：\", consumer.toString());\n                System.out.println();\n            });\n        } finally {\n            // 消费过程未报错则执行异步提交，速度更快，不阻塞consumer线程\n            consumer.commitAsync((offsets, exception) -> {\n                // offsets中的`offsetAndMetadata`包含本次提交后希望处理的下一个offset\n                print(\"本次提交后希望处理的下一个offset:\", offsets);\n                if (exception != null) {\n                    exception.printStackTrace();\n                }\n            });\n        }\n    }\n} catch (Exception e) {\n    e.printStackTrace();\n} finally {\n    try {\n        // 消费过程报错的话就尝试同步提交，防止未提交offset造成风险\n        consumer.commitSync();\n    } finally {\n        consumer.close();\n    }\n}\n```\n### kafka consumer消费时指定offset\n\n有些时候我们并不想按照默认情况读取最新offset位置的消息，kafka对此提供了查找特定offset的api，可以实现向后回退几个消息或者向前跳过几个消息：\n\n```java\nprivate static void runConsumerSeekOffset(Map<String, Object> consumerConfig, long specificOffset) {\n    Consumer<String, String> consumer = new KafkaConsumer<>(consumerConfig);\n    consumer.subscribe(Collections.singleton(\"test_multi_par_topic_1\"));\n    try {\n        // 使用seek()方法将consumer的offset重置到指定位置\n        consumer.assignment().forEach(topicPartition -> {\n            consumer.seek(topicPartition, specificOffset);\n        });\n        while (true) {\n            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(10));\n            records.forEach(record -> {\n                printRecord(record);\n                print(\"当前consumer实例：\", consumer.toString());\n                System.out.println();\n            });\n        }\n    } finally {\n        consumer.close();\n    }\n}\n```\n\n### kafka consumer rebalance监听器\n\nconsumer和kafka的Coodinator交互的心跳心中包含是否需要rebalance信息，如果需要rebalance则停止拉取数据并直接提交offset，rebalance完成后consumer有可能失去对当前分配的partition的消费权\n\nkafka提供了rebalance监听器用于让用户设置在rebalance发生后需要做的一些资源回收的操作，并且可以在监听器中手动提交当前已经处理完成的消息offset，以下是相对比较保险不会造成消费丢失的一种提交策略：\n\n```java\nprivate static void runConsumerRebanlanceListener(Map<String, Object> consumerConfig) {\n    Consumer<String, String> consumer = new KafkaConsumer<>(consumerConfig);\n    // 已处理的消息的offset暂存区\n    final Map<TopicPartition, OffsetAndMetadata> currentOffsets = new HashMap<>();\n    consumer.subscribe(Collections.singleton(\"test_multi_par_topic_1\"), new ConsumerRebalanceListener() {\n        @Override\n        public void onPartitionsRevoked(Collection<TopicPartition> partitions) {\n            System.out.println(\"发生rebalance！\");\n            System.out.println(\"当前分配的partitions：\" + partitions);\n\t\t   // 将已经处理完成的offset进行同步提交\n            consumer.commitSync(currentOffsets);\n        }\n        @Override\n        public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n            System.out.println(\"rebalance完成！\");\n            System.out.println(\"rebalance后分配的partitions：\" + partitions);\n        }\n    });\n    try {\n        while (true) {\n            ConsumerRecords<String, String> records = consumer.poll(100);\n            currentOffsets.clear();\n            records.forEach(record -> {\n                printRecord(record);\n                print(\"当前consumer实例：\", consumer.toString());\n                // 当前处理完成，待提交的offset，存入暂存区\n                currentOffsets.put(\n                    new TopicPartition(record.topic(), record.partition()),\n                    new OffsetAndMetadata(record.offset() + 1, null));\n                System.out.println();\n            });\n            // 每隔批次消息处理完成后异步提交\n            consumer.commitAsync(currentOffsets, null);\n        }\n    } catch (Exception e) {\n        e.printStackTrace();\n    } finally {\n        try {\n            // 出错后同步提交\n            consumer.commitSync(currentOffsets);\n        } finally {\n            consumer.close();\n        }\n    }\n}\n```","source":"_posts/kafka学习笔记（3）——-消费者-consumer.md","raw":"title: kafka学习笔记（3）—— 消费者 consumer\nauthor: 天渊\ntags:\n  - Kafka\n  - 大数据\ncategories: []\ndate: 2019-03-18 13:21:00\n---\nkafka-consumer作为kafka消息队列的消费者端，通过接收topic的消息进行处理然后输出到下游数据源（数据库，文件系统，或者是另外的消息队列）<!--more-->\n\nkafka-consumer最大的特点是，遵循发布/订阅模型，多个consumer共同订阅同一个topic，通过offset对消息的消费位置进行标记：\n\n![upload successful](\\blog\\images\\pasted-7.png)\n\n**consumer的offset保存在哪里？**：老版本的kafka，offset保存在zookeeper中，但由于consumer的offset数据太过庞大，不适合存放在zookeeper，因此新版本的kafka单独维护了一个保存offset的topic：`__consumer_offsets`，以group-id，topic以及partition做为组合Key对每个consumer的offset进行检索\n\n### consumer消费数据\n\nconsumer以consumer-group（消费者组）为单位向kafka订阅topic并消费数据：\n\n![upload successful](\\blog\\images\\pasted-8.png)\n\nkafka consumer抓取数据基本流程图：\n\n![upload successful](\\blog\\images\\pasted-9.png)\n\n几点特性：\n\n- **partition主从热备**：消息的读/写工作全部交给leader partition来完成，slave partition主动与leader同步，通过LEO和leader epoch等信息同步数据，leader通过ISR列表保存当前存活的slave状态\n- **可靠性**：只有当ISR列表中所有副本都成功收到的消息才能提供给consumer，可以提供给consumer的这部分消息由`high water`来进行控制 (设置`replica.lag.time.max.ms`参数可保证副本同步消息的时间上限)\n- **零拷贝**：kafka通过零拷贝的方式将数据返回给consumer\n\n#### consumer的java api\n\n使用kafka-consumer高级api进行消费操作：\n\n1. 创建单个consumer进行消费：\n\n   ```java\n   public class ConsumerGroupTest {\n       public static void main(String[] args) {\n           Map<String, Object> consumerConfig = new HashMap<>();\n           consumerConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"10.106.151.187:9092\");\n           consumerConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n           consumerConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n           consumerConfig.put(ConsumerConfig.GROUP_ID_CONFIG, \"test-group-1\");\n           runConsumer(consumerConfig);\n       }\n       private static void runConsumer(Map<String, Object> consumerConfig) {\n           Consumer<String, String> consumer = new KafkaConsumer<>(consumerConfig);\n           consumer.subscribe(Collections.singleton(\"test_multi_par_topic_1\"));\n           try {\n               while (true) {\n                   // poll拉取消息，最长等待时间10秒\n                   ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(10));\n                   records.forEach(record -> {\n                       printRecord(record);\n                       print(\"当前consumer实例：\", consumer.toString());\n                       System.out.println();\n                   });\n               }\n           } finally {\n               consumer.close();\n           }\n       }\n       private static void printRecord(ConsumerRecord<String, String> record) {\n           System.out.println(\"当前record：====> \"\n                              + \" topic:\" + record.topic()\n                              + \" partition:\" + record.partition()\n                              + \" offset:\" + record.offset()\n                              + \" value:\" + record.value()\n                             );\n       }\n       private static void print(String name, Object value) {\n           System.out.println(\"KafkaConsumer ====> \" + name + \" is \" + \"{ \" + value + \" }\");\n       }\n   }\n   ```\n\n   单个consumer实例可以订阅多个topic，也可以通过正则表达式订阅topic：\n\n   ```java\n   // 订阅多个topic\n   consumer.subscribe(Arrays.asList(\"test-topic-1\", \"test-topic-2\"));\n   // 通过正则表达式订阅多个topic\n   consumer.subscribe(Pattern.compile(\"test.*\"));\n   ```\n\n2. 创建消费者组订阅包含多个partition的topic：\n\n   创建一个叫做“test-group-1”的消费组，订阅“test_multi_par_topic_1” topic， 该topic包含三个partition：\n\n   ```java\n   public static void main(String[] args) {\n       Map<String, Object> consumerConfig = new HashMap<>();\n       consumerConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"10.106.151.187:9092\");\n       consumerConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n       consumerConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n       consumerConfig.put(ConsumerConfig.GROUP_ID_CONFIG, \"test-group-1\");\n       runConsumerManualCommit(consumerConfig);\n   }\n   \n   private static void runConsumer(Map<String, Object> consumerConfig) {\n       Consumer<String, String> consumer = new KafkaConsumer<>(consumerConfig);\n       consumer.subscribe(Collections.singleton(\"test_multi_par_topic_1\"));\n       try {\n           while (true) {\n               // poll拉取消息，最长等待时间10秒\n               ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(10));\n               records.forEach(record -> {\n                   printRecord(record);\n                   print(\"当前consumer实例：\", consumer.toString());\n                   System.out.println();\n               });\n           }\n       } finally {\n           consumer.close();\n       }\n   }\n   ```\n   \n   首先只启动一个实例，可以看到，当前consumer实例消费了全部的三个partition的数据：\n   \n![upload successful](\\blog\\images\\pasted-10.png)\n\n    \n   向该组加入一个consumer实例，可以看到，之前`@48322fe3`这个consumer实例只分到了partition2，而新加入的`@365ae362`这个实例分到了0和1：：\n   \n![upload successful](\\blog\\images\\pasted-11.png) \n\n![upload successful](\\blog\\images\\pasted-12.png)\n\n继续加consumer实例进来，最早的元老实例1，分到了partition2：\n \n![upload successful](\\blog\\images\\pasted-13.png)\n\t\n之后加入的实例2分到了partition0：\n\n![upload successful](\\blog\\images\\pasted-14.png)\n\n最新加入的实例3 `@345dd14f`，分到了parition1：\n\n![upload successful](\\blog\\images\\pasted-15.png)\n\t\n接下来将元老实例1`@48322fe3`停掉，观察实例2和实例3 （注意观察实例1的最后消费offset），实例1最后消费情况，消费完offset=85就挂掉了：\n   \n![upload successful](\\blog\\images\\pasted-16.png)\n   \n观察实例2可以发现，实例2除了继续消费partition0，还认领了之前实例3消费的partition1的任务\n  \n![upload successful](\\blog\\images\\pasted-17.png)\n\n观察实例3，消费partition1直到offset=91的位置，发生了rebalance，之后partition1的任务分派给了上面实例2，自己分到了因实例1挂掉而无人认领的partition2，并且从实例1最后消费位置即offset=86开始消费\n   \n   \n![upload successful](\\blog\\images\\pasted-18.png)\n\n### consumer-group\n\n单个consumer-group即可以只消费一个topic的消息，也可以同时消费多个topic的消息\n\n#### consumer-group订阅topic\n\n单个consumer-group在订阅某个topic时，如果不特殊指定订阅某个partition，kafka将启用`Coordinator`对consumer-group内的consumer实例进行负载均衡，有以下特点：\n\n1. 组内的一个consumer实例消费全部的partition：\n\n\t![upload successful](\\blog\\images\\pasted-19.png)\n\n2. 组内继续加入consumer实例，一同消费多个partition，消费过程与另外的consumer完全隔离不受影响：\n\n\t![upload successful](\\blog\\images\\pasted-20.png)\n\n3. 组内继续加入consumer，每个consumer实例单独消费一个partition，此时consumer数目与partition数目一致：\n\n\t![upload successful](\\blog\\images\\pasted-21.png)\n\n4. 继续加入consumer，数目超过partition数目，此时多出来的consumer将分不到partition进行消费：\n\n\t![upload successful](\\blog\\images\\pasted-22.png)\n\n如上可以看出，当单个consumer-group订阅topic进行消费时，kafka的Coordinator保证topic的数据能够被均匀分派到组内的各个消费者上，并且topic中的**单个partition只能被单个consumer-group中的其中一个consumer消费**\n\n不过，如果有其他consumer-group的consumer参与消费这个topic，将与之前的consumer-group隔离，Coordinator将单独为这个新的组进行负载均衡：\n\n   ![upload successful](\\blog\\images\\pasted-23.png)\n    \n#### consumer分区再平衡\n\n- 每当一个consumer-group有新成员加入，并且和老成员一起消费同一个topic的时候，Coordinator都将进行分区再平衡（`rebalance`），为了平衡消费能力，老成员消费的partition有可能会被分派给新加入的consumer\n- 当有consumer实例挂掉时，之前分派给他的partition将会重新分派给剩余还活着的consumer（conusmer实例通过发送心跳让kafka集群知道他还活着）\n- 订阅的topic新加入partition也会触发rebalance\n- 通过正则表达式订阅某个类型的topic，当新加入该类型的topic时，也会发生rebalance\n\n#### consumer rebalance的大致流程：\n\n1. Topic/Partition的改变或者新Consumer的加入或者已有Consumer停止，将触发Coordinator注册在Zookeeper上的watch，Coordinator收到通知准备发起Rebalance操作。\n2. Coordinator通过在HeartbeatResponse中返回IllegalGeneration错误码通知各个consumer发起Rebalance操作。\n3. 存活的Consumer向Coordinator发送JoinGroupRequest\n4. Coordinator在Zookeeper中增加Group的Generation ID并将新的Partition分配情况写入Zookeeper\n5. Coordinator向存活的consumer发送JoinGroupResponse\n6. 存活的consumer收到JoinGroupResponse后重新启动新一轮消费\n\n### consumer配置\n\n除了上述`bootstrap.servers`,`key.deserializer`,`value.deserializer`,`group.id`这几个配置项必须进行配置之外，其他的配置项均为可选项：\n\n```properties\n# 单次拉取消息的最小字节数，如果该值不为0，在consumer拉取消息时，如果可消费数据达不到该值，broker将等待一段时间(fetch.max.wait.ms)直到有足够数据或者等待超时，再返回给consumer\nfetch.min.bytes=1024\n# 单次拉取消息的最长等待时间\nfetch.max.wait.ms=500\n# 指定consumer单次poll()从分区中拉取的最大字节数，默认1MB\nmax.partition.fetch.bytes=1048576\n# kafka集群判断consumer连接中断的最长等待时间，默认10秒，如果consumer超过该时间没有发送心跳，则会判断为死亡进而触发rebalance\nsession.timeout.ms=10000\n# 心跳间隔时间，建议不超过session.timeout.ms的1/3\nheartbeat.interval.ms=3000\n# 是否开启自动提交offset，默认是开启的，如果开启，将每隔auto.commit.interval.ms的时间将消费完成但未提交offset的consumer统一向kafka集群提交一次（风险：当consumer消费完成但未提交offset就挂掉时，重启后将造成消息重复消费）\nenable.auto.commit=true\n# 自动统一提交offset的时间间隔\nauto.commit.interval.ms=5000\n# 开始消费的consumer-group（或者该consumer掉线已久，已经丢失有效的offset信息）初始化offset的策略，\n# latest：默认值，默认从最新的有效offset开始消费\n# earliest：从最早的有效offset开始消费\n# none：如果kafka没有保存该consumer-group的offset信息则直接抛异常\nauto.offset.reset=[latest, earliest, none]\n# 分区分派策略类，kafka-clients自带的分区策略有Range和RoundRobin\n# 必须是PartitionAssignor的实现类\npartition.assignment.strategy=class org.apache.kafka.clients.consumer.RangeAssignor\n# 单次poll()拉取的消息数量最大值，默认是500个\nmax.poll.records=500\n```\n\n### kafka consumer的offset提交策略\n\nconsumer每次消费数据完成后需要提交offset给集群以更新自己的消费状态，提交过程非常重要，直接关系到消费过程的稳定性，提交异常的话可能导致以下两种后果：\n\n- 重复消费：一般发生在还没来得及提交offset即被中断消费的情况\n  \n  ![upload successful](\\blog\\images\\pasted-24.png)\n\n- 丢失消费：一般发生在消费过程有耗时操作的情况，如果在此期间提交了当前还没处理完成的消息的offset，会造成消费丢失：\n\n  ![upload successful](\\blog\\images\\pasted-25.png)\n\nkafka提供了`手动commit`和`自动commit`两种提交策略：\n\n1. **自动提交**：将`enable.auto.commit`设置为true并且将`auto.commit.interval.ms`设置为大于0的时间，即可开启自动提交，每次调用`consumer.poll()`方法时都会检查是否达到提交间隔时间，并将上一次拉取消息中最大的一个offset信息发送给集群中的`__consumer_offsets`这个topic\n\n   缺点：自动提交不需要用户手动commit，因此提交过程不可控\n\n2. **手动提交**：手动提交又分为`commitSync()`和`commitAsync()`两种方式，该模式下`enable.auto.commit`必须为false，consumer api任何情况都不会自动帮用户提交offset，一切由用户主动控制：\n\n   `commitSync()`：同步提交，直接提交之前拉取的最新的offset，用户可自己保证在消息处理完毕后直接提交当前offset，缺点是整个提交过程是阻塞的，并且提交失败会进行重试\n\n   `commitAsync()`：异步提交，同样也是提交之前拉取的最新的offset，改善了同步提交过程会产生阻塞的缺点，支持回调函数，提交过程不进行重试\n\n比较好的手动提交方式是`同步和异步组合提交`：\n\n```java\ntry {\n    while (true) {\n        // poll拉取消息，最长等待时间10秒\n        try {\n            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(10));\n            records.forEach(record -> {\n                printRecord(record);\n                print(\"当前consumer实例：\", consumer.toString());\n                System.out.println();\n            });\n        } finally {\n            // 消费过程未报错则执行异步提交，速度更快，不阻塞consumer线程\n            consumer.commitAsync((offsets, exception) -> {\n                // offsets中的`offsetAndMetadata`包含本次提交后希望处理的下一个offset\n                print(\"本次提交后希望处理的下一个offset:\", offsets);\n                if (exception != null) {\n                    exception.printStackTrace();\n                }\n            });\n        }\n    }\n} catch (Exception e) {\n    e.printStackTrace();\n} finally {\n    try {\n        // 消费过程报错的话就尝试同步提交，防止未提交offset造成风险\n        consumer.commitSync();\n    } finally {\n        consumer.close();\n    }\n}\n```\n### kafka consumer消费时指定offset\n\n有些时候我们并不想按照默认情况读取最新offset位置的消息，kafka对此提供了查找特定offset的api，可以实现向后回退几个消息或者向前跳过几个消息：\n\n```java\nprivate static void runConsumerSeekOffset(Map<String, Object> consumerConfig, long specificOffset) {\n    Consumer<String, String> consumer = new KafkaConsumer<>(consumerConfig);\n    consumer.subscribe(Collections.singleton(\"test_multi_par_topic_1\"));\n    try {\n        // 使用seek()方法将consumer的offset重置到指定位置\n        consumer.assignment().forEach(topicPartition -> {\n            consumer.seek(topicPartition, specificOffset);\n        });\n        while (true) {\n            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(10));\n            records.forEach(record -> {\n                printRecord(record);\n                print(\"当前consumer实例：\", consumer.toString());\n                System.out.println();\n            });\n        }\n    } finally {\n        consumer.close();\n    }\n}\n```\n\n### kafka consumer rebalance监听器\n\nconsumer和kafka的Coodinator交互的心跳心中包含是否需要rebalance信息，如果需要rebalance则停止拉取数据并直接提交offset，rebalance完成后consumer有可能失去对当前分配的partition的消费权\n\nkafka提供了rebalance监听器用于让用户设置在rebalance发生后需要做的一些资源回收的操作，并且可以在监听器中手动提交当前已经处理完成的消息offset，以下是相对比较保险不会造成消费丢失的一种提交策略：\n\n```java\nprivate static void runConsumerRebanlanceListener(Map<String, Object> consumerConfig) {\n    Consumer<String, String> consumer = new KafkaConsumer<>(consumerConfig);\n    // 已处理的消息的offset暂存区\n    final Map<TopicPartition, OffsetAndMetadata> currentOffsets = new HashMap<>();\n    consumer.subscribe(Collections.singleton(\"test_multi_par_topic_1\"), new ConsumerRebalanceListener() {\n        @Override\n        public void onPartitionsRevoked(Collection<TopicPartition> partitions) {\n            System.out.println(\"发生rebalance！\");\n            System.out.println(\"当前分配的partitions：\" + partitions);\n\t\t   // 将已经处理完成的offset进行同步提交\n            consumer.commitSync(currentOffsets);\n        }\n        @Override\n        public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n            System.out.println(\"rebalance完成！\");\n            System.out.println(\"rebalance后分配的partitions：\" + partitions);\n        }\n    });\n    try {\n        while (true) {\n            ConsumerRecords<String, String> records = consumer.poll(100);\n            currentOffsets.clear();\n            records.forEach(record -> {\n                printRecord(record);\n                print(\"当前consumer实例：\", consumer.toString());\n                // 当前处理完成，待提交的offset，存入暂存区\n                currentOffsets.put(\n                    new TopicPartition(record.topic(), record.partition()),\n                    new OffsetAndMetadata(record.offset() + 1, null));\n                System.out.println();\n            });\n            // 每隔批次消息处理完成后异步提交\n            consumer.commitAsync(currentOffsets, null);\n        }\n    } catch (Exception e) {\n        e.printStackTrace();\n    } finally {\n        try {\n            // 出错后同步提交\n            consumer.commitSync(currentOffsets);\n        } finally {\n            consumer.close();\n        }\n    }\n}\n```","slug":"kafka学习笔记（3）——-消费者-consumer","published":1,"updated":"2021-05-31T03:06:33.198Z","_id":"ckf0h31i3001iactsg5hfi9re","comments":1,"layout":"post","photos":[],"link":"","content":"<p>kafka-consumer作为kafka消息队列的消费者端，通过接收topic的消息进行处理然后输出到下游数据源（数据库，文件系统，或者是另外的消息队列）<a id=\"more\"></a></p>\n<p>kafka-consumer最大的特点是，遵循发布/订阅模型，多个consumer共同订阅同一个topic，通过offset对消息的消费位置进行标记：</p>\n<p><img src=\"\\blog\\images\\pasted-7.png\" alt=\"upload successful\"></p>\n<p><strong>consumer的offset保存在哪里？</strong>：老版本的kafka，offset保存在zookeeper中，但由于consumer的offset数据太过庞大，不适合存放在zookeeper，因此新版本的kafka单独维护了一个保存offset的topic：<code>__consumer_offsets</code>，以group-id，topic以及partition做为组合Key对每个consumer的offset进行检索</p>\n<h3 id=\"consumer消费数据\"><a href=\"#consumer消费数据\" class=\"headerlink\" title=\"consumer消费数据\"></a>consumer消费数据</h3><p>consumer以consumer-group（消费者组）为单位向kafka订阅topic并消费数据：</p>\n<p><img src=\"\\blog\\images\\pasted-8.png\" alt=\"upload successful\"></p>\n<p>kafka consumer抓取数据基本流程图：</p>\n<p><img src=\"\\blog\\images\\pasted-9.png\" alt=\"upload successful\"></p>\n<p>几点特性：</p>\n<ul>\n<li><strong>partition主从热备</strong>：消息的读/写工作全部交给leader partition来完成，slave partition主动与leader同步，通过LEO和leader epoch等信息同步数据，leader通过ISR列表保存当前存活的slave状态</li>\n<li><strong>可靠性</strong>：只有当ISR列表中所有副本都成功收到的消息才能提供给consumer，可以提供给consumer的这部分消息由<code>high water</code>来进行控制 (设置<code>replica.lag.time.max.ms</code>参数可保证副本同步消息的时间上限)</li>\n<li><strong>零拷贝</strong>：kafka通过零拷贝的方式将数据返回给consumer</li>\n</ul>\n<h4 id=\"consumer的java-api\"><a href=\"#consumer的java-api\" class=\"headerlink\" title=\"consumer的java api\"></a>consumer的java api</h4><p>使用kafka-consumer高级api进行消费操作：</p>\n<ol>\n<li><p>创建单个consumer进行消费：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ConsumerGroupTest</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Map&lt;String, Object&gt; consumerConfig = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">        consumerConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class=\"string\">\"10.106.151.187:9092\"</span>);</span><br><span class=\"line\">        consumerConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class=\"line\">        consumerConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class=\"line\">        consumerConfig.put(ConsumerConfig.GROUP_ID_CONFIG, <span class=\"string\">\"test-group-1\"</span>);</span><br><span class=\"line\">        runConsumer(consumerConfig);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">runConsumer</span><span class=\"params\">(Map&lt;String, Object&gt; consumerConfig)</span> </span>&#123;</span><br><span class=\"line\">        Consumer&lt;String, String&gt; consumer = <span class=\"keyword\">new</span> KafkaConsumer&lt;&gt;(consumerConfig);</span><br><span class=\"line\">        consumer.subscribe(Collections.singleton(<span class=\"string\">\"test_multi_par_topic_1\"</span>));</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// poll拉取消息，最长等待时间10秒</span></span><br><span class=\"line\">                ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class=\"number\">10</span>));</span><br><span class=\"line\">                records.forEach(record -&gt; &#123;</span><br><span class=\"line\">                    printRecord(record);</span><br><span class=\"line\">                    print(<span class=\"string\">\"当前consumer实例：\"</span>, consumer.toString());</span><br><span class=\"line\">                    System.out.println();</span><br><span class=\"line\">                &#125;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">            consumer.close();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">printRecord</span><span class=\"params\">(ConsumerRecord&lt;String, String&gt; record)</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"当前record：====&gt; \"</span></span><br><span class=\"line\">                           + <span class=\"string\">\" topic:\"</span> + record.topic()</span><br><span class=\"line\">                           + <span class=\"string\">\" partition:\"</span> + record.partition()</span><br><span class=\"line\">                           + <span class=\"string\">\" offset:\"</span> + record.offset()</span><br><span class=\"line\">                           + <span class=\"string\">\" value:\"</span> + record.value()</span><br><span class=\"line\">                          );</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">print</span><span class=\"params\">(String name, Object value)</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"KafkaConsumer ====&gt; \"</span> + name + <span class=\"string\">\" is \"</span> + <span class=\"string\">\"&#123; \"</span> + value + <span class=\"string\">\" &#125;\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>单个consumer实例可以订阅多个topic，也可以通过正则表达式订阅topic：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 订阅多个topic</span></span><br><span class=\"line\">consumer.subscribe(Arrays.asList(<span class=\"string\">\"test-topic-1\"</span>, <span class=\"string\">\"test-topic-2\"</span>));</span><br><span class=\"line\"><span class=\"comment\">// 通过正则表达式订阅多个topic</span></span><br><span class=\"line\">consumer.subscribe(Pattern.compile(<span class=\"string\">\"test.*\"</span>));</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建消费者组订阅包含多个partition的topic：</p>\n<p>创建一个叫做“test-group-1”的消费组，订阅“test_multi_par_topic_1” topic， 该topic包含三个partition：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    Map&lt;String, Object&gt; consumerConfig = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">    consumerConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class=\"string\">\"10.106.151.187:9092\"</span>);</span><br><span class=\"line\">    consumerConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class=\"line\">    consumerConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class=\"line\">    consumerConfig.put(ConsumerConfig.GROUP_ID_CONFIG, <span class=\"string\">\"test-group-1\"</span>);</span><br><span class=\"line\">    runConsumerManualCommit(consumerConfig);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">runConsumer</span><span class=\"params\">(Map&lt;String, Object&gt; consumerConfig)</span> </span>&#123;</span><br><span class=\"line\">    Consumer&lt;String, String&gt; consumer = <span class=\"keyword\">new</span> KafkaConsumer&lt;&gt;(consumerConfig);</span><br><span class=\"line\">    consumer.subscribe(Collections.singleton(<span class=\"string\">\"test_multi_par_topic_1\"</span>));</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// poll拉取消息，最长等待时间10秒</span></span><br><span class=\"line\">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class=\"number\">10</span>));</span><br><span class=\"line\">            records.forEach(record -&gt; &#123;</span><br><span class=\"line\">                printRecord(record);</span><br><span class=\"line\">                print(<span class=\"string\">\"当前consumer实例：\"</span>, consumer.toString());</span><br><span class=\"line\">                System.out.println();</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        consumer.close();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>   首先只启动一个实例，可以看到，当前consumer实例消费了全部的三个partition的数据：</p>\n<p><img src=\"\\blog\\images\\pasted-10.png\" alt=\"upload successful\"></p>\n<p>   向该组加入一个consumer实例，可以看到，之前<code>@48322fe3</code>这个consumer实例只分到了partition2，而新加入的<code>@365ae362</code>这个实例分到了0和1：：</p>\n<p><img src=\"\\blog\\images\\pasted-11.png\" alt=\"upload successful\"> </p>\n<p><img src=\"\\blog\\images\\pasted-12.png\" alt=\"upload successful\"></p>\n<p>继续加consumer实例进来，最早的元老实例1，分到了partition2：</p>\n<p><img src=\"\\blog\\images\\pasted-13.png\" alt=\"upload successful\"></p>\n<p>之后加入的实例2分到了partition0：</p>\n<p><img src=\"\\blog\\images\\pasted-14.png\" alt=\"upload successful\"></p>\n<p>最新加入的实例3 <code>@345dd14f</code>，分到了parition1：</p>\n<p><img src=\"\\blog\\images\\pasted-15.png\" alt=\"upload successful\"></p>\n<p>接下来将元老实例1<code>@48322fe3</code>停掉，观察实例2和实例3 （注意观察实例1的最后消费offset），实例1最后消费情况，消费完offset=85就挂掉了：</p>\n<p><img src=\"\\blog\\images\\pasted-16.png\" alt=\"upload successful\"></p>\n<p>观察实例2可以发现，实例2除了继续消费partition0，还认领了之前实例3消费的partition1的任务</p>\n<p><img src=\"\\blog\\images\\pasted-17.png\" alt=\"upload successful\"></p>\n<p>观察实例3，消费partition1直到offset=91的位置，发生了rebalance，之后partition1的任务分派给了上面实例2，自己分到了因实例1挂掉而无人认领的partition2，并且从实例1最后消费位置即offset=86开始消费</p>\n<p><img src=\"\\blog\\images\\pasted-18.png\" alt=\"upload successful\"></p>\n<h3 id=\"consumer-group\"><a href=\"#consumer-group\" class=\"headerlink\" title=\"consumer-group\"></a>consumer-group</h3><p>单个consumer-group即可以只消费一个topic的消息，也可以同时消费多个topic的消息</p>\n<h4 id=\"consumer-group订阅topic\"><a href=\"#consumer-group订阅topic\" class=\"headerlink\" title=\"consumer-group订阅topic\"></a>consumer-group订阅topic</h4><p>单个consumer-group在订阅某个topic时，如果不特殊指定订阅某个partition，kafka将启用<code>Coordinator</code>对consumer-group内的consumer实例进行负载均衡，有以下特点：</p>\n<ol>\n<li><p>组内的一个consumer实例消费全部的partition：</p>\n<p> <img src=\"\\blog\\images\\pasted-19.png\" alt=\"upload successful\"></p>\n</li>\n<li><p>组内继续加入consumer实例，一同消费多个partition，消费过程与另外的consumer完全隔离不受影响：</p>\n<p> <img src=\"\\blog\\images\\pasted-20.png\" alt=\"upload successful\"></p>\n</li>\n<li><p>组内继续加入consumer，每个consumer实例单独消费一个partition，此时consumer数目与partition数目一致：</p>\n<p> <img src=\"\\blog\\images\\pasted-21.png\" alt=\"upload successful\"></p>\n</li>\n<li><p>继续加入consumer，数目超过partition数目，此时多出来的consumer将分不到partition进行消费：</p>\n<p> <img src=\"\\blog\\images\\pasted-22.png\" alt=\"upload successful\"></p>\n</li>\n</ol>\n<p>如上可以看出，当单个consumer-group订阅topic进行消费时，kafka的Coordinator保证topic的数据能够被均匀分派到组内的各个消费者上，并且topic中的<strong>单个partition只能被单个consumer-group中的其中一个consumer消费</strong></p>\n<p>不过，如果有其他consumer-group的consumer参与消费这个topic，将与之前的consumer-group隔离，Coordinator将单独为这个新的组进行负载均衡：</p>\n<p>   <img src=\"\\blog\\images\\pasted-23.png\" alt=\"upload successful\"></p>\n<h4 id=\"consumer分区再平衡\"><a href=\"#consumer分区再平衡\" class=\"headerlink\" title=\"consumer分区再平衡\"></a>consumer分区再平衡</h4><ul>\n<li>每当一个consumer-group有新成员加入，并且和老成员一起消费同一个topic的时候，Coordinator都将进行分区再平衡（<code>rebalance</code>），为了平衡消费能力，老成员消费的partition有可能会被分派给新加入的consumer</li>\n<li>当有consumer实例挂掉时，之前分派给他的partition将会重新分派给剩余还活着的consumer（conusmer实例通过发送心跳让kafka集群知道他还活着）</li>\n<li>订阅的topic新加入partition也会触发rebalance</li>\n<li>通过正则表达式订阅某个类型的topic，当新加入该类型的topic时，也会发生rebalance</li>\n</ul>\n<h4 id=\"consumer-rebalance的大致流程：\"><a href=\"#consumer-rebalance的大致流程：\" class=\"headerlink\" title=\"consumer rebalance的大致流程：\"></a>consumer rebalance的大致流程：</h4><ol>\n<li>Topic/Partition的改变或者新Consumer的加入或者已有Consumer停止，将触发Coordinator注册在Zookeeper上的watch，Coordinator收到通知准备发起Rebalance操作。</li>\n<li>Coordinator通过在HeartbeatResponse中返回IllegalGeneration错误码通知各个consumer发起Rebalance操作。</li>\n<li>存活的Consumer向Coordinator发送JoinGroupRequest</li>\n<li>Coordinator在Zookeeper中增加Group的Generation ID并将新的Partition分配情况写入Zookeeper</li>\n<li>Coordinator向存活的consumer发送JoinGroupResponse</li>\n<li>存活的consumer收到JoinGroupResponse后重新启动新一轮消费</li>\n</ol>\n<h3 id=\"consumer配置\"><a href=\"#consumer配置\" class=\"headerlink\" title=\"consumer配置\"></a>consumer配置</h3><p>除了上述<code>bootstrap.servers</code>,<code>key.deserializer</code>,<code>value.deserializer</code>,<code>group.id</code>这几个配置项必须进行配置之外，其他的配置项均为可选项：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 单次拉取消息的最小字节数，如果该值不为0，在consumer拉取消息时，如果可消费数据达不到该值，broker将等待一段时间(fetch.max.wait.ms)直到有足够数据或者等待超时，再返回给consumer</span><br><span class=\"line\">fetch.min.bytes=1024</span><br><span class=\"line\"># 单次拉取消息的最长等待时间</span><br><span class=\"line\">fetch.max.wait.ms=500</span><br><span class=\"line\"># 指定consumer单次poll()从分区中拉取的最大字节数，默认1MB</span><br><span class=\"line\">max.partition.fetch.bytes=1048576</span><br><span class=\"line\"># kafka集群判断consumer连接中断的最长等待时间，默认10秒，如果consumer超过该时间没有发送心跳，则会判断为死亡进而触发rebalance</span><br><span class=\"line\">session.timeout.ms=10000</span><br><span class=\"line\"># 心跳间隔时间，建议不超过session.timeout.ms的1/3</span><br><span class=\"line\">heartbeat.interval.ms=3000</span><br><span class=\"line\"># 是否开启自动提交offset，默认是开启的，如果开启，将每隔auto.commit.interval.ms的时间将消费完成但未提交offset的consumer统一向kafka集群提交一次（风险：当consumer消费完成但未提交offset就挂掉时，重启后将造成消息重复消费）</span><br><span class=\"line\">enable.auto.commit=true</span><br><span class=\"line\"># 自动统一提交offset的时间间隔</span><br><span class=\"line\">auto.commit.interval.ms=5000</span><br><span class=\"line\"># 开始消费的consumer-group（或者该consumer掉线已久，已经丢失有效的offset信息）初始化offset的策略，</span><br><span class=\"line\"># latest：默认值，默认从最新的有效offset开始消费</span><br><span class=\"line\"># earliest：从最早的有效offset开始消费</span><br><span class=\"line\"># none：如果kafka没有保存该consumer-group的offset信息则直接抛异常</span><br><span class=\"line\">auto.offset.reset=[latest, earliest, none]</span><br><span class=\"line\"># 分区分派策略类，kafka-clients自带的分区策略有Range和RoundRobin</span><br><span class=\"line\"># 必须是PartitionAssignor的实现类</span><br><span class=\"line\">partition.assignment.strategy=class org.apache.kafka.clients.consumer.RangeAssignor</span><br><span class=\"line\"># 单次poll()拉取的消息数量最大值，默认是500个</span><br><span class=\"line\">max.poll.records=500</span><br></pre></td></tr></table></figure>\n<h3 id=\"kafka-consumer的offset提交策略\"><a href=\"#kafka-consumer的offset提交策略\" class=\"headerlink\" title=\"kafka consumer的offset提交策略\"></a>kafka consumer的offset提交策略</h3><p>consumer每次消费数据完成后需要提交offset给集群以更新自己的消费状态，提交过程非常重要，直接关系到消费过程的稳定性，提交异常的话可能导致以下两种后果：</p>\n<ul>\n<li><p>重复消费：一般发生在还没来得及提交offset即被中断消费的情况</p>\n<p><img src=\"\\blog\\images\\pasted-24.png\" alt=\"upload successful\"></p>\n</li>\n<li><p>丢失消费：一般发生在消费过程有耗时操作的情况，如果在此期间提交了当前还没处理完成的消息的offset，会造成消费丢失：</p>\n<p><img src=\"\\blog\\images\\pasted-25.png\" alt=\"upload successful\"></p>\n</li>\n</ul>\n<p>kafka提供了<code>手动commit</code>和<code>自动commit</code>两种提交策略：</p>\n<ol>\n<li><p><strong>自动提交</strong>：将<code>enable.auto.commit</code>设置为true并且将<code>auto.commit.interval.ms</code>设置为大于0的时间，即可开启自动提交，每次调用<code>consumer.poll()</code>方法时都会检查是否达到提交间隔时间，并将上一次拉取消息中最大的一个offset信息发送给集群中的<code>__consumer_offsets</code>这个topic</p>\n<p>缺点：自动提交不需要用户手动commit，因此提交过程不可控</p>\n</li>\n<li><p><strong>手动提交</strong>：手动提交又分为<code>commitSync()</code>和<code>commitAsync()</code>两种方式，该模式下<code>enable.auto.commit</code>必须为false，consumer api任何情况都不会自动帮用户提交offset，一切由用户主动控制：</p>\n<p><code>commitSync()</code>：同步提交，直接提交之前拉取的最新的offset，用户可自己保证在消息处理完毕后直接提交当前offset，缺点是整个提交过程是阻塞的，并且提交失败会进行重试</p>\n<p><code>commitAsync()</code>：异步提交，同样也是提交之前拉取的最新的offset，改善了同步提交过程会产生阻塞的缺点，支持回调函数，提交过程不进行重试</p>\n</li>\n</ol>\n<p>比较好的手动提交方式是<code>同步和异步组合提交</code>：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// poll拉取消息，最长等待时间10秒</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class=\"number\">10</span>));</span><br><span class=\"line\">            records.forEach(record -&gt; &#123;</span><br><span class=\"line\">                printRecord(record);</span><br><span class=\"line\">                print(<span class=\"string\">\"当前consumer实例：\"</span>, consumer.toString());</span><br><span class=\"line\">                System.out.println();</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 消费过程未报错则执行异步提交，速度更快，不阻塞consumer线程</span></span><br><span class=\"line\">            consumer.commitAsync((offsets, exception) -&gt; &#123;</span><br><span class=\"line\">                <span class=\"comment\">// offsets中的`offsetAndMetadata`包含本次提交后希望处理的下一个offset</span></span><br><span class=\"line\">                print(<span class=\"string\">\"本次提交后希望处理的下一个offset:\"</span>, offsets);</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (exception != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                    exception.printStackTrace();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">    e.printStackTrace();</span><br><span class=\"line\">&#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 消费过程报错的话就尝试同步提交，防止未提交offset造成风险</span></span><br><span class=\"line\">        consumer.commitSync();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        consumer.close();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"kafka-consumer消费时指定offset\"><a href=\"#kafka-consumer消费时指定offset\" class=\"headerlink\" title=\"kafka consumer消费时指定offset\"></a>kafka consumer消费时指定offset</h3><p>有些时候我们并不想按照默认情况读取最新offset位置的消息，kafka对此提供了查找特定offset的api，可以实现向后回退几个消息或者向前跳过几个消息：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">runConsumerSeekOffset</span><span class=\"params\">(Map&lt;String, Object&gt; consumerConfig, <span class=\"keyword\">long</span> specificOffset)</span> </span>&#123;</span><br><span class=\"line\">    Consumer&lt;String, String&gt; consumer = <span class=\"keyword\">new</span> KafkaConsumer&lt;&gt;(consumerConfig);</span><br><span class=\"line\">    consumer.subscribe(Collections.singleton(<span class=\"string\">\"test_multi_par_topic_1\"</span>));</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 使用seek()方法将consumer的offset重置到指定位置</span></span><br><span class=\"line\">        consumer.assignment().forEach(topicPartition -&gt; &#123;</span><br><span class=\"line\">            consumer.seek(topicPartition, specificOffset);</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) &#123;</span><br><span class=\"line\">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class=\"number\">10</span>));</span><br><span class=\"line\">            records.forEach(record -&gt; &#123;</span><br><span class=\"line\">                printRecord(record);</span><br><span class=\"line\">                print(<span class=\"string\">\"当前consumer实例：\"</span>, consumer.toString());</span><br><span class=\"line\">                System.out.println();</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        consumer.close();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"kafka-consumer-rebalance监听器\"><a href=\"#kafka-consumer-rebalance监听器\" class=\"headerlink\" title=\"kafka consumer rebalance监听器\"></a>kafka consumer rebalance监听器</h3><p>consumer和kafka的Coodinator交互的心跳心中包含是否需要rebalance信息，如果需要rebalance则停止拉取数据并直接提交offset，rebalance完成后consumer有可能失去对当前分配的partition的消费权</p>\n<p>kafka提供了rebalance监听器用于让用户设置在rebalance发生后需要做的一些资源回收的操作，并且可以在监听器中手动提交当前已经处理完成的消息offset，以下是相对比较保险不会造成消费丢失的一种提交策略：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">runConsumerRebanlanceListener</span><span class=\"params\">(Map&lt;String, Object&gt; consumerConfig)</span> </span>&#123;</span><br><span class=\"line\">    Consumer&lt;String, String&gt; consumer = <span class=\"keyword\">new</span> KafkaConsumer&lt;&gt;(consumerConfig);</span><br><span class=\"line\">    <span class=\"comment\">// 已处理的消息的offset暂存区</span></span><br><span class=\"line\">    <span class=\"keyword\">final</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; currentOffsets = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">    consumer.subscribe(Collections.singleton(<span class=\"string\">\"test_multi_par_topic_1\"</span>), <span class=\"keyword\">new</span> ConsumerRebalanceListener() &#123;</span><br><span class=\"line\">        <span class=\"meta\">@Override</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">onPartitionsRevoked</span><span class=\"params\">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"发生rebalance！\"</span>);</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"当前分配的partitions：\"</span> + partitions);</span><br><span class=\"line\">\t\t   <span class=\"comment\">// 将已经处理完成的offset进行同步提交</span></span><br><span class=\"line\">            consumer.commitSync(currentOffsets);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"meta\">@Override</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">onPartitionsAssigned</span><span class=\"params\">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"rebalance完成！\"</span>);</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"rebalance后分配的partitions：\"</span> + partitions);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) &#123;</span><br><span class=\"line\">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class=\"number\">100</span>);</span><br><span class=\"line\">            currentOffsets.clear();</span><br><span class=\"line\">            records.forEach(record -&gt; &#123;</span><br><span class=\"line\">                printRecord(record);</span><br><span class=\"line\">                print(<span class=\"string\">\"当前consumer实例：\"</span>, consumer.toString());</span><br><span class=\"line\">                <span class=\"comment\">// 当前处理完成，待提交的offset，存入暂存区</span></span><br><span class=\"line\">                currentOffsets.put(</span><br><span class=\"line\">                    <span class=\"keyword\">new</span> TopicPartition(record.topic(), record.partition()),</span><br><span class=\"line\">                    <span class=\"keyword\">new</span> OffsetAndMetadata(record.offset() + <span class=\"number\">1</span>, <span class=\"keyword\">null</span>));</span><br><span class=\"line\">                System.out.println();</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">            <span class=\"comment\">// 每隔批次消息处理完成后异步提交</span></span><br><span class=\"line\">            consumer.commitAsync(currentOffsets, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 出错后同步提交</span></span><br><span class=\"line\">            consumer.commitSync(currentOffsets);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">            consumer.close();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<p>kafka-consumer作为kafka消息队列的消费者端，通过接收topic的消息进行处理然后输出到下游数据源（数据库，文件系统，或者是另外的消息队列）","more":"</p>\n<p>kafka-consumer最大的特点是，遵循发布/订阅模型，多个consumer共同订阅同一个topic，通过offset对消息的消费位置进行标记：</p>\n<p><img src=\"\\blog\\images\\pasted-7.png\" alt=\"upload successful\"></p>\n<p><strong>consumer的offset保存在哪里？</strong>：老版本的kafka，offset保存在zookeeper中，但由于consumer的offset数据太过庞大，不适合存放在zookeeper，因此新版本的kafka单独维护了一个保存offset的topic：<code>__consumer_offsets</code>，以group-id，topic以及partition做为组合Key对每个consumer的offset进行检索</p>\n<h3 id=\"consumer消费数据\"><a href=\"#consumer消费数据\" class=\"headerlink\" title=\"consumer消费数据\"></a>consumer消费数据</h3><p>consumer以consumer-group（消费者组）为单位向kafka订阅topic并消费数据：</p>\n<p><img src=\"\\blog\\images\\pasted-8.png\" alt=\"upload successful\"></p>\n<p>kafka consumer抓取数据基本流程图：</p>\n<p><img src=\"\\blog\\images\\pasted-9.png\" alt=\"upload successful\"></p>\n<p>几点特性：</p>\n<ul>\n<li><strong>partition主从热备</strong>：消息的读/写工作全部交给leader partition来完成，slave partition主动与leader同步，通过LEO和leader epoch等信息同步数据，leader通过ISR列表保存当前存活的slave状态</li>\n<li><strong>可靠性</strong>：只有当ISR列表中所有副本都成功收到的消息才能提供给consumer，可以提供给consumer的这部分消息由<code>high water</code>来进行控制 (设置<code>replica.lag.time.max.ms</code>参数可保证副本同步消息的时间上限)</li>\n<li><strong>零拷贝</strong>：kafka通过零拷贝的方式将数据返回给consumer</li>\n</ul>\n<h4 id=\"consumer的java-api\"><a href=\"#consumer的java-api\" class=\"headerlink\" title=\"consumer的java api\"></a>consumer的java api</h4><p>使用kafka-consumer高级api进行消费操作：</p>\n<ol>\n<li><p>创建单个consumer进行消费：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ConsumerGroupTest</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Map&lt;String, Object&gt; consumerConfig = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">        consumerConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class=\"string\">\"10.106.151.187:9092\"</span>);</span><br><span class=\"line\">        consumerConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class=\"line\">        consumerConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class=\"line\">        consumerConfig.put(ConsumerConfig.GROUP_ID_CONFIG, <span class=\"string\">\"test-group-1\"</span>);</span><br><span class=\"line\">        runConsumer(consumerConfig);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">runConsumer</span><span class=\"params\">(Map&lt;String, Object&gt; consumerConfig)</span> </span>&#123;</span><br><span class=\"line\">        Consumer&lt;String, String&gt; consumer = <span class=\"keyword\">new</span> KafkaConsumer&lt;&gt;(consumerConfig);</span><br><span class=\"line\">        consumer.subscribe(Collections.singleton(<span class=\"string\">\"test_multi_par_topic_1\"</span>));</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// poll拉取消息，最长等待时间10秒</span></span><br><span class=\"line\">                ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class=\"number\">10</span>));</span><br><span class=\"line\">                records.forEach(record -&gt; &#123;</span><br><span class=\"line\">                    printRecord(record);</span><br><span class=\"line\">                    print(<span class=\"string\">\"当前consumer实例：\"</span>, consumer.toString());</span><br><span class=\"line\">                    System.out.println();</span><br><span class=\"line\">                &#125;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">            consumer.close();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">printRecord</span><span class=\"params\">(ConsumerRecord&lt;String, String&gt; record)</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"当前record：====&gt; \"</span></span><br><span class=\"line\">                           + <span class=\"string\">\" topic:\"</span> + record.topic()</span><br><span class=\"line\">                           + <span class=\"string\">\" partition:\"</span> + record.partition()</span><br><span class=\"line\">                           + <span class=\"string\">\" offset:\"</span> + record.offset()</span><br><span class=\"line\">                           + <span class=\"string\">\" value:\"</span> + record.value()</span><br><span class=\"line\">                          );</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">print</span><span class=\"params\">(String name, Object value)</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"KafkaConsumer ====&gt; \"</span> + name + <span class=\"string\">\" is \"</span> + <span class=\"string\">\"&#123; \"</span> + value + <span class=\"string\">\" &#125;\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>单个consumer实例可以订阅多个topic，也可以通过正则表达式订阅topic：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 订阅多个topic</span></span><br><span class=\"line\">consumer.subscribe(Arrays.asList(<span class=\"string\">\"test-topic-1\"</span>, <span class=\"string\">\"test-topic-2\"</span>));</span><br><span class=\"line\"><span class=\"comment\">// 通过正则表达式订阅多个topic</span></span><br><span class=\"line\">consumer.subscribe(Pattern.compile(<span class=\"string\">\"test.*\"</span>));</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建消费者组订阅包含多个partition的topic：</p>\n<p>创建一个叫做“test-group-1”的消费组，订阅“test_multi_par_topic_1” topic， 该topic包含三个partition：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    Map&lt;String, Object&gt; consumerConfig = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">    consumerConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class=\"string\">\"10.106.151.187:9092\"</span>);</span><br><span class=\"line\">    consumerConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class=\"line\">    consumerConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class=\"line\">    consumerConfig.put(ConsumerConfig.GROUP_ID_CONFIG, <span class=\"string\">\"test-group-1\"</span>);</span><br><span class=\"line\">    runConsumerManualCommit(consumerConfig);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">runConsumer</span><span class=\"params\">(Map&lt;String, Object&gt; consumerConfig)</span> </span>&#123;</span><br><span class=\"line\">    Consumer&lt;String, String&gt; consumer = <span class=\"keyword\">new</span> KafkaConsumer&lt;&gt;(consumerConfig);</span><br><span class=\"line\">    consumer.subscribe(Collections.singleton(<span class=\"string\">\"test_multi_par_topic_1\"</span>));</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// poll拉取消息，最长等待时间10秒</span></span><br><span class=\"line\">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class=\"number\">10</span>));</span><br><span class=\"line\">            records.forEach(record -&gt; &#123;</span><br><span class=\"line\">                printRecord(record);</span><br><span class=\"line\">                print(<span class=\"string\">\"当前consumer实例：\"</span>, consumer.toString());</span><br><span class=\"line\">                System.out.println();</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        consumer.close();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>   首先只启动一个实例，可以看到，当前consumer实例消费了全部的三个partition的数据：</p>\n<p><img src=\"\\blog\\images\\pasted-10.png\" alt=\"upload successful\"></p>\n<p>   向该组加入一个consumer实例，可以看到，之前<code>@48322fe3</code>这个consumer实例只分到了partition2，而新加入的<code>@365ae362</code>这个实例分到了0和1：：</p>\n<p><img src=\"\\blog\\images\\pasted-11.png\" alt=\"upload successful\"> </p>\n<p><img src=\"\\blog\\images\\pasted-12.png\" alt=\"upload successful\"></p>\n<p>继续加consumer实例进来，最早的元老实例1，分到了partition2：</p>\n<p><img src=\"\\blog\\images\\pasted-13.png\" alt=\"upload successful\"></p>\n<p>之后加入的实例2分到了partition0：</p>\n<p><img src=\"\\blog\\images\\pasted-14.png\" alt=\"upload successful\"></p>\n<p>最新加入的实例3 <code>@345dd14f</code>，分到了parition1：</p>\n<p><img src=\"\\blog\\images\\pasted-15.png\" alt=\"upload successful\"></p>\n<p>接下来将元老实例1<code>@48322fe3</code>停掉，观察实例2和实例3 （注意观察实例1的最后消费offset），实例1最后消费情况，消费完offset=85就挂掉了：</p>\n<p><img src=\"\\blog\\images\\pasted-16.png\" alt=\"upload successful\"></p>\n<p>观察实例2可以发现，实例2除了继续消费partition0，还认领了之前实例3消费的partition1的任务</p>\n<p><img src=\"\\blog\\images\\pasted-17.png\" alt=\"upload successful\"></p>\n<p>观察实例3，消费partition1直到offset=91的位置，发生了rebalance，之后partition1的任务分派给了上面实例2，自己分到了因实例1挂掉而无人认领的partition2，并且从实例1最后消费位置即offset=86开始消费</p>\n<p><img src=\"\\blog\\images\\pasted-18.png\" alt=\"upload successful\"></p>\n<h3 id=\"consumer-group\"><a href=\"#consumer-group\" class=\"headerlink\" title=\"consumer-group\"></a>consumer-group</h3><p>单个consumer-group即可以只消费一个topic的消息，也可以同时消费多个topic的消息</p>\n<h4 id=\"consumer-group订阅topic\"><a href=\"#consumer-group订阅topic\" class=\"headerlink\" title=\"consumer-group订阅topic\"></a>consumer-group订阅topic</h4><p>单个consumer-group在订阅某个topic时，如果不特殊指定订阅某个partition，kafka将启用<code>Coordinator</code>对consumer-group内的consumer实例进行负载均衡，有以下特点：</p>\n<ol>\n<li><p>组内的一个consumer实例消费全部的partition：</p>\n<p> <img src=\"\\blog\\images\\pasted-19.png\" alt=\"upload successful\"></p>\n</li>\n<li><p>组内继续加入consumer实例，一同消费多个partition，消费过程与另外的consumer完全隔离不受影响：</p>\n<p> <img src=\"\\blog\\images\\pasted-20.png\" alt=\"upload successful\"></p>\n</li>\n<li><p>组内继续加入consumer，每个consumer实例单独消费一个partition，此时consumer数目与partition数目一致：</p>\n<p> <img src=\"\\blog\\images\\pasted-21.png\" alt=\"upload successful\"></p>\n</li>\n<li><p>继续加入consumer，数目超过partition数目，此时多出来的consumer将分不到partition进行消费：</p>\n<p> <img src=\"\\blog\\images\\pasted-22.png\" alt=\"upload successful\"></p>\n</li>\n</ol>\n<p>如上可以看出，当单个consumer-group订阅topic进行消费时，kafka的Coordinator保证topic的数据能够被均匀分派到组内的各个消费者上，并且topic中的<strong>单个partition只能被单个consumer-group中的其中一个consumer消费</strong></p>\n<p>不过，如果有其他consumer-group的consumer参与消费这个topic，将与之前的consumer-group隔离，Coordinator将单独为这个新的组进行负载均衡：</p>\n<p>   <img src=\"\\blog\\images\\pasted-23.png\" alt=\"upload successful\"></p>\n<h4 id=\"consumer分区再平衡\"><a href=\"#consumer分区再平衡\" class=\"headerlink\" title=\"consumer分区再平衡\"></a>consumer分区再平衡</h4><ul>\n<li>每当一个consumer-group有新成员加入，并且和老成员一起消费同一个topic的时候，Coordinator都将进行分区再平衡（<code>rebalance</code>），为了平衡消费能力，老成员消费的partition有可能会被分派给新加入的consumer</li>\n<li>当有consumer实例挂掉时，之前分派给他的partition将会重新分派给剩余还活着的consumer（conusmer实例通过发送心跳让kafka集群知道他还活着）</li>\n<li>订阅的topic新加入partition也会触发rebalance</li>\n<li>通过正则表达式订阅某个类型的topic，当新加入该类型的topic时，也会发生rebalance</li>\n</ul>\n<h4 id=\"consumer-rebalance的大致流程：\"><a href=\"#consumer-rebalance的大致流程：\" class=\"headerlink\" title=\"consumer rebalance的大致流程：\"></a>consumer rebalance的大致流程：</h4><ol>\n<li>Topic/Partition的改变或者新Consumer的加入或者已有Consumer停止，将触发Coordinator注册在Zookeeper上的watch，Coordinator收到通知准备发起Rebalance操作。</li>\n<li>Coordinator通过在HeartbeatResponse中返回IllegalGeneration错误码通知各个consumer发起Rebalance操作。</li>\n<li>存活的Consumer向Coordinator发送JoinGroupRequest</li>\n<li>Coordinator在Zookeeper中增加Group的Generation ID并将新的Partition分配情况写入Zookeeper</li>\n<li>Coordinator向存活的consumer发送JoinGroupResponse</li>\n<li>存活的consumer收到JoinGroupResponse后重新启动新一轮消费</li>\n</ol>\n<h3 id=\"consumer配置\"><a href=\"#consumer配置\" class=\"headerlink\" title=\"consumer配置\"></a>consumer配置</h3><p>除了上述<code>bootstrap.servers</code>,<code>key.deserializer</code>,<code>value.deserializer</code>,<code>group.id</code>这几个配置项必须进行配置之外，其他的配置项均为可选项：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 单次拉取消息的最小字节数，如果该值不为0，在consumer拉取消息时，如果可消费数据达不到该值，broker将等待一段时间(fetch.max.wait.ms)直到有足够数据或者等待超时，再返回给consumer</span><br><span class=\"line\">fetch.min.bytes=1024</span><br><span class=\"line\"># 单次拉取消息的最长等待时间</span><br><span class=\"line\">fetch.max.wait.ms=500</span><br><span class=\"line\"># 指定consumer单次poll()从分区中拉取的最大字节数，默认1MB</span><br><span class=\"line\">max.partition.fetch.bytes=1048576</span><br><span class=\"line\"># kafka集群判断consumer连接中断的最长等待时间，默认10秒，如果consumer超过该时间没有发送心跳，则会判断为死亡进而触发rebalance</span><br><span class=\"line\">session.timeout.ms=10000</span><br><span class=\"line\"># 心跳间隔时间，建议不超过session.timeout.ms的1/3</span><br><span class=\"line\">heartbeat.interval.ms=3000</span><br><span class=\"line\"># 是否开启自动提交offset，默认是开启的，如果开启，将每隔auto.commit.interval.ms的时间将消费完成但未提交offset的consumer统一向kafka集群提交一次（风险：当consumer消费完成但未提交offset就挂掉时，重启后将造成消息重复消费）</span><br><span class=\"line\">enable.auto.commit=true</span><br><span class=\"line\"># 自动统一提交offset的时间间隔</span><br><span class=\"line\">auto.commit.interval.ms=5000</span><br><span class=\"line\"># 开始消费的consumer-group（或者该consumer掉线已久，已经丢失有效的offset信息）初始化offset的策略，</span><br><span class=\"line\"># latest：默认值，默认从最新的有效offset开始消费</span><br><span class=\"line\"># earliest：从最早的有效offset开始消费</span><br><span class=\"line\"># none：如果kafka没有保存该consumer-group的offset信息则直接抛异常</span><br><span class=\"line\">auto.offset.reset=[latest, earliest, none]</span><br><span class=\"line\"># 分区分派策略类，kafka-clients自带的分区策略有Range和RoundRobin</span><br><span class=\"line\"># 必须是PartitionAssignor的实现类</span><br><span class=\"line\">partition.assignment.strategy=class org.apache.kafka.clients.consumer.RangeAssignor</span><br><span class=\"line\"># 单次poll()拉取的消息数量最大值，默认是500个</span><br><span class=\"line\">max.poll.records=500</span><br></pre></td></tr></table></figure>\n<h3 id=\"kafka-consumer的offset提交策略\"><a href=\"#kafka-consumer的offset提交策略\" class=\"headerlink\" title=\"kafka consumer的offset提交策略\"></a>kafka consumer的offset提交策略</h3><p>consumer每次消费数据完成后需要提交offset给集群以更新自己的消费状态，提交过程非常重要，直接关系到消费过程的稳定性，提交异常的话可能导致以下两种后果：</p>\n<ul>\n<li><p>重复消费：一般发生在还没来得及提交offset即被中断消费的情况</p>\n<p><img src=\"\\blog\\images\\pasted-24.png\" alt=\"upload successful\"></p>\n</li>\n<li><p>丢失消费：一般发生在消费过程有耗时操作的情况，如果在此期间提交了当前还没处理完成的消息的offset，会造成消费丢失：</p>\n<p><img src=\"\\blog\\images\\pasted-25.png\" alt=\"upload successful\"></p>\n</li>\n</ul>\n<p>kafka提供了<code>手动commit</code>和<code>自动commit</code>两种提交策略：</p>\n<ol>\n<li><p><strong>自动提交</strong>：将<code>enable.auto.commit</code>设置为true并且将<code>auto.commit.interval.ms</code>设置为大于0的时间，即可开启自动提交，每次调用<code>consumer.poll()</code>方法时都会检查是否达到提交间隔时间，并将上一次拉取消息中最大的一个offset信息发送给集群中的<code>__consumer_offsets</code>这个topic</p>\n<p>缺点：自动提交不需要用户手动commit，因此提交过程不可控</p>\n</li>\n<li><p><strong>手动提交</strong>：手动提交又分为<code>commitSync()</code>和<code>commitAsync()</code>两种方式，该模式下<code>enable.auto.commit</code>必须为false，consumer api任何情况都不会自动帮用户提交offset，一切由用户主动控制：</p>\n<p><code>commitSync()</code>：同步提交，直接提交之前拉取的最新的offset，用户可自己保证在消息处理完毕后直接提交当前offset，缺点是整个提交过程是阻塞的，并且提交失败会进行重试</p>\n<p><code>commitAsync()</code>：异步提交，同样也是提交之前拉取的最新的offset，改善了同步提交过程会产生阻塞的缺点，支持回调函数，提交过程不进行重试</p>\n</li>\n</ol>\n<p>比较好的手动提交方式是<code>同步和异步组合提交</code>：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// poll拉取消息，最长等待时间10秒</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class=\"number\">10</span>));</span><br><span class=\"line\">            records.forEach(record -&gt; &#123;</span><br><span class=\"line\">                printRecord(record);</span><br><span class=\"line\">                print(<span class=\"string\">\"当前consumer实例：\"</span>, consumer.toString());</span><br><span class=\"line\">                System.out.println();</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 消费过程未报错则执行异步提交，速度更快，不阻塞consumer线程</span></span><br><span class=\"line\">            consumer.commitAsync((offsets, exception) -&gt; &#123;</span><br><span class=\"line\">                <span class=\"comment\">// offsets中的`offsetAndMetadata`包含本次提交后希望处理的下一个offset</span></span><br><span class=\"line\">                print(<span class=\"string\">\"本次提交后希望处理的下一个offset:\"</span>, offsets);</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (exception != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                    exception.printStackTrace();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">    e.printStackTrace();</span><br><span class=\"line\">&#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 消费过程报错的话就尝试同步提交，防止未提交offset造成风险</span></span><br><span class=\"line\">        consumer.commitSync();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        consumer.close();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"kafka-consumer消费时指定offset\"><a href=\"#kafka-consumer消费时指定offset\" class=\"headerlink\" title=\"kafka consumer消费时指定offset\"></a>kafka consumer消费时指定offset</h3><p>有些时候我们并不想按照默认情况读取最新offset位置的消息，kafka对此提供了查找特定offset的api，可以实现向后回退几个消息或者向前跳过几个消息：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">runConsumerSeekOffset</span><span class=\"params\">(Map&lt;String, Object&gt; consumerConfig, <span class=\"keyword\">long</span> specificOffset)</span> </span>&#123;</span><br><span class=\"line\">    Consumer&lt;String, String&gt; consumer = <span class=\"keyword\">new</span> KafkaConsumer&lt;&gt;(consumerConfig);</span><br><span class=\"line\">    consumer.subscribe(Collections.singleton(<span class=\"string\">\"test_multi_par_topic_1\"</span>));</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 使用seek()方法将consumer的offset重置到指定位置</span></span><br><span class=\"line\">        consumer.assignment().forEach(topicPartition -&gt; &#123;</span><br><span class=\"line\">            consumer.seek(topicPartition, specificOffset);</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) &#123;</span><br><span class=\"line\">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class=\"number\">10</span>));</span><br><span class=\"line\">            records.forEach(record -&gt; &#123;</span><br><span class=\"line\">                printRecord(record);</span><br><span class=\"line\">                print(<span class=\"string\">\"当前consumer实例：\"</span>, consumer.toString());</span><br><span class=\"line\">                System.out.println();</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        consumer.close();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"kafka-consumer-rebalance监听器\"><a href=\"#kafka-consumer-rebalance监听器\" class=\"headerlink\" title=\"kafka consumer rebalance监听器\"></a>kafka consumer rebalance监听器</h3><p>consumer和kafka的Coodinator交互的心跳心中包含是否需要rebalance信息，如果需要rebalance则停止拉取数据并直接提交offset，rebalance完成后consumer有可能失去对当前分配的partition的消费权</p>\n<p>kafka提供了rebalance监听器用于让用户设置在rebalance发生后需要做的一些资源回收的操作，并且可以在监听器中手动提交当前已经处理完成的消息offset，以下是相对比较保险不会造成消费丢失的一种提交策略：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">runConsumerRebanlanceListener</span><span class=\"params\">(Map&lt;String, Object&gt; consumerConfig)</span> </span>&#123;</span><br><span class=\"line\">    Consumer&lt;String, String&gt; consumer = <span class=\"keyword\">new</span> KafkaConsumer&lt;&gt;(consumerConfig);</span><br><span class=\"line\">    <span class=\"comment\">// 已处理的消息的offset暂存区</span></span><br><span class=\"line\">    <span class=\"keyword\">final</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; currentOffsets = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">    consumer.subscribe(Collections.singleton(<span class=\"string\">\"test_multi_par_topic_1\"</span>), <span class=\"keyword\">new</span> ConsumerRebalanceListener() &#123;</span><br><span class=\"line\">        <span class=\"meta\">@Override</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">onPartitionsRevoked</span><span class=\"params\">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"发生rebalance！\"</span>);</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"当前分配的partitions：\"</span> + partitions);</span><br><span class=\"line\">\t\t   <span class=\"comment\">// 将已经处理完成的offset进行同步提交</span></span><br><span class=\"line\">            consumer.commitSync(currentOffsets);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"meta\">@Override</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">onPartitionsAssigned</span><span class=\"params\">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"rebalance完成！\"</span>);</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"rebalance后分配的partitions：\"</span> + partitions);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) &#123;</span><br><span class=\"line\">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class=\"number\">100</span>);</span><br><span class=\"line\">            currentOffsets.clear();</span><br><span class=\"line\">            records.forEach(record -&gt; &#123;</span><br><span class=\"line\">                printRecord(record);</span><br><span class=\"line\">                print(<span class=\"string\">\"当前consumer实例：\"</span>, consumer.toString());</span><br><span class=\"line\">                <span class=\"comment\">// 当前处理完成，待提交的offset，存入暂存区</span></span><br><span class=\"line\">                currentOffsets.put(</span><br><span class=\"line\">                    <span class=\"keyword\">new</span> TopicPartition(record.topic(), record.partition()),</span><br><span class=\"line\">                    <span class=\"keyword\">new</span> OffsetAndMetadata(record.offset() + <span class=\"number\">1</span>, <span class=\"keyword\">null</span>));</span><br><span class=\"line\">                System.out.println();</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">            <span class=\"comment\">// 每隔批次消息处理完成后异步提交</span></span><br><span class=\"line\">            consumer.commitAsync(currentOffsets, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 出错后同步提交</span></span><br><span class=\"line\">            consumer.commitSync(currentOffsets);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">            consumer.close();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 11(1)","author":"天渊","date":"2019-12-11T07:12:00.000Z","_content":"本章主要对计算机系统种的网络编程模型进行讲解，主要基于Linux网络api\n<!--more-->\n### 初始C-S模型\n\n计算机系统中典型的网络应用都是基于C-S架构即`客户端-服务器模型`，一个典型的网络任务的基本流程是由客户端进程和服务器进程协同完成以下操作：\n\n1. 客户端向服务器发起`请求（request）`\n2. 服务器收到请求，解析这个请求知道客户端需要什么资源，开始操作这个请求并获取资源\n3. 服务器操作完成后发起`响应（response）`，将客户端需要的资源发送给客户端，并等待下一个请求\n4. 客户端收到响应并处理服务端返还的资源\n\n### LAN和WAN\n\n`LAN（Local Area Network）`即局域网，将一片区域内的计算机通过集线器和网桥进行连接，每台计算机都可以向局域网内的任意一台计算机发送网路请求，通过网桥来判断该向局域网内的哪台计算机路由该请求\n\n`WAN（Wide Area Network）`即广域网，各个LAN网络通过路由器与其他局域网进行互联，形成一个WAN网络，如下图所示：\n\n![](http://img.mantian.site/201912101005_792.png)\n\n该方式的缺陷在于，每个局域网都有着不同的各不兼容的网络技术实现，怎么样让这些主机与互联网上的任意一台目的主机进行互联？这时候就需要一种统一的网络层协议来消除不同网络之间的差异，通过这一层协议控制主机和路由器协同工作实现数据传输，这种协议需要具备两种最重要的能力：\n\n1. `命名机制`：每台WAN上的主机都会被分配至少一个互联网络地址，网络层协议通过定义这种一致的主机地址消除了不同的局域网技术之间主机地址格式的差异\n2. `传送机制`：网络层协议通过定义`包（Package）`的形式把主机发送的数据打包成不连续的包，再将数据进行传输，消除了不同的联网技术中封装编码位和数据传输帧的方式的差异，一个包的header必须包括包大小，源主机地址以及目标主机地址\n\n目前运用得最广泛的网络层协议就是IP协议","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-11-1.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 11(1)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-12-11 15:12:00\n---\n本章主要对计算机系统种的网络编程模型进行讲解，主要基于Linux网络api\n<!--more-->\n### 初始C-S模型\n\n计算机系统中典型的网络应用都是基于C-S架构即`客户端-服务器模型`，一个典型的网络任务的基本流程是由客户端进程和服务器进程协同完成以下操作：\n\n1. 客户端向服务器发起`请求（request）`\n2. 服务器收到请求，解析这个请求知道客户端需要什么资源，开始操作这个请求并获取资源\n3. 服务器操作完成后发起`响应（response）`，将客户端需要的资源发送给客户端，并等待下一个请求\n4. 客户端收到响应并处理服务端返还的资源\n\n### LAN和WAN\n\n`LAN（Local Area Network）`即局域网，将一片区域内的计算机通过集线器和网桥进行连接，每台计算机都可以向局域网内的任意一台计算机发送网路请求，通过网桥来判断该向局域网内的哪台计算机路由该请求\n\n`WAN（Wide Area Network）`即广域网，各个LAN网络通过路由器与其他局域网进行互联，形成一个WAN网络，如下图所示：\n\n![](http://img.mantian.site/201912101005_792.png)\n\n该方式的缺陷在于，每个局域网都有着不同的各不兼容的网络技术实现，怎么样让这些主机与互联网上的任意一台目的主机进行互联？这时候就需要一种统一的网络层协议来消除不同网络之间的差异，通过这一层协议控制主机和路由器协同工作实现数据传输，这种协议需要具备两种最重要的能力：\n\n1. `命名机制`：每台WAN上的主机都会被分配至少一个互联网络地址，网络层协议通过定义这种一致的主机地址消除了不同的局域网技术之间主机地址格式的差异\n2. `传送机制`：网络层协议通过定义`包（Package）`的形式把主机发送的数据打包成不连续的包，再将数据进行传输，消除了不同的联网技术中封装编码位和数据传输帧的方式的差异，一个包的header必须包括包大小，源主机地址以及目标主机地址\n\n目前运用得最广泛的网络层协议就是IP协议","slug":"《深入理解计算机系统》读书笔记——Chapter-11-1","published":1,"updated":"2021-05-31T03:06:33.199Z","_id":"ckf0h31i5001mactshveq7puh","comments":1,"layout":"post","photos":[],"link":"","content":"<p>本章主要对计算机系统种的网络编程模型进行讲解，主要基于Linux网络api<br><a id=\"more\"></a></p>\n<h3 id=\"初始C-S模型\"><a href=\"#初始C-S模型\" class=\"headerlink\" title=\"初始C-S模型\"></a>初始C-S模型</h3><p>计算机系统中典型的网络应用都是基于C-S架构即<code>客户端-服务器模型</code>，一个典型的网络任务的基本流程是由客户端进程和服务器进程协同完成以下操作：</p>\n<ol>\n<li>客户端向服务器发起<code>请求（request）</code></li>\n<li>服务器收到请求，解析这个请求知道客户端需要什么资源，开始操作这个请求并获取资源</li>\n<li>服务器操作完成后发起<code>响应（response）</code>，将客户端需要的资源发送给客户端，并等待下一个请求</li>\n<li>客户端收到响应并处理服务端返还的资源</li>\n</ol>\n<h3 id=\"LAN和WAN\"><a href=\"#LAN和WAN\" class=\"headerlink\" title=\"LAN和WAN\"></a>LAN和WAN</h3><p><code>LAN（Local Area Network）</code>即局域网，将一片区域内的计算机通过集线器和网桥进行连接，每台计算机都可以向局域网内的任意一台计算机发送网路请求，通过网桥来判断该向局域网内的哪台计算机路由该请求</p>\n<p><code>WAN（Wide Area Network）</code>即广域网，各个LAN网络通过路由器与其他局域网进行互联，形成一个WAN网络，如下图所示：</p>\n<p><img src=\"http://img.mantian.site/201912101005_792.png\" alt></p>\n<p>该方式的缺陷在于，每个局域网都有着不同的各不兼容的网络技术实现，怎么样让这些主机与互联网上的任意一台目的主机进行互联？这时候就需要一种统一的网络层协议来消除不同网络之间的差异，通过这一层协议控制主机和路由器协同工作实现数据传输，这种协议需要具备两种最重要的能力：</p>\n<ol>\n<li><code>命名机制</code>：每台WAN上的主机都会被分配至少一个互联网络地址，网络层协议通过定义这种一致的主机地址消除了不同的局域网技术之间主机地址格式的差异</li>\n<li><code>传送机制</code>：网络层协议通过定义<code>包（Package）</code>的形式把主机发送的数据打包成不连续的包，再将数据进行传输，消除了不同的联网技术中封装编码位和数据传输帧的方式的差异，一个包的header必须包括包大小，源主机地址以及目标主机地址</li>\n</ol>\n<p>目前运用得最广泛的网络层协议就是IP协议</p>\n","site":{"data":{}},"excerpt":"<p>本章主要对计算机系统种的网络编程模型进行讲解，主要基于Linux网络api<br>","more":"</p>\n<h3 id=\"初始C-S模型\"><a href=\"#初始C-S模型\" class=\"headerlink\" title=\"初始C-S模型\"></a>初始C-S模型</h3><p>计算机系统中典型的网络应用都是基于C-S架构即<code>客户端-服务器模型</code>，一个典型的网络任务的基本流程是由客户端进程和服务器进程协同完成以下操作：</p>\n<ol>\n<li>客户端向服务器发起<code>请求（request）</code></li>\n<li>服务器收到请求，解析这个请求知道客户端需要什么资源，开始操作这个请求并获取资源</li>\n<li>服务器操作完成后发起<code>响应（response）</code>，将客户端需要的资源发送给客户端，并等待下一个请求</li>\n<li>客户端收到响应并处理服务端返还的资源</li>\n</ol>\n<h3 id=\"LAN和WAN\"><a href=\"#LAN和WAN\" class=\"headerlink\" title=\"LAN和WAN\"></a>LAN和WAN</h3><p><code>LAN（Local Area Network）</code>即局域网，将一片区域内的计算机通过集线器和网桥进行连接，每台计算机都可以向局域网内的任意一台计算机发送网路请求，通过网桥来判断该向局域网内的哪台计算机路由该请求</p>\n<p><code>WAN（Wide Area Network）</code>即广域网，各个LAN网络通过路由器与其他局域网进行互联，形成一个WAN网络，如下图所示：</p>\n<p><img src=\"http://img.mantian.site/201912101005_792.png\" alt></p>\n<p>该方式的缺陷在于，每个局域网都有着不同的各不兼容的网络技术实现，怎么样让这些主机与互联网上的任意一台目的主机进行互联？这时候就需要一种统一的网络层协议来消除不同网络之间的差异，通过这一层协议控制主机和路由器协同工作实现数据传输，这种协议需要具备两种最重要的能力：</p>\n<ol>\n<li><code>命名机制</code>：每台WAN上的主机都会被分配至少一个互联网络地址，网络层协议通过定义这种一致的主机地址消除了不同的局域网技术之间主机地址格式的差异</li>\n<li><code>传送机制</code>：网络层协议通过定义<code>包（Package）</code>的形式把主机发送的数据打包成不连续的包，再将数据进行传输，消除了不同的联网技术中封装编码位和数据传输帧的方式的差异，一个包的header必须包括包大小，源主机地址以及目标主机地址</li>\n</ol>\n<p>目前运用得最广泛的网络层协议就是IP协议</p>"},{"title":"netty-ByteBuf浅析","author":"天渊","date":"2019-02-12T09:59:00.000Z","_content":"netty使用`ByteBuf`来提代jdk自带的`ByteBuffer`作为nio的数据传输载体，相比于jdk原生实现，功能更加丰富，灵活性更强<!-- more -->，具有以下优点：\n\n- 扩展性好，用户可自定义所需要的缓冲区实现\n- 内置复合缓冲区实现了零拷贝功能\n- 容量按需增长\n- 读数据和写数据有独立的index，互相隔离，互不干扰\n- 支持引用计数和池化\n\n在netty中`ByteBuf`有三种实现：`heapBuffer`，`directBuffer`，`compositeBuffer`，通常情况下使用directBuffer：\n\n1. **heapBuffer**：即将数据存储通过java Byte数组的方式（称为支撑数组）存储在jvm heap中，使用以下方式快速创建一个heapBuffer，但java进行io读写时仍然需要将堆内内存的数据拷贝到堆外并传递给底层的C库:\n\n   ```java\n   ByteBuf buffer = ByteBufAllocator.DEFAULT.heapBuffer();\n   // 可以直接将所需Byte数组拿出来\n   if (buffer.hasArray()) {\n   \tbyte[] bufferArray = buffer.array();\n   \tint offset = buffer.arrayOffset() + buffer.readerIndex();\n   \tint length = buffer.readableBytes();\n       // 通过读指针和可读长度获取所需的数据\n   \tbyte[] neededData = Arrays.copyOfRange(bufferArray, offset, offset + length);\n   }\n   ```\n\n2. **directBuffer**：使用堆外内存存储数据，直接使用堆外内存进行io操作，好处是比`heapBuffer`少一次内存拷贝且在io操作频繁的时候大大降低了gc压力，缺点是需要手动释放内存空间：\n\n   ```java\n   ByteBuf buffer = ByteBufAllocator.DEFAULT.directBuffer();\n   ```\n\n   `directBuffer`没有支撑数组，因此不能直接提取Byte数组，需要通过读写指针取数据\n\n3. **compositeBuffer**：复合buffer，其中可同时包含堆内数据和堆外数据，其实现是`ByteBuf`的子类：`CompositeByteBuf`，通过以下方式组装一个复合buffer，访问复合buffer的方式也类似于`directBuffer`，不能直接访问其支撑数组：\n\n   ```java\n   CompositeByteBuf compBuf = ByteBufAllocator.DEFAULT.compositeBuffer();\n   compBuf.addComponents(buffer, heapBuffer);\n   ```\n\n   复合buffer广泛运用于需要组合多种不同数据源的buffer，在对不同数据源的数据进行整合后提供统一的ByteBuf API供用户使用\n\n\n\n### ByteBuf字节操作\n\n以下操作均以`directBuffer`为例\n\n","source":"_posts/netty-ByteBuf浅析.md","raw":"title: netty-ByteBuf浅析\nauthor: 天渊\ntags:\n  - Netty\n  - Java\ncategories:\n  - 基础知识\ndate: 2019-02-12 17:59:00\n---\nnetty使用`ByteBuf`来提代jdk自带的`ByteBuffer`作为nio的数据传输载体，相比于jdk原生实现，功能更加丰富，灵活性更强<!-- more -->，具有以下优点：\n\n- 扩展性好，用户可自定义所需要的缓冲区实现\n- 内置复合缓冲区实现了零拷贝功能\n- 容量按需增长\n- 读数据和写数据有独立的index，互相隔离，互不干扰\n- 支持引用计数和池化\n\n在netty中`ByteBuf`有三种实现：`heapBuffer`，`directBuffer`，`compositeBuffer`，通常情况下使用directBuffer：\n\n1. **heapBuffer**：即将数据存储通过java Byte数组的方式（称为支撑数组）存储在jvm heap中，使用以下方式快速创建一个heapBuffer，但java进行io读写时仍然需要将堆内内存的数据拷贝到堆外并传递给底层的C库:\n\n   ```java\n   ByteBuf buffer = ByteBufAllocator.DEFAULT.heapBuffer();\n   // 可以直接将所需Byte数组拿出来\n   if (buffer.hasArray()) {\n   \tbyte[] bufferArray = buffer.array();\n   \tint offset = buffer.arrayOffset() + buffer.readerIndex();\n   \tint length = buffer.readableBytes();\n       // 通过读指针和可读长度获取所需的数据\n   \tbyte[] neededData = Arrays.copyOfRange(bufferArray, offset, offset + length);\n   }\n   ```\n\n2. **directBuffer**：使用堆外内存存储数据，直接使用堆外内存进行io操作，好处是比`heapBuffer`少一次内存拷贝且在io操作频繁的时候大大降低了gc压力，缺点是需要手动释放内存空间：\n\n   ```java\n   ByteBuf buffer = ByteBufAllocator.DEFAULT.directBuffer();\n   ```\n\n   `directBuffer`没有支撑数组，因此不能直接提取Byte数组，需要通过读写指针取数据\n\n3. **compositeBuffer**：复合buffer，其中可同时包含堆内数据和堆外数据，其实现是`ByteBuf`的子类：`CompositeByteBuf`，通过以下方式组装一个复合buffer，访问复合buffer的方式也类似于`directBuffer`，不能直接访问其支撑数组：\n\n   ```java\n   CompositeByteBuf compBuf = ByteBufAllocator.DEFAULT.compositeBuffer();\n   compBuf.addComponents(buffer, heapBuffer);\n   ```\n\n   复合buffer广泛运用于需要组合多种不同数据源的buffer，在对不同数据源的数据进行整合后提供统一的ByteBuf API供用户使用\n\n\n\n### ByteBuf字节操作\n\n以下操作均以`directBuffer`为例\n\n","slug":"netty-ByteBuf浅析","published":1,"updated":"2021-05-31T03:06:33.198Z","_id":"ckf0h31i7001nactszwim85fl","comments":1,"layout":"post","photos":[],"link":"","content":"<p>netty使用<code>ByteBuf</code>来提代jdk自带的<code>ByteBuffer</code>作为nio的数据传输载体，相比于jdk原生实现，功能更加丰富，灵活性更强<a id=\"more\"></a>，具有以下优点：</p>\n<ul>\n<li>扩展性好，用户可自定义所需要的缓冲区实现</li>\n<li>内置复合缓冲区实现了零拷贝功能</li>\n<li>容量按需增长</li>\n<li>读数据和写数据有独立的index，互相隔离，互不干扰</li>\n<li>支持引用计数和池化</li>\n</ul>\n<p>在netty中<code>ByteBuf</code>有三种实现：<code>heapBuffer</code>，<code>directBuffer</code>，<code>compositeBuffer</code>，通常情况下使用directBuffer：</p>\n<ol>\n<li><p><strong>heapBuffer</strong>：即将数据存储通过java Byte数组的方式（称为支撑数组）存储在jvm heap中，使用以下方式快速创建一个heapBuffer，但java进行io读写时仍然需要将堆内内存的数据拷贝到堆外并传递给底层的C库:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ByteBuf buffer = ByteBufAllocator.DEFAULT.heapBuffer();</span><br><span class=\"line\"><span class=\"comment\">// 可以直接将所需Byte数组拿出来</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (buffer.hasArray()) &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">byte</span>[] bufferArray = buffer.array();</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> offset = buffer.arrayOffset() + buffer.readerIndex();</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> length = buffer.readableBytes();</span><br><span class=\"line\">    <span class=\"comment\">// 通过读指针和可读长度获取所需的数据</span></span><br><span class=\"line\">\t<span class=\"keyword\">byte</span>[] neededData = Arrays.copyOfRange(bufferArray, offset, offset + length);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>directBuffer</strong>：使用堆外内存存储数据，直接使用堆外内存进行io操作，好处是比<code>heapBuffer</code>少一次内存拷贝且在io操作频繁的时候大大降低了gc压力，缺点是需要手动释放内存空间：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ByteBuf buffer = ByteBufAllocator.DEFAULT.directBuffer();</span><br></pre></td></tr></table></figure>\n<p><code>directBuffer</code>没有支撑数组，因此不能直接提取Byte数组，需要通过读写指针取数据</p>\n</li>\n<li><p><strong>compositeBuffer</strong>：复合buffer，其中可同时包含堆内数据和堆外数据，其实现是<code>ByteBuf</code>的子类：<code>CompositeByteBuf</code>，通过以下方式组装一个复合buffer，访问复合buffer的方式也类似于<code>directBuffer</code>，不能直接访问其支撑数组：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CompositeByteBuf compBuf = ByteBufAllocator.DEFAULT.compositeBuffer();</span><br><span class=\"line\">compBuf.addComponents(buffer, heapBuffer);</span><br></pre></td></tr></table></figure>\n<p>复合buffer广泛运用于需要组合多种不同数据源的buffer，在对不同数据源的数据进行整合后提供统一的ByteBuf API供用户使用</p>\n</li>\n</ol>\n<h3 id=\"ByteBuf字节操作\"><a href=\"#ByteBuf字节操作\" class=\"headerlink\" title=\"ByteBuf字节操作\"></a>ByteBuf字节操作</h3><p>以下操作均以<code>directBuffer</code>为例</p>\n","site":{"data":{}},"excerpt":"<p>netty使用<code>ByteBuf</code>来提代jdk自带的<code>ByteBuffer</code>作为nio的数据传输载体，相比于jdk原生实现，功能更加丰富，灵活性更强","more":"，具有以下优点：</p>\n<ul>\n<li>扩展性好，用户可自定义所需要的缓冲区实现</li>\n<li>内置复合缓冲区实现了零拷贝功能</li>\n<li>容量按需增长</li>\n<li>读数据和写数据有独立的index，互相隔离，互不干扰</li>\n<li>支持引用计数和池化</li>\n</ul>\n<p>在netty中<code>ByteBuf</code>有三种实现：<code>heapBuffer</code>，<code>directBuffer</code>，<code>compositeBuffer</code>，通常情况下使用directBuffer：</p>\n<ol>\n<li><p><strong>heapBuffer</strong>：即将数据存储通过java Byte数组的方式（称为支撑数组）存储在jvm heap中，使用以下方式快速创建一个heapBuffer，但java进行io读写时仍然需要将堆内内存的数据拷贝到堆外并传递给底层的C库:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ByteBuf buffer = ByteBufAllocator.DEFAULT.heapBuffer();</span><br><span class=\"line\"><span class=\"comment\">// 可以直接将所需Byte数组拿出来</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (buffer.hasArray()) &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">byte</span>[] bufferArray = buffer.array();</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> offset = buffer.arrayOffset() + buffer.readerIndex();</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> length = buffer.readableBytes();</span><br><span class=\"line\">    <span class=\"comment\">// 通过读指针和可读长度获取所需的数据</span></span><br><span class=\"line\">\t<span class=\"keyword\">byte</span>[] neededData = Arrays.copyOfRange(bufferArray, offset, offset + length);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>directBuffer</strong>：使用堆外内存存储数据，直接使用堆外内存进行io操作，好处是比<code>heapBuffer</code>少一次内存拷贝且在io操作频繁的时候大大降低了gc压力，缺点是需要手动释放内存空间：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ByteBuf buffer = ByteBufAllocator.DEFAULT.directBuffer();</span><br></pre></td></tr></table></figure>\n<p><code>directBuffer</code>没有支撑数组，因此不能直接提取Byte数组，需要通过读写指针取数据</p>\n</li>\n<li><p><strong>compositeBuffer</strong>：复合buffer，其中可同时包含堆内数据和堆外数据，其实现是<code>ByteBuf</code>的子类：<code>CompositeByteBuf</code>，通过以下方式组装一个复合buffer，访问复合buffer的方式也类似于<code>directBuffer</code>，不能直接访问其支撑数组：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CompositeByteBuf compBuf = ByteBufAllocator.DEFAULT.compositeBuffer();</span><br><span class=\"line\">compBuf.addComponents(buffer, heapBuffer);</span><br></pre></td></tr></table></figure>\n<p>复合buffer广泛运用于需要组合多种不同数据源的buffer，在对不同数据源的数据进行整合后提供统一的ByteBuf API供用户使用</p>\n</li>\n</ol>\n<h3 id=\"ByteBuf字节操作\"><a href=\"#ByteBuf字节操作\" class=\"headerlink\" title=\"ByteBuf字节操作\"></a>ByteBuf字节操作</h3><p>以下操作均以<code>directBuffer</code>为例</p>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 10","author":"天渊","date":"2019-12-03T07:11:00.000Z","_content":"I/O是计算机系统中不可或缺的一部分，本章将了解I/O和其他系统之间的依赖和交互关系，以及通过C程序调用内核提供的I/O函数来实现一些通用的I/O功能，重点介绍了Unix I/O的一些概念和使用\n<!--more-->\n\n### Unix I/O和文件系统\n\n在类Unix系统中，I/O设备都被定义为文件，输入和输出都是对该文件的读操作和写操作，所有的文件操作都抽象出了一个通用的应用接口即`Unix I/O`\n\n**文件描述符（File Descriptor）**：一个进程打开一个文件时，内核都会给它返回一个非负整数即文件描述符，后续该进程对这个文件的所有操作都基于这个描述符，每个进程默认都有三个打开的文件即`标准输入`，`标准输出`和`标准错误`，对应的描述符分别为1，2和3\n\n**文件类型**：每个Linux文件都有一个`类型（type）`来定义该文件在系统中的角色，常用的文件类型有三种：`普通文件`，`目录`和`套接字（Socket）`，每个文件在Linux文件树中都有自己对应的位置\n\n#### 对文件的操作\n\n##### 打开/关闭文件\n\n使用`open`函数打开文件，内核会返回一个文件描述符，还可以指定对该文件的操作权限\n\n使用`close`传入对应的描述符关闭该文件\n\n##### 读写文件\n\n通过`read`函数从文件中读取n个字节到指定的buffer内存位置中，该函数返回当前读取的字节数，返回0代表当前操作触发了EOF，返回-1则表示错误\n\n通过`write`函数将指定buffer内存位置中的n个字节写入到指定文件中\n\n##### 读取文件元数据\n\n通过`fstat`函数来将某个文件的元数据读入到一个`stat`结构体中：\n\n```c\nstruct stat status;\nfstat(fd, &status);\nif (S_ISREG(status.st_mode)) {\n    printf(\"the type is regular\");\n    printf(\", and st_size is %ld\", status.st_size);\n} else if (S_ISDIR(status.st_mode)) {\n    printf(\"the type is dir\");\n} else {\n    printf(\"the type is other\");\n}\n```\n\n这个`stat`结构体包含了一个文件所能拥有的所有状态，包括文件类型，所属inode节点和设备，以及所属的user和group，以及文件大小和创建时间等\n\n##### 读取目录文件\n\n通过`opendir`函数打开一个目录，该函数返回一个指针类型`DIR`，再调用`readdir`函数对这个`DIR`指针进行遍历，可返回一个结构体指针`dirent`，该结构体包含了该目录项的名称，inode号以及名称长度：\n\n```c\nDIR *dir = opendir(\"D:\\\\code learning\\\\csapp-chapter11-code\");\nstruct dirent *dire;\nwhile ((dire = readdir(dir)) != NULL) {\n    printf(\"found file: %s\\n\", dire->d_name);\n}\nclosedir(dir);\n```\n\n它将`csapp-chapter11-code`目录下的所有文件以及目录项打印了出来（不过没有进行递归遍历）\n\n#### 共享文件\n\n操作系统内核使用以下三个概念来管理一个进程打开的文件：\n\n`描述符表（descriptor table）`：每个进程打开的文件所对应的文件描述符表，表中每一项都指向了下述文件表中的某一项\n\n`文件表（file table）`：所有进程共享这张文件表，该表中的每一项包含该文件位置（即读写指针），引用计数（被上述某个进程的描述符表项引用一次就加1，如果引用计数为0，该项就被会删除），还有一个指向下述v-node表中的某一项\n\n`v-node表`：所有进程共享该表，表中每一项都包含了对应文件的`stat`结构体中的大部分信息，例如`st_mode`信息和`st_size`信息\n\n上述三张表对应关系如下：\n\n![](http://img.mantian.site/201912031128_991.png)\n\n需要注意的是，每个描述符表项与文件表项**一一对应**，如果某个文件被打开了两次，生成了2个描述符，那就有两个文件表项，但这两个文件表项都指向了v-node表中的统一项\n\n**父子进程打开文件的情况**：父进程调用fork生成子进程后，子进程拥有和父进程描述符表相同的一份副本，其中每一个描述符项都与父进行指向同一个文件表项\n\n每一个文件表项都拥有自己的文件位置，因此两个进程持有相同的文件描述符，其对该文件的读写操作都会对对方造成影响，而如果持有相同文件的不同文件描述符，相互之间的文件位置，也就是读写操作就是独立的\n\n#### I/O重定向\n\n在Linux系统中，通常在执行一个命令式，需要将输出结果由标准输出流转移到某个文件中，这时候就需要使用`I/O重定向`，一般是使用`>`符号：\n\n在系统层面，调用`dup2`函数使某一个文件的I/O流重定向到其他的文件中去：\n\n```c\nint fd1 = open(\"D:\\\\code learning\\\\csapp-chapter11-code\\\\test.txt\", O_RDWR, S_IRUSR);\nint fd2 = open(\"D:\\\\code learning\\\\csapp-chapter11-code\\\\test2.txt\", O_RDWR, S_IRUSR);\nchar c;\nread(fd2, &c, 1);\ndup2(fd2, fd1);\nread(fd1, &c, 1);\nprintf(\"c=%c\", c);\n```\n\n如上所示，一开始fd1和fd2是不同的文件描述符，对应不同的文件表项，首先从fd2中读一个字符，随后将fd1重定向到fd2，此时再读fd1，读出来的就已经是fd2对应的文件信息了，fd1此时指向的文件表项也跟fd2相同，此时对fd1的任何操作都与fd2完全一致\n\n如下图：\n\n![](http://img.mantian.site/201912031414_946.png)\n\n上面是调用了`dup2(fd4, fd1)`的结果，将fd1重定向到fd4，重定向完成后fd1原来的文件表项引用计数变为0，被系统回收，相应的v-node项也被删掉，此时fd1和fd4都指向了同一个文件表项B，引用计数变为2\n\n#### 标准I/O库\n\n像`open`和`read`这些函数都是低级别I/O函数，C语言还额外封装了一组高级别的I/O函数称为`标准I/O库`，包括针对文件读写的`fread`和`fwrite`函数，读写字符串的`fgets`和`fputs`函数，以及常见针对标准输入输出流的`scanf`和`printf`函数\n\n##### 该如何选择I/O库\n\n除了读取元数据使用的`stat`函数外，其他情况下都建议使用标准I/O库，不使用低级别的I/O库\n\n\n\n\n\n\n\n\n\n","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-10.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 10\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-12-03 15:11:00\n---\nI/O是计算机系统中不可或缺的一部分，本章将了解I/O和其他系统之间的依赖和交互关系，以及通过C程序调用内核提供的I/O函数来实现一些通用的I/O功能，重点介绍了Unix I/O的一些概念和使用\n<!--more-->\n\n### Unix I/O和文件系统\n\n在类Unix系统中，I/O设备都被定义为文件，输入和输出都是对该文件的读操作和写操作，所有的文件操作都抽象出了一个通用的应用接口即`Unix I/O`\n\n**文件描述符（File Descriptor）**：一个进程打开一个文件时，内核都会给它返回一个非负整数即文件描述符，后续该进程对这个文件的所有操作都基于这个描述符，每个进程默认都有三个打开的文件即`标准输入`，`标准输出`和`标准错误`，对应的描述符分别为1，2和3\n\n**文件类型**：每个Linux文件都有一个`类型（type）`来定义该文件在系统中的角色，常用的文件类型有三种：`普通文件`，`目录`和`套接字（Socket）`，每个文件在Linux文件树中都有自己对应的位置\n\n#### 对文件的操作\n\n##### 打开/关闭文件\n\n使用`open`函数打开文件，内核会返回一个文件描述符，还可以指定对该文件的操作权限\n\n使用`close`传入对应的描述符关闭该文件\n\n##### 读写文件\n\n通过`read`函数从文件中读取n个字节到指定的buffer内存位置中，该函数返回当前读取的字节数，返回0代表当前操作触发了EOF，返回-1则表示错误\n\n通过`write`函数将指定buffer内存位置中的n个字节写入到指定文件中\n\n##### 读取文件元数据\n\n通过`fstat`函数来将某个文件的元数据读入到一个`stat`结构体中：\n\n```c\nstruct stat status;\nfstat(fd, &status);\nif (S_ISREG(status.st_mode)) {\n    printf(\"the type is regular\");\n    printf(\", and st_size is %ld\", status.st_size);\n} else if (S_ISDIR(status.st_mode)) {\n    printf(\"the type is dir\");\n} else {\n    printf(\"the type is other\");\n}\n```\n\n这个`stat`结构体包含了一个文件所能拥有的所有状态，包括文件类型，所属inode节点和设备，以及所属的user和group，以及文件大小和创建时间等\n\n##### 读取目录文件\n\n通过`opendir`函数打开一个目录，该函数返回一个指针类型`DIR`，再调用`readdir`函数对这个`DIR`指针进行遍历，可返回一个结构体指针`dirent`，该结构体包含了该目录项的名称，inode号以及名称长度：\n\n```c\nDIR *dir = opendir(\"D:\\\\code learning\\\\csapp-chapter11-code\");\nstruct dirent *dire;\nwhile ((dire = readdir(dir)) != NULL) {\n    printf(\"found file: %s\\n\", dire->d_name);\n}\nclosedir(dir);\n```\n\n它将`csapp-chapter11-code`目录下的所有文件以及目录项打印了出来（不过没有进行递归遍历）\n\n#### 共享文件\n\n操作系统内核使用以下三个概念来管理一个进程打开的文件：\n\n`描述符表（descriptor table）`：每个进程打开的文件所对应的文件描述符表，表中每一项都指向了下述文件表中的某一项\n\n`文件表（file table）`：所有进程共享这张文件表，该表中的每一项包含该文件位置（即读写指针），引用计数（被上述某个进程的描述符表项引用一次就加1，如果引用计数为0，该项就被会删除），还有一个指向下述v-node表中的某一项\n\n`v-node表`：所有进程共享该表，表中每一项都包含了对应文件的`stat`结构体中的大部分信息，例如`st_mode`信息和`st_size`信息\n\n上述三张表对应关系如下：\n\n![](http://img.mantian.site/201912031128_991.png)\n\n需要注意的是，每个描述符表项与文件表项**一一对应**，如果某个文件被打开了两次，生成了2个描述符，那就有两个文件表项，但这两个文件表项都指向了v-node表中的统一项\n\n**父子进程打开文件的情况**：父进程调用fork生成子进程后，子进程拥有和父进程描述符表相同的一份副本，其中每一个描述符项都与父进行指向同一个文件表项\n\n每一个文件表项都拥有自己的文件位置，因此两个进程持有相同的文件描述符，其对该文件的读写操作都会对对方造成影响，而如果持有相同文件的不同文件描述符，相互之间的文件位置，也就是读写操作就是独立的\n\n#### I/O重定向\n\n在Linux系统中，通常在执行一个命令式，需要将输出结果由标准输出流转移到某个文件中，这时候就需要使用`I/O重定向`，一般是使用`>`符号：\n\n在系统层面，调用`dup2`函数使某一个文件的I/O流重定向到其他的文件中去：\n\n```c\nint fd1 = open(\"D:\\\\code learning\\\\csapp-chapter11-code\\\\test.txt\", O_RDWR, S_IRUSR);\nint fd2 = open(\"D:\\\\code learning\\\\csapp-chapter11-code\\\\test2.txt\", O_RDWR, S_IRUSR);\nchar c;\nread(fd2, &c, 1);\ndup2(fd2, fd1);\nread(fd1, &c, 1);\nprintf(\"c=%c\", c);\n```\n\n如上所示，一开始fd1和fd2是不同的文件描述符，对应不同的文件表项，首先从fd2中读一个字符，随后将fd1重定向到fd2，此时再读fd1，读出来的就已经是fd2对应的文件信息了，fd1此时指向的文件表项也跟fd2相同，此时对fd1的任何操作都与fd2完全一致\n\n如下图：\n\n![](http://img.mantian.site/201912031414_946.png)\n\n上面是调用了`dup2(fd4, fd1)`的结果，将fd1重定向到fd4，重定向完成后fd1原来的文件表项引用计数变为0，被系统回收，相应的v-node项也被删掉，此时fd1和fd4都指向了同一个文件表项B，引用计数变为2\n\n#### 标准I/O库\n\n像`open`和`read`这些函数都是低级别I/O函数，C语言还额外封装了一组高级别的I/O函数称为`标准I/O库`，包括针对文件读写的`fread`和`fwrite`函数，读写字符串的`fgets`和`fputs`函数，以及常见针对标准输入输出流的`scanf`和`printf`函数\n\n##### 该如何选择I/O库\n\n除了读取元数据使用的`stat`函数外，其他情况下都建议使用标准I/O库，不使用低级别的I/O库\n\n\n\n\n\n\n\n\n\n","slug":"《深入理解计算机系统》读书笔记——Chapter-10","published":1,"updated":"2021-05-31T03:06:33.199Z","_id":"ckf0h31ia001ractstfu7y476","comments":1,"layout":"post","photos":[],"link":"","content":"<p>I/O是计算机系统中不可或缺的一部分，本章将了解I/O和其他系统之间的依赖和交互关系，以及通过C程序调用内核提供的I/O函数来实现一些通用的I/O功能，重点介绍了Unix I/O的一些概念和使用<br><a id=\"more\"></a></p>\n<h3 id=\"Unix-I-O和文件系统\"><a href=\"#Unix-I-O和文件系统\" class=\"headerlink\" title=\"Unix I/O和文件系统\"></a>Unix I/O和文件系统</h3><p>在类Unix系统中，I/O设备都被定义为文件，输入和输出都是对该文件的读操作和写操作，所有的文件操作都抽象出了一个通用的应用接口即<code>Unix I/O</code></p>\n<p><strong>文件描述符（File Descriptor）</strong>：一个进程打开一个文件时，内核都会给它返回一个非负整数即文件描述符，后续该进程对这个文件的所有操作都基于这个描述符，每个进程默认都有三个打开的文件即<code>标准输入</code>，<code>标准输出</code>和<code>标准错误</code>，对应的描述符分别为1，2和3</p>\n<p><strong>文件类型</strong>：每个Linux文件都有一个<code>类型（type）</code>来定义该文件在系统中的角色，常用的文件类型有三种：<code>普通文件</code>，<code>目录</code>和<code>套接字（Socket）</code>，每个文件在Linux文件树中都有自己对应的位置</p>\n<h4 id=\"对文件的操作\"><a href=\"#对文件的操作\" class=\"headerlink\" title=\"对文件的操作\"></a>对文件的操作</h4><h5 id=\"打开-关闭文件\"><a href=\"#打开-关闭文件\" class=\"headerlink\" title=\"打开/关闭文件\"></a>打开/关闭文件</h5><p>使用<code>open</code>函数打开文件，内核会返回一个文件描述符，还可以指定对该文件的操作权限</p>\n<p>使用<code>close</code>传入对应的描述符关闭该文件</p>\n<h5 id=\"读写文件\"><a href=\"#读写文件\" class=\"headerlink\" title=\"读写文件\"></a>读写文件</h5><p>通过<code>read</code>函数从文件中读取n个字节到指定的buffer内存位置中，该函数返回当前读取的字节数，返回0代表当前操作触发了EOF，返回-1则表示错误</p>\n<p>通过<code>write</code>函数将指定buffer内存位置中的n个字节写入到指定文件中</p>\n<h5 id=\"读取文件元数据\"><a href=\"#读取文件元数据\" class=\"headerlink\" title=\"读取文件元数据\"></a>读取文件元数据</h5><p>通过<code>fstat</code>函数来将某个文件的元数据读入到一个<code>stat</code>结构体中：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">stat</span> <span class=\"title\">status</span>;</span></span><br><span class=\"line\">fstat(fd, &amp;status);</span><br><span class=\"line\"><span class=\"keyword\">if</span> (S_ISREG(status.st_mode)) &#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"the type is regular\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\", and st_size is %ld\"</span>, status.st_size);</span><br><span class=\"line\">&#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (S_ISDIR(status.st_mode)) &#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"the type is dir\"</span>);</span><br><span class=\"line\">&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"the type is other\"</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这个<code>stat</code>结构体包含了一个文件所能拥有的所有状态，包括文件类型，所属inode节点和设备，以及所属的user和group，以及文件大小和创建时间等</p>\n<h5 id=\"读取目录文件\"><a href=\"#读取目录文件\" class=\"headerlink\" title=\"读取目录文件\"></a>读取目录文件</h5><p>通过<code>opendir</code>函数打开一个目录，该函数返回一个指针类型<code>DIR</code>，再调用<code>readdir</code>函数对这个<code>DIR</code>指针进行遍历，可返回一个结构体指针<code>dirent</code>，该结构体包含了该目录项的名称，inode号以及名称长度：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DIR *dir = opendir(<span class=\"string\">\"D:\\\\code learning\\\\csapp-chapter11-code\"</span>);</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">dirent</span> *<span class=\"title\">dire</span>;</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> ((dire = readdir(dir)) != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"found file: %s\\n\"</span>, dire-&gt;d_name);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">closedir(dir);</span><br></pre></td></tr></table></figure>\n<p>它将<code>csapp-chapter11-code</code>目录下的所有文件以及目录项打印了出来（不过没有进行递归遍历）</p>\n<h4 id=\"共享文件\"><a href=\"#共享文件\" class=\"headerlink\" title=\"共享文件\"></a>共享文件</h4><p>操作系统内核使用以下三个概念来管理一个进程打开的文件：</p>\n<p><code>描述符表（descriptor table）</code>：每个进程打开的文件所对应的文件描述符表，表中每一项都指向了下述文件表中的某一项</p>\n<p><code>文件表（file table）</code>：所有进程共享这张文件表，该表中的每一项包含该文件位置（即读写指针），引用计数（被上述某个进程的描述符表项引用一次就加1，如果引用计数为0，该项就被会删除），还有一个指向下述v-node表中的某一项</p>\n<p><code>v-node表</code>：所有进程共享该表，表中每一项都包含了对应文件的<code>stat</code>结构体中的大部分信息，例如<code>st_mode</code>信息和<code>st_size</code>信息</p>\n<p>上述三张表对应关系如下：</p>\n<p><img src=\"http://img.mantian.site/201912031128_991.png\" alt></p>\n<p>需要注意的是，每个描述符表项与文件表项<strong>一一对应</strong>，如果某个文件被打开了两次，生成了2个描述符，那就有两个文件表项，但这两个文件表项都指向了v-node表中的统一项</p>\n<p><strong>父子进程打开文件的情况</strong>：父进程调用fork生成子进程后，子进程拥有和父进程描述符表相同的一份副本，其中每一个描述符项都与父进行指向同一个文件表项</p>\n<p>每一个文件表项都拥有自己的文件位置，因此两个进程持有相同的文件描述符，其对该文件的读写操作都会对对方造成影响，而如果持有相同文件的不同文件描述符，相互之间的文件位置，也就是读写操作就是独立的</p>\n<h4 id=\"I-O重定向\"><a href=\"#I-O重定向\" class=\"headerlink\" title=\"I/O重定向\"></a>I/O重定向</h4><p>在Linux系统中，通常在执行一个命令式，需要将输出结果由标准输出流转移到某个文件中，这时候就需要使用<code>I/O重定向</code>，一般是使用<code>&gt;</code>符号：</p>\n<p>在系统层面，调用<code>dup2</code>函数使某一个文件的I/O流重定向到其他的文件中去：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> fd1 = open(<span class=\"string\">\"D:\\\\code learning\\\\csapp-chapter11-code\\\\test.txt\"</span>, O_RDWR, S_IRUSR);</span><br><span class=\"line\"><span class=\"keyword\">int</span> fd2 = open(<span class=\"string\">\"D:\\\\code learning\\\\csapp-chapter11-code\\\\test2.txt\"</span>, O_RDWR, S_IRUSR);</span><br><span class=\"line\"><span class=\"keyword\">char</span> c;</span><br><span class=\"line\">read(fd2, &amp;c, <span class=\"number\">1</span>);</span><br><span class=\"line\">dup2(fd2, fd1);</span><br><span class=\"line\">read(fd1, &amp;c, <span class=\"number\">1</span>);</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"c=%c\"</span>, c);</span><br></pre></td></tr></table></figure>\n<p>如上所示，一开始fd1和fd2是不同的文件描述符，对应不同的文件表项，首先从fd2中读一个字符，随后将fd1重定向到fd2，此时再读fd1，读出来的就已经是fd2对应的文件信息了，fd1此时指向的文件表项也跟fd2相同，此时对fd1的任何操作都与fd2完全一致</p>\n<p>如下图：</p>\n<p><img src=\"http://img.mantian.site/201912031414_946.png\" alt></p>\n<p>上面是调用了<code>dup2(fd4, fd1)</code>的结果，将fd1重定向到fd4，重定向完成后fd1原来的文件表项引用计数变为0，被系统回收，相应的v-node项也被删掉，此时fd1和fd4都指向了同一个文件表项B，引用计数变为2</p>\n<h4 id=\"标准I-O库\"><a href=\"#标准I-O库\" class=\"headerlink\" title=\"标准I/O库\"></a>标准I/O库</h4><p>像<code>open</code>和<code>read</code>这些函数都是低级别I/O函数，C语言还额外封装了一组高级别的I/O函数称为<code>标准I/O库</code>，包括针对文件读写的<code>fread</code>和<code>fwrite</code>函数，读写字符串的<code>fgets</code>和<code>fputs</code>函数，以及常见针对标准输入输出流的<code>scanf</code>和<code>printf</code>函数</p>\n<h5 id=\"该如何选择I-O库\"><a href=\"#该如何选择I-O库\" class=\"headerlink\" title=\"该如何选择I/O库\"></a>该如何选择I/O库</h5><p>除了读取元数据使用的<code>stat</code>函数外，其他情况下都建议使用标准I/O库，不使用低级别的I/O库</p>\n","site":{"data":{}},"excerpt":"<p>I/O是计算机系统中不可或缺的一部分，本章将了解I/O和其他系统之间的依赖和交互关系，以及通过C程序调用内核提供的I/O函数来实现一些通用的I/O功能，重点介绍了Unix I/O的一些概念和使用<br>","more":"</p>\n<h3 id=\"Unix-I-O和文件系统\"><a href=\"#Unix-I-O和文件系统\" class=\"headerlink\" title=\"Unix I/O和文件系统\"></a>Unix I/O和文件系统</h3><p>在类Unix系统中，I/O设备都被定义为文件，输入和输出都是对该文件的读操作和写操作，所有的文件操作都抽象出了一个通用的应用接口即<code>Unix I/O</code></p>\n<p><strong>文件描述符（File Descriptor）</strong>：一个进程打开一个文件时，内核都会给它返回一个非负整数即文件描述符，后续该进程对这个文件的所有操作都基于这个描述符，每个进程默认都有三个打开的文件即<code>标准输入</code>，<code>标准输出</code>和<code>标准错误</code>，对应的描述符分别为1，2和3</p>\n<p><strong>文件类型</strong>：每个Linux文件都有一个<code>类型（type）</code>来定义该文件在系统中的角色，常用的文件类型有三种：<code>普通文件</code>，<code>目录</code>和<code>套接字（Socket）</code>，每个文件在Linux文件树中都有自己对应的位置</p>\n<h4 id=\"对文件的操作\"><a href=\"#对文件的操作\" class=\"headerlink\" title=\"对文件的操作\"></a>对文件的操作</h4><h5 id=\"打开-关闭文件\"><a href=\"#打开-关闭文件\" class=\"headerlink\" title=\"打开/关闭文件\"></a>打开/关闭文件</h5><p>使用<code>open</code>函数打开文件，内核会返回一个文件描述符，还可以指定对该文件的操作权限</p>\n<p>使用<code>close</code>传入对应的描述符关闭该文件</p>\n<h5 id=\"读写文件\"><a href=\"#读写文件\" class=\"headerlink\" title=\"读写文件\"></a>读写文件</h5><p>通过<code>read</code>函数从文件中读取n个字节到指定的buffer内存位置中，该函数返回当前读取的字节数，返回0代表当前操作触发了EOF，返回-1则表示错误</p>\n<p>通过<code>write</code>函数将指定buffer内存位置中的n个字节写入到指定文件中</p>\n<h5 id=\"读取文件元数据\"><a href=\"#读取文件元数据\" class=\"headerlink\" title=\"读取文件元数据\"></a>读取文件元数据</h5><p>通过<code>fstat</code>函数来将某个文件的元数据读入到一个<code>stat</code>结构体中：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">stat</span> <span class=\"title\">status</span>;</span></span><br><span class=\"line\">fstat(fd, &amp;status);</span><br><span class=\"line\"><span class=\"keyword\">if</span> (S_ISREG(status.st_mode)) &#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"the type is regular\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\", and st_size is %ld\"</span>, status.st_size);</span><br><span class=\"line\">&#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (S_ISDIR(status.st_mode)) &#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"the type is dir\"</span>);</span><br><span class=\"line\">&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"the type is other\"</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这个<code>stat</code>结构体包含了一个文件所能拥有的所有状态，包括文件类型，所属inode节点和设备，以及所属的user和group，以及文件大小和创建时间等</p>\n<h5 id=\"读取目录文件\"><a href=\"#读取目录文件\" class=\"headerlink\" title=\"读取目录文件\"></a>读取目录文件</h5><p>通过<code>opendir</code>函数打开一个目录，该函数返回一个指针类型<code>DIR</code>，再调用<code>readdir</code>函数对这个<code>DIR</code>指针进行遍历，可返回一个结构体指针<code>dirent</code>，该结构体包含了该目录项的名称，inode号以及名称长度：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DIR *dir = opendir(<span class=\"string\">\"D:\\\\code learning\\\\csapp-chapter11-code\"</span>);</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">dirent</span> *<span class=\"title\">dire</span>;</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> ((dire = readdir(dir)) != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"found file: %s\\n\"</span>, dire-&gt;d_name);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">closedir(dir);</span><br></pre></td></tr></table></figure>\n<p>它将<code>csapp-chapter11-code</code>目录下的所有文件以及目录项打印了出来（不过没有进行递归遍历）</p>\n<h4 id=\"共享文件\"><a href=\"#共享文件\" class=\"headerlink\" title=\"共享文件\"></a>共享文件</h4><p>操作系统内核使用以下三个概念来管理一个进程打开的文件：</p>\n<p><code>描述符表（descriptor table）</code>：每个进程打开的文件所对应的文件描述符表，表中每一项都指向了下述文件表中的某一项</p>\n<p><code>文件表（file table）</code>：所有进程共享这张文件表，该表中的每一项包含该文件位置（即读写指针），引用计数（被上述某个进程的描述符表项引用一次就加1，如果引用计数为0，该项就被会删除），还有一个指向下述v-node表中的某一项</p>\n<p><code>v-node表</code>：所有进程共享该表，表中每一项都包含了对应文件的<code>stat</code>结构体中的大部分信息，例如<code>st_mode</code>信息和<code>st_size</code>信息</p>\n<p>上述三张表对应关系如下：</p>\n<p><img src=\"http://img.mantian.site/201912031128_991.png\" alt></p>\n<p>需要注意的是，每个描述符表项与文件表项<strong>一一对应</strong>，如果某个文件被打开了两次，生成了2个描述符，那就有两个文件表项，但这两个文件表项都指向了v-node表中的统一项</p>\n<p><strong>父子进程打开文件的情况</strong>：父进程调用fork生成子进程后，子进程拥有和父进程描述符表相同的一份副本，其中每一个描述符项都与父进行指向同一个文件表项</p>\n<p>每一个文件表项都拥有自己的文件位置，因此两个进程持有相同的文件描述符，其对该文件的读写操作都会对对方造成影响，而如果持有相同文件的不同文件描述符，相互之间的文件位置，也就是读写操作就是独立的</p>\n<h4 id=\"I-O重定向\"><a href=\"#I-O重定向\" class=\"headerlink\" title=\"I/O重定向\"></a>I/O重定向</h4><p>在Linux系统中，通常在执行一个命令式，需要将输出结果由标准输出流转移到某个文件中，这时候就需要使用<code>I/O重定向</code>，一般是使用<code>&gt;</code>符号：</p>\n<p>在系统层面，调用<code>dup2</code>函数使某一个文件的I/O流重定向到其他的文件中去：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> fd1 = open(<span class=\"string\">\"D:\\\\code learning\\\\csapp-chapter11-code\\\\test.txt\"</span>, O_RDWR, S_IRUSR);</span><br><span class=\"line\"><span class=\"keyword\">int</span> fd2 = open(<span class=\"string\">\"D:\\\\code learning\\\\csapp-chapter11-code\\\\test2.txt\"</span>, O_RDWR, S_IRUSR);</span><br><span class=\"line\"><span class=\"keyword\">char</span> c;</span><br><span class=\"line\">read(fd2, &amp;c, <span class=\"number\">1</span>);</span><br><span class=\"line\">dup2(fd2, fd1);</span><br><span class=\"line\">read(fd1, &amp;c, <span class=\"number\">1</span>);</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"c=%c\"</span>, c);</span><br></pre></td></tr></table></figure>\n<p>如上所示，一开始fd1和fd2是不同的文件描述符，对应不同的文件表项，首先从fd2中读一个字符，随后将fd1重定向到fd2，此时再读fd1，读出来的就已经是fd2对应的文件信息了，fd1此时指向的文件表项也跟fd2相同，此时对fd1的任何操作都与fd2完全一致</p>\n<p>如下图：</p>\n<p><img src=\"http://img.mantian.site/201912031414_946.png\" alt></p>\n<p>上面是调用了<code>dup2(fd4, fd1)</code>的结果，将fd1重定向到fd4，重定向完成后fd1原来的文件表项引用计数变为0，被系统回收，相应的v-node项也被删掉，此时fd1和fd4都指向了同一个文件表项B，引用计数变为2</p>\n<h4 id=\"标准I-O库\"><a href=\"#标准I-O库\" class=\"headerlink\" title=\"标准I/O库\"></a>标准I/O库</h4><p>像<code>open</code>和<code>read</code>这些函数都是低级别I/O函数，C语言还额外封装了一组高级别的I/O函数称为<code>标准I/O库</code>，包括针对文件读写的<code>fread</code>和<code>fwrite</code>函数，读写字符串的<code>fgets</code>和<code>fputs</code>函数，以及常见针对标准输入输出流的<code>scanf</code>和<code>printf</code>函数</p>\n<h5 id=\"该如何选择I-O库\"><a href=\"#该如何选择I-O库\" class=\"headerlink\" title=\"该如何选择I/O库\"></a>该如何选择I/O库</h5><p>除了读取元数据使用的<code>stat</code>函数外，其他情况下都建议使用标准I/O库，不使用低级别的I/O库</p>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 11(2)","author":"天渊","date":"2019-12-11T07:13:00.000Z","_content":"\n### IP协议 & 全球IP因特网\n<!--more-->\n一个典型的因特网架构模型就是如下图所示：\n\n![](http://img.mantian.site/201912101106_404.png)\n\n因特网上的每台主机都运行着实现了TCP/IP协议族的软件，这些软件在很多计算机中都是以`套接字接口（Socket）`和各种I/O函数（例如Unix I/O）暴露给用户进行使用\n\n**IP协议**：IP协议（Internet Protocol）实现了通用的基本的网络包传送机制，这种网络传输包也叫`数据报（datagram）`，IP层的协议就负责将数据报从一台主机传送给另一台主机，但是IP层的传输是不可靠的，数据发送出去后并不会管对方主机是否收到或者是否在传输过程中丢失或者出错\n\n**UDP协议**：UDP协议（Unreliable Datagram Protocol），不可靠的数据报协议，从名字上就可以看出，UDP协议在传输可靠性方面与IP协议并没有区别，只不过在IP层上再封装了一层，可以实现基于套接字的进程之间数据传输\n\n**TCP协议**：TCP协议（Transmission Control Protocol），传输控制协议是，顾名思义该协议在IP协议的基础上实现了可靠进程间全双工的连接和传输\n\n以下内容是对IP协议的一些细节进行的讲解\n\n#### IP地址\n\nIP地址（传统的IPv4地址）是一个32位无符号整数，通常用点分十进制来表示，每个点将一个IP地址分割为4个字节\n\n使用`hostname -i`命令查看Linux环境下主机ip：\n\n```shell\n[root@localhost ~]$ hostname -i\n10.250.140.27\n```\n\n#### 域名\n\n使用IP地址标记主机地址的方式不太容易让人记住，因此推出了`域名（domain name）`，将ip地址和域名进行映射便于寻址，该映射关系可以保存在主机本地的`hosts`文件，但目前运用最广泛的还是遍布世界的`DNS服务（Domain Name Service）`来进行管理，DNS服务由成百上千万的`主机条目结构（Host Entry Structure）`组成，每一个条目定义了一组从域名到IP地址的映射\n\nLinux环境下可以通过`nslookup`命令来查看一个域名和IP地址之间的映射关系\n\n#### 网络连接 & 套接字接口\n\n在OSI七层模型中，传输层的TCP协议是基于连接的，通过点对点的方式，两台主机进行全双工的通信，是一种可靠传输协议，TCP连接的两个端点就是`套接字Socket`，相应的套接字地址就是`address:port`的形式\n\n##### 套接字接口\n\n`套接字接口（Socket Interface）`是一组函数，是对底层网络协议的封装，现代操作系统上大多都实现了套接字接口，下图描绘了如何用套接字接口提供的函数来进行网络连接和通信：\n\n![](http://img.mantian.site/201912101426_857.png)\n\n从Linux的角度看，一个Socket就是一个有相应描述符的打开的文件\n\n以下C程序是在win10上进行socket编程的例子：\n\n```c\n/*服务端*/\n#include <stdio.h>\n#include <inaddr.h>\n#include \"fcntl.h\"\n#include \"winsock2.h\"\n#pragma comment(lib, \"ws2_32.lib\")\n\nint main(int argc, char* argv[]) {\n    // 初始化WSA\n    WORD socket_version = MAKEWORD(2, 2);\n    WSADATA was_data;\n    if (WSAStartup(socket_version, &was_data) != 0) {\n        return 0;\n    }\n\t// 创建socket描述符\n    SOCKET server_socket = socket(AF_INET, SOCK_STREAM, 0);\n    // 初始化sockaddr_in\n    struct sockaddr_in sin;\n    sin.sin_family = AF_INET;\n    sin.sin_port = htons(8080);\n    sin.sin_addr.S_un.S_addr = INADDR_ANY;\n\t// 将socket绑定到相应地址和端口上\n    if (bind(server_socket, (LPSOCKADDR)&sin, sizeof(sin)) == SOCKET_ERROR) {\n        printf(\"bind error !\");\n        return 1;\n    }\n\t// socket监听该地址和端口\n    if (listen(server_socket, 1024) == SOCKET_ERROR) {\n        printf(\"listen error !\");\n        return 1;\n    }\n\n    SOCKET client_socket;\n    struct sockaddr_in client_addr;\n    int remote_addr_len = sizeof(client_addr);\n    char recv_data[256];\n    int count = 0;\n    while (count < 10) {\n        printf(\"等待连接...\\n\");\n        // 服务端socket接受一个从客户端发来的tcp请求，建立连接，创建客户端socket描述符\n        client_socket = accept(server_socket, (SOCKADDR *)&client_addr, &remote_addr_len);\n        if (client_socket == INVALID_SOCKET) {\n            continue;\n        }\n        printf(\"接收到连接：%s...\\n\", inet_ntoa(client_addr.sin_addr));\n        // 接收客户端数据\n        int ret = recv(client_socket, recv_data, 255, 0);\n        if (ret > 0) {\n            recv_data[ret] = 0x00;\n            printf(\"%s\", recv_data);\n        }\n\n        char* data = \"hello client!\";\n        // 向客户端发送数据\n        send(client_socket, data, strlen(data), 0);\n        // 关闭客户端socket\n        closesocket(client_socket);\n        count++;\n    }\n\t// 关闭服务端socket\n    closesocket(server_socket);\n    WSACleanup();\n    return 0;\n}\n```\n\n客户端socket和服务端类似，只不过需要调用`connect`函数向服务端发送连接请求：\n\n```c\n/*客户端*/\n#include <stdio.h>\n#include \"fcntl.h\"\n#include \"winsock2.h\"\n#pragma comment(lib, \"ws2_32.lib\")\n\nint main() {\n    WORD socket_version = MAKEWORD(2, 2);\n    WSADATA was_data;\n    if (WSAStartup(socket_version, &was_data) != 0) {\n        return 0;\n    }\n\n    SOCKET client_socket = socket(AF_INET, SOCK_STREAM, 0);\n    struct sockaddr_in sin;\n    sin.sin_family = AF_INET;\n    sin.sin_port = htons(8080);\n    sin.sin_addr.S_un.S_addr = inet_addr(\"127.0.0.1\");\n\n    if (connect(client_socket, (LPSOCKADDR)&sin, sizeof(sin)) == SOCKET_ERROR) {\n        printf(\"connect error.\");\n        closesocket(client_socket);\n        return 1;\n    }\n    printf(\"到%s的连接建立...\\n\", inet_ntoa(sin.sin_addr));\n    char data[256];\n    send(client_socket, data, strlen(data), 0);\n\n    char recv_data[256];\n    int ret = recv(client_socket, recv_data, 255, 0);\n    if (ret > 0) {\n        recv_data[ret] = 0x00;\n        printf(recv_data);\n    }\n\n    closesocket(client_socket);\n    WSACleanup();\n    return 0;\n}\n```\n\n### Web服务器\n\n目前运用最广泛的Web服务使用的应用层协议是`Http协议`","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-11-2.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 11(2)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-12-11 15:13:00\n---\n\n### IP协议 & 全球IP因特网\n<!--more-->\n一个典型的因特网架构模型就是如下图所示：\n\n![](http://img.mantian.site/201912101106_404.png)\n\n因特网上的每台主机都运行着实现了TCP/IP协议族的软件，这些软件在很多计算机中都是以`套接字接口（Socket）`和各种I/O函数（例如Unix I/O）暴露给用户进行使用\n\n**IP协议**：IP协议（Internet Protocol）实现了通用的基本的网络包传送机制，这种网络传输包也叫`数据报（datagram）`，IP层的协议就负责将数据报从一台主机传送给另一台主机，但是IP层的传输是不可靠的，数据发送出去后并不会管对方主机是否收到或者是否在传输过程中丢失或者出错\n\n**UDP协议**：UDP协议（Unreliable Datagram Protocol），不可靠的数据报协议，从名字上就可以看出，UDP协议在传输可靠性方面与IP协议并没有区别，只不过在IP层上再封装了一层，可以实现基于套接字的进程之间数据传输\n\n**TCP协议**：TCP协议（Transmission Control Protocol），传输控制协议是，顾名思义该协议在IP协议的基础上实现了可靠进程间全双工的连接和传输\n\n以下内容是对IP协议的一些细节进行的讲解\n\n#### IP地址\n\nIP地址（传统的IPv4地址）是一个32位无符号整数，通常用点分十进制来表示，每个点将一个IP地址分割为4个字节\n\n使用`hostname -i`命令查看Linux环境下主机ip：\n\n```shell\n[root@localhost ~]$ hostname -i\n10.250.140.27\n```\n\n#### 域名\n\n使用IP地址标记主机地址的方式不太容易让人记住，因此推出了`域名（domain name）`，将ip地址和域名进行映射便于寻址，该映射关系可以保存在主机本地的`hosts`文件，但目前运用最广泛的还是遍布世界的`DNS服务（Domain Name Service）`来进行管理，DNS服务由成百上千万的`主机条目结构（Host Entry Structure）`组成，每一个条目定义了一组从域名到IP地址的映射\n\nLinux环境下可以通过`nslookup`命令来查看一个域名和IP地址之间的映射关系\n\n#### 网络连接 & 套接字接口\n\n在OSI七层模型中，传输层的TCP协议是基于连接的，通过点对点的方式，两台主机进行全双工的通信，是一种可靠传输协议，TCP连接的两个端点就是`套接字Socket`，相应的套接字地址就是`address:port`的形式\n\n##### 套接字接口\n\n`套接字接口（Socket Interface）`是一组函数，是对底层网络协议的封装，现代操作系统上大多都实现了套接字接口，下图描绘了如何用套接字接口提供的函数来进行网络连接和通信：\n\n![](http://img.mantian.site/201912101426_857.png)\n\n从Linux的角度看，一个Socket就是一个有相应描述符的打开的文件\n\n以下C程序是在win10上进行socket编程的例子：\n\n```c\n/*服务端*/\n#include <stdio.h>\n#include <inaddr.h>\n#include \"fcntl.h\"\n#include \"winsock2.h\"\n#pragma comment(lib, \"ws2_32.lib\")\n\nint main(int argc, char* argv[]) {\n    // 初始化WSA\n    WORD socket_version = MAKEWORD(2, 2);\n    WSADATA was_data;\n    if (WSAStartup(socket_version, &was_data) != 0) {\n        return 0;\n    }\n\t// 创建socket描述符\n    SOCKET server_socket = socket(AF_INET, SOCK_STREAM, 0);\n    // 初始化sockaddr_in\n    struct sockaddr_in sin;\n    sin.sin_family = AF_INET;\n    sin.sin_port = htons(8080);\n    sin.sin_addr.S_un.S_addr = INADDR_ANY;\n\t// 将socket绑定到相应地址和端口上\n    if (bind(server_socket, (LPSOCKADDR)&sin, sizeof(sin)) == SOCKET_ERROR) {\n        printf(\"bind error !\");\n        return 1;\n    }\n\t// socket监听该地址和端口\n    if (listen(server_socket, 1024) == SOCKET_ERROR) {\n        printf(\"listen error !\");\n        return 1;\n    }\n\n    SOCKET client_socket;\n    struct sockaddr_in client_addr;\n    int remote_addr_len = sizeof(client_addr);\n    char recv_data[256];\n    int count = 0;\n    while (count < 10) {\n        printf(\"等待连接...\\n\");\n        // 服务端socket接受一个从客户端发来的tcp请求，建立连接，创建客户端socket描述符\n        client_socket = accept(server_socket, (SOCKADDR *)&client_addr, &remote_addr_len);\n        if (client_socket == INVALID_SOCKET) {\n            continue;\n        }\n        printf(\"接收到连接：%s...\\n\", inet_ntoa(client_addr.sin_addr));\n        // 接收客户端数据\n        int ret = recv(client_socket, recv_data, 255, 0);\n        if (ret > 0) {\n            recv_data[ret] = 0x00;\n            printf(\"%s\", recv_data);\n        }\n\n        char* data = \"hello client!\";\n        // 向客户端发送数据\n        send(client_socket, data, strlen(data), 0);\n        // 关闭客户端socket\n        closesocket(client_socket);\n        count++;\n    }\n\t// 关闭服务端socket\n    closesocket(server_socket);\n    WSACleanup();\n    return 0;\n}\n```\n\n客户端socket和服务端类似，只不过需要调用`connect`函数向服务端发送连接请求：\n\n```c\n/*客户端*/\n#include <stdio.h>\n#include \"fcntl.h\"\n#include \"winsock2.h\"\n#pragma comment(lib, \"ws2_32.lib\")\n\nint main() {\n    WORD socket_version = MAKEWORD(2, 2);\n    WSADATA was_data;\n    if (WSAStartup(socket_version, &was_data) != 0) {\n        return 0;\n    }\n\n    SOCKET client_socket = socket(AF_INET, SOCK_STREAM, 0);\n    struct sockaddr_in sin;\n    sin.sin_family = AF_INET;\n    sin.sin_port = htons(8080);\n    sin.sin_addr.S_un.S_addr = inet_addr(\"127.0.0.1\");\n\n    if (connect(client_socket, (LPSOCKADDR)&sin, sizeof(sin)) == SOCKET_ERROR) {\n        printf(\"connect error.\");\n        closesocket(client_socket);\n        return 1;\n    }\n    printf(\"到%s的连接建立...\\n\", inet_ntoa(sin.sin_addr));\n    char data[256];\n    send(client_socket, data, strlen(data), 0);\n\n    char recv_data[256];\n    int ret = recv(client_socket, recv_data, 255, 0);\n    if (ret > 0) {\n        recv_data[ret] = 0x00;\n        printf(recv_data);\n    }\n\n    closesocket(client_socket);\n    WSACleanup();\n    return 0;\n}\n```\n\n### Web服务器\n\n目前运用最广泛的Web服务使用的应用层协议是`Http协议`","slug":"《深入理解计算机系统》读书笔记——Chapter-11-2","published":1,"updated":"2021-05-31T03:06:33.199Z","_id":"ckf0h31ib001tactsalfr2k6g","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"IP协议-amp-全球IP因特网\"><a href=\"#IP协议-amp-全球IP因特网\" class=\"headerlink\" title=\"IP协议 &amp; 全球IP因特网\"></a>IP协议 &amp; 全球IP因特网</h3><a id=\"more\"></a>\n<p>一个典型的因特网架构模型就是如下图所示：</p>\n<p><img src=\"http://img.mantian.site/201912101106_404.png\" alt></p>\n<p>因特网上的每台主机都运行着实现了TCP/IP协议族的软件，这些软件在很多计算机中都是以<code>套接字接口（Socket）</code>和各种I/O函数（例如Unix I/O）暴露给用户进行使用</p>\n<p><strong>IP协议</strong>：IP协议（Internet Protocol）实现了通用的基本的网络包传送机制，这种网络传输包也叫<code>数据报（datagram）</code>，IP层的协议就负责将数据报从一台主机传送给另一台主机，但是IP层的传输是不可靠的，数据发送出去后并不会管对方主机是否收到或者是否在传输过程中丢失或者出错</p>\n<p><strong>UDP协议</strong>：UDP协议（Unreliable Datagram Protocol），不可靠的数据报协议，从名字上就可以看出，UDP协议在传输可靠性方面与IP协议并没有区别，只不过在IP层上再封装了一层，可以实现基于套接字的进程之间数据传输</p>\n<p><strong>TCP协议</strong>：TCP协议（Transmission Control Protocol），传输控制协议是，顾名思义该协议在IP协议的基础上实现了可靠进程间全双工的连接和传输</p>\n<p>以下内容是对IP协议的一些细节进行的讲解</p>\n<h4 id=\"IP地址\"><a href=\"#IP地址\" class=\"headerlink\" title=\"IP地址\"></a>IP地址</h4><p>IP地址（传统的IPv4地址）是一个32位无符号整数，通常用点分十进制来表示，每个点将一个IP地址分割为4个字节</p>\n<p>使用<code>hostname -i</code>命令查看Linux环境下主机ip：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]$ hostname -i</span><br><span class=\"line\">10.250.140.27</span><br></pre></td></tr></table></figure>\n<h4 id=\"域名\"><a href=\"#域名\" class=\"headerlink\" title=\"域名\"></a>域名</h4><p>使用IP地址标记主机地址的方式不太容易让人记住，因此推出了<code>域名（domain name）</code>，将ip地址和域名进行映射便于寻址，该映射关系可以保存在主机本地的<code>hosts</code>文件，但目前运用最广泛的还是遍布世界的<code>DNS服务（Domain Name Service）</code>来进行管理，DNS服务由成百上千万的<code>主机条目结构（Host Entry Structure）</code>组成，每一个条目定义了一组从域名到IP地址的映射</p>\n<p>Linux环境下可以通过<code>nslookup</code>命令来查看一个域名和IP地址之间的映射关系</p>\n<h4 id=\"网络连接-amp-套接字接口\"><a href=\"#网络连接-amp-套接字接口\" class=\"headerlink\" title=\"网络连接 &amp; 套接字接口\"></a>网络连接 &amp; 套接字接口</h4><p>在OSI七层模型中，传输层的TCP协议是基于连接的，通过点对点的方式，两台主机进行全双工的通信，是一种可靠传输协议，TCP连接的两个端点就是<code>套接字Socket</code>，相应的套接字地址就是<code>address:port</code>的形式</p>\n<h5 id=\"套接字接口\"><a href=\"#套接字接口\" class=\"headerlink\" title=\"套接字接口\"></a>套接字接口</h5><p><code>套接字接口（Socket Interface）</code>是一组函数，是对底层网络协议的封装，现代操作系统上大多都实现了套接字接口，下图描绘了如何用套接字接口提供的函数来进行网络连接和通信：</p>\n<p><img src=\"http://img.mantian.site/201912101426_857.png\" alt></p>\n<p>从Linux的角度看，一个Socket就是一个有相应描述符的打开的文件</p>\n<p>以下C程序是在win10上进行socket编程的例子：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*服务端*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;inaddr.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"fcntl.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"winsock2.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">pragma</span> comment(lib, <span class=\"meta-string\">\"ws2_32.lib\"</span>)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>* argv[])</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 初始化WSA</span></span><br><span class=\"line\">    WORD socket_version = MAKEWORD(<span class=\"number\">2</span>, <span class=\"number\">2</span>);</span><br><span class=\"line\">    WSADATA was_data;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (WSAStartup(socket_version, &amp;was_data) != <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">\t<span class=\"comment\">// 创建socket描述符</span></span><br><span class=\"line\">    SOCKET server_socket = socket(AF_INET, SOCK_STREAM, <span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"comment\">// 初始化sockaddr_in</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">sockaddr_in</span> <span class=\"title\">sin</span>;</span></span><br><span class=\"line\">    <span class=\"built_in\">sin</span>.sin_family = AF_INET;</span><br><span class=\"line\">    <span class=\"built_in\">sin</span>.sin_port = htons(<span class=\"number\">8080</span>);</span><br><span class=\"line\">    <span class=\"built_in\">sin</span>.sin_addr.S_un.S_addr = INADDR_ANY;</span><br><span class=\"line\">\t<span class=\"comment\">// 将socket绑定到相应地址和端口上</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (bind(server_socket, (LPSOCKADDR)&amp;<span class=\"built_in\">sin</span>, <span class=\"keyword\">sizeof</span>(<span class=\"built_in\">sin</span>)) == SOCKET_ERROR) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"bind error !\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">\t<span class=\"comment\">// socket监听该地址和端口</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (listen(server_socket, <span class=\"number\">1024</span>) == SOCKET_ERROR) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"listen error !\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    SOCKET client_socket;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">sockaddr_in</span> <span class=\"title\">client_addr</span>;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> remote_addr_len = <span class=\"keyword\">sizeof</span>(client_addr);</span><br><span class=\"line\">    <span class=\"keyword\">char</span> recv_data[<span class=\"number\">256</span>];</span><br><span class=\"line\">    <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (count &lt; <span class=\"number\">10</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"等待连接...\\n\"</span>);</span><br><span class=\"line\">        <span class=\"comment\">// 服务端socket接受一个从客户端发来的tcp请求，建立连接，创建客户端socket描述符</span></span><br><span class=\"line\">        client_socket = accept(server_socket, (SOCKADDR *)&amp;client_addr, &amp;remote_addr_len);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (client_socket == INVALID_SOCKET) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"接收到连接：%s...\\n\"</span>, inet_ntoa(client_addr.sin_addr));</span><br><span class=\"line\">        <span class=\"comment\">// 接收客户端数据</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> ret = recv(client_socket, recv_data, <span class=\"number\">255</span>, <span class=\"number\">0</span>);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (ret &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            recv_data[ret] = <span class=\"number\">0x00</span>;</span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"%s\"</span>, recv_data);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">char</span>* data = <span class=\"string\">\"hello client!\"</span>;</span><br><span class=\"line\">        <span class=\"comment\">// 向客户端发送数据</span></span><br><span class=\"line\">        send(client_socket, data, <span class=\"built_in\">strlen</span>(data), <span class=\"number\">0</span>);</span><br><span class=\"line\">        <span class=\"comment\">// 关闭客户端socket</span></span><br><span class=\"line\">        closesocket(client_socket);</span><br><span class=\"line\">        count++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">\t<span class=\"comment\">// 关闭服务端socket</span></span><br><span class=\"line\">    closesocket(server_socket);</span><br><span class=\"line\">    WSACleanup();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>客户端socket和服务端类似，只不过需要调用<code>connect</code>函数向服务端发送连接请求：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*客户端*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"fcntl.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"winsock2.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">pragma</span> comment(lib, <span class=\"meta-string\">\"ws2_32.lib\"</span>)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    WORD socket_version = MAKEWORD(<span class=\"number\">2</span>, <span class=\"number\">2</span>);</span><br><span class=\"line\">    WSADATA was_data;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (WSAStartup(socket_version, &amp;was_data) != <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    SOCKET client_socket = socket(AF_INET, SOCK_STREAM, <span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">sockaddr_in</span> <span class=\"title\">sin</span>;</span></span><br><span class=\"line\">    <span class=\"built_in\">sin</span>.sin_family = AF_INET;</span><br><span class=\"line\">    <span class=\"built_in\">sin</span>.sin_port = htons(<span class=\"number\">8080</span>);</span><br><span class=\"line\">    <span class=\"built_in\">sin</span>.sin_addr.S_un.S_addr = inet_addr(<span class=\"string\">\"127.0.0.1\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (connect(client_socket, (LPSOCKADDR)&amp;<span class=\"built_in\">sin</span>, <span class=\"keyword\">sizeof</span>(<span class=\"built_in\">sin</span>)) == SOCKET_ERROR) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"connect error.\"</span>);</span><br><span class=\"line\">        closesocket(client_socket);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"到%s的连接建立...\\n\"</span>, inet_ntoa(<span class=\"built_in\">sin</span>.sin_addr));</span><br><span class=\"line\">    <span class=\"keyword\">char</span> data[<span class=\"number\">256</span>];</span><br><span class=\"line\">    send(client_socket, data, <span class=\"built_in\">strlen</span>(data), <span class=\"number\">0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">char</span> recv_data[<span class=\"number\">256</span>];</span><br><span class=\"line\">    <span class=\"keyword\">int</span> ret = recv(client_socket, recv_data, <span class=\"number\">255</span>, <span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (ret &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        recv_data[ret] = <span class=\"number\">0x00</span>;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(recv_data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    closesocket(client_socket);</span><br><span class=\"line\">    WSACleanup();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"Web服务器\"><a href=\"#Web服务器\" class=\"headerlink\" title=\"Web服务器\"></a>Web服务器</h3><p>目前运用最广泛的Web服务使用的应用层协议是<code>Http协议</code></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"IP协议-amp-全球IP因特网\"><a href=\"#IP协议-amp-全球IP因特网\" class=\"headerlink\" title=\"IP协议 &amp; 全球IP因特网\"></a>IP协议 &amp; 全球IP因特网</h3>","more":"<p>一个典型的因特网架构模型就是如下图所示：</p>\n<p><img src=\"http://img.mantian.site/201912101106_404.png\" alt></p>\n<p>因特网上的每台主机都运行着实现了TCP/IP协议族的软件，这些软件在很多计算机中都是以<code>套接字接口（Socket）</code>和各种I/O函数（例如Unix I/O）暴露给用户进行使用</p>\n<p><strong>IP协议</strong>：IP协议（Internet Protocol）实现了通用的基本的网络包传送机制，这种网络传输包也叫<code>数据报（datagram）</code>，IP层的协议就负责将数据报从一台主机传送给另一台主机，但是IP层的传输是不可靠的，数据发送出去后并不会管对方主机是否收到或者是否在传输过程中丢失或者出错</p>\n<p><strong>UDP协议</strong>：UDP协议（Unreliable Datagram Protocol），不可靠的数据报协议，从名字上就可以看出，UDP协议在传输可靠性方面与IP协议并没有区别，只不过在IP层上再封装了一层，可以实现基于套接字的进程之间数据传输</p>\n<p><strong>TCP协议</strong>：TCP协议（Transmission Control Protocol），传输控制协议是，顾名思义该协议在IP协议的基础上实现了可靠进程间全双工的连接和传输</p>\n<p>以下内容是对IP协议的一些细节进行的讲解</p>\n<h4 id=\"IP地址\"><a href=\"#IP地址\" class=\"headerlink\" title=\"IP地址\"></a>IP地址</h4><p>IP地址（传统的IPv4地址）是一个32位无符号整数，通常用点分十进制来表示，每个点将一个IP地址分割为4个字节</p>\n<p>使用<code>hostname -i</code>命令查看Linux环境下主机ip：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]$ hostname -i</span><br><span class=\"line\">10.250.140.27</span><br></pre></td></tr></table></figure>\n<h4 id=\"域名\"><a href=\"#域名\" class=\"headerlink\" title=\"域名\"></a>域名</h4><p>使用IP地址标记主机地址的方式不太容易让人记住，因此推出了<code>域名（domain name）</code>，将ip地址和域名进行映射便于寻址，该映射关系可以保存在主机本地的<code>hosts</code>文件，但目前运用最广泛的还是遍布世界的<code>DNS服务（Domain Name Service）</code>来进行管理，DNS服务由成百上千万的<code>主机条目结构（Host Entry Structure）</code>组成，每一个条目定义了一组从域名到IP地址的映射</p>\n<p>Linux环境下可以通过<code>nslookup</code>命令来查看一个域名和IP地址之间的映射关系</p>\n<h4 id=\"网络连接-amp-套接字接口\"><a href=\"#网络连接-amp-套接字接口\" class=\"headerlink\" title=\"网络连接 &amp; 套接字接口\"></a>网络连接 &amp; 套接字接口</h4><p>在OSI七层模型中，传输层的TCP协议是基于连接的，通过点对点的方式，两台主机进行全双工的通信，是一种可靠传输协议，TCP连接的两个端点就是<code>套接字Socket</code>，相应的套接字地址就是<code>address:port</code>的形式</p>\n<h5 id=\"套接字接口\"><a href=\"#套接字接口\" class=\"headerlink\" title=\"套接字接口\"></a>套接字接口</h5><p><code>套接字接口（Socket Interface）</code>是一组函数，是对底层网络协议的封装，现代操作系统上大多都实现了套接字接口，下图描绘了如何用套接字接口提供的函数来进行网络连接和通信：</p>\n<p><img src=\"http://img.mantian.site/201912101426_857.png\" alt></p>\n<p>从Linux的角度看，一个Socket就是一个有相应描述符的打开的文件</p>\n<p>以下C程序是在win10上进行socket编程的例子：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*服务端*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;inaddr.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"fcntl.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"winsock2.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">pragma</span> comment(lib, <span class=\"meta-string\">\"ws2_32.lib\"</span>)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>* argv[])</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 初始化WSA</span></span><br><span class=\"line\">    WORD socket_version = MAKEWORD(<span class=\"number\">2</span>, <span class=\"number\">2</span>);</span><br><span class=\"line\">    WSADATA was_data;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (WSAStartup(socket_version, &amp;was_data) != <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">\t<span class=\"comment\">// 创建socket描述符</span></span><br><span class=\"line\">    SOCKET server_socket = socket(AF_INET, SOCK_STREAM, <span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"comment\">// 初始化sockaddr_in</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">sockaddr_in</span> <span class=\"title\">sin</span>;</span></span><br><span class=\"line\">    <span class=\"built_in\">sin</span>.sin_family = AF_INET;</span><br><span class=\"line\">    <span class=\"built_in\">sin</span>.sin_port = htons(<span class=\"number\">8080</span>);</span><br><span class=\"line\">    <span class=\"built_in\">sin</span>.sin_addr.S_un.S_addr = INADDR_ANY;</span><br><span class=\"line\">\t<span class=\"comment\">// 将socket绑定到相应地址和端口上</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (bind(server_socket, (LPSOCKADDR)&amp;<span class=\"built_in\">sin</span>, <span class=\"keyword\">sizeof</span>(<span class=\"built_in\">sin</span>)) == SOCKET_ERROR) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"bind error !\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">\t<span class=\"comment\">// socket监听该地址和端口</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (listen(server_socket, <span class=\"number\">1024</span>) == SOCKET_ERROR) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"listen error !\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    SOCKET client_socket;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">sockaddr_in</span> <span class=\"title\">client_addr</span>;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> remote_addr_len = <span class=\"keyword\">sizeof</span>(client_addr);</span><br><span class=\"line\">    <span class=\"keyword\">char</span> recv_data[<span class=\"number\">256</span>];</span><br><span class=\"line\">    <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (count &lt; <span class=\"number\">10</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"等待连接...\\n\"</span>);</span><br><span class=\"line\">        <span class=\"comment\">// 服务端socket接受一个从客户端发来的tcp请求，建立连接，创建客户端socket描述符</span></span><br><span class=\"line\">        client_socket = accept(server_socket, (SOCKADDR *)&amp;client_addr, &amp;remote_addr_len);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (client_socket == INVALID_SOCKET) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"接收到连接：%s...\\n\"</span>, inet_ntoa(client_addr.sin_addr));</span><br><span class=\"line\">        <span class=\"comment\">// 接收客户端数据</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> ret = recv(client_socket, recv_data, <span class=\"number\">255</span>, <span class=\"number\">0</span>);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (ret &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            recv_data[ret] = <span class=\"number\">0x00</span>;</span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"%s\"</span>, recv_data);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">char</span>* data = <span class=\"string\">\"hello client!\"</span>;</span><br><span class=\"line\">        <span class=\"comment\">// 向客户端发送数据</span></span><br><span class=\"line\">        send(client_socket, data, <span class=\"built_in\">strlen</span>(data), <span class=\"number\">0</span>);</span><br><span class=\"line\">        <span class=\"comment\">// 关闭客户端socket</span></span><br><span class=\"line\">        closesocket(client_socket);</span><br><span class=\"line\">        count++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">\t<span class=\"comment\">// 关闭服务端socket</span></span><br><span class=\"line\">    closesocket(server_socket);</span><br><span class=\"line\">    WSACleanup();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>客户端socket和服务端类似，只不过需要调用<code>connect</code>函数向服务端发送连接请求：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*客户端*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"fcntl.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"winsock2.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">pragma</span> comment(lib, <span class=\"meta-string\">\"ws2_32.lib\"</span>)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    WORD socket_version = MAKEWORD(<span class=\"number\">2</span>, <span class=\"number\">2</span>);</span><br><span class=\"line\">    WSADATA was_data;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (WSAStartup(socket_version, &amp;was_data) != <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    SOCKET client_socket = socket(AF_INET, SOCK_STREAM, <span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">sockaddr_in</span> <span class=\"title\">sin</span>;</span></span><br><span class=\"line\">    <span class=\"built_in\">sin</span>.sin_family = AF_INET;</span><br><span class=\"line\">    <span class=\"built_in\">sin</span>.sin_port = htons(<span class=\"number\">8080</span>);</span><br><span class=\"line\">    <span class=\"built_in\">sin</span>.sin_addr.S_un.S_addr = inet_addr(<span class=\"string\">\"127.0.0.1\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (connect(client_socket, (LPSOCKADDR)&amp;<span class=\"built_in\">sin</span>, <span class=\"keyword\">sizeof</span>(<span class=\"built_in\">sin</span>)) == SOCKET_ERROR) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"connect error.\"</span>);</span><br><span class=\"line\">        closesocket(client_socket);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"到%s的连接建立...\\n\"</span>, inet_ntoa(<span class=\"built_in\">sin</span>.sin_addr));</span><br><span class=\"line\">    <span class=\"keyword\">char</span> data[<span class=\"number\">256</span>];</span><br><span class=\"line\">    send(client_socket, data, <span class=\"built_in\">strlen</span>(data), <span class=\"number\">0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">char</span> recv_data[<span class=\"number\">256</span>];</span><br><span class=\"line\">    <span class=\"keyword\">int</span> ret = recv(client_socket, recv_data, <span class=\"number\">255</span>, <span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (ret &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        recv_data[ret] = <span class=\"number\">0x00</span>;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(recv_data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    closesocket(client_socket);</span><br><span class=\"line\">    WSACleanup();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"Web服务器\"><a href=\"#Web服务器\" class=\"headerlink\" title=\"Web服务器\"></a>Web服务器</h3><p>目前运用最广泛的Web服务使用的应用层协议是<code>Http协议</code></p>"},{"title":"vue学习笔记（1） —— 用vue-cli搭建spa工程","author":"天渊","date":"2019-03-18T05:09:22.000Z","_content":"使用webpack和vue搭建搭建单页面应用程序（SPA，Single-Page Application）是前端开发的发展趋势之一，现在来学习一下在Intellij IDEA中使用`vue-cli`搭建一个基于vue框架的SPA demo程序，并部署到nginx服务器\n<!--more-->\n\n### 初始化工程\n\n1. 首先保证本机安装有最新版的node.js和npm，使用`node -v`查看版本，不赘述\n\n2. 命令行执行`npm install -g vue-cli`全局安装`vue-cli`\n3. 进入想要构建工程的目录，执行命令`vue init webpack project-name`，webpack默认版本目前是2.0\n4. 接下来需要为初始化工程进行配置，根据提示按需配置，一般来说直接默认就够了\n\n### 配置IDEA\n\n需要在IDEA中安装vue相关的插件\n\n1. `File -> Settings -> Plugins -> Browse respositoties`搜索`Vue.js`安装，然后重启IDEA\n\n2. `File -> Settings -> Editor -> File Types -> HTML`，将`.vue`文件配置为默认的html类型\n\n3. `File -> Settings -> Language & Frameworks -> JavaScript`，将js版本设置为ES6\n\n4. 使用IDEA打开之前初始化完成的vue工程，点击工具栏的`Edit Configurations`进行启动配置：command选择`run`，Scripts选择`dev`环境\n\n5. 点击启动：\n   \n\t![upload successful](\\blog\\images\\pasted-4.png)\n\n6. 打开`http://localhost:8080/`即可看到官方的HelloWorld页面，接下来在此工程的基础上进行开发即可\n\n\n\n### 认识vue-cli工程结构\n\n在vue-cli工程初始化完成后的工程中，目录如下：\n\n![upload successful](\\blog\\images\\pasted-5.png)\n\n1. 最重要的文件夹是`src`，这下面包含了跟页面app有关的所有源代码，包括各类js, css, .vue模板，以及router\n2. 除了`src`文件夹，最外层的`index.html`即为项目主页，即`SPA`中那个`single-page`\n3. `static`文件夹存放其他类型的静态资源如图片和字体等\n4. 其他文件夹（test, build, config）是与项目构建，编译和测试相关的配置，现阶段暂时不用管\n\n为何vue工程有自己独特的`.vue`文件？官网叫其为单文件组件，通过webpack源码转换，会全部转换为对应的文件，通常用于自定义组件模板，包括`template`的html模板，`style`样式以及js脚本，如HelloWorld工程的`App.vue`文件：\n\n![upload successful](\\blog\\images\\pasted-6.png)\n\n`template`为html页面框架，`style`为当前组件的css样式，`script`则主要用于编写并导出当前组件脚本。\n\n### vue-cli工程运行流程\n\nSPA工程遵循一定的规则和流程对页面进行渲染，以当前HelloWorld工程为例：\n\n1. 首先打开主页面`index.html`，vue基于`el`属性，对`id=\"app\"`的这个div进行渲染，脚本位于入口js文件`main.js`中，有关的js脚本以及router文件都需要导入到这个入口js文件中来：\n\n   ```html\n   <body>\n       <div id=\"app\"></div>\n   </body>\n   ```\n\n   ```javascript\n   new Vue({\n     el: '#app',\n     router,\n     components: { App },\n     template: '<App/>'\n   })\n   ```\n\n2. 如上，`router`为vue-router路由对象，用于配置需要导入的组件页面，本例子中router配置于`/router/index.js`文件中：\n\n   ```javascript\n   Vue.use(Router)\n   export default new Router({\n     routes: [\n       {\n         path: '/',\n         name: 'HelloWorld',\n         component: HelloWorld\n       }\n     ]\n   })\n   ```\n\n   将`HelloWorld`组件配置到router对象中\n\n3. `components`用于配置自定义组件 `App`，来自于`App.vue`文件：\n\n   ```html\n   <template>\n     <div id=\"app\">\n       <img src=\"./assets/logo.png\">\n       <router-view/>\n     </div>\n   </template>\n   \n   <script>\n   // 命名并导出当前组件\n   export default {\n     name: 'App'\n   }\n   </script>\n   \n   <style>\n   ...\n   </style>\n   ```\n\n4. `template`用于将当前html替换为自定义组件模板`App`，也是来自于`App.vue`文件\n\n5. `<App/>`中的`<router-view/>`标签用于渲染之前router对象中配置的页面，即`HelloWorld.vue`中的内容\n\n至此整个流程完成","source":"_posts/vue学习笔记-——-用vue-cli搭建spa工程.md","raw":"title: vue学习笔记（1） —— 用vue-cli搭建spa工程\nauthor: 天渊\ndate: 2019-03-18 13:09:22\ntags:\n---\n使用webpack和vue搭建搭建单页面应用程序（SPA，Single-Page Application）是前端开发的发展趋势之一，现在来学习一下在Intellij IDEA中使用`vue-cli`搭建一个基于vue框架的SPA demo程序，并部署到nginx服务器\n<!--more-->\n\n### 初始化工程\n\n1. 首先保证本机安装有最新版的node.js和npm，使用`node -v`查看版本，不赘述\n\n2. 命令行执行`npm install -g vue-cli`全局安装`vue-cli`\n3. 进入想要构建工程的目录，执行命令`vue init webpack project-name`，webpack默认版本目前是2.0\n4. 接下来需要为初始化工程进行配置，根据提示按需配置，一般来说直接默认就够了\n\n### 配置IDEA\n\n需要在IDEA中安装vue相关的插件\n\n1. `File -> Settings -> Plugins -> Browse respositoties`搜索`Vue.js`安装，然后重启IDEA\n\n2. `File -> Settings -> Editor -> File Types -> HTML`，将`.vue`文件配置为默认的html类型\n\n3. `File -> Settings -> Language & Frameworks -> JavaScript`，将js版本设置为ES6\n\n4. 使用IDEA打开之前初始化完成的vue工程，点击工具栏的`Edit Configurations`进行启动配置：command选择`run`，Scripts选择`dev`环境\n\n5. 点击启动：\n   \n\t![upload successful](\\blog\\images\\pasted-4.png)\n\n6. 打开`http://localhost:8080/`即可看到官方的HelloWorld页面，接下来在此工程的基础上进行开发即可\n\n\n\n### 认识vue-cli工程结构\n\n在vue-cli工程初始化完成后的工程中，目录如下：\n\n![upload successful](\\blog\\images\\pasted-5.png)\n\n1. 最重要的文件夹是`src`，这下面包含了跟页面app有关的所有源代码，包括各类js, css, .vue模板，以及router\n2. 除了`src`文件夹，最外层的`index.html`即为项目主页，即`SPA`中那个`single-page`\n3. `static`文件夹存放其他类型的静态资源如图片和字体等\n4. 其他文件夹（test, build, config）是与项目构建，编译和测试相关的配置，现阶段暂时不用管\n\n为何vue工程有自己独特的`.vue`文件？官网叫其为单文件组件，通过webpack源码转换，会全部转换为对应的文件，通常用于自定义组件模板，包括`template`的html模板，`style`样式以及js脚本，如HelloWorld工程的`App.vue`文件：\n\n![upload successful](\\blog\\images\\pasted-6.png)\n\n`template`为html页面框架，`style`为当前组件的css样式，`script`则主要用于编写并导出当前组件脚本。\n\n### vue-cli工程运行流程\n\nSPA工程遵循一定的规则和流程对页面进行渲染，以当前HelloWorld工程为例：\n\n1. 首先打开主页面`index.html`，vue基于`el`属性，对`id=\"app\"`的这个div进行渲染，脚本位于入口js文件`main.js`中，有关的js脚本以及router文件都需要导入到这个入口js文件中来：\n\n   ```html\n   <body>\n       <div id=\"app\"></div>\n   </body>\n   ```\n\n   ```javascript\n   new Vue({\n     el: '#app',\n     router,\n     components: { App },\n     template: '<App/>'\n   })\n   ```\n\n2. 如上，`router`为vue-router路由对象，用于配置需要导入的组件页面，本例子中router配置于`/router/index.js`文件中：\n\n   ```javascript\n   Vue.use(Router)\n   export default new Router({\n     routes: [\n       {\n         path: '/',\n         name: 'HelloWorld',\n         component: HelloWorld\n       }\n     ]\n   })\n   ```\n\n   将`HelloWorld`组件配置到router对象中\n\n3. `components`用于配置自定义组件 `App`，来自于`App.vue`文件：\n\n   ```html\n   <template>\n     <div id=\"app\">\n       <img src=\"./assets/logo.png\">\n       <router-view/>\n     </div>\n   </template>\n   \n   <script>\n   // 命名并导出当前组件\n   export default {\n     name: 'App'\n   }\n   </script>\n   \n   <style>\n   ...\n   </style>\n   ```\n\n4. `template`用于将当前html替换为自定义组件模板`App`，也是来自于`App.vue`文件\n\n5. `<App/>`中的`<router-view/>`标签用于渲染之前router对象中配置的页面，即`HelloWorld.vue`中的内容\n\n至此整个流程完成","slug":"vue学习笔记-——-用vue-cli搭建spa工程","published":1,"updated":"2021-05-31T03:06:33.198Z","_id":"ckf0h31ic001wactsyai4fg5v","comments":1,"layout":"post","photos":[],"link":"","content":"<p>使用webpack和vue搭建搭建单页面应用程序（SPA，Single-Page Application）是前端开发的发展趋势之一，现在来学习一下在Intellij IDEA中使用<code>vue-cli</code>搭建一个基于vue框架的SPA demo程序，并部署到nginx服务器<br><a id=\"more\"></a></p>\n<h3 id=\"初始化工程\"><a href=\"#初始化工程\" class=\"headerlink\" title=\"初始化工程\"></a>初始化工程</h3><ol>\n<li><p>首先保证本机安装有最新版的node.js和npm，使用<code>node -v</code>查看版本，不赘述</p>\n</li>\n<li><p>命令行执行<code>npm install -g vue-cli</code>全局安装<code>vue-cli</code></p>\n</li>\n<li>进入想要构建工程的目录，执行命令<code>vue init webpack project-name</code>，webpack默认版本目前是2.0</li>\n<li>接下来需要为初始化工程进行配置，根据提示按需配置，一般来说直接默认就够了</li>\n</ol>\n<h3 id=\"配置IDEA\"><a href=\"#配置IDEA\" class=\"headerlink\" title=\"配置IDEA\"></a>配置IDEA</h3><p>需要在IDEA中安装vue相关的插件</p>\n<ol>\n<li><p><code>File -&gt; Settings -&gt; Plugins -&gt; Browse respositoties</code>搜索<code>Vue.js</code>安装，然后重启IDEA</p>\n</li>\n<li><p><code>File -&gt; Settings -&gt; Editor -&gt; File Types -&gt; HTML</code>，将<code>.vue</code>文件配置为默认的html类型</p>\n</li>\n<li><p><code>File -&gt; Settings -&gt; Language &amp; Frameworks -&gt; JavaScript</code>，将js版本设置为ES6</p>\n</li>\n<li><p>使用IDEA打开之前初始化完成的vue工程，点击工具栏的<code>Edit Configurations</code>进行启动配置：command选择<code>run</code>，Scripts选择<code>dev</code>环境</p>\n</li>\n<li><p>点击启动：</p>\n<p> <img src=\"\\blog\\images\\pasted-4.png\" alt=\"upload successful\"></p>\n</li>\n<li><p>打开<code>http://localhost:8080/</code>即可看到官方的HelloWorld页面，接下来在此工程的基础上进行开发即可</p>\n</li>\n</ol>\n<h3 id=\"认识vue-cli工程结构\"><a href=\"#认识vue-cli工程结构\" class=\"headerlink\" title=\"认识vue-cli工程结构\"></a>认识vue-cli工程结构</h3><p>在vue-cli工程初始化完成后的工程中，目录如下：</p>\n<p><img src=\"\\blog\\images\\pasted-5.png\" alt=\"upload successful\"></p>\n<ol>\n<li>最重要的文件夹是<code>src</code>，这下面包含了跟页面app有关的所有源代码，包括各类js, css, .vue模板，以及router</li>\n<li>除了<code>src</code>文件夹，最外层的<code>index.html</code>即为项目主页，即<code>SPA</code>中那个<code>single-page</code></li>\n<li><code>static</code>文件夹存放其他类型的静态资源如图片和字体等</li>\n<li>其他文件夹（test, build, config）是与项目构建，编译和测试相关的配置，现阶段暂时不用管</li>\n</ol>\n<p>为何vue工程有自己独特的<code>.vue</code>文件？官网叫其为单文件组件，通过webpack源码转换，会全部转换为对应的文件，通常用于自定义组件模板，包括<code>template</code>的html模板，<code>style</code>样式以及js脚本，如HelloWorld工程的<code>App.vue</code>文件：</p>\n<p><img src=\"\\blog\\images\\pasted-6.png\" alt=\"upload successful\"></p>\n<p><code>template</code>为html页面框架，<code>style</code>为当前组件的css样式，<code>script</code>则主要用于编写并导出当前组件脚本。</p>\n<h3 id=\"vue-cli工程运行流程\"><a href=\"#vue-cli工程运行流程\" class=\"headerlink\" title=\"vue-cli工程运行流程\"></a>vue-cli工程运行流程</h3><p>SPA工程遵循一定的规则和流程对页面进行渲染，以当前HelloWorld工程为例：</p>\n<ol>\n<li><p>首先打开主页面<code>index.html</code>，vue基于<code>el</code>属性，对<code>id=&quot;app&quot;</code>的这个div进行渲染，脚本位于入口js文件<code>main.js</code>中，有关的js脚本以及router文件都需要导入到这个入口js文件中来：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"app\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">new</span> Vue(&#123;</span><br><span class=\"line\">  el: <span class=\"string\">'#app'</span>,</span><br><span class=\"line\">  router,</span><br><span class=\"line\">  components: &#123; App &#125;,</span><br><span class=\"line\">  template: <span class=\"string\">'&lt;App/&gt;'</span></span><br><span class=\"line\">&#125;)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>如上，<code>router</code>为vue-router路由对象，用于配置需要导入的组件页面，本例子中router配置于<code>/router/index.js</code>文件中：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Vue.use(Router)</span><br><span class=\"line\"><span class=\"keyword\">export</span> <span class=\"keyword\">default</span> <span class=\"keyword\">new</span> Router(&#123;</span><br><span class=\"line\">  routes: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      path: <span class=\"string\">'/'</span>,</span><br><span class=\"line\">      name: <span class=\"string\">'HelloWorld'</span>,</span><br><span class=\"line\">      component: HelloWorld</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;)</span><br></pre></td></tr></table></figure>\n<p>将<code>HelloWorld</code>组件配置到router对象中</p>\n</li>\n<li><p><code>components</code>用于配置自定义组件 <code>App</code>，来自于<code>App.vue</code>文件：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">template</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"app\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">img</span> <span class=\"attr\">src</span>=<span class=\"string\">\"./assets/logo.png\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">router-view</span>/&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">template</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span><span class=\"undefined\"></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"comment\">// 命名并导出当前组件</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"keyword\">export</span> <span class=\"keyword\">default</span> &#123;</span></span><br><span class=\"line\"><span class=\"javascript\">  name: <span class=\"string\">'App'</span></span></span><br><span class=\"line\"><span class=\"undefined\">&#125;</span></span><br><span class=\"line\"><span class=\"undefined\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">style</span>&gt;</span><span class=\"undefined\"></span></span><br><span class=\"line\"><span class=\"undefined\">...</span></span><br><span class=\"line\"><span class=\"undefined\"></span><span class=\"tag\">&lt;/<span class=\"name\">style</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>template</code>用于将当前html替换为自定义组件模板<code>App</code>，也是来自于<code>App.vue</code>文件</p>\n</li>\n<li><p><code>&lt;App/&gt;</code>中的<code>&lt;router-view/&gt;</code>标签用于渲染之前router对象中配置的页面，即<code>HelloWorld.vue</code>中的内容</p>\n</li>\n</ol>\n<p>至此整个流程完成</p>\n","site":{"data":{}},"excerpt":"<p>使用webpack和vue搭建搭建单页面应用程序（SPA，Single-Page Application）是前端开发的发展趋势之一，现在来学习一下在Intellij IDEA中使用<code>vue-cli</code>搭建一个基于vue框架的SPA demo程序，并部署到nginx服务器<br>","more":"</p>\n<h3 id=\"初始化工程\"><a href=\"#初始化工程\" class=\"headerlink\" title=\"初始化工程\"></a>初始化工程</h3><ol>\n<li><p>首先保证本机安装有最新版的node.js和npm，使用<code>node -v</code>查看版本，不赘述</p>\n</li>\n<li><p>命令行执行<code>npm install -g vue-cli</code>全局安装<code>vue-cli</code></p>\n</li>\n<li>进入想要构建工程的目录，执行命令<code>vue init webpack project-name</code>，webpack默认版本目前是2.0</li>\n<li>接下来需要为初始化工程进行配置，根据提示按需配置，一般来说直接默认就够了</li>\n</ol>\n<h3 id=\"配置IDEA\"><a href=\"#配置IDEA\" class=\"headerlink\" title=\"配置IDEA\"></a>配置IDEA</h3><p>需要在IDEA中安装vue相关的插件</p>\n<ol>\n<li><p><code>File -&gt; Settings -&gt; Plugins -&gt; Browse respositoties</code>搜索<code>Vue.js</code>安装，然后重启IDEA</p>\n</li>\n<li><p><code>File -&gt; Settings -&gt; Editor -&gt; File Types -&gt; HTML</code>，将<code>.vue</code>文件配置为默认的html类型</p>\n</li>\n<li><p><code>File -&gt; Settings -&gt; Language &amp; Frameworks -&gt; JavaScript</code>，将js版本设置为ES6</p>\n</li>\n<li><p>使用IDEA打开之前初始化完成的vue工程，点击工具栏的<code>Edit Configurations</code>进行启动配置：command选择<code>run</code>，Scripts选择<code>dev</code>环境</p>\n</li>\n<li><p>点击启动：</p>\n<p> <img src=\"\\blog\\images\\pasted-4.png\" alt=\"upload successful\"></p>\n</li>\n<li><p>打开<code>http://localhost:8080/</code>即可看到官方的HelloWorld页面，接下来在此工程的基础上进行开发即可</p>\n</li>\n</ol>\n<h3 id=\"认识vue-cli工程结构\"><a href=\"#认识vue-cli工程结构\" class=\"headerlink\" title=\"认识vue-cli工程结构\"></a>认识vue-cli工程结构</h3><p>在vue-cli工程初始化完成后的工程中，目录如下：</p>\n<p><img src=\"\\blog\\images\\pasted-5.png\" alt=\"upload successful\"></p>\n<ol>\n<li>最重要的文件夹是<code>src</code>，这下面包含了跟页面app有关的所有源代码，包括各类js, css, .vue模板，以及router</li>\n<li>除了<code>src</code>文件夹，最外层的<code>index.html</code>即为项目主页，即<code>SPA</code>中那个<code>single-page</code></li>\n<li><code>static</code>文件夹存放其他类型的静态资源如图片和字体等</li>\n<li>其他文件夹（test, build, config）是与项目构建，编译和测试相关的配置，现阶段暂时不用管</li>\n</ol>\n<p>为何vue工程有自己独特的<code>.vue</code>文件？官网叫其为单文件组件，通过webpack源码转换，会全部转换为对应的文件，通常用于自定义组件模板，包括<code>template</code>的html模板，<code>style</code>样式以及js脚本，如HelloWorld工程的<code>App.vue</code>文件：</p>\n<p><img src=\"\\blog\\images\\pasted-6.png\" alt=\"upload successful\"></p>\n<p><code>template</code>为html页面框架，<code>style</code>为当前组件的css样式，<code>script</code>则主要用于编写并导出当前组件脚本。</p>\n<h3 id=\"vue-cli工程运行流程\"><a href=\"#vue-cli工程运行流程\" class=\"headerlink\" title=\"vue-cli工程运行流程\"></a>vue-cli工程运行流程</h3><p>SPA工程遵循一定的规则和流程对页面进行渲染，以当前HelloWorld工程为例：</p>\n<ol>\n<li><p>首先打开主页面<code>index.html</code>，vue基于<code>el</code>属性，对<code>id=&quot;app&quot;</code>的这个div进行渲染，脚本位于入口js文件<code>main.js</code>中，有关的js脚本以及router文件都需要导入到这个入口js文件中来：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"app\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">new</span> Vue(&#123;</span><br><span class=\"line\">  el: <span class=\"string\">'#app'</span>,</span><br><span class=\"line\">  router,</span><br><span class=\"line\">  components: &#123; App &#125;,</span><br><span class=\"line\">  template: <span class=\"string\">'&lt;App/&gt;'</span></span><br><span class=\"line\">&#125;)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>如上，<code>router</code>为vue-router路由对象，用于配置需要导入的组件页面，本例子中router配置于<code>/router/index.js</code>文件中：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Vue.use(Router)</span><br><span class=\"line\"><span class=\"keyword\">export</span> <span class=\"keyword\">default</span> <span class=\"keyword\">new</span> Router(&#123;</span><br><span class=\"line\">  routes: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      path: <span class=\"string\">'/'</span>,</span><br><span class=\"line\">      name: <span class=\"string\">'HelloWorld'</span>,</span><br><span class=\"line\">      component: HelloWorld</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;)</span><br></pre></td></tr></table></figure>\n<p>将<code>HelloWorld</code>组件配置到router对象中</p>\n</li>\n<li><p><code>components</code>用于配置自定义组件 <code>App</code>，来自于<code>App.vue</code>文件：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">template</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">\"app\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">img</span> <span class=\"attr\">src</span>=<span class=\"string\">\"./assets/logo.png\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">router-view</span>/&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">template</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span><span class=\"undefined\"></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"comment\">// 命名并导出当前组件</span></span></span><br><span class=\"line\"><span class=\"javascript\"><span class=\"keyword\">export</span> <span class=\"keyword\">default</span> &#123;</span></span><br><span class=\"line\"><span class=\"javascript\">  name: <span class=\"string\">'App'</span></span></span><br><span class=\"line\"><span class=\"undefined\">&#125;</span></span><br><span class=\"line\"><span class=\"undefined\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">style</span>&gt;</span><span class=\"undefined\"></span></span><br><span class=\"line\"><span class=\"undefined\">...</span></span><br><span class=\"line\"><span class=\"undefined\"></span><span class=\"tag\">&lt;/<span class=\"name\">style</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>template</code>用于将当前html替换为自定义组件模板<code>App</code>，也是来自于<code>App.vue</code>文件</p>\n</li>\n<li><p><code>&lt;App/&gt;</code>中的<code>&lt;router-view/&gt;</code>标签用于渲染之前router对象中配置的页面，即<code>HelloWorld.vue</code>中的内容</p>\n</li>\n</ol>\n<p>至此整个流程完成</p>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 3(2)","author":"天渊","date":"2019-10-01T10:25:00.000Z","_content":"第三章：`程序的机器级表示`\n\n第三章读书笔记第二部分，本部分主要了解：\n\n1. 计算机中算术和逻辑操作在机器层面的具体实现\n2. 计算机中控制语句（条件和循环，还有switch）的具体实现\n3. 计算机中函数执行过程的具体实现，包括运行时栈的实现，局部变量存储以及递归的实现\n<!--more-->\n\n### 算术和逻辑运算\n\n算术和逻辑操作包括加减乘除还有移位等操作，这些操作分为`加载有效地址`，`一元操作`（只有一个操作数），`二元操作`（有两个操作数）和`移位操作`，一共四大类，基本上囊括了计算机系统中所有基本操作指令\n\n#### 加载有效地址：leaq\n\n`leaq (load effective address)`操作是一种特殊的运算操作，该操作是`mov`操作的一个变种，但是对于`mov`，像下面这种操作是引用了内存地址，`%rdi`寄存器保存了某个变量的内存地址，`mov`根据这个地址去内存找相应的值然后拷贝到`%rax`寄存器上：\n\n```assembly\nmovq\t(%rdi), %rax\n```\n\n而对于`leaq`操作，则是直接将某个内存的地址值拷贝到寄存器或者其他内存，那么目标寄存器或者内存就会保存另外一个内存的指针，比如下面这个操作，`leaq`是直接把`%rdi`保存的值拷贝到`%rax`寄存器，那么`%rax`和`rdi`同时都保存了某个内存地址：\n\n```assembly\nleaq\t(%rdi), %rax\n```\n\n该操作就是C语言中`int a = &b`这个操作的具体实现，将某个变量的指针取出来存到另一个变量中，因此`leaq`操作就叫做`加载有效地址`，需要注意的是`leaq`没有其他不同大小的操作数，在x86-64中只加载8字节数，因为内存地址的大小就是8字节\n\n##### leaq执行有限加法和乘法\n\n由于`leaq`计算内存地址的功能，因此可以基于内存地址计算过程来进行一些简单的加法和乘法操作，某些简单的C语言加减乘操作会被编译为多个`leaq`的汇编指令，比如如下操作：\n\n```c\nlong t = x + 4 * y + 12 * z\n```\n\n会被gcc编译器编译为如下的汇编指令：\n\n```assembly\nx in %rdi, y in %rsi, z in %rdx\n\nleaq\t(%rdi, %rsi, 4), %rax\t// x + 4 * y\nleaq\t(%rdx, %rdx, 2), %rdx\t// z + 2 * z = 3 * z\nleaq\t(%rax, %rdx, 4), %rax\t// (x + 4 * y) + 4 * (3 * z) = x + 4 * y + 12 * z\n```\n\n#### 一元操作\n\n一元操作只有一个操作数，既是源又是目的地，操作数可以是寄存器，也可以是内存地址，比如自增操作或者取反操作，是直接改变的当前位置的数据，没有拷贝操作\n\n内存操作，`%rax`存储值为0x100，内存0x110处存储的值为0x13：\n\n```assembly\nincq\t16(%rax)\t//结果为0x13 + 0x1 = 0x14\n```\n\n寄存器操作，`%rcx`存储值为0x1：\n\n```assembly\ndecq\t%rcx\t//结果为0x0\n```\n\n#### 二元操作\n\n像加减乘和异或这样的操作就属于二元操作，二元操作相对来说要复杂一些，不仅有两个操作数，而且操作过程也比较反直觉\n\n在二元操作中，第二个操作数即是源又是目的，比如对于操作`subq %rax,%rdx`，操作过程是将`%rdx`减去`%rax`的值，然后再把结果存入`%rdx`，有点类似于`x-=y`这样的操作，x就是`%rdx`，y就是`%rax`\n\n二元操作中，第一个操作数可以是立即数，第二个操作数不能是立即数，只能是寄存器或者内存地址\n\n内存和寄存器的二元操作，其中`%rax`的值为0x100，`%rdx`的值为0x3，内存0x108处的值为0xAB，求以下操作的结果\n\n```assembly\nsubq\t%rdx, 8(%rax)\t//先找到源操作数8(%rax)也就是0x108位置的数0xAB，然后再减去0x3\n\t\t\t\t\t\t//最后结果即为0xA8，将结果再存回0x108\n```\n\n#### 移位操作\n\n移位操作中，第一个操作数是移位量，可以是立即数或者单字节寄存器`%c1`\n\n第二个操作数是要移位的数，即是源也是目的地，可以是寄存器也可以是内存地址\n\n移位操作大致上分为两种：`左移位`，`右移位`\n\n具体还能分位`算术移位`或者`逻辑移位`，其中`算术左移`和`逻辑左移`没有区别，空出来的位都填充为0\n\n`算术右移`和`逻辑右移`的区别在于：`算术右移`空出来的高位全部填充符号位，而`逻辑右移`空出来的高位全部填充为0\n\n### 控制语句的实现\n\n程序中的条件，循环和分支语句，需要有条件的执行，此时就不能按照传统方式将指令一条接一条地执行，而是需要根据条件从当前指令跳转到其他指令进行执行\n\n计算机提供了两种机制来实现指令的有条件跳转：\n\n1. 测试数据值\n2. 根据测试结果改变控制流或数据流\n\n#### 条件码寄存器\n\nCPU维护了一种单个位`条件码`寄存器，这种寄存器只有0和1两种值，保存最近的运算操作产生结果的状态，通过检测这些寄存器来执行条件分支的跳转指令：\n\n1. CF：进位标志，最近的操作是否使最高位产生了进位（无符号溢出）\n2. ZF：零标志，最近的操作结果是否为0\n3. SF：符号标志，最近的操作结果是否为负数\n4. OF：溢出标志，与CF的区别是OF是有符号的补码溢出\n\n之前描述的所有算术和逻辑运算指令在计算结果后，都会同时设置`条件码`\n\n除此之外还有两个指令是专门用于设置`条件码`寄存器，而不会改变操作数：\n\n1. CMP指令：CMP指令的操作和`SUB`指令都是一样的，都是做减法，不过CMP指令只修改条件码寄存器（ZF或者SF），用以比较两个数的大小，而不用修改任何一个操作数\n2. TEST指令：TEST指令的操作和`AND`指令是一样的，都是作`&`操作，可以用来判断某数的符号\n\n#### 如何访问条件码\n\n条件码设置好后，需要读取条件码的状态来决定如何跳转","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-3-2.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 3(2)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-10-01 18:25:00\n---\n第三章：`程序的机器级表示`\n\n第三章读书笔记第二部分，本部分主要了解：\n\n1. 计算机中算术和逻辑操作在机器层面的具体实现\n2. 计算机中控制语句（条件和循环，还有switch）的具体实现\n3. 计算机中函数执行过程的具体实现，包括运行时栈的实现，局部变量存储以及递归的实现\n<!--more-->\n\n### 算术和逻辑运算\n\n算术和逻辑操作包括加减乘除还有移位等操作，这些操作分为`加载有效地址`，`一元操作`（只有一个操作数），`二元操作`（有两个操作数）和`移位操作`，一共四大类，基本上囊括了计算机系统中所有基本操作指令\n\n#### 加载有效地址：leaq\n\n`leaq (load effective address)`操作是一种特殊的运算操作，该操作是`mov`操作的一个变种，但是对于`mov`，像下面这种操作是引用了内存地址，`%rdi`寄存器保存了某个变量的内存地址，`mov`根据这个地址去内存找相应的值然后拷贝到`%rax`寄存器上：\n\n```assembly\nmovq\t(%rdi), %rax\n```\n\n而对于`leaq`操作，则是直接将某个内存的地址值拷贝到寄存器或者其他内存，那么目标寄存器或者内存就会保存另外一个内存的指针，比如下面这个操作，`leaq`是直接把`%rdi`保存的值拷贝到`%rax`寄存器，那么`%rax`和`rdi`同时都保存了某个内存地址：\n\n```assembly\nleaq\t(%rdi), %rax\n```\n\n该操作就是C语言中`int a = &b`这个操作的具体实现，将某个变量的指针取出来存到另一个变量中，因此`leaq`操作就叫做`加载有效地址`，需要注意的是`leaq`没有其他不同大小的操作数，在x86-64中只加载8字节数，因为内存地址的大小就是8字节\n\n##### leaq执行有限加法和乘法\n\n由于`leaq`计算内存地址的功能，因此可以基于内存地址计算过程来进行一些简单的加法和乘法操作，某些简单的C语言加减乘操作会被编译为多个`leaq`的汇编指令，比如如下操作：\n\n```c\nlong t = x + 4 * y + 12 * z\n```\n\n会被gcc编译器编译为如下的汇编指令：\n\n```assembly\nx in %rdi, y in %rsi, z in %rdx\n\nleaq\t(%rdi, %rsi, 4), %rax\t// x + 4 * y\nleaq\t(%rdx, %rdx, 2), %rdx\t// z + 2 * z = 3 * z\nleaq\t(%rax, %rdx, 4), %rax\t// (x + 4 * y) + 4 * (3 * z) = x + 4 * y + 12 * z\n```\n\n#### 一元操作\n\n一元操作只有一个操作数，既是源又是目的地，操作数可以是寄存器，也可以是内存地址，比如自增操作或者取反操作，是直接改变的当前位置的数据，没有拷贝操作\n\n内存操作，`%rax`存储值为0x100，内存0x110处存储的值为0x13：\n\n```assembly\nincq\t16(%rax)\t//结果为0x13 + 0x1 = 0x14\n```\n\n寄存器操作，`%rcx`存储值为0x1：\n\n```assembly\ndecq\t%rcx\t//结果为0x0\n```\n\n#### 二元操作\n\n像加减乘和异或这样的操作就属于二元操作，二元操作相对来说要复杂一些，不仅有两个操作数，而且操作过程也比较反直觉\n\n在二元操作中，第二个操作数即是源又是目的，比如对于操作`subq %rax,%rdx`，操作过程是将`%rdx`减去`%rax`的值，然后再把结果存入`%rdx`，有点类似于`x-=y`这样的操作，x就是`%rdx`，y就是`%rax`\n\n二元操作中，第一个操作数可以是立即数，第二个操作数不能是立即数，只能是寄存器或者内存地址\n\n内存和寄存器的二元操作，其中`%rax`的值为0x100，`%rdx`的值为0x3，内存0x108处的值为0xAB，求以下操作的结果\n\n```assembly\nsubq\t%rdx, 8(%rax)\t//先找到源操作数8(%rax)也就是0x108位置的数0xAB，然后再减去0x3\n\t\t\t\t\t\t//最后结果即为0xA8，将结果再存回0x108\n```\n\n#### 移位操作\n\n移位操作中，第一个操作数是移位量，可以是立即数或者单字节寄存器`%c1`\n\n第二个操作数是要移位的数，即是源也是目的地，可以是寄存器也可以是内存地址\n\n移位操作大致上分为两种：`左移位`，`右移位`\n\n具体还能分位`算术移位`或者`逻辑移位`，其中`算术左移`和`逻辑左移`没有区别，空出来的位都填充为0\n\n`算术右移`和`逻辑右移`的区别在于：`算术右移`空出来的高位全部填充符号位，而`逻辑右移`空出来的高位全部填充为0\n\n### 控制语句的实现\n\n程序中的条件，循环和分支语句，需要有条件的执行，此时就不能按照传统方式将指令一条接一条地执行，而是需要根据条件从当前指令跳转到其他指令进行执行\n\n计算机提供了两种机制来实现指令的有条件跳转：\n\n1. 测试数据值\n2. 根据测试结果改变控制流或数据流\n\n#### 条件码寄存器\n\nCPU维护了一种单个位`条件码`寄存器，这种寄存器只有0和1两种值，保存最近的运算操作产生结果的状态，通过检测这些寄存器来执行条件分支的跳转指令：\n\n1. CF：进位标志，最近的操作是否使最高位产生了进位（无符号溢出）\n2. ZF：零标志，最近的操作结果是否为0\n3. SF：符号标志，最近的操作结果是否为负数\n4. OF：溢出标志，与CF的区别是OF是有符号的补码溢出\n\n之前描述的所有算术和逻辑运算指令在计算结果后，都会同时设置`条件码`\n\n除此之外还有两个指令是专门用于设置`条件码`寄存器，而不会改变操作数：\n\n1. CMP指令：CMP指令的操作和`SUB`指令都是一样的，都是做减法，不过CMP指令只修改条件码寄存器（ZF或者SF），用以比较两个数的大小，而不用修改任何一个操作数\n2. TEST指令：TEST指令的操作和`AND`指令是一样的，都是作`&`操作，可以用来判断某数的符号\n\n#### 如何访问条件码\n\n条件码设置好后，需要读取条件码的状态来决定如何跳转","slug":"《深入理解计算机系统》读书笔记——Chapter-3-2","published":1,"updated":"2019-10-07T07:48:39.948Z","_id":"ckf0h31ie0020actsihar3mbt","comments":1,"layout":"post","photos":[],"link":"","content":"<p>第三章：<code>程序的机器级表示</code></p>\n<p>第三章读书笔记第二部分，本部分主要了解：</p>\n<ol>\n<li>计算机中算术和逻辑操作在机器层面的具体实现</li>\n<li>计算机中控制语句（条件和循环，还有switch）的具体实现</li>\n<li>计算机中函数执行过程的具体实现，包括运行时栈的实现，局部变量存储以及递归的实现<a id=\"more\"></a>\n</li>\n</ol>\n<h3 id=\"算术和逻辑运算\"><a href=\"#算术和逻辑运算\" class=\"headerlink\" title=\"算术和逻辑运算\"></a>算术和逻辑运算</h3><p>算术和逻辑操作包括加减乘除还有移位等操作，这些操作分为<code>加载有效地址</code>，<code>一元操作</code>（只有一个操作数），<code>二元操作</code>（有两个操作数）和<code>移位操作</code>，一共四大类，基本上囊括了计算机系统中所有基本操作指令</p>\n<h4 id=\"加载有效地址：leaq\"><a href=\"#加载有效地址：leaq\" class=\"headerlink\" title=\"加载有效地址：leaq\"></a>加载有效地址：leaq</h4><p><code>leaq (load effective address)</code>操作是一种特殊的运算操作，该操作是<code>mov</code>操作的一个变种，但是对于<code>mov</code>，像下面这种操作是引用了内存地址，<code>%rdi</code>寄存器保存了某个变量的内存地址，<code>mov</code>根据这个地址去内存找相应的值然后拷贝到<code>%rax</code>寄存器上：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">movq\t(%rdi), %rax</span><br></pre></td></tr></table></figure>\n<p>而对于<code>leaq</code>操作，则是直接将某个内存的地址值拷贝到寄存器或者其他内存，那么目标寄存器或者内存就会保存另外一个内存的指针，比如下面这个操作，<code>leaq</code>是直接把<code>%rdi</code>保存的值拷贝到<code>%rax</code>寄存器，那么<code>%rax</code>和<code>rdi</code>同时都保存了某个内存地址：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">leaq\t(%rdi), %rax</span><br></pre></td></tr></table></figure>\n<p>该操作就是C语言中<code>int a = &amp;b</code>这个操作的具体实现，将某个变量的指针取出来存到另一个变量中，因此<code>leaq</code>操作就叫做<code>加载有效地址</code>，需要注意的是<code>leaq</code>没有其他不同大小的操作数，在x86-64中只加载8字节数，因为内存地址的大小就是8字节</p>\n<h5 id=\"leaq执行有限加法和乘法\"><a href=\"#leaq执行有限加法和乘法\" class=\"headerlink\" title=\"leaq执行有限加法和乘法\"></a>leaq执行有限加法和乘法</h5><p>由于<code>leaq</code>计算内存地址的功能，因此可以基于内存地址计算过程来进行一些简单的加法和乘法操作，某些简单的C语言加减乘操作会被编译为多个<code>leaq</code>的汇编指令，比如如下操作：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">long</span> t = x + <span class=\"number\">4</span> * y + <span class=\"number\">12</span> * z</span><br></pre></td></tr></table></figure>\n<p>会被gcc编译器编译为如下的汇编指令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x in %rdi, y in %rsi, z in %rdx</span><br><span class=\"line\"></span><br><span class=\"line\">leaq\t(%rdi, %rsi, 4), %rax\t// x + 4 * y</span><br><span class=\"line\">leaq\t(%rdx, %rdx, 2), %rdx\t// z + 2 * z = 3 * z</span><br><span class=\"line\">leaq\t(%rax, %rdx, 4), %rax\t// (x + 4 * y) + 4 * (3 * z) = x + 4 * y + 12 * z</span><br></pre></td></tr></table></figure>\n<h4 id=\"一元操作\"><a href=\"#一元操作\" class=\"headerlink\" title=\"一元操作\"></a>一元操作</h4><p>一元操作只有一个操作数，既是源又是目的地，操作数可以是寄存器，也可以是内存地址，比如自增操作或者取反操作，是直接改变的当前位置的数据，没有拷贝操作</p>\n<p>内存操作，<code>%rax</code>存储值为0x100，内存0x110处存储的值为0x13：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">incq\t16(%rax)\t//结果为0x13 + 0x1 = 0x14</span><br></pre></td></tr></table></figure>\n<p>寄存器操作，<code>%rcx</code>存储值为0x1：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">decq\t%rcx\t//结果为0x0</span><br></pre></td></tr></table></figure>\n<h4 id=\"二元操作\"><a href=\"#二元操作\" class=\"headerlink\" title=\"二元操作\"></a>二元操作</h4><p>像加减乘和异或这样的操作就属于二元操作，二元操作相对来说要复杂一些，不仅有两个操作数，而且操作过程也比较反直觉</p>\n<p>在二元操作中，第二个操作数即是源又是目的，比如对于操作<code>subq %rax,%rdx</code>，操作过程是将<code>%rdx</code>减去<code>%rax</code>的值，然后再把结果存入<code>%rdx</code>，有点类似于<code>x-=y</code>这样的操作，x就是<code>%rdx</code>，y就是<code>%rax</code></p>\n<p>二元操作中，第一个操作数可以是立即数，第二个操作数不能是立即数，只能是寄存器或者内存地址</p>\n<p>内存和寄存器的二元操作，其中<code>%rax</code>的值为0x100，<code>%rdx</code>的值为0x3，内存0x108处的值为0xAB，求以下操作的结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">subq\t%rdx, 8(%rax)\t//先找到源操作数8(%rax)也就是0x108位置的数0xAB，然后再减去0x3</span><br><span class=\"line\">\t\t\t\t\t\t//最后结果即为0xA8，将结果再存回0x108</span><br></pre></td></tr></table></figure>\n<h4 id=\"移位操作\"><a href=\"#移位操作\" class=\"headerlink\" title=\"移位操作\"></a>移位操作</h4><p>移位操作中，第一个操作数是移位量，可以是立即数或者单字节寄存器<code>%c1</code></p>\n<p>第二个操作数是要移位的数，即是源也是目的地，可以是寄存器也可以是内存地址</p>\n<p>移位操作大致上分为两种：<code>左移位</code>，<code>右移位</code></p>\n<p>具体还能分位<code>算术移位</code>或者<code>逻辑移位</code>，其中<code>算术左移</code>和<code>逻辑左移</code>没有区别，空出来的位都填充为0</p>\n<p><code>算术右移</code>和<code>逻辑右移</code>的区别在于：<code>算术右移</code>空出来的高位全部填充符号位，而<code>逻辑右移</code>空出来的高位全部填充为0</p>\n<h3 id=\"控制语句的实现\"><a href=\"#控制语句的实现\" class=\"headerlink\" title=\"控制语句的实现\"></a>控制语句的实现</h3><p>程序中的条件，循环和分支语句，需要有条件的执行，此时就不能按照传统方式将指令一条接一条地执行，而是需要根据条件从当前指令跳转到其他指令进行执行</p>\n<p>计算机提供了两种机制来实现指令的有条件跳转：</p>\n<ol>\n<li>测试数据值</li>\n<li>根据测试结果改变控制流或数据流</li>\n</ol>\n<h4 id=\"条件码寄存器\"><a href=\"#条件码寄存器\" class=\"headerlink\" title=\"条件码寄存器\"></a>条件码寄存器</h4><p>CPU维护了一种单个位<code>条件码</code>寄存器，这种寄存器只有0和1两种值，保存最近的运算操作产生结果的状态，通过检测这些寄存器来执行条件分支的跳转指令：</p>\n<ol>\n<li>CF：进位标志，最近的操作是否使最高位产生了进位（无符号溢出）</li>\n<li>ZF：零标志，最近的操作结果是否为0</li>\n<li>SF：符号标志，最近的操作结果是否为负数</li>\n<li>OF：溢出标志，与CF的区别是OF是有符号的补码溢出</li>\n</ol>\n<p>之前描述的所有算术和逻辑运算指令在计算结果后，都会同时设置<code>条件码</code></p>\n<p>除此之外还有两个指令是专门用于设置<code>条件码</code>寄存器，而不会改变操作数：</p>\n<ol>\n<li>CMP指令：CMP指令的操作和<code>SUB</code>指令都是一样的，都是做减法，不过CMP指令只修改条件码寄存器（ZF或者SF），用以比较两个数的大小，而不用修改任何一个操作数</li>\n<li>TEST指令：TEST指令的操作和<code>AND</code>指令是一样的，都是作<code>&amp;</code>操作，可以用来判断某数的符号</li>\n</ol>\n<h4 id=\"如何访问条件码\"><a href=\"#如何访问条件码\" class=\"headerlink\" title=\"如何访问条件码\"></a>如何访问条件码</h4><p>条件码设置好后，需要读取条件码的状态来决定如何跳转</p>\n","site":{"data":{}},"excerpt":"<p>第三章：<code>程序的机器级表示</code></p>\n<p>第三章读书笔记第二部分，本部分主要了解：</p>\n<ol>\n<li>计算机中算术和逻辑操作在机器层面的具体实现</li>\n<li>计算机中控制语句（条件和循环，还有switch）的具体实现</li>\n<li>计算机中函数执行过程的具体实现，包括运行时栈的实现，局部变量存储以及递归的实现","more":"</li>\n</ol>\n<h3 id=\"算术和逻辑运算\"><a href=\"#算术和逻辑运算\" class=\"headerlink\" title=\"算术和逻辑运算\"></a>算术和逻辑运算</h3><p>算术和逻辑操作包括加减乘除还有移位等操作，这些操作分为<code>加载有效地址</code>，<code>一元操作</code>（只有一个操作数），<code>二元操作</code>（有两个操作数）和<code>移位操作</code>，一共四大类，基本上囊括了计算机系统中所有基本操作指令</p>\n<h4 id=\"加载有效地址：leaq\"><a href=\"#加载有效地址：leaq\" class=\"headerlink\" title=\"加载有效地址：leaq\"></a>加载有效地址：leaq</h4><p><code>leaq (load effective address)</code>操作是一种特殊的运算操作，该操作是<code>mov</code>操作的一个变种，但是对于<code>mov</code>，像下面这种操作是引用了内存地址，<code>%rdi</code>寄存器保存了某个变量的内存地址，<code>mov</code>根据这个地址去内存找相应的值然后拷贝到<code>%rax</code>寄存器上：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">movq\t(%rdi), %rax</span><br></pre></td></tr></table></figure>\n<p>而对于<code>leaq</code>操作，则是直接将某个内存的地址值拷贝到寄存器或者其他内存，那么目标寄存器或者内存就会保存另外一个内存的指针，比如下面这个操作，<code>leaq</code>是直接把<code>%rdi</code>保存的值拷贝到<code>%rax</code>寄存器，那么<code>%rax</code>和<code>rdi</code>同时都保存了某个内存地址：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">leaq\t(%rdi), %rax</span><br></pre></td></tr></table></figure>\n<p>该操作就是C语言中<code>int a = &amp;b</code>这个操作的具体实现，将某个变量的指针取出来存到另一个变量中，因此<code>leaq</code>操作就叫做<code>加载有效地址</code>，需要注意的是<code>leaq</code>没有其他不同大小的操作数，在x86-64中只加载8字节数，因为内存地址的大小就是8字节</p>\n<h5 id=\"leaq执行有限加法和乘法\"><a href=\"#leaq执行有限加法和乘法\" class=\"headerlink\" title=\"leaq执行有限加法和乘法\"></a>leaq执行有限加法和乘法</h5><p>由于<code>leaq</code>计算内存地址的功能，因此可以基于内存地址计算过程来进行一些简单的加法和乘法操作，某些简单的C语言加减乘操作会被编译为多个<code>leaq</code>的汇编指令，比如如下操作：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">long</span> t = x + <span class=\"number\">4</span> * y + <span class=\"number\">12</span> * z</span><br></pre></td></tr></table></figure>\n<p>会被gcc编译器编译为如下的汇编指令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x in %rdi, y in %rsi, z in %rdx</span><br><span class=\"line\"></span><br><span class=\"line\">leaq\t(%rdi, %rsi, 4), %rax\t// x + 4 * y</span><br><span class=\"line\">leaq\t(%rdx, %rdx, 2), %rdx\t// z + 2 * z = 3 * z</span><br><span class=\"line\">leaq\t(%rax, %rdx, 4), %rax\t// (x + 4 * y) + 4 * (3 * z) = x + 4 * y + 12 * z</span><br></pre></td></tr></table></figure>\n<h4 id=\"一元操作\"><a href=\"#一元操作\" class=\"headerlink\" title=\"一元操作\"></a>一元操作</h4><p>一元操作只有一个操作数，既是源又是目的地，操作数可以是寄存器，也可以是内存地址，比如自增操作或者取反操作，是直接改变的当前位置的数据，没有拷贝操作</p>\n<p>内存操作，<code>%rax</code>存储值为0x100，内存0x110处存储的值为0x13：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">incq\t16(%rax)\t//结果为0x13 + 0x1 = 0x14</span><br></pre></td></tr></table></figure>\n<p>寄存器操作，<code>%rcx</code>存储值为0x1：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">decq\t%rcx\t//结果为0x0</span><br></pre></td></tr></table></figure>\n<h4 id=\"二元操作\"><a href=\"#二元操作\" class=\"headerlink\" title=\"二元操作\"></a>二元操作</h4><p>像加减乘和异或这样的操作就属于二元操作，二元操作相对来说要复杂一些，不仅有两个操作数，而且操作过程也比较反直觉</p>\n<p>在二元操作中，第二个操作数即是源又是目的，比如对于操作<code>subq %rax,%rdx</code>，操作过程是将<code>%rdx</code>减去<code>%rax</code>的值，然后再把结果存入<code>%rdx</code>，有点类似于<code>x-=y</code>这样的操作，x就是<code>%rdx</code>，y就是<code>%rax</code></p>\n<p>二元操作中，第一个操作数可以是立即数，第二个操作数不能是立即数，只能是寄存器或者内存地址</p>\n<p>内存和寄存器的二元操作，其中<code>%rax</code>的值为0x100，<code>%rdx</code>的值为0x3，内存0x108处的值为0xAB，求以下操作的结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">subq\t%rdx, 8(%rax)\t//先找到源操作数8(%rax)也就是0x108位置的数0xAB，然后再减去0x3</span><br><span class=\"line\">\t\t\t\t\t\t//最后结果即为0xA8，将结果再存回0x108</span><br></pre></td></tr></table></figure>\n<h4 id=\"移位操作\"><a href=\"#移位操作\" class=\"headerlink\" title=\"移位操作\"></a>移位操作</h4><p>移位操作中，第一个操作数是移位量，可以是立即数或者单字节寄存器<code>%c1</code></p>\n<p>第二个操作数是要移位的数，即是源也是目的地，可以是寄存器也可以是内存地址</p>\n<p>移位操作大致上分为两种：<code>左移位</code>，<code>右移位</code></p>\n<p>具体还能分位<code>算术移位</code>或者<code>逻辑移位</code>，其中<code>算术左移</code>和<code>逻辑左移</code>没有区别，空出来的位都填充为0</p>\n<p><code>算术右移</code>和<code>逻辑右移</code>的区别在于：<code>算术右移</code>空出来的高位全部填充符号位，而<code>逻辑右移</code>空出来的高位全部填充为0</p>\n<h3 id=\"控制语句的实现\"><a href=\"#控制语句的实现\" class=\"headerlink\" title=\"控制语句的实现\"></a>控制语句的实现</h3><p>程序中的条件，循环和分支语句，需要有条件的执行，此时就不能按照传统方式将指令一条接一条地执行，而是需要根据条件从当前指令跳转到其他指令进行执行</p>\n<p>计算机提供了两种机制来实现指令的有条件跳转：</p>\n<ol>\n<li>测试数据值</li>\n<li>根据测试结果改变控制流或数据流</li>\n</ol>\n<h4 id=\"条件码寄存器\"><a href=\"#条件码寄存器\" class=\"headerlink\" title=\"条件码寄存器\"></a>条件码寄存器</h4><p>CPU维护了一种单个位<code>条件码</code>寄存器，这种寄存器只有0和1两种值，保存最近的运算操作产生结果的状态，通过检测这些寄存器来执行条件分支的跳转指令：</p>\n<ol>\n<li>CF：进位标志，最近的操作是否使最高位产生了进位（无符号溢出）</li>\n<li>ZF：零标志，最近的操作结果是否为0</li>\n<li>SF：符号标志，最近的操作结果是否为负数</li>\n<li>OF：溢出标志，与CF的区别是OF是有符号的补码溢出</li>\n</ol>\n<p>之前描述的所有算术和逻辑运算指令在计算结果后，都会同时设置<code>条件码</code></p>\n<p>除此之外还有两个指令是专门用于设置<code>条件码</code>寄存器，而不会改变操作数：</p>\n<ol>\n<li>CMP指令：CMP指令的操作和<code>SUB</code>指令都是一样的，都是做减法，不过CMP指令只修改条件码寄存器（ZF或者SF），用以比较两个数的大小，而不用修改任何一个操作数</li>\n<li>TEST指令：TEST指令的操作和<code>AND</code>指令是一样的，都是作<code>&amp;</code>操作，可以用来判断某数的符号</li>\n</ol>\n<h4 id=\"如何访问条件码\"><a href=\"#如何访问条件码\" class=\"headerlink\" title=\"如何访问条件码\"></a>如何访问条件码</h4><p>条件码设置好后，需要读取条件码的状态来决定如何跳转</p>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 2(2)","author":"天渊","date":"2019-09-11T06:53:00.000Z","_content":"第二章`信息的表示和处理` 第二部分读书笔记\n\n第二部分是对整数的运算规则和浮点数的表示做一些讲解\n<!--more-->\n\n目录：\n\n- 整数运算\n- 浮点\n\n\n### 整数运算\n\n#### 无符号加法\n\n使用无符号加法需要注意溢出的情况，下列无符号short求和最后结果就发生了溢出，同样产生了截断，实际结果比理想的结果少了2^16^\n\n```c\nunsigned short c = 44444 + 22222;\nprintf(\"a is %u, b is %u, result is %u\", a, b, c);\n```\n\n最后结果为1130，想要的结果是66666\n\n#### 补码加法\n\n大部分时间进行数值计算都是对补码进行操作，在进行补码加法时需要考虑当结果太大或者太小时会不会发生溢出的情况\n\n与无符号加法类似，如果加法结果超过当前数值类型的位数范围时会发生正溢出（太大）或者负溢出（太小）：\n\n![](http://img.mantian.site/201909101634_839.png)\n\n```c\nshort c = -22222 + (-22222);\nprintf(\"a is %u, b is %u, result is %u\", a, b, c);\n```\n\n其结果为21092，发生了负溢出，其结果比想要的结果大了65536，也就是2^16^\n\n以下函数无法判断两个有符号补码数相加是否发生了溢出：\n\n```c\nint check_overflow_short_add(int a, int b) {\n    int c = a + b;\n    return (c - a) == b && (c - b) == a;\n}\n```\n\n两个补码a和b相加得到结果c，不管有没有溢出，c-a的结果始终还是b，c-b的结果始终还是a\n\n#### 无符号乘法\n\n无符号乘法也存在高位截断的问题：\n\n```c\nunsigned short a = 222;\nunsigned short b = 333;\nunsigned short c = a * b;\nprintf(\"%d\", c);\n```\n\n理想结果为73926，实际得到的结果为8390，说明溢出的部分被截断了，只剩下了低16位的数据，也就是少了2^16^\n\n#### 补码乘法\n\n补码乘法与无符号乘法差不多，与补码加法一样也需要注意正溢出和负溢出截断的问题\n\n#### 对于某些常数乘法的优化\n\n乘法运算在大多数计算机上都是一个相当慢的运算，需要消耗过多的时钟周期，因此编译器对常数乘法运算会进行一些优化，用移位或者加法运算来代替常数因子的乘法运算\n\n`移位优化`：某个数与2的幂作乘法就可以进行移位运算，`X * 2^k`就可以直接将X左移k位\n\n`加法优化`：将乘数拆散为2的幂次的和，比如`X * 14`就可以拆为`X * (2^3 + 2^2 + 2)`，然后再用移位计算各个部分的值，最后再统一相加\n\n### 浮点数\n\n现代计算机采用`IEEE浮点数标准`来处理带小数点的数字\n\n#### 二进制表示小数\n\n与整数的二进制表示法类似，带小数的数字是用2的负幂次叠加来进行表示，比如5.75就可以拆散为：\n\n`4 + 0 + 1 + 1/2 + 1/4`，用二进制进行表示就是：`101.11`\n\n二进制用以下规则表示带小数的数字，整数部分就是2的正幂次，小数部分就是2的负幂次：\n\n![](http://img.mantian.site/201909111019_571.png)\n\n**缺陷**：可以看出，二进制表示小数无法做到像十进制这么精确，像1/5这种小数通过十进制可以表示为0.2，但是用二进制的话只能通过增加二进制小数位数构造一个近似值来逼近，例如`0.00110011`这个二进制小数转换为十进制是`0.19921875`，已经很接近了\n\n#### IEEE浮点数表示法\n\n在二进制定点表示法的基础上，IEEE标准用以下公式来存储一个浮点数：\n\n<img src=\"http://img.mantian.site/201909111339_460.png\" style=\"zoom: 67%;\" />\n\n各个参数解释如下：\n\n- `s`：符号标记，无论是float还是double类型都是有符号数，s为1则表示负数，s为0表示正数\n- `M`：尾数，保存浮点数的实际有效位，其大小是`1 <= M < 2`，以`1.1101`这样的形式展示；不过存储的时候会省略小数点左边的1，只存储右边的位，我们把保留下来的小数点右边的位称为`f`\n- `E`：阶码，对尾数M进行加权，判断M的小数点需要左移或者右移多少位，最终计算得到真正的浮点数二进制表示\n\n计算机系统保存浮点数就是对这三个参数分别进行编码保存到固定的位数中，float类型保存到32位长度中，double类型则保存到64位长度中\n\n**float & double**：单精度浮点（float）和双精度浮点（double）除了最高位的符号位s，剩下的区别主要体现在对M和E的保存位数不一样：\n\n- `float`：E取8位，M取23位\n- `double`：E取11位，M取52位\n\n以32位的float为例讲一下编码保存各个参数的规则：\n\n- 编码s：保存为1或者0\n- 编码E：E的值即要表现2的正幂次，也要表现2的负幂次，而编码保存后的八位数`e`只能是无符号整数，范围是0 ~ 2^8^-1=255，因此E的真实取值范围需要在这个基础上做一个2^7^-1=127的偏移处理，也就是说`e = E + 127`\n- 编码M：省略掉M小数点左边的1，只保留小数点右边的23位，也就是`f`\n\n基于这个基本表示规则，有四种不同的情况，以32位float为例：\n\n- `E编码保存的值(e)不为0或者255(2^8-1)`：这种情况即为普通情况，E的取值范围是`-126 ~ 127`\n- `e所有位都为0`：称为非规格化值，规定这种情况在解码时舍弃掉M小数点左边的1，只保留`f`；这种情况一般时拿来表示正0或者负0，或者非常逼近于0的小数\n- `e所有位都为1 & f所有位为0`：无穷大数，s为1是负无穷，s为0是正无穷\n- `e所有位都为1 & f不为0`：NaN，用来表现不是数字（无意义的数字）的情况\n\n**例子**：以float类型`1.25`为例，计算机系统中使用32位二进制`00111111101000000000000000000000`来保存1.25\n\n<img src=\"http://img.mantian.site/201909111448_137.png\" style=\"zoom:75%;\" />\n\n如图：\n\n1. 符号位s为0，表示正数\n2. 阶码位e有8位，其值是127，因此`E = 127 - 127 = 0`，阶码E为0\n3. 尾数位f有23位，其值是二进制0.01，也就是1/(2^2^) = 1/4\n\n最终值`V = 1 * (1/(2^2)) * 1 = 1.25`","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-2-2.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 2(2)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-09-11 14:53:00\n---\n第二章`信息的表示和处理` 第二部分读书笔记\n\n第二部分是对整数的运算规则和浮点数的表示做一些讲解\n<!--more-->\n\n目录：\n\n- 整数运算\n- 浮点\n\n\n### 整数运算\n\n#### 无符号加法\n\n使用无符号加法需要注意溢出的情况，下列无符号short求和最后结果就发生了溢出，同样产生了截断，实际结果比理想的结果少了2^16^\n\n```c\nunsigned short c = 44444 + 22222;\nprintf(\"a is %u, b is %u, result is %u\", a, b, c);\n```\n\n最后结果为1130，想要的结果是66666\n\n#### 补码加法\n\n大部分时间进行数值计算都是对补码进行操作，在进行补码加法时需要考虑当结果太大或者太小时会不会发生溢出的情况\n\n与无符号加法类似，如果加法结果超过当前数值类型的位数范围时会发生正溢出（太大）或者负溢出（太小）：\n\n![](http://img.mantian.site/201909101634_839.png)\n\n```c\nshort c = -22222 + (-22222);\nprintf(\"a is %u, b is %u, result is %u\", a, b, c);\n```\n\n其结果为21092，发生了负溢出，其结果比想要的结果大了65536，也就是2^16^\n\n以下函数无法判断两个有符号补码数相加是否发生了溢出：\n\n```c\nint check_overflow_short_add(int a, int b) {\n    int c = a + b;\n    return (c - a) == b && (c - b) == a;\n}\n```\n\n两个补码a和b相加得到结果c，不管有没有溢出，c-a的结果始终还是b，c-b的结果始终还是a\n\n#### 无符号乘法\n\n无符号乘法也存在高位截断的问题：\n\n```c\nunsigned short a = 222;\nunsigned short b = 333;\nunsigned short c = a * b;\nprintf(\"%d\", c);\n```\n\n理想结果为73926，实际得到的结果为8390，说明溢出的部分被截断了，只剩下了低16位的数据，也就是少了2^16^\n\n#### 补码乘法\n\n补码乘法与无符号乘法差不多，与补码加法一样也需要注意正溢出和负溢出截断的问题\n\n#### 对于某些常数乘法的优化\n\n乘法运算在大多数计算机上都是一个相当慢的运算，需要消耗过多的时钟周期，因此编译器对常数乘法运算会进行一些优化，用移位或者加法运算来代替常数因子的乘法运算\n\n`移位优化`：某个数与2的幂作乘法就可以进行移位运算，`X * 2^k`就可以直接将X左移k位\n\n`加法优化`：将乘数拆散为2的幂次的和，比如`X * 14`就可以拆为`X * (2^3 + 2^2 + 2)`，然后再用移位计算各个部分的值，最后再统一相加\n\n### 浮点数\n\n现代计算机采用`IEEE浮点数标准`来处理带小数点的数字\n\n#### 二进制表示小数\n\n与整数的二进制表示法类似，带小数的数字是用2的负幂次叠加来进行表示，比如5.75就可以拆散为：\n\n`4 + 0 + 1 + 1/2 + 1/4`，用二进制进行表示就是：`101.11`\n\n二进制用以下规则表示带小数的数字，整数部分就是2的正幂次，小数部分就是2的负幂次：\n\n![](http://img.mantian.site/201909111019_571.png)\n\n**缺陷**：可以看出，二进制表示小数无法做到像十进制这么精确，像1/5这种小数通过十进制可以表示为0.2，但是用二进制的话只能通过增加二进制小数位数构造一个近似值来逼近，例如`0.00110011`这个二进制小数转换为十进制是`0.19921875`，已经很接近了\n\n#### IEEE浮点数表示法\n\n在二进制定点表示法的基础上，IEEE标准用以下公式来存储一个浮点数：\n\n<img src=\"http://img.mantian.site/201909111339_460.png\" style=\"zoom: 67%;\" />\n\n各个参数解释如下：\n\n- `s`：符号标记，无论是float还是double类型都是有符号数，s为1则表示负数，s为0表示正数\n- `M`：尾数，保存浮点数的实际有效位，其大小是`1 <= M < 2`，以`1.1101`这样的形式展示；不过存储的时候会省略小数点左边的1，只存储右边的位，我们把保留下来的小数点右边的位称为`f`\n- `E`：阶码，对尾数M进行加权，判断M的小数点需要左移或者右移多少位，最终计算得到真正的浮点数二进制表示\n\n计算机系统保存浮点数就是对这三个参数分别进行编码保存到固定的位数中，float类型保存到32位长度中，double类型则保存到64位长度中\n\n**float & double**：单精度浮点（float）和双精度浮点（double）除了最高位的符号位s，剩下的区别主要体现在对M和E的保存位数不一样：\n\n- `float`：E取8位，M取23位\n- `double`：E取11位，M取52位\n\n以32位的float为例讲一下编码保存各个参数的规则：\n\n- 编码s：保存为1或者0\n- 编码E：E的值即要表现2的正幂次，也要表现2的负幂次，而编码保存后的八位数`e`只能是无符号整数，范围是0 ~ 2^8^-1=255，因此E的真实取值范围需要在这个基础上做一个2^7^-1=127的偏移处理，也就是说`e = E + 127`\n- 编码M：省略掉M小数点左边的1，只保留小数点右边的23位，也就是`f`\n\n基于这个基本表示规则，有四种不同的情况，以32位float为例：\n\n- `E编码保存的值(e)不为0或者255(2^8-1)`：这种情况即为普通情况，E的取值范围是`-126 ~ 127`\n- `e所有位都为0`：称为非规格化值，规定这种情况在解码时舍弃掉M小数点左边的1，只保留`f`；这种情况一般时拿来表示正0或者负0，或者非常逼近于0的小数\n- `e所有位都为1 & f所有位为0`：无穷大数，s为1是负无穷，s为0是正无穷\n- `e所有位都为1 & f不为0`：NaN，用来表现不是数字（无意义的数字）的情况\n\n**例子**：以float类型`1.25`为例，计算机系统中使用32位二进制`00111111101000000000000000000000`来保存1.25\n\n<img src=\"http://img.mantian.site/201909111448_137.png\" style=\"zoom:75%;\" />\n\n如图：\n\n1. 符号位s为0，表示正数\n2. 阶码位e有8位，其值是127，因此`E = 127 - 127 = 0`，阶码E为0\n3. 尾数位f有23位，其值是二进制0.01，也就是1/(2^2^) = 1/4\n\n最终值`V = 1 * (1/(2^2)) * 1 = 1.25`","slug":"《深入理解计算机系统》读书笔记——Chapter-2-2","published":1,"updated":"2021-05-31T03:06:33.199Z","_id":"ckf0h31if0023acts9218e886","comments":1,"layout":"post","photos":[],"link":"","content":"<p>第二章<code>信息的表示和处理</code> 第二部分读书笔记</p>\n<p>第二部分是对整数的运算规则和浮点数的表示做一些讲解<br><a id=\"more\"></a></p>\n<p>目录：</p>\n<ul>\n<li>整数运算</li>\n<li>浮点</li>\n</ul>\n<h3 id=\"整数运算\"><a href=\"#整数运算\" class=\"headerlink\" title=\"整数运算\"></a>整数运算</h3><h4 id=\"无符号加法\"><a href=\"#无符号加法\" class=\"headerlink\" title=\"无符号加法\"></a>无符号加法</h4><p>使用无符号加法需要注意溢出的情况，下列无符号short求和最后结果就发生了溢出，同样产生了截断，实际结果比理想的结果少了2^16^</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> c = <span class=\"number\">44444</span> + <span class=\"number\">22222</span>;</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"a is %u, b is %u, result is %u\"</span>, a, b, c);</span><br></pre></td></tr></table></figure>\n<p>最后结果为1130，想要的结果是66666</p>\n<h4 id=\"补码加法\"><a href=\"#补码加法\" class=\"headerlink\" title=\"补码加法\"></a>补码加法</h4><p>大部分时间进行数值计算都是对补码进行操作，在进行补码加法时需要考虑当结果太大或者太小时会不会发生溢出的情况</p>\n<p>与无符号加法类似，如果加法结果超过当前数值类型的位数范围时会发生正溢出（太大）或者负溢出（太小）：</p>\n<p><img src=\"http://img.mantian.site/201909101634_839.png\" alt></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">short</span> c = <span class=\"number\">-22222</span> + (<span class=\"number\">-22222</span>);</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"a is %u, b is %u, result is %u\"</span>, a, b, c);</span><br></pre></td></tr></table></figure>\n<p>其结果为21092，发生了负溢出，其结果比想要的结果大了65536，也就是2^16^</p>\n<p>以下函数无法判断两个有符号补码数相加是否发生了溢出：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">check_overflow_short_add</span><span class=\"params\">(<span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> c = a + b;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (c - a) == b &amp;&amp; (c - b) == a;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>两个补码a和b相加得到结果c，不管有没有溢出，c-a的结果始终还是b，c-b的结果始终还是a</p>\n<h4 id=\"无符号乘法\"><a href=\"#无符号乘法\" class=\"headerlink\" title=\"无符号乘法\"></a>无符号乘法</h4><p>无符号乘法也存在高位截断的问题：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> a = <span class=\"number\">222</span>;</span><br><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> b = <span class=\"number\">333</span>;</span><br><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> c = a * b;</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\"</span>, c);</span><br></pre></td></tr></table></figure>\n<p>理想结果为73926，实际得到的结果为8390，说明溢出的部分被截断了，只剩下了低16位的数据，也就是少了2^16^</p>\n<h4 id=\"补码乘法\"><a href=\"#补码乘法\" class=\"headerlink\" title=\"补码乘法\"></a>补码乘法</h4><p>补码乘法与无符号乘法差不多，与补码加法一样也需要注意正溢出和负溢出截断的问题</p>\n<h4 id=\"对于某些常数乘法的优化\"><a href=\"#对于某些常数乘法的优化\" class=\"headerlink\" title=\"对于某些常数乘法的优化\"></a>对于某些常数乘法的优化</h4><p>乘法运算在大多数计算机上都是一个相当慢的运算，需要消耗过多的时钟周期，因此编译器对常数乘法运算会进行一些优化，用移位或者加法运算来代替常数因子的乘法运算</p>\n<p><code>移位优化</code>：某个数与2的幂作乘法就可以进行移位运算，<code>X * 2^k</code>就可以直接将X左移k位</p>\n<p><code>加法优化</code>：将乘数拆散为2的幂次的和，比如<code>X * 14</code>就可以拆为<code>X * (2^3 + 2^2 + 2)</code>，然后再用移位计算各个部分的值，最后再统一相加</p>\n<h3 id=\"浮点数\"><a href=\"#浮点数\" class=\"headerlink\" title=\"浮点数\"></a>浮点数</h3><p>现代计算机采用<code>IEEE浮点数标准</code>来处理带小数点的数字</p>\n<h4 id=\"二进制表示小数\"><a href=\"#二进制表示小数\" class=\"headerlink\" title=\"二进制表示小数\"></a>二进制表示小数</h4><p>与整数的二进制表示法类似，带小数的数字是用2的负幂次叠加来进行表示，比如5.75就可以拆散为：</p>\n<p><code>4 + 0 + 1 + 1/2 + 1/4</code>，用二进制进行表示就是：<code>101.11</code></p>\n<p>二进制用以下规则表示带小数的数字，整数部分就是2的正幂次，小数部分就是2的负幂次：</p>\n<p><img src=\"http://img.mantian.site/201909111019_571.png\" alt></p>\n<p><strong>缺陷</strong>：可以看出，二进制表示小数无法做到像十进制这么精确，像1/5这种小数通过十进制可以表示为0.2，但是用二进制的话只能通过增加二进制小数位数构造一个近似值来逼近，例如<code>0.00110011</code>这个二进制小数转换为十进制是<code>0.19921875</code>，已经很接近了</p>\n<h4 id=\"IEEE浮点数表示法\"><a href=\"#IEEE浮点数表示法\" class=\"headerlink\" title=\"IEEE浮点数表示法\"></a>IEEE浮点数表示法</h4><p>在二进制定点表示法的基础上，IEEE标准用以下公式来存储一个浮点数：</p>\n<p><img src=\"http://img.mantian.site/201909111339_460.png\" style=\"zoom: 67%;\"></p>\n<p>各个参数解释如下：</p>\n<ul>\n<li><code>s</code>：符号标记，无论是float还是double类型都是有符号数，s为1则表示负数，s为0表示正数</li>\n<li><code>M</code>：尾数，保存浮点数的实际有效位，其大小是<code>1 &lt;= M &lt; 2</code>，以<code>1.1101</code>这样的形式展示；不过存储的时候会省略小数点左边的1，只存储右边的位，我们把保留下来的小数点右边的位称为<code>f</code></li>\n<li><code>E</code>：阶码，对尾数M进行加权，判断M的小数点需要左移或者右移多少位，最终计算得到真正的浮点数二进制表示</li>\n</ul>\n<p>计算机系统保存浮点数就是对这三个参数分别进行编码保存到固定的位数中，float类型保存到32位长度中，double类型则保存到64位长度中</p>\n<p><strong>float &amp; double</strong>：单精度浮点（float）和双精度浮点（double）除了最高位的符号位s，剩下的区别主要体现在对M和E的保存位数不一样：</p>\n<ul>\n<li><code>float</code>：E取8位，M取23位</li>\n<li><code>double</code>：E取11位，M取52位</li>\n</ul>\n<p>以32位的float为例讲一下编码保存各个参数的规则：</p>\n<ul>\n<li>编码s：保存为1或者0</li>\n<li>编码E：E的值即要表现2的正幂次，也要表现2的负幂次，而编码保存后的八位数<code>e</code>只能是无符号整数，范围是0 ~ 2^8^-1=255，因此E的真实取值范围需要在这个基础上做一个2^7^-1=127的偏移处理，也就是说<code>e = E + 127</code></li>\n<li>编码M：省略掉M小数点左边的1，只保留小数点右边的23位，也就是<code>f</code></li>\n</ul>\n<p>基于这个基本表示规则，有四种不同的情况，以32位float为例：</p>\n<ul>\n<li><code>E编码保存的值(e)不为0或者255(2^8-1)</code>：这种情况即为普通情况，E的取值范围是<code>-126 ~ 127</code></li>\n<li><code>e所有位都为0</code>：称为非规格化值，规定这种情况在解码时舍弃掉M小数点左边的1，只保留<code>f</code>；这种情况一般时拿来表示正0或者负0，或者非常逼近于0的小数</li>\n<li><code>e所有位都为1 &amp; f所有位为0</code>：无穷大数，s为1是负无穷，s为0是正无穷</li>\n<li><code>e所有位都为1 &amp; f不为0</code>：NaN，用来表现不是数字（无意义的数字）的情况</li>\n</ul>\n<p><strong>例子</strong>：以float类型<code>1.25</code>为例，计算机系统中使用32位二进制<code>00111111101000000000000000000000</code>来保存1.25</p>\n<p><img src=\"http://img.mantian.site/201909111448_137.png\" style=\"zoom:75%;\"></p>\n<p>如图：</p>\n<ol>\n<li>符号位s为0，表示正数</li>\n<li>阶码位e有8位，其值是127，因此<code>E = 127 - 127 = 0</code>，阶码E为0</li>\n<li>尾数位f有23位，其值是二进制0.01，也就是1/(2^2^) = 1/4</li>\n</ol>\n<p>最终值<code>V = 1 * (1/(2^2)) * 1 = 1.25</code></p>\n","site":{"data":{}},"excerpt":"<p>第二章<code>信息的表示和处理</code> 第二部分读书笔记</p>\n<p>第二部分是对整数的运算规则和浮点数的表示做一些讲解<br>","more":"</p>\n<p>目录：</p>\n<ul>\n<li>整数运算</li>\n<li>浮点</li>\n</ul>\n<h3 id=\"整数运算\"><a href=\"#整数运算\" class=\"headerlink\" title=\"整数运算\"></a>整数运算</h3><h4 id=\"无符号加法\"><a href=\"#无符号加法\" class=\"headerlink\" title=\"无符号加法\"></a>无符号加法</h4><p>使用无符号加法需要注意溢出的情况，下列无符号short求和最后结果就发生了溢出，同样产生了截断，实际结果比理想的结果少了2^16^</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> c = <span class=\"number\">44444</span> + <span class=\"number\">22222</span>;</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"a is %u, b is %u, result is %u\"</span>, a, b, c);</span><br></pre></td></tr></table></figure>\n<p>最后结果为1130，想要的结果是66666</p>\n<h4 id=\"补码加法\"><a href=\"#补码加法\" class=\"headerlink\" title=\"补码加法\"></a>补码加法</h4><p>大部分时间进行数值计算都是对补码进行操作，在进行补码加法时需要考虑当结果太大或者太小时会不会发生溢出的情况</p>\n<p>与无符号加法类似，如果加法结果超过当前数值类型的位数范围时会发生正溢出（太大）或者负溢出（太小）：</p>\n<p><img src=\"http://img.mantian.site/201909101634_839.png\" alt></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">short</span> c = <span class=\"number\">-22222</span> + (<span class=\"number\">-22222</span>);</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"a is %u, b is %u, result is %u\"</span>, a, b, c);</span><br></pre></td></tr></table></figure>\n<p>其结果为21092，发生了负溢出，其结果比想要的结果大了65536，也就是2^16^</p>\n<p>以下函数无法判断两个有符号补码数相加是否发生了溢出：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">check_overflow_short_add</span><span class=\"params\">(<span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> c = a + b;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (c - a) == b &amp;&amp; (c - b) == a;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>两个补码a和b相加得到结果c，不管有没有溢出，c-a的结果始终还是b，c-b的结果始终还是a</p>\n<h4 id=\"无符号乘法\"><a href=\"#无符号乘法\" class=\"headerlink\" title=\"无符号乘法\"></a>无符号乘法</h4><p>无符号乘法也存在高位截断的问题：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> a = <span class=\"number\">222</span>;</span><br><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> b = <span class=\"number\">333</span>;</span><br><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> c = a * b;</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\"</span>, c);</span><br></pre></td></tr></table></figure>\n<p>理想结果为73926，实际得到的结果为8390，说明溢出的部分被截断了，只剩下了低16位的数据，也就是少了2^16^</p>\n<h4 id=\"补码乘法\"><a href=\"#补码乘法\" class=\"headerlink\" title=\"补码乘法\"></a>补码乘法</h4><p>补码乘法与无符号乘法差不多，与补码加法一样也需要注意正溢出和负溢出截断的问题</p>\n<h4 id=\"对于某些常数乘法的优化\"><a href=\"#对于某些常数乘法的优化\" class=\"headerlink\" title=\"对于某些常数乘法的优化\"></a>对于某些常数乘法的优化</h4><p>乘法运算在大多数计算机上都是一个相当慢的运算，需要消耗过多的时钟周期，因此编译器对常数乘法运算会进行一些优化，用移位或者加法运算来代替常数因子的乘法运算</p>\n<p><code>移位优化</code>：某个数与2的幂作乘法就可以进行移位运算，<code>X * 2^k</code>就可以直接将X左移k位</p>\n<p><code>加法优化</code>：将乘数拆散为2的幂次的和，比如<code>X * 14</code>就可以拆为<code>X * (2^3 + 2^2 + 2)</code>，然后再用移位计算各个部分的值，最后再统一相加</p>\n<h3 id=\"浮点数\"><a href=\"#浮点数\" class=\"headerlink\" title=\"浮点数\"></a>浮点数</h3><p>现代计算机采用<code>IEEE浮点数标准</code>来处理带小数点的数字</p>\n<h4 id=\"二进制表示小数\"><a href=\"#二进制表示小数\" class=\"headerlink\" title=\"二进制表示小数\"></a>二进制表示小数</h4><p>与整数的二进制表示法类似，带小数的数字是用2的负幂次叠加来进行表示，比如5.75就可以拆散为：</p>\n<p><code>4 + 0 + 1 + 1/2 + 1/4</code>，用二进制进行表示就是：<code>101.11</code></p>\n<p>二进制用以下规则表示带小数的数字，整数部分就是2的正幂次，小数部分就是2的负幂次：</p>\n<p><img src=\"http://img.mantian.site/201909111019_571.png\" alt></p>\n<p><strong>缺陷</strong>：可以看出，二进制表示小数无法做到像十进制这么精确，像1/5这种小数通过十进制可以表示为0.2，但是用二进制的话只能通过增加二进制小数位数构造一个近似值来逼近，例如<code>0.00110011</code>这个二进制小数转换为十进制是<code>0.19921875</code>，已经很接近了</p>\n<h4 id=\"IEEE浮点数表示法\"><a href=\"#IEEE浮点数表示法\" class=\"headerlink\" title=\"IEEE浮点数表示法\"></a>IEEE浮点数表示法</h4><p>在二进制定点表示法的基础上，IEEE标准用以下公式来存储一个浮点数：</p>\n<p><img src=\"http://img.mantian.site/201909111339_460.png\" style=\"zoom: 67%;\"></p>\n<p>各个参数解释如下：</p>\n<ul>\n<li><code>s</code>：符号标记，无论是float还是double类型都是有符号数，s为1则表示负数，s为0表示正数</li>\n<li><code>M</code>：尾数，保存浮点数的实际有效位，其大小是<code>1 &lt;= M &lt; 2</code>，以<code>1.1101</code>这样的形式展示；不过存储的时候会省略小数点左边的1，只存储右边的位，我们把保留下来的小数点右边的位称为<code>f</code></li>\n<li><code>E</code>：阶码，对尾数M进行加权，判断M的小数点需要左移或者右移多少位，最终计算得到真正的浮点数二进制表示</li>\n</ul>\n<p>计算机系统保存浮点数就是对这三个参数分别进行编码保存到固定的位数中，float类型保存到32位长度中，double类型则保存到64位长度中</p>\n<p><strong>float &amp; double</strong>：单精度浮点（float）和双精度浮点（double）除了最高位的符号位s，剩下的区别主要体现在对M和E的保存位数不一样：</p>\n<ul>\n<li><code>float</code>：E取8位，M取23位</li>\n<li><code>double</code>：E取11位，M取52位</li>\n</ul>\n<p>以32位的float为例讲一下编码保存各个参数的规则：</p>\n<ul>\n<li>编码s：保存为1或者0</li>\n<li>编码E：E的值即要表现2的正幂次，也要表现2的负幂次，而编码保存后的八位数<code>e</code>只能是无符号整数，范围是0 ~ 2^8^-1=255，因此E的真实取值范围需要在这个基础上做一个2^7^-1=127的偏移处理，也就是说<code>e = E + 127</code></li>\n<li>编码M：省略掉M小数点左边的1，只保留小数点右边的23位，也就是<code>f</code></li>\n</ul>\n<p>基于这个基本表示规则，有四种不同的情况，以32位float为例：</p>\n<ul>\n<li><code>E编码保存的值(e)不为0或者255(2^8-1)</code>：这种情况即为普通情况，E的取值范围是<code>-126 ~ 127</code></li>\n<li><code>e所有位都为0</code>：称为非规格化值，规定这种情况在解码时舍弃掉M小数点左边的1，只保留<code>f</code>；这种情况一般时拿来表示正0或者负0，或者非常逼近于0的小数</li>\n<li><code>e所有位都为1 &amp; f所有位为0</code>：无穷大数，s为1是负无穷，s为0是正无穷</li>\n<li><code>e所有位都为1 &amp; f不为0</code>：NaN，用来表现不是数字（无意义的数字）的情况</li>\n</ul>\n<p><strong>例子</strong>：以float类型<code>1.25</code>为例，计算机系统中使用32位二进制<code>00111111101000000000000000000000</code>来保存1.25</p>\n<p><img src=\"http://img.mantian.site/201909111448_137.png\" style=\"zoom:75%;\"></p>\n<p>如图：</p>\n<ol>\n<li>符号位s为0，表示正数</li>\n<li>阶码位e有8位，其值是127，因此<code>E = 127 - 127 = 0</code>，阶码E为0</li>\n<li>尾数位f有23位，其值是二进制0.01，也就是1/(2^2^) = 1/4</li>\n</ol>\n<p>最终值<code>V = 1 * (1/(2^2)) * 1 = 1.25</code></p>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 1","author":"天渊","date":"2019-09-01T00:23:00.000Z","_content":"深入理解计算机系统 —— 第一章：\n\n本书第一章是从一个基本的c语言hello world程序是如何被计算机执行的作为线索，简单介绍了计算机系统中的基本组成和一些核心概念，这些核心概念会贯穿整本书的讲解\n\n<!--more-->\n\n#### 目录\n\n- 何为信息？bit + 上下文\n- 程序的编译，如何让机器读懂你的程序\n- 了解一下编译原理\n- 处理器是如何处理内存指令的，包含系统硬件组成简介\n- 高速缓存为加速处理器读写起到关键作用\n- 存储设备的层次结构\n- 操作系统是如何运作在系统硬件上的（线程，进程，虚拟内存，文件系统等）\n- 重要概念总结（Amdahl定律，并发与并行，计算机系统中的抽象）\n\n\n\n#### 信息就是bit+上下文\n\n信息在计算机系统中是以何种形式存在的？计算机系统中所有信息（内存中的数据，用户编写的程序，磁盘中的文件，网络中传输的信号和文件等）都是以一串bit表示的\n\n如何区分这些bit串要表达的不同含义？这时就需要判断这些bit串的上下文，不同的bit串在不同的上下文中可能表示一个整数，一个字符串或者一个特殊的cpu指令\n\n> C语言的前世今生：\n>\n> C语言是一种高级语言，诞生于为Unix操作系统编写各种应用程序的需求，由于其小而简单并易于移植到不同系统的特性而广受欢迎；不过由于它的指针特性等不易于程序员掌握的特性以及缺乏一些抽象的显示支持如类，对象以及异常等，因此不太适合用于编写大型的企业级应用，往往更适合于编写偏底层的小型应用\n\n#### 如何让机器读懂你的程序？程序的编译\n\n程序员编写好一个c语言源文件，是不能直接运行在系统上的，因为机器读不懂，cpu无法直接执行源文件\n\n只有将源文件编译为cpu能够执行的一系列的机器语言指令，然后将这些指令打包为**可执行文件**，才能被cpu执行\n\n##### c语言源文件的编译过程\n\nc语言源文件`hello.c`编译为cpu能够执行的可执行文件需要以下过程：\n\n1. 预处理阶段\n\n> 执行单位：预处理器cpp\n>\n> 生成：修改后的源文件`hello.i`\n>\n> 目的：根据`#`字符开头的命令，读取其他程序包到源文件中比如`stdio.h`，形成一个新的源文件\n\n2. 汇编阶段\n\n这个阶段又包括两个过程，一个是编译器编译为汇编文本文件，然后由汇编器编译为二进制格式的可重定位目标程序\n\n> 执行单位：编译器ccl + 汇编器as\n>\n> 生成：汇编文本文件`hello.s` ， 二进制的可重定位目标程序`hello.o`\n>\n> 目的：源文件编译后的汇编程序已经非常接近机器能够执行的机器指令了，不同的高级语言编译后的汇编语言指令都是同一种\n\n3. 链接阶段\n\n由于`hello.c`中会使用c语言标准库的printf函数，这个阶段会将已经编译好的printf函数链接到我们的`hello.o`文件中，生成最终的可执行文件，执行的时候加载到内存中由cpu读取指令进执行\n\n#### 了解一下编译原理\n\n虽然源代码的编译过程由系统编译器自行完成，但了解一些编译原理也是有必要的：\n\n- 有助于编写性能良好的程序，熟悉编译原理的话就知道自己写的程序将会编译成什么样的机器指令去执行，什么样的执行过程对cpu执行来说才是最优的\n- 理解链接时出现的错误，比如如何区分静态变量和全局变量，为什么直到运行时才发现链接错误\n- 避免缓冲区溢出等安全隐患，理解数据和信息存储在栈上的方法会引起的后果\n\n#### 处理器是如何处理内存指令的\n\n在理解我们的`hello`可执行文件是如何被cpu执行前，需要先了解系统硬件的组成和协作过程\n\n##### 系统硬件组成介绍\n\n一个基本的冯诺依曼体系的计算机系统由`处理器`，`主存`，`I/O设备`和`总线`组成\n\n- **处理器**CPU：系统的大脑，负责执行程序机器指令，由`算术逻辑单元ALU`，`程序计数器PC`，`寄存器`组成，PC指向主存中某条需要执行的机器指令，由ALU读取该指令并执行该指令的操作，再更新PC使其指向下一条指令\n- **主存**：包括RAM临时存储和ROM永久存储，主存是系统cpu执行指令时用来临时存放程序指令和数据的地方，每个主存的存储字节都有其唯一的地址\n- **I/O设备**：包括显示器，鼠标键盘，网卡和磁盘等用于系统和外界交互的硬件设备，每个I/O设备都需要适配器与I/O总线相连\n- **总线**：一个携带信息字节负责在各个部件间传输信息的电子管道，总线传输宽度由`字长`确定，现代操作系统一般为32位字长或者64位字长\n\n##### hello程序的执行过程\n\n在键盘上输入命令执行`hello`文件或者鼠标在屏幕上点击该可执行文件后，依次发生了以下事件：\n\n1. shell程序会启动一系列指令将二进制可执行文件从磁盘通过I/O总线加载到主存中（通过`DMA`技术直接将数据拷贝到主存而不经过cpu的加载和存储等操作）\n2. hello文件加载到主存后，cpu通过内存总线读取主存中的机器指令，这些指令会将`hello world`字符串从主存复制到cpu寄存器，再从寄存器通过I/O总线输出给显卡适配器\n3. 显卡适配器获取到具体需要打印的`hello world`字符串，将信息输出到屏幕上\n\n#### 高速缓存为加速处理器读写起到关键作用\n\n以上hello程序执行的过程中，需要先把信息从磁盘复制到主存，再由cpu根据指令从主存复制字符串信息到寄存器，然后再输出给I/O，这一来一去的复制过程大大降低的程序的执行速度，因为cpu从寄存器中读数据速度远大于从主存中读取数据，复制过程就成了瓶颈\n\n`高速缓存`利用了空间和时间局部性原理，存放cpu近期可能会用到的信息能够大大降低cpu从主存读取数据带来的运行瓶颈\n\n主流cpu采用`SRAM`技术，一共将高速缓存分为`L1`,`L2`和`L3`三个层级，其中最靠近cpu的`L1`高速缓存存取速度最快，容量也最低\n\n#### 存储设备的层次结构\n\n计算机系统中的存储设备组织成一个存储器层次结构，从小往上，存储容量越小，访问速度越快：\n\n![1566833029236](http://img.mantian.site/1566833029236.png)\n\n#### 操作系统是如何运作在系统硬件上的\n\n用户的应用程序，比如一个shell脚本程序，或者一个c程序，是无法直接和系统硬件打交道的，取而代之的是操作系统，充当了用户程序和系统底层硬件的中间层，提供了统一的系统调用让用户程序间接访问系统硬件，这么做有两个目的：\n\n- 防止用户程序失控滥用系统硬件\n\n- 向用户程序提供简单一致的机制来对付复杂的底层硬件\n\n通过`进程`,`虚拟内存`和`文件系统`这几种机制来实现以上两个目的\n\n##### 进程\n\n进程是现代操作系统中最重要的一个概念，操作系统使用进程这个概念来使得某一个应用程序与本机上其他应用程序进行资源隔离，并且让这个应用程序以为本台机器上只有它自己一个程序在运行\n\n`进程上下文切换`：\n\n- 单个CPU核心同一时间只能运行一个程序，如何让多个程序运行在这个CPU核心上？CPU通过**上下文切换**来并发地处理多个进程；\n\n- 进程的上下文包含该进程在PC，寄存器和主存中暂存的数据\n\n- CPU执行进程的上下文切换时需要切换到内核态\n\n##### 线程\n\n现代操作系统中，一个进程可以由多个线程组成，每个线程相互之间共享进程的代码和全局数据，可以把进程看作轻量级的进程，CPU也是并发地处理多个线程的请求，同样也会存在上下文切换的情况\n\n##### 虚拟内存\n\n操作系统为了让进程更方便地管理自己的内存空间，使用虚拟内存这一概念为每个进程提供一个抽象，让进程认为自己独占了整个内存空间，因此进程操作的内存地址空间都是操作系统创建出来的虚拟内存地址空间，底层真实内存地址空间是不提供给进程直接访问的\n\n虚拟内存地址空间的组成如下：\n\n- `只读代码和数据区`：包含程序代码数据和全局变量，进程初始化时就被分配\n- `运行时堆`：堆可以动态缩/扩容，通过malloc和free等函数动态分配的内存\n- `共享库`：存放c标准库等需要共享的代码和数据，与动态链接有关\n- `栈`：编译器使用栈这种数据结构来实现函数调用，用户栈在运行时也可以动态缩/扩容\n- `内核虚拟内存`：为内核调用保留的地址空间\n\n##### 文件系统\n\n在类Unix系统中，万物皆文件，包括磁盘，网络以及键盘鼠标显示器等IO设备，都看作文件\n\n操作系统使用文件系统这一概念将底层IO设备进行了抽象，应用程序无需关注硬件设备复杂的实现技术，只需要关注操作系统提供的文件系统接口就行了\n\n\n\n#### 重要概念总结\n\n##### Amdahl定律\n\nAmdahl定律的概念简要概况：系统中某个部分组件进行性能提升的比率，小于对系统整体带来性能提升的比率，也就是说如果要对系统整体进行性能提升，只优化某部分的性能是不够的，必须提升系统绝大多数组件的性能\n\n##### 并发和并行\n\n- 并发：指一个系统同时有多个活动在同时进行\n- 并行：使用并发的方式让系统运行得更快\n\n`线程级并发`：一个进程中运行多个线程就是线程级并发技术，并且现代CPU使用超线程技术让单个CPU核心运行不止一个线程\n\n`指令级并行`：现代CPU可以在一个时钟周期内执行多条指令，称为指令级并行，这种处理器也称为`超标量处理器`\n\n`单指令多数据并行`：现代CPU允许一条指令产生多个可以并行执行的操作，称为单指令多数据并行（SIMD）\n\n##### 抽象\n\n现代计算机科学中最重要的概念之一就是`抽象`，计算机系统中无时无刻不存在抽象这个概念的运用，提供不同层次的抽象来隐藏底层实现的复杂性","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-1.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 1\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-09-01 08:23:00\n---\n深入理解计算机系统 —— 第一章：\n\n本书第一章是从一个基本的c语言hello world程序是如何被计算机执行的作为线索，简单介绍了计算机系统中的基本组成和一些核心概念，这些核心概念会贯穿整本书的讲解\n\n<!--more-->\n\n#### 目录\n\n- 何为信息？bit + 上下文\n- 程序的编译，如何让机器读懂你的程序\n- 了解一下编译原理\n- 处理器是如何处理内存指令的，包含系统硬件组成简介\n- 高速缓存为加速处理器读写起到关键作用\n- 存储设备的层次结构\n- 操作系统是如何运作在系统硬件上的（线程，进程，虚拟内存，文件系统等）\n- 重要概念总结（Amdahl定律，并发与并行，计算机系统中的抽象）\n\n\n\n#### 信息就是bit+上下文\n\n信息在计算机系统中是以何种形式存在的？计算机系统中所有信息（内存中的数据，用户编写的程序，磁盘中的文件，网络中传输的信号和文件等）都是以一串bit表示的\n\n如何区分这些bit串要表达的不同含义？这时就需要判断这些bit串的上下文，不同的bit串在不同的上下文中可能表示一个整数，一个字符串或者一个特殊的cpu指令\n\n> C语言的前世今生：\n>\n> C语言是一种高级语言，诞生于为Unix操作系统编写各种应用程序的需求，由于其小而简单并易于移植到不同系统的特性而广受欢迎；不过由于它的指针特性等不易于程序员掌握的特性以及缺乏一些抽象的显示支持如类，对象以及异常等，因此不太适合用于编写大型的企业级应用，往往更适合于编写偏底层的小型应用\n\n#### 如何让机器读懂你的程序？程序的编译\n\n程序员编写好一个c语言源文件，是不能直接运行在系统上的，因为机器读不懂，cpu无法直接执行源文件\n\n只有将源文件编译为cpu能够执行的一系列的机器语言指令，然后将这些指令打包为**可执行文件**，才能被cpu执行\n\n##### c语言源文件的编译过程\n\nc语言源文件`hello.c`编译为cpu能够执行的可执行文件需要以下过程：\n\n1. 预处理阶段\n\n> 执行单位：预处理器cpp\n>\n> 生成：修改后的源文件`hello.i`\n>\n> 目的：根据`#`字符开头的命令，读取其他程序包到源文件中比如`stdio.h`，形成一个新的源文件\n\n2. 汇编阶段\n\n这个阶段又包括两个过程，一个是编译器编译为汇编文本文件，然后由汇编器编译为二进制格式的可重定位目标程序\n\n> 执行单位：编译器ccl + 汇编器as\n>\n> 生成：汇编文本文件`hello.s` ， 二进制的可重定位目标程序`hello.o`\n>\n> 目的：源文件编译后的汇编程序已经非常接近机器能够执行的机器指令了，不同的高级语言编译后的汇编语言指令都是同一种\n\n3. 链接阶段\n\n由于`hello.c`中会使用c语言标准库的printf函数，这个阶段会将已经编译好的printf函数链接到我们的`hello.o`文件中，生成最终的可执行文件，执行的时候加载到内存中由cpu读取指令进执行\n\n#### 了解一下编译原理\n\n虽然源代码的编译过程由系统编译器自行完成，但了解一些编译原理也是有必要的：\n\n- 有助于编写性能良好的程序，熟悉编译原理的话就知道自己写的程序将会编译成什么样的机器指令去执行，什么样的执行过程对cpu执行来说才是最优的\n- 理解链接时出现的错误，比如如何区分静态变量和全局变量，为什么直到运行时才发现链接错误\n- 避免缓冲区溢出等安全隐患，理解数据和信息存储在栈上的方法会引起的后果\n\n#### 处理器是如何处理内存指令的\n\n在理解我们的`hello`可执行文件是如何被cpu执行前，需要先了解系统硬件的组成和协作过程\n\n##### 系统硬件组成介绍\n\n一个基本的冯诺依曼体系的计算机系统由`处理器`，`主存`，`I/O设备`和`总线`组成\n\n- **处理器**CPU：系统的大脑，负责执行程序机器指令，由`算术逻辑单元ALU`，`程序计数器PC`，`寄存器`组成，PC指向主存中某条需要执行的机器指令，由ALU读取该指令并执行该指令的操作，再更新PC使其指向下一条指令\n- **主存**：包括RAM临时存储和ROM永久存储，主存是系统cpu执行指令时用来临时存放程序指令和数据的地方，每个主存的存储字节都有其唯一的地址\n- **I/O设备**：包括显示器，鼠标键盘，网卡和磁盘等用于系统和外界交互的硬件设备，每个I/O设备都需要适配器与I/O总线相连\n- **总线**：一个携带信息字节负责在各个部件间传输信息的电子管道，总线传输宽度由`字长`确定，现代操作系统一般为32位字长或者64位字长\n\n##### hello程序的执行过程\n\n在键盘上输入命令执行`hello`文件或者鼠标在屏幕上点击该可执行文件后，依次发生了以下事件：\n\n1. shell程序会启动一系列指令将二进制可执行文件从磁盘通过I/O总线加载到主存中（通过`DMA`技术直接将数据拷贝到主存而不经过cpu的加载和存储等操作）\n2. hello文件加载到主存后，cpu通过内存总线读取主存中的机器指令，这些指令会将`hello world`字符串从主存复制到cpu寄存器，再从寄存器通过I/O总线输出给显卡适配器\n3. 显卡适配器获取到具体需要打印的`hello world`字符串，将信息输出到屏幕上\n\n#### 高速缓存为加速处理器读写起到关键作用\n\n以上hello程序执行的过程中，需要先把信息从磁盘复制到主存，再由cpu根据指令从主存复制字符串信息到寄存器，然后再输出给I/O，这一来一去的复制过程大大降低的程序的执行速度，因为cpu从寄存器中读数据速度远大于从主存中读取数据，复制过程就成了瓶颈\n\n`高速缓存`利用了空间和时间局部性原理，存放cpu近期可能会用到的信息能够大大降低cpu从主存读取数据带来的运行瓶颈\n\n主流cpu采用`SRAM`技术，一共将高速缓存分为`L1`,`L2`和`L3`三个层级，其中最靠近cpu的`L1`高速缓存存取速度最快，容量也最低\n\n#### 存储设备的层次结构\n\n计算机系统中的存储设备组织成一个存储器层次结构，从小往上，存储容量越小，访问速度越快：\n\n![1566833029236](http://img.mantian.site/1566833029236.png)\n\n#### 操作系统是如何运作在系统硬件上的\n\n用户的应用程序，比如一个shell脚本程序，或者一个c程序，是无法直接和系统硬件打交道的，取而代之的是操作系统，充当了用户程序和系统底层硬件的中间层，提供了统一的系统调用让用户程序间接访问系统硬件，这么做有两个目的：\n\n- 防止用户程序失控滥用系统硬件\n\n- 向用户程序提供简单一致的机制来对付复杂的底层硬件\n\n通过`进程`,`虚拟内存`和`文件系统`这几种机制来实现以上两个目的\n\n##### 进程\n\n进程是现代操作系统中最重要的一个概念，操作系统使用进程这个概念来使得某一个应用程序与本机上其他应用程序进行资源隔离，并且让这个应用程序以为本台机器上只有它自己一个程序在运行\n\n`进程上下文切换`：\n\n- 单个CPU核心同一时间只能运行一个程序，如何让多个程序运行在这个CPU核心上？CPU通过**上下文切换**来并发地处理多个进程；\n\n- 进程的上下文包含该进程在PC，寄存器和主存中暂存的数据\n\n- CPU执行进程的上下文切换时需要切换到内核态\n\n##### 线程\n\n现代操作系统中，一个进程可以由多个线程组成，每个线程相互之间共享进程的代码和全局数据，可以把进程看作轻量级的进程，CPU也是并发地处理多个线程的请求，同样也会存在上下文切换的情况\n\n##### 虚拟内存\n\n操作系统为了让进程更方便地管理自己的内存空间，使用虚拟内存这一概念为每个进程提供一个抽象，让进程认为自己独占了整个内存空间，因此进程操作的内存地址空间都是操作系统创建出来的虚拟内存地址空间，底层真实内存地址空间是不提供给进程直接访问的\n\n虚拟内存地址空间的组成如下：\n\n- `只读代码和数据区`：包含程序代码数据和全局变量，进程初始化时就被分配\n- `运行时堆`：堆可以动态缩/扩容，通过malloc和free等函数动态分配的内存\n- `共享库`：存放c标准库等需要共享的代码和数据，与动态链接有关\n- `栈`：编译器使用栈这种数据结构来实现函数调用，用户栈在运行时也可以动态缩/扩容\n- `内核虚拟内存`：为内核调用保留的地址空间\n\n##### 文件系统\n\n在类Unix系统中，万物皆文件，包括磁盘，网络以及键盘鼠标显示器等IO设备，都看作文件\n\n操作系统使用文件系统这一概念将底层IO设备进行了抽象，应用程序无需关注硬件设备复杂的实现技术，只需要关注操作系统提供的文件系统接口就行了\n\n\n\n#### 重要概念总结\n\n##### Amdahl定律\n\nAmdahl定律的概念简要概况：系统中某个部分组件进行性能提升的比率，小于对系统整体带来性能提升的比率，也就是说如果要对系统整体进行性能提升，只优化某部分的性能是不够的，必须提升系统绝大多数组件的性能\n\n##### 并发和并行\n\n- 并发：指一个系统同时有多个活动在同时进行\n- 并行：使用并发的方式让系统运行得更快\n\n`线程级并发`：一个进程中运行多个线程就是线程级并发技术，并且现代CPU使用超线程技术让单个CPU核心运行不止一个线程\n\n`指令级并行`：现代CPU可以在一个时钟周期内执行多条指令，称为指令级并行，这种处理器也称为`超标量处理器`\n\n`单指令多数据并行`：现代CPU允许一条指令产生多个可以并行执行的操作，称为单指令多数据并行（SIMD）\n\n##### 抽象\n\n现代计算机科学中最重要的概念之一就是`抽象`，计算机系统中无时无刻不存在抽象这个概念的运用，提供不同层次的抽象来隐藏底层实现的复杂性","slug":"《深入理解计算机系统》读书笔记——Chapter-1","published":1,"updated":"2019-09-01T00:27:34.524Z","_id":"ckf0h31ig0027acts2tmqrw0p","comments":1,"layout":"post","photos":[],"link":"","content":"<p>深入理解计算机系统 —— 第一章：</p>\n<p>本书第一章是从一个基本的c语言hello world程序是如何被计算机执行的作为线索，简单介绍了计算机系统中的基本组成和一些核心概念，这些核心概念会贯穿整本书的讲解</p>\n<a id=\"more\"></a>\n<h4 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h4><ul>\n<li>何为信息？bit + 上下文</li>\n<li>程序的编译，如何让机器读懂你的程序</li>\n<li>了解一下编译原理</li>\n<li>处理器是如何处理内存指令的，包含系统硬件组成简介</li>\n<li>高速缓存为加速处理器读写起到关键作用</li>\n<li>存储设备的层次结构</li>\n<li>操作系统是如何运作在系统硬件上的（线程，进程，虚拟内存，文件系统等）</li>\n<li>重要概念总结（Amdahl定律，并发与并行，计算机系统中的抽象）</li>\n</ul>\n<h4 id=\"信息就是bit-上下文\"><a href=\"#信息就是bit-上下文\" class=\"headerlink\" title=\"信息就是bit+上下文\"></a>信息就是bit+上下文</h4><p>信息在计算机系统中是以何种形式存在的？计算机系统中所有信息（内存中的数据，用户编写的程序，磁盘中的文件，网络中传输的信号和文件等）都是以一串bit表示的</p>\n<p>如何区分这些bit串要表达的不同含义？这时就需要判断这些bit串的上下文，不同的bit串在不同的上下文中可能表示一个整数，一个字符串或者一个特殊的cpu指令</p>\n<blockquote>\n<p>C语言的前世今生：</p>\n<p>C语言是一种高级语言，诞生于为Unix操作系统编写各种应用程序的需求，由于其小而简单并易于移植到不同系统的特性而广受欢迎；不过由于它的指针特性等不易于程序员掌握的特性以及缺乏一些抽象的显示支持如类，对象以及异常等，因此不太适合用于编写大型的企业级应用，往往更适合于编写偏底层的小型应用</p>\n</blockquote>\n<h4 id=\"如何让机器读懂你的程序？程序的编译\"><a href=\"#如何让机器读懂你的程序？程序的编译\" class=\"headerlink\" title=\"如何让机器读懂你的程序？程序的编译\"></a>如何让机器读懂你的程序？程序的编译</h4><p>程序员编写好一个c语言源文件，是不能直接运行在系统上的，因为机器读不懂，cpu无法直接执行源文件</p>\n<p>只有将源文件编译为cpu能够执行的一系列的机器语言指令，然后将这些指令打包为<strong>可执行文件</strong>，才能被cpu执行</p>\n<h5 id=\"c语言源文件的编译过程\"><a href=\"#c语言源文件的编译过程\" class=\"headerlink\" title=\"c语言源文件的编译过程\"></a>c语言源文件的编译过程</h5><p>c语言源文件<code>hello.c</code>编译为cpu能够执行的可执行文件需要以下过程：</p>\n<ol>\n<li>预处理阶段</li>\n</ol>\n<blockquote>\n<p>执行单位：预处理器cpp</p>\n<p>生成：修改后的源文件<code>hello.i</code></p>\n<p>目的：根据<code>#</code>字符开头的命令，读取其他程序包到源文件中比如<code>stdio.h</code>，形成一个新的源文件</p>\n</blockquote>\n<ol start=\"2\">\n<li>汇编阶段</li>\n</ol>\n<p>这个阶段又包括两个过程，一个是编译器编译为汇编文本文件，然后由汇编器编译为二进制格式的可重定位目标程序</p>\n<blockquote>\n<p>执行单位：编译器ccl + 汇编器as</p>\n<p>生成：汇编文本文件<code>hello.s</code> ， 二进制的可重定位目标程序<code>hello.o</code></p>\n<p>目的：源文件编译后的汇编程序已经非常接近机器能够执行的机器指令了，不同的高级语言编译后的汇编语言指令都是同一种</p>\n</blockquote>\n<ol start=\"3\">\n<li>链接阶段</li>\n</ol>\n<p>由于<code>hello.c</code>中会使用c语言标准库的printf函数，这个阶段会将已经编译好的printf函数链接到我们的<code>hello.o</code>文件中，生成最终的可执行文件，执行的时候加载到内存中由cpu读取指令进执行</p>\n<h4 id=\"了解一下编译原理\"><a href=\"#了解一下编译原理\" class=\"headerlink\" title=\"了解一下编译原理\"></a>了解一下编译原理</h4><p>虽然源代码的编译过程由系统编译器自行完成，但了解一些编译原理也是有必要的：</p>\n<ul>\n<li>有助于编写性能良好的程序，熟悉编译原理的话就知道自己写的程序将会编译成什么样的机器指令去执行，什么样的执行过程对cpu执行来说才是最优的</li>\n<li>理解链接时出现的错误，比如如何区分静态变量和全局变量，为什么直到运行时才发现链接错误</li>\n<li>避免缓冲区溢出等安全隐患，理解数据和信息存储在栈上的方法会引起的后果</li>\n</ul>\n<h4 id=\"处理器是如何处理内存指令的\"><a href=\"#处理器是如何处理内存指令的\" class=\"headerlink\" title=\"处理器是如何处理内存指令的\"></a>处理器是如何处理内存指令的</h4><p>在理解我们的<code>hello</code>可执行文件是如何被cpu执行前，需要先了解系统硬件的组成和协作过程</p>\n<h5 id=\"系统硬件组成介绍\"><a href=\"#系统硬件组成介绍\" class=\"headerlink\" title=\"系统硬件组成介绍\"></a>系统硬件组成介绍</h5><p>一个基本的冯诺依曼体系的计算机系统由<code>处理器</code>，<code>主存</code>，<code>I/O设备</code>和<code>总线</code>组成</p>\n<ul>\n<li><strong>处理器</strong>CPU：系统的大脑，负责执行程序机器指令，由<code>算术逻辑单元ALU</code>，<code>程序计数器PC</code>，<code>寄存器</code>组成，PC指向主存中某条需要执行的机器指令，由ALU读取该指令并执行该指令的操作，再更新PC使其指向下一条指令</li>\n<li><strong>主存</strong>：包括RAM临时存储和ROM永久存储，主存是系统cpu执行指令时用来临时存放程序指令和数据的地方，每个主存的存储字节都有其唯一的地址</li>\n<li><strong>I/O设备</strong>：包括显示器，鼠标键盘，网卡和磁盘等用于系统和外界交互的硬件设备，每个I/O设备都需要适配器与I/O总线相连</li>\n<li><strong>总线</strong>：一个携带信息字节负责在各个部件间传输信息的电子管道，总线传输宽度由<code>字长</code>确定，现代操作系统一般为32位字长或者64位字长</li>\n</ul>\n<h5 id=\"hello程序的执行过程\"><a href=\"#hello程序的执行过程\" class=\"headerlink\" title=\"hello程序的执行过程\"></a>hello程序的执行过程</h5><p>在键盘上输入命令执行<code>hello</code>文件或者鼠标在屏幕上点击该可执行文件后，依次发生了以下事件：</p>\n<ol>\n<li>shell程序会启动一系列指令将二进制可执行文件从磁盘通过I/O总线加载到主存中（通过<code>DMA</code>技术直接将数据拷贝到主存而不经过cpu的加载和存储等操作）</li>\n<li>hello文件加载到主存后，cpu通过内存总线读取主存中的机器指令，这些指令会将<code>hello world</code>字符串从主存复制到cpu寄存器，再从寄存器通过I/O总线输出给显卡适配器</li>\n<li>显卡适配器获取到具体需要打印的<code>hello world</code>字符串，将信息输出到屏幕上</li>\n</ol>\n<h4 id=\"高速缓存为加速处理器读写起到关键作用\"><a href=\"#高速缓存为加速处理器读写起到关键作用\" class=\"headerlink\" title=\"高速缓存为加速处理器读写起到关键作用\"></a>高速缓存为加速处理器读写起到关键作用</h4><p>以上hello程序执行的过程中，需要先把信息从磁盘复制到主存，再由cpu根据指令从主存复制字符串信息到寄存器，然后再输出给I/O，这一来一去的复制过程大大降低的程序的执行速度，因为cpu从寄存器中读数据速度远大于从主存中读取数据，复制过程就成了瓶颈</p>\n<p><code>高速缓存</code>利用了空间和时间局部性原理，存放cpu近期可能会用到的信息能够大大降低cpu从主存读取数据带来的运行瓶颈</p>\n<p>主流cpu采用<code>SRAM</code>技术，一共将高速缓存分为<code>L1</code>,<code>L2</code>和<code>L3</code>三个层级，其中最靠近cpu的<code>L1</code>高速缓存存取速度最快，容量也最低</p>\n<h4 id=\"存储设备的层次结构\"><a href=\"#存储设备的层次结构\" class=\"headerlink\" title=\"存储设备的层次结构\"></a>存储设备的层次结构</h4><p>计算机系统中的存储设备组织成一个存储器层次结构，从小往上，存储容量越小，访问速度越快：</p>\n<p><img src=\"http://img.mantian.site/1566833029236.png\" alt=\"1566833029236\"></p>\n<h4 id=\"操作系统是如何运作在系统硬件上的\"><a href=\"#操作系统是如何运作在系统硬件上的\" class=\"headerlink\" title=\"操作系统是如何运作在系统硬件上的\"></a>操作系统是如何运作在系统硬件上的</h4><p>用户的应用程序，比如一个shell脚本程序，或者一个c程序，是无法直接和系统硬件打交道的，取而代之的是操作系统，充当了用户程序和系统底层硬件的中间层，提供了统一的系统调用让用户程序间接访问系统硬件，这么做有两个目的：</p>\n<ul>\n<li><p>防止用户程序失控滥用系统硬件</p>\n</li>\n<li><p>向用户程序提供简单一致的机制来对付复杂的底层硬件</p>\n</li>\n</ul>\n<p>通过<code>进程</code>,<code>虚拟内存</code>和<code>文件系统</code>这几种机制来实现以上两个目的</p>\n<h5 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h5><p>进程是现代操作系统中最重要的一个概念，操作系统使用进程这个概念来使得某一个应用程序与本机上其他应用程序进行资源隔离，并且让这个应用程序以为本台机器上只有它自己一个程序在运行</p>\n<p><code>进程上下文切换</code>：</p>\n<ul>\n<li><p>单个CPU核心同一时间只能运行一个程序，如何让多个程序运行在这个CPU核心上？CPU通过<strong>上下文切换</strong>来并发地处理多个进程；</p>\n</li>\n<li><p>进程的上下文包含该进程在PC，寄存器和主存中暂存的数据</p>\n</li>\n<li><p>CPU执行进程的上下文切换时需要切换到内核态</p>\n</li>\n</ul>\n<h5 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h5><p>现代操作系统中，一个进程可以由多个线程组成，每个线程相互之间共享进程的代码和全局数据，可以把进程看作轻量级的进程，CPU也是并发地处理多个线程的请求，同样也会存在上下文切换的情况</p>\n<h5 id=\"虚拟内存\"><a href=\"#虚拟内存\" class=\"headerlink\" title=\"虚拟内存\"></a>虚拟内存</h5><p>操作系统为了让进程更方便地管理自己的内存空间，使用虚拟内存这一概念为每个进程提供一个抽象，让进程认为自己独占了整个内存空间，因此进程操作的内存地址空间都是操作系统创建出来的虚拟内存地址空间，底层真实内存地址空间是不提供给进程直接访问的</p>\n<p>虚拟内存地址空间的组成如下：</p>\n<ul>\n<li><code>只读代码和数据区</code>：包含程序代码数据和全局变量，进程初始化时就被分配</li>\n<li><code>运行时堆</code>：堆可以动态缩/扩容，通过malloc和free等函数动态分配的内存</li>\n<li><code>共享库</code>：存放c标准库等需要共享的代码和数据，与动态链接有关</li>\n<li><code>栈</code>：编译器使用栈这种数据结构来实现函数调用，用户栈在运行时也可以动态缩/扩容</li>\n<li><code>内核虚拟内存</code>：为内核调用保留的地址空间</li>\n</ul>\n<h5 id=\"文件系统\"><a href=\"#文件系统\" class=\"headerlink\" title=\"文件系统\"></a>文件系统</h5><p>在类Unix系统中，万物皆文件，包括磁盘，网络以及键盘鼠标显示器等IO设备，都看作文件</p>\n<p>操作系统使用文件系统这一概念将底层IO设备进行了抽象，应用程序无需关注硬件设备复杂的实现技术，只需要关注操作系统提供的文件系统接口就行了</p>\n<h4 id=\"重要概念总结\"><a href=\"#重要概念总结\" class=\"headerlink\" title=\"重要概念总结\"></a>重要概念总结</h4><h5 id=\"Amdahl定律\"><a href=\"#Amdahl定律\" class=\"headerlink\" title=\"Amdahl定律\"></a>Amdahl定律</h5><p>Amdahl定律的概念简要概况：系统中某个部分组件进行性能提升的比率，小于对系统整体带来性能提升的比率，也就是说如果要对系统整体进行性能提升，只优化某部分的性能是不够的，必须提升系统绝大多数组件的性能</p>\n<h5 id=\"并发和并行\"><a href=\"#并发和并行\" class=\"headerlink\" title=\"并发和并行\"></a>并发和并行</h5><ul>\n<li>并发：指一个系统同时有多个活动在同时进行</li>\n<li>并行：使用并发的方式让系统运行得更快</li>\n</ul>\n<p><code>线程级并发</code>：一个进程中运行多个线程就是线程级并发技术，并且现代CPU使用超线程技术让单个CPU核心运行不止一个线程</p>\n<p><code>指令级并行</code>：现代CPU可以在一个时钟周期内执行多条指令，称为指令级并行，这种处理器也称为<code>超标量处理器</code></p>\n<p><code>单指令多数据并行</code>：现代CPU允许一条指令产生多个可以并行执行的操作，称为单指令多数据并行（SIMD）</p>\n<h5 id=\"抽象\"><a href=\"#抽象\" class=\"headerlink\" title=\"抽象\"></a>抽象</h5><p>现代计算机科学中最重要的概念之一就是<code>抽象</code>，计算机系统中无时无刻不存在抽象这个概念的运用，提供不同层次的抽象来隐藏底层实现的复杂性</p>\n","site":{"data":{}},"excerpt":"<p>深入理解计算机系统 —— 第一章：</p>\n<p>本书第一章是从一个基本的c语言hello world程序是如何被计算机执行的作为线索，简单介绍了计算机系统中的基本组成和一些核心概念，这些核心概念会贯穿整本书的讲解</p>","more":"<h4 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h4><ul>\n<li>何为信息？bit + 上下文</li>\n<li>程序的编译，如何让机器读懂你的程序</li>\n<li>了解一下编译原理</li>\n<li>处理器是如何处理内存指令的，包含系统硬件组成简介</li>\n<li>高速缓存为加速处理器读写起到关键作用</li>\n<li>存储设备的层次结构</li>\n<li>操作系统是如何运作在系统硬件上的（线程，进程，虚拟内存，文件系统等）</li>\n<li>重要概念总结（Amdahl定律，并发与并行，计算机系统中的抽象）</li>\n</ul>\n<h4 id=\"信息就是bit-上下文\"><a href=\"#信息就是bit-上下文\" class=\"headerlink\" title=\"信息就是bit+上下文\"></a>信息就是bit+上下文</h4><p>信息在计算机系统中是以何种形式存在的？计算机系统中所有信息（内存中的数据，用户编写的程序，磁盘中的文件，网络中传输的信号和文件等）都是以一串bit表示的</p>\n<p>如何区分这些bit串要表达的不同含义？这时就需要判断这些bit串的上下文，不同的bit串在不同的上下文中可能表示一个整数，一个字符串或者一个特殊的cpu指令</p>\n<blockquote>\n<p>C语言的前世今生：</p>\n<p>C语言是一种高级语言，诞生于为Unix操作系统编写各种应用程序的需求，由于其小而简单并易于移植到不同系统的特性而广受欢迎；不过由于它的指针特性等不易于程序员掌握的特性以及缺乏一些抽象的显示支持如类，对象以及异常等，因此不太适合用于编写大型的企业级应用，往往更适合于编写偏底层的小型应用</p>\n</blockquote>\n<h4 id=\"如何让机器读懂你的程序？程序的编译\"><a href=\"#如何让机器读懂你的程序？程序的编译\" class=\"headerlink\" title=\"如何让机器读懂你的程序？程序的编译\"></a>如何让机器读懂你的程序？程序的编译</h4><p>程序员编写好一个c语言源文件，是不能直接运行在系统上的，因为机器读不懂，cpu无法直接执行源文件</p>\n<p>只有将源文件编译为cpu能够执行的一系列的机器语言指令，然后将这些指令打包为<strong>可执行文件</strong>，才能被cpu执行</p>\n<h5 id=\"c语言源文件的编译过程\"><a href=\"#c语言源文件的编译过程\" class=\"headerlink\" title=\"c语言源文件的编译过程\"></a>c语言源文件的编译过程</h5><p>c语言源文件<code>hello.c</code>编译为cpu能够执行的可执行文件需要以下过程：</p>\n<ol>\n<li>预处理阶段</li>\n</ol>\n<blockquote>\n<p>执行单位：预处理器cpp</p>\n<p>生成：修改后的源文件<code>hello.i</code></p>\n<p>目的：根据<code>#</code>字符开头的命令，读取其他程序包到源文件中比如<code>stdio.h</code>，形成一个新的源文件</p>\n</blockquote>\n<ol start=\"2\">\n<li>汇编阶段</li>\n</ol>\n<p>这个阶段又包括两个过程，一个是编译器编译为汇编文本文件，然后由汇编器编译为二进制格式的可重定位目标程序</p>\n<blockquote>\n<p>执行单位：编译器ccl + 汇编器as</p>\n<p>生成：汇编文本文件<code>hello.s</code> ， 二进制的可重定位目标程序<code>hello.o</code></p>\n<p>目的：源文件编译后的汇编程序已经非常接近机器能够执行的机器指令了，不同的高级语言编译后的汇编语言指令都是同一种</p>\n</blockquote>\n<ol start=\"3\">\n<li>链接阶段</li>\n</ol>\n<p>由于<code>hello.c</code>中会使用c语言标准库的printf函数，这个阶段会将已经编译好的printf函数链接到我们的<code>hello.o</code>文件中，生成最终的可执行文件，执行的时候加载到内存中由cpu读取指令进执行</p>\n<h4 id=\"了解一下编译原理\"><a href=\"#了解一下编译原理\" class=\"headerlink\" title=\"了解一下编译原理\"></a>了解一下编译原理</h4><p>虽然源代码的编译过程由系统编译器自行完成，但了解一些编译原理也是有必要的：</p>\n<ul>\n<li>有助于编写性能良好的程序，熟悉编译原理的话就知道自己写的程序将会编译成什么样的机器指令去执行，什么样的执行过程对cpu执行来说才是最优的</li>\n<li>理解链接时出现的错误，比如如何区分静态变量和全局变量，为什么直到运行时才发现链接错误</li>\n<li>避免缓冲区溢出等安全隐患，理解数据和信息存储在栈上的方法会引起的后果</li>\n</ul>\n<h4 id=\"处理器是如何处理内存指令的\"><a href=\"#处理器是如何处理内存指令的\" class=\"headerlink\" title=\"处理器是如何处理内存指令的\"></a>处理器是如何处理内存指令的</h4><p>在理解我们的<code>hello</code>可执行文件是如何被cpu执行前，需要先了解系统硬件的组成和协作过程</p>\n<h5 id=\"系统硬件组成介绍\"><a href=\"#系统硬件组成介绍\" class=\"headerlink\" title=\"系统硬件组成介绍\"></a>系统硬件组成介绍</h5><p>一个基本的冯诺依曼体系的计算机系统由<code>处理器</code>，<code>主存</code>，<code>I/O设备</code>和<code>总线</code>组成</p>\n<ul>\n<li><strong>处理器</strong>CPU：系统的大脑，负责执行程序机器指令，由<code>算术逻辑单元ALU</code>，<code>程序计数器PC</code>，<code>寄存器</code>组成，PC指向主存中某条需要执行的机器指令，由ALU读取该指令并执行该指令的操作，再更新PC使其指向下一条指令</li>\n<li><strong>主存</strong>：包括RAM临时存储和ROM永久存储，主存是系统cpu执行指令时用来临时存放程序指令和数据的地方，每个主存的存储字节都有其唯一的地址</li>\n<li><strong>I/O设备</strong>：包括显示器，鼠标键盘，网卡和磁盘等用于系统和外界交互的硬件设备，每个I/O设备都需要适配器与I/O总线相连</li>\n<li><strong>总线</strong>：一个携带信息字节负责在各个部件间传输信息的电子管道，总线传输宽度由<code>字长</code>确定，现代操作系统一般为32位字长或者64位字长</li>\n</ul>\n<h5 id=\"hello程序的执行过程\"><a href=\"#hello程序的执行过程\" class=\"headerlink\" title=\"hello程序的执行过程\"></a>hello程序的执行过程</h5><p>在键盘上输入命令执行<code>hello</code>文件或者鼠标在屏幕上点击该可执行文件后，依次发生了以下事件：</p>\n<ol>\n<li>shell程序会启动一系列指令将二进制可执行文件从磁盘通过I/O总线加载到主存中（通过<code>DMA</code>技术直接将数据拷贝到主存而不经过cpu的加载和存储等操作）</li>\n<li>hello文件加载到主存后，cpu通过内存总线读取主存中的机器指令，这些指令会将<code>hello world</code>字符串从主存复制到cpu寄存器，再从寄存器通过I/O总线输出给显卡适配器</li>\n<li>显卡适配器获取到具体需要打印的<code>hello world</code>字符串，将信息输出到屏幕上</li>\n</ol>\n<h4 id=\"高速缓存为加速处理器读写起到关键作用\"><a href=\"#高速缓存为加速处理器读写起到关键作用\" class=\"headerlink\" title=\"高速缓存为加速处理器读写起到关键作用\"></a>高速缓存为加速处理器读写起到关键作用</h4><p>以上hello程序执行的过程中，需要先把信息从磁盘复制到主存，再由cpu根据指令从主存复制字符串信息到寄存器，然后再输出给I/O，这一来一去的复制过程大大降低的程序的执行速度，因为cpu从寄存器中读数据速度远大于从主存中读取数据，复制过程就成了瓶颈</p>\n<p><code>高速缓存</code>利用了空间和时间局部性原理，存放cpu近期可能会用到的信息能够大大降低cpu从主存读取数据带来的运行瓶颈</p>\n<p>主流cpu采用<code>SRAM</code>技术，一共将高速缓存分为<code>L1</code>,<code>L2</code>和<code>L3</code>三个层级，其中最靠近cpu的<code>L1</code>高速缓存存取速度最快，容量也最低</p>\n<h4 id=\"存储设备的层次结构\"><a href=\"#存储设备的层次结构\" class=\"headerlink\" title=\"存储设备的层次结构\"></a>存储设备的层次结构</h4><p>计算机系统中的存储设备组织成一个存储器层次结构，从小往上，存储容量越小，访问速度越快：</p>\n<p><img src=\"http://img.mantian.site/1566833029236.png\" alt=\"1566833029236\"></p>\n<h4 id=\"操作系统是如何运作在系统硬件上的\"><a href=\"#操作系统是如何运作在系统硬件上的\" class=\"headerlink\" title=\"操作系统是如何运作在系统硬件上的\"></a>操作系统是如何运作在系统硬件上的</h4><p>用户的应用程序，比如一个shell脚本程序，或者一个c程序，是无法直接和系统硬件打交道的，取而代之的是操作系统，充当了用户程序和系统底层硬件的中间层，提供了统一的系统调用让用户程序间接访问系统硬件，这么做有两个目的：</p>\n<ul>\n<li><p>防止用户程序失控滥用系统硬件</p>\n</li>\n<li><p>向用户程序提供简单一致的机制来对付复杂的底层硬件</p>\n</li>\n</ul>\n<p>通过<code>进程</code>,<code>虚拟内存</code>和<code>文件系统</code>这几种机制来实现以上两个目的</p>\n<h5 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h5><p>进程是现代操作系统中最重要的一个概念，操作系统使用进程这个概念来使得某一个应用程序与本机上其他应用程序进行资源隔离，并且让这个应用程序以为本台机器上只有它自己一个程序在运行</p>\n<p><code>进程上下文切换</code>：</p>\n<ul>\n<li><p>单个CPU核心同一时间只能运行一个程序，如何让多个程序运行在这个CPU核心上？CPU通过<strong>上下文切换</strong>来并发地处理多个进程；</p>\n</li>\n<li><p>进程的上下文包含该进程在PC，寄存器和主存中暂存的数据</p>\n</li>\n<li><p>CPU执行进程的上下文切换时需要切换到内核态</p>\n</li>\n</ul>\n<h5 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h5><p>现代操作系统中，一个进程可以由多个线程组成，每个线程相互之间共享进程的代码和全局数据，可以把进程看作轻量级的进程，CPU也是并发地处理多个线程的请求，同样也会存在上下文切换的情况</p>\n<h5 id=\"虚拟内存\"><a href=\"#虚拟内存\" class=\"headerlink\" title=\"虚拟内存\"></a>虚拟内存</h5><p>操作系统为了让进程更方便地管理自己的内存空间，使用虚拟内存这一概念为每个进程提供一个抽象，让进程认为自己独占了整个内存空间，因此进程操作的内存地址空间都是操作系统创建出来的虚拟内存地址空间，底层真实内存地址空间是不提供给进程直接访问的</p>\n<p>虚拟内存地址空间的组成如下：</p>\n<ul>\n<li><code>只读代码和数据区</code>：包含程序代码数据和全局变量，进程初始化时就被分配</li>\n<li><code>运行时堆</code>：堆可以动态缩/扩容，通过malloc和free等函数动态分配的内存</li>\n<li><code>共享库</code>：存放c标准库等需要共享的代码和数据，与动态链接有关</li>\n<li><code>栈</code>：编译器使用栈这种数据结构来实现函数调用，用户栈在运行时也可以动态缩/扩容</li>\n<li><code>内核虚拟内存</code>：为内核调用保留的地址空间</li>\n</ul>\n<h5 id=\"文件系统\"><a href=\"#文件系统\" class=\"headerlink\" title=\"文件系统\"></a>文件系统</h5><p>在类Unix系统中，万物皆文件，包括磁盘，网络以及键盘鼠标显示器等IO设备，都看作文件</p>\n<p>操作系统使用文件系统这一概念将底层IO设备进行了抽象，应用程序无需关注硬件设备复杂的实现技术，只需要关注操作系统提供的文件系统接口就行了</p>\n<h4 id=\"重要概念总结\"><a href=\"#重要概念总结\" class=\"headerlink\" title=\"重要概念总结\"></a>重要概念总结</h4><h5 id=\"Amdahl定律\"><a href=\"#Amdahl定律\" class=\"headerlink\" title=\"Amdahl定律\"></a>Amdahl定律</h5><p>Amdahl定律的概念简要概况：系统中某个部分组件进行性能提升的比率，小于对系统整体带来性能提升的比率，也就是说如果要对系统整体进行性能提升，只优化某部分的性能是不够的，必须提升系统绝大多数组件的性能</p>\n<h5 id=\"并发和并行\"><a href=\"#并发和并行\" class=\"headerlink\" title=\"并发和并行\"></a>并发和并行</h5><ul>\n<li>并发：指一个系统同时有多个活动在同时进行</li>\n<li>并行：使用并发的方式让系统运行得更快</li>\n</ul>\n<p><code>线程级并发</code>：一个进程中运行多个线程就是线程级并发技术，并且现代CPU使用超线程技术让单个CPU核心运行不止一个线程</p>\n<p><code>指令级并行</code>：现代CPU可以在一个时钟周期内执行多条指令，称为指令级并行，这种处理器也称为<code>超标量处理器</code></p>\n<p><code>单指令多数据并行</code>：现代CPU允许一条指令产生多个可以并行执行的操作，称为单指令多数据并行（SIMD）</p>\n<h5 id=\"抽象\"><a href=\"#抽象\" class=\"headerlink\" title=\"抽象\"></a>抽象</h5><p>现代计算机科学中最重要的概念之一就是<code>抽象</code>，计算机系统中无时无刻不存在抽象这个概念的运用，提供不同层次的抽象来隐藏底层实现的复杂性</p>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 3(1)","author":"天渊","date":"2019-09-17T02:50:00.000Z","_content":"第三章：`程序的机器级表示`\n\n本章将会了解：\n\n1. C语言代码是如何编译为汇编指令，讲解其中的一些编译器优化行为\n2. 汇编指令在机器级的实现，包括栈结构进行过程间数据和控制的传递和局部变量的存储，并学习机器级是如何实现数组这样的数据结构\n\n<!--more-->\n\n### 程序的编码\n\n编译器编译c文件生成的包含汇编指令的s文件，汇编指令已经包含了具体的机器级指令的执行过程，相对于二进制可执行文件而言，汇编指令更加易于阅读，并且能够体现一些在c语言中隐藏的处理器状态\n\n一个程序内包含以下几部分内容：`可执行的机器码`，`操作系统需要的一些信息`，`管理过程调用和返回的运行时栈`，`用户分配的内存块（malloc等）`\n\n> **虚拟地址空间的规范**：\n>\n> x86-64中，地址的寻址范围最高虽然为2^64^-1，不过在目前的视线中地址的高16位必须设置为0，所以一个地址能够指定的是2^48^或64TB范围内的一个字节\n\n有如下的C语言代码`mstore.c`：\n\n```c\nlong mult2(long, long);\nvoid multstore(long x, long y, long *dest) {\n    long t = mult2(x, y);\n    *dest = t;\n}\n```\n\n将这段代码进行编译得到`mstore.o`，再使用反汇编器objdump进行反编译得到如下的汇编代码：\n\n```bash\n0000000000000000 <multstore>:\n   0:   53                      push   %rbx\n   1:   48 89 d3                mov    %rdx,%rbx\n   4:   e8 00 00 00 00          callq  9 <multstore+0x9>\n   9:   48 89 03                mov    %rax,(%rbx)\n   c:   5b                      pop    %rbx\n   d:   c3                      retq\n```\n\n这段汇编代码包含了`mstore.c`程序需要执行的全部指令，左边是机器码指令，右边是汇编指令，机器码和汇编指令在同一个系统中总是一一对应的，其中某些指令结尾的`q`可以忽略\n\n现在另外再编写一个包含main函数的文件`main.c`，用于执行：\n\n```c\n#include <stdio.h>\nvoid multstore(long, long, long *);\nlong mult2(long a, long b) {\n    long s = a * b;\n    return s;\n}\nint main() {\n    long d;\n    multstore(2, 3, &d);\n    printf(\"2 * 3 --> %d\\n\", d);\n    return 0;\n}\n```\n\n编译器需要将`main.c`和`mstore.c`两个文件的函数进行链接：\n\n```bash\n[root@localhost ~]# gcc -Og -o prog main.c mstore.c\n```\n\n编译为可执行文件`prog`后再用`objdump`进行反编译，反编译完成后的结果包含`multstore`函数对应的汇编指令：\n\n```bash\n000000000040056b <multstore>:\n  40056b:       53                      push   %rbx\n  40056c:       48 89 d3                mov    %rdx,%rbx\n  40056f:       e8 b9 ff ff ff          callq  40052d <mult2>\n  400574:       48 89 03                mov    %rax,(%rbx)\n  400577:       5b                      pop    %rbx\n  400578:       c3                      retq   \n  400579:       0f 1f 80 00 00 00 00    nopl   0x0(%rax)\n```\n\n可以看到，链接后的`multstore`与之前未链接的`multstore`有两个不同点：\n\n- 第三行`call`指令调用mult2函数时，调用地址变成了具体的函数地址`40052d`\n- 最后加上了一个占位指令`nop`，没有实际意义，只是回了让函数代码变为16字节，一个存储器优化\n\n### 访问信息\n\n这一部分主要讲的是cpu通过寄存器执行指令的具体过程\n\n#### 寄存器\n\n上面的汇编指令例子中有诸如`%rdx`和`%rbx`这样的标识，代表的是x86架构最早的8个寄存器，标号从`%rax`一直到`%rbp`\n\nIA32架构扩展到x86-64架构后，除了将原来的8个寄存器扩展为64位，还增加了8个寄存器，命名从`%r8`到`%r15`\n\n以下是这16个寄存器的具体表示，其中像`%eax`和`%ebx`这类是32位寄存器标号，像`%ax`和`%bx`这类是16位寄存器标号，像`a1`和`b1`这类是8位寄存器标号，不同的寄存器标号对应了当前寄存器上指定低位的字节数据，这些都是为了兼容以前8位，16位和32位机器上编译的程序\n\n<img src=\"http://img.mantian.site/201909161543_84.png\" style=\"zoom:80%;\" />\n\n图中，右边是每个寄存器对应的不同的角色\n\n在x86-64机器上，如果某段程序生成了低位指令，例如生成了一个2字节16位的`%ax`指令，需要以`%rax`这个寄存器为目标，那么高48位的字节怎么处理？有两条规则：\n\n- 对于8位和16位的指令，保持剩下的高位字节数不变\n- 对于32位的指令，给剩下32位的字节数置为0\n\n#### 指令的操作数格式\n\n一个指令具体要干啥？多数情况下就是将某个数据放置到某个寄存器或者内存位置，或者将某个数据从某个位置读出，放到某个寄存器或者内存中，这时候就引入了`操作数`的概念，指定某个操作中需要使用的`源数据`（可以是常数或者某个地址）和放置结果的`目的位置`\n\n**`操作数`如何指定源数据？**\n\n- `立即数`：立即数也就是常数，用`$`符号后面跟着数字的方式表示：`$0x1F`\n\n- `寄存器`：操作数位于某个寄存器上，表示方式是直接指定某个寄存器标号`ra`，然后用`R[ra]`来表示这个寄存器存储的值，比如上述例子中的某条指令就是将`%rdx上的数据移动到`%rbx`上： `mov  %rdx,%rbx`\n\n- `内存`：指定内存上操作数的过程相对来说就比较复杂了，需要涉及到以下4个参数：`立即数偏移Imm`， `基址寄存器rb`，`变址寄存器ri`，`比例因子s`；计算有效内存地址的公式是：\n\n  <img src=\"http://img.mantian.site/201909161624_428.png\" style=\"zoom:50%;\" />\n\n  也就是一个立即数加上`基址寄存器`保存的值，再加上`变址寄存器`保存的值乘以一个偏移比例因子\n\n  通过以下这种格式来表示某个内存操作数：\n\n  <img src=\"http://img.mantian.site/201909161628_844.png\" style=\"zoom:80%;\" />\n\n  其中，四个参数并不需要全部出现，有时候会省略个别参数，以下是内存操作数格式表，其他所有情况都是最后一种的特殊情况：\n\n  ![](http://img.mantian.site/201909161630_895.png)\n\n  \n\n了解了以上三种操作数形式，就可以计算出下列操作数表示的具体值了：\n\n>  已知寄存器`%rcx`保存的值是`0x1`，`%rdx`保存的值是`0x3`，求`260(%rcx, %rdx, 2)`这个操作数表示的值？\n>\n> 根据上述公式，这个操作数对应的地址值应该是`260 + 1 + 3 * 2 = 267`，转换为16进制就是`0x10B`，也就是说这个操作数对应的是内存`0x10B`处的数据\n\n**8字节寄存器**：x86-64中，总是以8字节的寄存器如`%rax`等来表示某个内存的地址\n\n#### 数据传送指令\n\n现在，有了数据位置（寄存器和内存）和操作数，就需要具体的指令来挪动这些数据了\n\n计算机系统中最频繁的就是将一数据从一个位置复制到另一个位置的指令，也就是`MOV`指令，该指令在复制数据时不会做任何修改操作；`MOV`指令根据操作的字节位数还细分为以下几种，其中一个字代表2字节：\n\n![](http://img.mantian.site/201909161654_300.png)\n\n如果需要对寄存器的数据进行以上操作，对应的寄存器标号的字节位数必须与`mov`指令的最后字符相匹配，比如说操作4字节的寄存器`%eax`，需要的指令是`movl`\n\n如果源寄存器和目的寄存器的大小不一致怎么处理？`movz`系列的命令就能将较小的源寄存器数据复制到较大的寄存器，复制完成后会将高位填充为0，其中指令结尾两个符号分别表示源寄存器大小和目标寄存器大小：\n\n![](http://img.mantian.site/201909171627_383.png)\n\n`movz`复制到较大寄存器后，只能将剩余的高位全部用0填充，会忽略掉源数据的符号；`movs`系列的指令与`movz`类似，不过在进行扩展时会考虑源数据的符号位，如果源数据最高位是1，则将目标寄存器剩余的最高位全部设置为1\n\n![](http://img.mantian.site/201909161745_573.png)\n\n如上，`movs`指令最后两位也是表示源寄存器大小和目标寄存器大小；最后一个`cltq`指令只能以`%eax`作为源，以`%rax`作为目标，仅仅作符号扩展用\n\n**内存无法直接复制**：x86-64规定，不能使用`mov`指令直接将数据从一个内存地址复制到另一个内存地址，只能先复制到寄存器\n\n##### 数据传送指令示例\n\n如下有这么一段C程序，将y赋值给指针变量`*xp`，最后返回`*xp`的旧值：\n\n```c\nlong exchange(long *xp, long y) {\n    long x = *xp;\n    *xp = y;\n    return x;\n}\n```\n\n用`gcc -Og -S`命令生成过渡汇编代码后，可以看到exchange函数被编译为如下的汇编指令：\n\n```\nmovq    (%rdi), %rax\nmovq    %rsi, (%rdi)\nret\n```\n\n这段代码执行的过程如下：\n\n1. 使用`movq`命令从`%rdi`这个寄存器记录的内存地址位置上（也就是`*xp`指针指向的内存）复制8个字节的数字到`%rax`寄存器\n2. 使用`movq`命令从`%rsi`上复制8个字节的数字（也就是`y`）到`%rdi`记录的内存地址\n3. 最后使用`ret`命令将`%rax`寄存器的值返回 （`%rax`一般就是用来保存函数返回值）\n\n**思考**：如果需要用汇编指令实现以下程序，具体指令应该是怎样的？\n\n```c\nchar *a;\nint *b;\n*a = -127;\nint *b = (int) *a;\n```\n\n首先在c语言规范中，如果要将低位数的有符号类型强制转换为高位数的有符号类型，需要先扩充位数，然后再按照高位数的方式读取，所以具体汇编指令如下，假设`*a`保存在`%rdi`上，`*b`保存在`%rsi`上：\n\n```assembly\nmovsbl\t(%rdi), %rax\t// 从(%rdi)读取一个字节复制到%rax上然后进行符号填充\nmovl\t%rax, (%rsi)\t// 读取4字节到(%rsi)内存\n```\n\n因为`char`类型默认是有符号的，因此扩展时需要进行有符号扩展，使用`movsbl`指令\n\n#### 压入和弹出栈数据\n\n计算机系统使用`栈`这个数据结构来实现函数的调用过程，涉及到`入栈(push)`和`出栈(pop)`的指令，每次入栈或者出栈操作都是对栈顶进行操作\n\n- `pushq`：将8字节的数字压入栈顶，对应一个操作数即需要压入的数据源\n- `popq`：将8字节的数字弹出栈顶，也是只有一个操作数即弹出的数据的目的地\n\n内存中`栈`这个数据结构可以当成一个数组，方向是由上往下的，栈顶在底部，地址最小，栈底在顶部，地址最大，因此如果是需要对某个8字节的数字进行`入栈`操作，就得先获取栈顶地址，然后将地址减去8得到一个新的地址，然后把数字放入这个新地址\n\n假设，我们现在有个数字存放于`%rax`上，我们先将他入栈，执行的指令是`%pushq  %rax`，然后将他出栈放到`%rdx`，执行指令`%pushq  %rdx`，栈顶指针保存于`%rsp`，具体过程如下：\n\n![](http://img.mantian.site/201909171557_719.png)\n\n1. 首先，需要找到压栈后数据在栈中的地址，也就是在原栈顶`0x108`的基础上减去8，得到新栈顶的地址`0x100`\n2. 然后，将`%rax`的数据复制到栈顶，也就是`0x100`这个位置，入栈操作就完成了\n3. 最后，将`0x100`位置的数据复制到`%rdx`，将栈顶地址加上8，出栈操作也就完成了","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-3.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 3(1)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-09-17 10:50:00\n---\n第三章：`程序的机器级表示`\n\n本章将会了解：\n\n1. C语言代码是如何编译为汇编指令，讲解其中的一些编译器优化行为\n2. 汇编指令在机器级的实现，包括栈结构进行过程间数据和控制的传递和局部变量的存储，并学习机器级是如何实现数组这样的数据结构\n\n<!--more-->\n\n### 程序的编码\n\n编译器编译c文件生成的包含汇编指令的s文件，汇编指令已经包含了具体的机器级指令的执行过程，相对于二进制可执行文件而言，汇编指令更加易于阅读，并且能够体现一些在c语言中隐藏的处理器状态\n\n一个程序内包含以下几部分内容：`可执行的机器码`，`操作系统需要的一些信息`，`管理过程调用和返回的运行时栈`，`用户分配的内存块（malloc等）`\n\n> **虚拟地址空间的规范**：\n>\n> x86-64中，地址的寻址范围最高虽然为2^64^-1，不过在目前的视线中地址的高16位必须设置为0，所以一个地址能够指定的是2^48^或64TB范围内的一个字节\n\n有如下的C语言代码`mstore.c`：\n\n```c\nlong mult2(long, long);\nvoid multstore(long x, long y, long *dest) {\n    long t = mult2(x, y);\n    *dest = t;\n}\n```\n\n将这段代码进行编译得到`mstore.o`，再使用反汇编器objdump进行反编译得到如下的汇编代码：\n\n```bash\n0000000000000000 <multstore>:\n   0:   53                      push   %rbx\n   1:   48 89 d3                mov    %rdx,%rbx\n   4:   e8 00 00 00 00          callq  9 <multstore+0x9>\n   9:   48 89 03                mov    %rax,(%rbx)\n   c:   5b                      pop    %rbx\n   d:   c3                      retq\n```\n\n这段汇编代码包含了`mstore.c`程序需要执行的全部指令，左边是机器码指令，右边是汇编指令，机器码和汇编指令在同一个系统中总是一一对应的，其中某些指令结尾的`q`可以忽略\n\n现在另外再编写一个包含main函数的文件`main.c`，用于执行：\n\n```c\n#include <stdio.h>\nvoid multstore(long, long, long *);\nlong mult2(long a, long b) {\n    long s = a * b;\n    return s;\n}\nint main() {\n    long d;\n    multstore(2, 3, &d);\n    printf(\"2 * 3 --> %d\\n\", d);\n    return 0;\n}\n```\n\n编译器需要将`main.c`和`mstore.c`两个文件的函数进行链接：\n\n```bash\n[root@localhost ~]# gcc -Og -o prog main.c mstore.c\n```\n\n编译为可执行文件`prog`后再用`objdump`进行反编译，反编译完成后的结果包含`multstore`函数对应的汇编指令：\n\n```bash\n000000000040056b <multstore>:\n  40056b:       53                      push   %rbx\n  40056c:       48 89 d3                mov    %rdx,%rbx\n  40056f:       e8 b9 ff ff ff          callq  40052d <mult2>\n  400574:       48 89 03                mov    %rax,(%rbx)\n  400577:       5b                      pop    %rbx\n  400578:       c3                      retq   \n  400579:       0f 1f 80 00 00 00 00    nopl   0x0(%rax)\n```\n\n可以看到，链接后的`multstore`与之前未链接的`multstore`有两个不同点：\n\n- 第三行`call`指令调用mult2函数时，调用地址变成了具体的函数地址`40052d`\n- 最后加上了一个占位指令`nop`，没有实际意义，只是回了让函数代码变为16字节，一个存储器优化\n\n### 访问信息\n\n这一部分主要讲的是cpu通过寄存器执行指令的具体过程\n\n#### 寄存器\n\n上面的汇编指令例子中有诸如`%rdx`和`%rbx`这样的标识，代表的是x86架构最早的8个寄存器，标号从`%rax`一直到`%rbp`\n\nIA32架构扩展到x86-64架构后，除了将原来的8个寄存器扩展为64位，还增加了8个寄存器，命名从`%r8`到`%r15`\n\n以下是这16个寄存器的具体表示，其中像`%eax`和`%ebx`这类是32位寄存器标号，像`%ax`和`%bx`这类是16位寄存器标号，像`a1`和`b1`这类是8位寄存器标号，不同的寄存器标号对应了当前寄存器上指定低位的字节数据，这些都是为了兼容以前8位，16位和32位机器上编译的程序\n\n<img src=\"http://img.mantian.site/201909161543_84.png\" style=\"zoom:80%;\" />\n\n图中，右边是每个寄存器对应的不同的角色\n\n在x86-64机器上，如果某段程序生成了低位指令，例如生成了一个2字节16位的`%ax`指令，需要以`%rax`这个寄存器为目标，那么高48位的字节怎么处理？有两条规则：\n\n- 对于8位和16位的指令，保持剩下的高位字节数不变\n- 对于32位的指令，给剩下32位的字节数置为0\n\n#### 指令的操作数格式\n\n一个指令具体要干啥？多数情况下就是将某个数据放置到某个寄存器或者内存位置，或者将某个数据从某个位置读出，放到某个寄存器或者内存中，这时候就引入了`操作数`的概念，指定某个操作中需要使用的`源数据`（可以是常数或者某个地址）和放置结果的`目的位置`\n\n**`操作数`如何指定源数据？**\n\n- `立即数`：立即数也就是常数，用`$`符号后面跟着数字的方式表示：`$0x1F`\n\n- `寄存器`：操作数位于某个寄存器上，表示方式是直接指定某个寄存器标号`ra`，然后用`R[ra]`来表示这个寄存器存储的值，比如上述例子中的某条指令就是将`%rdx上的数据移动到`%rbx`上： `mov  %rdx,%rbx`\n\n- `内存`：指定内存上操作数的过程相对来说就比较复杂了，需要涉及到以下4个参数：`立即数偏移Imm`， `基址寄存器rb`，`变址寄存器ri`，`比例因子s`；计算有效内存地址的公式是：\n\n  <img src=\"http://img.mantian.site/201909161624_428.png\" style=\"zoom:50%;\" />\n\n  也就是一个立即数加上`基址寄存器`保存的值，再加上`变址寄存器`保存的值乘以一个偏移比例因子\n\n  通过以下这种格式来表示某个内存操作数：\n\n  <img src=\"http://img.mantian.site/201909161628_844.png\" style=\"zoom:80%;\" />\n\n  其中，四个参数并不需要全部出现，有时候会省略个别参数，以下是内存操作数格式表，其他所有情况都是最后一种的特殊情况：\n\n  ![](http://img.mantian.site/201909161630_895.png)\n\n  \n\n了解了以上三种操作数形式，就可以计算出下列操作数表示的具体值了：\n\n>  已知寄存器`%rcx`保存的值是`0x1`，`%rdx`保存的值是`0x3`，求`260(%rcx, %rdx, 2)`这个操作数表示的值？\n>\n> 根据上述公式，这个操作数对应的地址值应该是`260 + 1 + 3 * 2 = 267`，转换为16进制就是`0x10B`，也就是说这个操作数对应的是内存`0x10B`处的数据\n\n**8字节寄存器**：x86-64中，总是以8字节的寄存器如`%rax`等来表示某个内存的地址\n\n#### 数据传送指令\n\n现在，有了数据位置（寄存器和内存）和操作数，就需要具体的指令来挪动这些数据了\n\n计算机系统中最频繁的就是将一数据从一个位置复制到另一个位置的指令，也就是`MOV`指令，该指令在复制数据时不会做任何修改操作；`MOV`指令根据操作的字节位数还细分为以下几种，其中一个字代表2字节：\n\n![](http://img.mantian.site/201909161654_300.png)\n\n如果需要对寄存器的数据进行以上操作，对应的寄存器标号的字节位数必须与`mov`指令的最后字符相匹配，比如说操作4字节的寄存器`%eax`，需要的指令是`movl`\n\n如果源寄存器和目的寄存器的大小不一致怎么处理？`movz`系列的命令就能将较小的源寄存器数据复制到较大的寄存器，复制完成后会将高位填充为0，其中指令结尾两个符号分别表示源寄存器大小和目标寄存器大小：\n\n![](http://img.mantian.site/201909171627_383.png)\n\n`movz`复制到较大寄存器后，只能将剩余的高位全部用0填充，会忽略掉源数据的符号；`movs`系列的指令与`movz`类似，不过在进行扩展时会考虑源数据的符号位，如果源数据最高位是1，则将目标寄存器剩余的最高位全部设置为1\n\n![](http://img.mantian.site/201909161745_573.png)\n\n如上，`movs`指令最后两位也是表示源寄存器大小和目标寄存器大小；最后一个`cltq`指令只能以`%eax`作为源，以`%rax`作为目标，仅仅作符号扩展用\n\n**内存无法直接复制**：x86-64规定，不能使用`mov`指令直接将数据从一个内存地址复制到另一个内存地址，只能先复制到寄存器\n\n##### 数据传送指令示例\n\n如下有这么一段C程序，将y赋值给指针变量`*xp`，最后返回`*xp`的旧值：\n\n```c\nlong exchange(long *xp, long y) {\n    long x = *xp;\n    *xp = y;\n    return x;\n}\n```\n\n用`gcc -Og -S`命令生成过渡汇编代码后，可以看到exchange函数被编译为如下的汇编指令：\n\n```\nmovq    (%rdi), %rax\nmovq    %rsi, (%rdi)\nret\n```\n\n这段代码执行的过程如下：\n\n1. 使用`movq`命令从`%rdi`这个寄存器记录的内存地址位置上（也就是`*xp`指针指向的内存）复制8个字节的数字到`%rax`寄存器\n2. 使用`movq`命令从`%rsi`上复制8个字节的数字（也就是`y`）到`%rdi`记录的内存地址\n3. 最后使用`ret`命令将`%rax`寄存器的值返回 （`%rax`一般就是用来保存函数返回值）\n\n**思考**：如果需要用汇编指令实现以下程序，具体指令应该是怎样的？\n\n```c\nchar *a;\nint *b;\n*a = -127;\nint *b = (int) *a;\n```\n\n首先在c语言规范中，如果要将低位数的有符号类型强制转换为高位数的有符号类型，需要先扩充位数，然后再按照高位数的方式读取，所以具体汇编指令如下，假设`*a`保存在`%rdi`上，`*b`保存在`%rsi`上：\n\n```assembly\nmovsbl\t(%rdi), %rax\t// 从(%rdi)读取一个字节复制到%rax上然后进行符号填充\nmovl\t%rax, (%rsi)\t// 读取4字节到(%rsi)内存\n```\n\n因为`char`类型默认是有符号的，因此扩展时需要进行有符号扩展，使用`movsbl`指令\n\n#### 压入和弹出栈数据\n\n计算机系统使用`栈`这个数据结构来实现函数的调用过程，涉及到`入栈(push)`和`出栈(pop)`的指令，每次入栈或者出栈操作都是对栈顶进行操作\n\n- `pushq`：将8字节的数字压入栈顶，对应一个操作数即需要压入的数据源\n- `popq`：将8字节的数字弹出栈顶，也是只有一个操作数即弹出的数据的目的地\n\n内存中`栈`这个数据结构可以当成一个数组，方向是由上往下的，栈顶在底部，地址最小，栈底在顶部，地址最大，因此如果是需要对某个8字节的数字进行`入栈`操作，就得先获取栈顶地址，然后将地址减去8得到一个新的地址，然后把数字放入这个新地址\n\n假设，我们现在有个数字存放于`%rax`上，我们先将他入栈，执行的指令是`%pushq  %rax`，然后将他出栈放到`%rdx`，执行指令`%pushq  %rdx`，栈顶指针保存于`%rsp`，具体过程如下：\n\n![](http://img.mantian.site/201909171557_719.png)\n\n1. 首先，需要找到压栈后数据在栈中的地址，也就是在原栈顶`0x108`的基础上减去8，得到新栈顶的地址`0x100`\n2. 然后，将`%rax`的数据复制到栈顶，也就是`0x100`这个位置，入栈操作就完成了\n3. 最后，将`0x100`位置的数据复制到`%rdx`，将栈顶地址加上8，出栈操作也就完成了","slug":"《深入理解计算机系统》读书笔记——Chapter-3","published":1,"updated":"2019-10-01T10:25:04.176Z","_id":"ckf0h31ih0029actsqs9b36iy","comments":1,"layout":"post","photos":[],"link":"","content":"<p>第三章：<code>程序的机器级表示</code></p>\n<p>本章将会了解：</p>\n<ol>\n<li>C语言代码是如何编译为汇编指令，讲解其中的一些编译器优化行为</li>\n<li>汇编指令在机器级的实现，包括栈结构进行过程间数据和控制的传递和局部变量的存储，并学习机器级是如何实现数组这样的数据结构</li>\n</ol>\n<a id=\"more\"></a>\n<h3 id=\"程序的编码\"><a href=\"#程序的编码\" class=\"headerlink\" title=\"程序的编码\"></a>程序的编码</h3><p>编译器编译c文件生成的包含汇编指令的s文件，汇编指令已经包含了具体的机器级指令的执行过程，相对于二进制可执行文件而言，汇编指令更加易于阅读，并且能够体现一些在c语言中隐藏的处理器状态</p>\n<p>一个程序内包含以下几部分内容：<code>可执行的机器码</code>，<code>操作系统需要的一些信息</code>，<code>管理过程调用和返回的运行时栈</code>，<code>用户分配的内存块（malloc等）</code></p>\n<blockquote>\n<p><strong>虚拟地址空间的规范</strong>：</p>\n<p>x86-64中，地址的寻址范围最高虽然为2^64^-1，不过在目前的视线中地址的高16位必须设置为0，所以一个地址能够指定的是2^48^或64TB范围内的一个字节</p>\n</blockquote>\n<p>有如下的C语言代码<code>mstore.c</code>：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">long</span> <span class=\"title\">mult2</span><span class=\"params\">(<span class=\"keyword\">long</span>, <span class=\"keyword\">long</span>)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">multstore</span><span class=\"params\">(<span class=\"keyword\">long</span> x, <span class=\"keyword\">long</span> y, <span class=\"keyword\">long</span> *dest)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">long</span> t = mult2(x, y);</span><br><span class=\"line\">    *dest = t;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>将这段代码进行编译得到<code>mstore.o</code>，再使用反汇编器objdump进行反编译得到如下的汇编代码：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">0000000000000000 &lt;multstore&gt;:</span><br><span class=\"line\">   0:   53                      push   %rbx</span><br><span class=\"line\">   1:   48 89 d3                mov    %rdx,%rbx</span><br><span class=\"line\">   4:   e8 00 00 00 00          callq  9 &lt;multstore+0x9&gt;</span><br><span class=\"line\">   9:   48 89 03                mov    %rax,(%rbx)</span><br><span class=\"line\">   c:   5b                      pop    %rbx</span><br><span class=\"line\">   d:   c3                      retq</span><br></pre></td></tr></table></figure>\n<p>这段汇编代码包含了<code>mstore.c</code>程序需要执行的全部指令，左边是机器码指令，右边是汇编指令，机器码和汇编指令在同一个系统中总是一一对应的，其中某些指令结尾的<code>q</code>可以忽略</p>\n<p>现在另外再编写一个包含main函数的文件<code>main.c</code>，用于执行：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">multstore</span><span class=\"params\">(<span class=\"keyword\">long</span>, <span class=\"keyword\">long</span>, <span class=\"keyword\">long</span> *)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">long</span> <span class=\"title\">mult2</span><span class=\"params\">(<span class=\"keyword\">long</span> a, <span class=\"keyword\">long</span> b)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">long</span> s = a * b;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> s;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">long</span> d;</span><br><span class=\"line\">    multstore(<span class=\"number\">2</span>, <span class=\"number\">3</span>, &amp;d);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"2 * 3 --&gt; %d\\n\"</span>, d);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>编译器需要将<code>main.c</code>和<code>mstore.c</code>两个文件的函数进行链接：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]<span class=\"comment\"># gcc -Og -o prog main.c mstore.c</span></span><br></pre></td></tr></table></figure>\n<p>编译为可执行文件<code>prog</code>后再用<code>objdump</code>进行反编译，反编译完成后的结果包含<code>multstore</code>函数对应的汇编指令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">000000000040056b &lt;multstore&gt;:</span><br><span class=\"line\">  40056b:       53                      push   %rbx</span><br><span class=\"line\">  40056c:       48 89 d3                mov    %rdx,%rbx</span><br><span class=\"line\">  40056f:       e8 b9 ff ff ff          callq  40052d &lt;mult2&gt;</span><br><span class=\"line\">  400574:       48 89 03                mov    %rax,(%rbx)</span><br><span class=\"line\">  400577:       5b                      pop    %rbx</span><br><span class=\"line\">  400578:       c3                      retq   </span><br><span class=\"line\">  400579:       0f 1f 80 00 00 00 00    nopl   0x0(%rax)</span><br></pre></td></tr></table></figure>\n<p>可以看到，链接后的<code>multstore</code>与之前未链接的<code>multstore</code>有两个不同点：</p>\n<ul>\n<li>第三行<code>call</code>指令调用mult2函数时，调用地址变成了具体的函数地址<code>40052d</code></li>\n<li>最后加上了一个占位指令<code>nop</code>，没有实际意义，只是回了让函数代码变为16字节，一个存储器优化</li>\n</ul>\n<h3 id=\"访问信息\"><a href=\"#访问信息\" class=\"headerlink\" title=\"访问信息\"></a>访问信息</h3><p>这一部分主要讲的是cpu通过寄存器执行指令的具体过程</p>\n<h4 id=\"寄存器\"><a href=\"#寄存器\" class=\"headerlink\" title=\"寄存器\"></a>寄存器</h4><p>上面的汇编指令例子中有诸如<code>%rdx</code>和<code>%rbx</code>这样的标识，代表的是x86架构最早的8个寄存器，标号从<code>%rax</code>一直到<code>%rbp</code></p>\n<p>IA32架构扩展到x86-64架构后，除了将原来的8个寄存器扩展为64位，还增加了8个寄存器，命名从<code>%r8</code>到<code>%r15</code></p>\n<p>以下是这16个寄存器的具体表示，其中像<code>%eax</code>和<code>%ebx</code>这类是32位寄存器标号，像<code>%ax</code>和<code>%bx</code>这类是16位寄存器标号，像<code>a1</code>和<code>b1</code>这类是8位寄存器标号，不同的寄存器标号对应了当前寄存器上指定低位的字节数据，这些都是为了兼容以前8位，16位和32位机器上编译的程序</p>\n<p><img src=\"http://img.mantian.site/201909161543_84.png\" style=\"zoom:80%;\"></p>\n<p>图中，右边是每个寄存器对应的不同的角色</p>\n<p>在x86-64机器上，如果某段程序生成了低位指令，例如生成了一个2字节16位的<code>%ax</code>指令，需要以<code>%rax</code>这个寄存器为目标，那么高48位的字节怎么处理？有两条规则：</p>\n<ul>\n<li>对于8位和16位的指令，保持剩下的高位字节数不变</li>\n<li>对于32位的指令，给剩下32位的字节数置为0</li>\n</ul>\n<h4 id=\"指令的操作数格式\"><a href=\"#指令的操作数格式\" class=\"headerlink\" title=\"指令的操作数格式\"></a>指令的操作数格式</h4><p>一个指令具体要干啥？多数情况下就是将某个数据放置到某个寄存器或者内存位置，或者将某个数据从某个位置读出，放到某个寄存器或者内存中，这时候就引入了<code>操作数</code>的概念，指定某个操作中需要使用的<code>源数据</code>（可以是常数或者某个地址）和放置结果的<code>目的位置</code></p>\n<p><strong><code>操作数</code>如何指定源数据？</strong></p>\n<ul>\n<li><p><code>立即数</code>：立即数也就是常数，用<code>$</code>符号后面跟着数字的方式表示：<code>$0x1F</code></p>\n</li>\n<li><p><code>寄存器</code>：操作数位于某个寄存器上，表示方式是直接指定某个寄存器标号<code>ra</code>，然后用<code>R[ra]</code>来表示这个寄存器存储的值，比如上述例子中的某条指令就是将<code>%rdx上的数据移动到</code>%rbx<code>上：</code>mov  %rdx,%rbx`</p>\n</li>\n<li><p><code>内存</code>：指定内存上操作数的过程相对来说就比较复杂了，需要涉及到以下4个参数：<code>立即数偏移Imm</code>， <code>基址寄存器rb</code>，<code>变址寄存器ri</code>，<code>比例因子s</code>；计算有效内存地址的公式是：</p>\n<p><img src=\"http://img.mantian.site/201909161624_428.png\" style=\"zoom:50%;\"></p>\n<p>也就是一个立即数加上<code>基址寄存器</code>保存的值，再加上<code>变址寄存器</code>保存的值乘以一个偏移比例因子</p>\n<p>通过以下这种格式来表示某个内存操作数：</p>\n<p><img src=\"http://img.mantian.site/201909161628_844.png\" style=\"zoom:80%;\"></p>\n<p>其中，四个参数并不需要全部出现，有时候会省略个别参数，以下是内存操作数格式表，其他所有情况都是最后一种的特殊情况：</p>\n<p><img src=\"http://img.mantian.site/201909161630_895.png\" alt></p>\n</li>\n</ul>\n<p>了解了以上三种操作数形式，就可以计算出下列操作数表示的具体值了：</p>\n<blockquote>\n<p> 已知寄存器<code>%rcx</code>保存的值是<code>0x1</code>，<code>%rdx</code>保存的值是<code>0x3</code>，求<code>260(%rcx, %rdx, 2)</code>这个操作数表示的值？</p>\n<p>根据上述公式，这个操作数对应的地址值应该是<code>260 + 1 + 3 * 2 = 267</code>，转换为16进制就是<code>0x10B</code>，也就是说这个操作数对应的是内存<code>0x10B</code>处的数据</p>\n</blockquote>\n<p><strong>8字节寄存器</strong>：x86-64中，总是以8字节的寄存器如<code>%rax</code>等来表示某个内存的地址</p>\n<h4 id=\"数据传送指令\"><a href=\"#数据传送指令\" class=\"headerlink\" title=\"数据传送指令\"></a>数据传送指令</h4><p>现在，有了数据位置（寄存器和内存）和操作数，就需要具体的指令来挪动这些数据了</p>\n<p>计算机系统中最频繁的就是将一数据从一个位置复制到另一个位置的指令，也就是<code>MOV</code>指令，该指令在复制数据时不会做任何修改操作；<code>MOV</code>指令根据操作的字节位数还细分为以下几种，其中一个字代表2字节：</p>\n<p><img src=\"http://img.mantian.site/201909161654_300.png\" alt></p>\n<p>如果需要对寄存器的数据进行以上操作，对应的寄存器标号的字节位数必须与<code>mov</code>指令的最后字符相匹配，比如说操作4字节的寄存器<code>%eax</code>，需要的指令是<code>movl</code></p>\n<p>如果源寄存器和目的寄存器的大小不一致怎么处理？<code>movz</code>系列的命令就能将较小的源寄存器数据复制到较大的寄存器，复制完成后会将高位填充为0，其中指令结尾两个符号分别表示源寄存器大小和目标寄存器大小：</p>\n<p><img src=\"http://img.mantian.site/201909171627_383.png\" alt></p>\n<p><code>movz</code>复制到较大寄存器后，只能将剩余的高位全部用0填充，会忽略掉源数据的符号；<code>movs</code>系列的指令与<code>movz</code>类似，不过在进行扩展时会考虑源数据的符号位，如果源数据最高位是1，则将目标寄存器剩余的最高位全部设置为1</p>\n<p><img src=\"http://img.mantian.site/201909161745_573.png\" alt></p>\n<p>如上，<code>movs</code>指令最后两位也是表示源寄存器大小和目标寄存器大小；最后一个<code>cltq</code>指令只能以<code>%eax</code>作为源，以<code>%rax</code>作为目标，仅仅作符号扩展用</p>\n<p><strong>内存无法直接复制</strong>：x86-64规定，不能使用<code>mov</code>指令直接将数据从一个内存地址复制到另一个内存地址，只能先复制到寄存器</p>\n<h5 id=\"数据传送指令示例\"><a href=\"#数据传送指令示例\" class=\"headerlink\" title=\"数据传送指令示例\"></a>数据传送指令示例</h5><p>如下有这么一段C程序，将y赋值给指针变量<code>*xp</code>，最后返回<code>*xp</code>的旧值：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">long</span> <span class=\"title\">exchange</span><span class=\"params\">(<span class=\"keyword\">long</span> *xp, <span class=\"keyword\">long</span> y)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">long</span> x = *xp;</span><br><span class=\"line\">    *xp = y;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>用<code>gcc -Og -S</code>命令生成过渡汇编代码后，可以看到exchange函数被编译为如下的汇编指令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">movq    (%rdi), %rax</span><br><span class=\"line\">movq    %rsi, (%rdi)</span><br><span class=\"line\">ret</span><br></pre></td></tr></table></figure>\n<p>这段代码执行的过程如下：</p>\n<ol>\n<li>使用<code>movq</code>命令从<code>%rdi</code>这个寄存器记录的内存地址位置上（也就是<code>*xp</code>指针指向的内存）复制8个字节的数字到<code>%rax</code>寄存器</li>\n<li>使用<code>movq</code>命令从<code>%rsi</code>上复制8个字节的数字（也就是<code>y</code>）到<code>%rdi</code>记录的内存地址</li>\n<li>最后使用<code>ret</code>命令将<code>%rax</code>寄存器的值返回 （<code>%rax</code>一般就是用来保存函数返回值）</li>\n</ol>\n<p><strong>思考</strong>：如果需要用汇编指令实现以下程序，具体指令应该是怎样的？</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">char</span> *a;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *b;</span><br><span class=\"line\">*a = <span class=\"number\">-127</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *b = (<span class=\"keyword\">int</span>) *a;</span><br></pre></td></tr></table></figure>\n<p>首先在c语言规范中，如果要将低位数的有符号类型强制转换为高位数的有符号类型，需要先扩充位数，然后再按照高位数的方式读取，所以具体汇编指令如下，假设<code>*a</code>保存在<code>%rdi</code>上，<code>*b</code>保存在<code>%rsi</code>上：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">movsbl\t(%rdi), %rax\t// 从(%rdi)读取一个字节复制到%rax上然后进行符号填充</span><br><span class=\"line\">movl\t%rax, (%rsi)\t// 读取4字节到(%rsi)内存</span><br></pre></td></tr></table></figure>\n<p>因为<code>char</code>类型默认是有符号的，因此扩展时需要进行有符号扩展，使用<code>movsbl</code>指令</p>\n<h4 id=\"压入和弹出栈数据\"><a href=\"#压入和弹出栈数据\" class=\"headerlink\" title=\"压入和弹出栈数据\"></a>压入和弹出栈数据</h4><p>计算机系统使用<code>栈</code>这个数据结构来实现函数的调用过程，涉及到<code>入栈(push)</code>和<code>出栈(pop)</code>的指令，每次入栈或者出栈操作都是对栈顶进行操作</p>\n<ul>\n<li><code>pushq</code>：将8字节的数字压入栈顶，对应一个操作数即需要压入的数据源</li>\n<li><code>popq</code>：将8字节的数字弹出栈顶，也是只有一个操作数即弹出的数据的目的地</li>\n</ul>\n<p>内存中<code>栈</code>这个数据结构可以当成一个数组，方向是由上往下的，栈顶在底部，地址最小，栈底在顶部，地址最大，因此如果是需要对某个8字节的数字进行<code>入栈</code>操作，就得先获取栈顶地址，然后将地址减去8得到一个新的地址，然后把数字放入这个新地址</p>\n<p>假设，我们现在有个数字存放于<code>%rax</code>上，我们先将他入栈，执行的指令是<code>%pushq  %rax</code>，然后将他出栈放到<code>%rdx</code>，执行指令<code>%pushq  %rdx</code>，栈顶指针保存于<code>%rsp</code>，具体过程如下：</p>\n<p><img src=\"http://img.mantian.site/201909171557_719.png\" alt></p>\n<ol>\n<li>首先，需要找到压栈后数据在栈中的地址，也就是在原栈顶<code>0x108</code>的基础上减去8，得到新栈顶的地址<code>0x100</code></li>\n<li>然后，将<code>%rax</code>的数据复制到栈顶，也就是<code>0x100</code>这个位置，入栈操作就完成了</li>\n<li>最后，将<code>0x100</code>位置的数据复制到<code>%rdx</code>，将栈顶地址加上8，出栈操作也就完成了</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>第三章：<code>程序的机器级表示</code></p>\n<p>本章将会了解：</p>\n<ol>\n<li>C语言代码是如何编译为汇编指令，讲解其中的一些编译器优化行为</li>\n<li>汇编指令在机器级的实现，包括栈结构进行过程间数据和控制的传递和局部变量的存储，并学习机器级是如何实现数组这样的数据结构</li>\n</ol>","more":"<h3 id=\"程序的编码\"><a href=\"#程序的编码\" class=\"headerlink\" title=\"程序的编码\"></a>程序的编码</h3><p>编译器编译c文件生成的包含汇编指令的s文件，汇编指令已经包含了具体的机器级指令的执行过程，相对于二进制可执行文件而言，汇编指令更加易于阅读，并且能够体现一些在c语言中隐藏的处理器状态</p>\n<p>一个程序内包含以下几部分内容：<code>可执行的机器码</code>，<code>操作系统需要的一些信息</code>，<code>管理过程调用和返回的运行时栈</code>，<code>用户分配的内存块（malloc等）</code></p>\n<blockquote>\n<p><strong>虚拟地址空间的规范</strong>：</p>\n<p>x86-64中，地址的寻址范围最高虽然为2^64^-1，不过在目前的视线中地址的高16位必须设置为0，所以一个地址能够指定的是2^48^或64TB范围内的一个字节</p>\n</blockquote>\n<p>有如下的C语言代码<code>mstore.c</code>：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">long</span> <span class=\"title\">mult2</span><span class=\"params\">(<span class=\"keyword\">long</span>, <span class=\"keyword\">long</span>)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">multstore</span><span class=\"params\">(<span class=\"keyword\">long</span> x, <span class=\"keyword\">long</span> y, <span class=\"keyword\">long</span> *dest)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">long</span> t = mult2(x, y);</span><br><span class=\"line\">    *dest = t;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>将这段代码进行编译得到<code>mstore.o</code>，再使用反汇编器objdump进行反编译得到如下的汇编代码：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">0000000000000000 &lt;multstore&gt;:</span><br><span class=\"line\">   0:   53                      push   %rbx</span><br><span class=\"line\">   1:   48 89 d3                mov    %rdx,%rbx</span><br><span class=\"line\">   4:   e8 00 00 00 00          callq  9 &lt;multstore+0x9&gt;</span><br><span class=\"line\">   9:   48 89 03                mov    %rax,(%rbx)</span><br><span class=\"line\">   c:   5b                      pop    %rbx</span><br><span class=\"line\">   d:   c3                      retq</span><br></pre></td></tr></table></figure>\n<p>这段汇编代码包含了<code>mstore.c</code>程序需要执行的全部指令，左边是机器码指令，右边是汇编指令，机器码和汇编指令在同一个系统中总是一一对应的，其中某些指令结尾的<code>q</code>可以忽略</p>\n<p>现在另外再编写一个包含main函数的文件<code>main.c</code>，用于执行：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">multstore</span><span class=\"params\">(<span class=\"keyword\">long</span>, <span class=\"keyword\">long</span>, <span class=\"keyword\">long</span> *)</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">long</span> <span class=\"title\">mult2</span><span class=\"params\">(<span class=\"keyword\">long</span> a, <span class=\"keyword\">long</span> b)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">long</span> s = a * b;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> s;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">long</span> d;</span><br><span class=\"line\">    multstore(<span class=\"number\">2</span>, <span class=\"number\">3</span>, &amp;d);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"2 * 3 --&gt; %d\\n\"</span>, d);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>编译器需要将<code>main.c</code>和<code>mstore.c</code>两个文件的函数进行链接：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]<span class=\"comment\"># gcc -Og -o prog main.c mstore.c</span></span><br></pre></td></tr></table></figure>\n<p>编译为可执行文件<code>prog</code>后再用<code>objdump</code>进行反编译，反编译完成后的结果包含<code>multstore</code>函数对应的汇编指令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">000000000040056b &lt;multstore&gt;:</span><br><span class=\"line\">  40056b:       53                      push   %rbx</span><br><span class=\"line\">  40056c:       48 89 d3                mov    %rdx,%rbx</span><br><span class=\"line\">  40056f:       e8 b9 ff ff ff          callq  40052d &lt;mult2&gt;</span><br><span class=\"line\">  400574:       48 89 03                mov    %rax,(%rbx)</span><br><span class=\"line\">  400577:       5b                      pop    %rbx</span><br><span class=\"line\">  400578:       c3                      retq   </span><br><span class=\"line\">  400579:       0f 1f 80 00 00 00 00    nopl   0x0(%rax)</span><br></pre></td></tr></table></figure>\n<p>可以看到，链接后的<code>multstore</code>与之前未链接的<code>multstore</code>有两个不同点：</p>\n<ul>\n<li>第三行<code>call</code>指令调用mult2函数时，调用地址变成了具体的函数地址<code>40052d</code></li>\n<li>最后加上了一个占位指令<code>nop</code>，没有实际意义，只是回了让函数代码变为16字节，一个存储器优化</li>\n</ul>\n<h3 id=\"访问信息\"><a href=\"#访问信息\" class=\"headerlink\" title=\"访问信息\"></a>访问信息</h3><p>这一部分主要讲的是cpu通过寄存器执行指令的具体过程</p>\n<h4 id=\"寄存器\"><a href=\"#寄存器\" class=\"headerlink\" title=\"寄存器\"></a>寄存器</h4><p>上面的汇编指令例子中有诸如<code>%rdx</code>和<code>%rbx</code>这样的标识，代表的是x86架构最早的8个寄存器，标号从<code>%rax</code>一直到<code>%rbp</code></p>\n<p>IA32架构扩展到x86-64架构后，除了将原来的8个寄存器扩展为64位，还增加了8个寄存器，命名从<code>%r8</code>到<code>%r15</code></p>\n<p>以下是这16个寄存器的具体表示，其中像<code>%eax</code>和<code>%ebx</code>这类是32位寄存器标号，像<code>%ax</code>和<code>%bx</code>这类是16位寄存器标号，像<code>a1</code>和<code>b1</code>这类是8位寄存器标号，不同的寄存器标号对应了当前寄存器上指定低位的字节数据，这些都是为了兼容以前8位，16位和32位机器上编译的程序</p>\n<p><img src=\"http://img.mantian.site/201909161543_84.png\" style=\"zoom:80%;\"></p>\n<p>图中，右边是每个寄存器对应的不同的角色</p>\n<p>在x86-64机器上，如果某段程序生成了低位指令，例如生成了一个2字节16位的<code>%ax</code>指令，需要以<code>%rax</code>这个寄存器为目标，那么高48位的字节怎么处理？有两条规则：</p>\n<ul>\n<li>对于8位和16位的指令，保持剩下的高位字节数不变</li>\n<li>对于32位的指令，给剩下32位的字节数置为0</li>\n</ul>\n<h4 id=\"指令的操作数格式\"><a href=\"#指令的操作数格式\" class=\"headerlink\" title=\"指令的操作数格式\"></a>指令的操作数格式</h4><p>一个指令具体要干啥？多数情况下就是将某个数据放置到某个寄存器或者内存位置，或者将某个数据从某个位置读出，放到某个寄存器或者内存中，这时候就引入了<code>操作数</code>的概念，指定某个操作中需要使用的<code>源数据</code>（可以是常数或者某个地址）和放置结果的<code>目的位置</code></p>\n<p><strong><code>操作数</code>如何指定源数据？</strong></p>\n<ul>\n<li><p><code>立即数</code>：立即数也就是常数，用<code>$</code>符号后面跟着数字的方式表示：<code>$0x1F</code></p>\n</li>\n<li><p><code>寄存器</code>：操作数位于某个寄存器上，表示方式是直接指定某个寄存器标号<code>ra</code>，然后用<code>R[ra]</code>来表示这个寄存器存储的值，比如上述例子中的某条指令就是将<code>%rdx上的数据移动到</code>%rbx<code>上：</code>mov  %rdx,%rbx`</p>\n</li>\n<li><p><code>内存</code>：指定内存上操作数的过程相对来说就比较复杂了，需要涉及到以下4个参数：<code>立即数偏移Imm</code>， <code>基址寄存器rb</code>，<code>变址寄存器ri</code>，<code>比例因子s</code>；计算有效内存地址的公式是：</p>\n<p><img src=\"http://img.mantian.site/201909161624_428.png\" style=\"zoom:50%;\"></p>\n<p>也就是一个立即数加上<code>基址寄存器</code>保存的值，再加上<code>变址寄存器</code>保存的值乘以一个偏移比例因子</p>\n<p>通过以下这种格式来表示某个内存操作数：</p>\n<p><img src=\"http://img.mantian.site/201909161628_844.png\" style=\"zoom:80%;\"></p>\n<p>其中，四个参数并不需要全部出现，有时候会省略个别参数，以下是内存操作数格式表，其他所有情况都是最后一种的特殊情况：</p>\n<p><img src=\"http://img.mantian.site/201909161630_895.png\" alt></p>\n</li>\n</ul>\n<p>了解了以上三种操作数形式，就可以计算出下列操作数表示的具体值了：</p>\n<blockquote>\n<p> 已知寄存器<code>%rcx</code>保存的值是<code>0x1</code>，<code>%rdx</code>保存的值是<code>0x3</code>，求<code>260(%rcx, %rdx, 2)</code>这个操作数表示的值？</p>\n<p>根据上述公式，这个操作数对应的地址值应该是<code>260 + 1 + 3 * 2 = 267</code>，转换为16进制就是<code>0x10B</code>，也就是说这个操作数对应的是内存<code>0x10B</code>处的数据</p>\n</blockquote>\n<p><strong>8字节寄存器</strong>：x86-64中，总是以8字节的寄存器如<code>%rax</code>等来表示某个内存的地址</p>\n<h4 id=\"数据传送指令\"><a href=\"#数据传送指令\" class=\"headerlink\" title=\"数据传送指令\"></a>数据传送指令</h4><p>现在，有了数据位置（寄存器和内存）和操作数，就需要具体的指令来挪动这些数据了</p>\n<p>计算机系统中最频繁的就是将一数据从一个位置复制到另一个位置的指令，也就是<code>MOV</code>指令，该指令在复制数据时不会做任何修改操作；<code>MOV</code>指令根据操作的字节位数还细分为以下几种，其中一个字代表2字节：</p>\n<p><img src=\"http://img.mantian.site/201909161654_300.png\" alt></p>\n<p>如果需要对寄存器的数据进行以上操作，对应的寄存器标号的字节位数必须与<code>mov</code>指令的最后字符相匹配，比如说操作4字节的寄存器<code>%eax</code>，需要的指令是<code>movl</code></p>\n<p>如果源寄存器和目的寄存器的大小不一致怎么处理？<code>movz</code>系列的命令就能将较小的源寄存器数据复制到较大的寄存器，复制完成后会将高位填充为0，其中指令结尾两个符号分别表示源寄存器大小和目标寄存器大小：</p>\n<p><img src=\"http://img.mantian.site/201909171627_383.png\" alt></p>\n<p><code>movz</code>复制到较大寄存器后，只能将剩余的高位全部用0填充，会忽略掉源数据的符号；<code>movs</code>系列的指令与<code>movz</code>类似，不过在进行扩展时会考虑源数据的符号位，如果源数据最高位是1，则将目标寄存器剩余的最高位全部设置为1</p>\n<p><img src=\"http://img.mantian.site/201909161745_573.png\" alt></p>\n<p>如上，<code>movs</code>指令最后两位也是表示源寄存器大小和目标寄存器大小；最后一个<code>cltq</code>指令只能以<code>%eax</code>作为源，以<code>%rax</code>作为目标，仅仅作符号扩展用</p>\n<p><strong>内存无法直接复制</strong>：x86-64规定，不能使用<code>mov</code>指令直接将数据从一个内存地址复制到另一个内存地址，只能先复制到寄存器</p>\n<h5 id=\"数据传送指令示例\"><a href=\"#数据传送指令示例\" class=\"headerlink\" title=\"数据传送指令示例\"></a>数据传送指令示例</h5><p>如下有这么一段C程序，将y赋值给指针变量<code>*xp</code>，最后返回<code>*xp</code>的旧值：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">long</span> <span class=\"title\">exchange</span><span class=\"params\">(<span class=\"keyword\">long</span> *xp, <span class=\"keyword\">long</span> y)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">long</span> x = *xp;</span><br><span class=\"line\">    *xp = y;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>用<code>gcc -Og -S</code>命令生成过渡汇编代码后，可以看到exchange函数被编译为如下的汇编指令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">movq    (%rdi), %rax</span><br><span class=\"line\">movq    %rsi, (%rdi)</span><br><span class=\"line\">ret</span><br></pre></td></tr></table></figure>\n<p>这段代码执行的过程如下：</p>\n<ol>\n<li>使用<code>movq</code>命令从<code>%rdi</code>这个寄存器记录的内存地址位置上（也就是<code>*xp</code>指针指向的内存）复制8个字节的数字到<code>%rax</code>寄存器</li>\n<li>使用<code>movq</code>命令从<code>%rsi</code>上复制8个字节的数字（也就是<code>y</code>）到<code>%rdi</code>记录的内存地址</li>\n<li>最后使用<code>ret</code>命令将<code>%rax</code>寄存器的值返回 （<code>%rax</code>一般就是用来保存函数返回值）</li>\n</ol>\n<p><strong>思考</strong>：如果需要用汇编指令实现以下程序，具体指令应该是怎样的？</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">char</span> *a;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *b;</span><br><span class=\"line\">*a = <span class=\"number\">-127</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> *b = (<span class=\"keyword\">int</span>) *a;</span><br></pre></td></tr></table></figure>\n<p>首先在c语言规范中，如果要将低位数的有符号类型强制转换为高位数的有符号类型，需要先扩充位数，然后再按照高位数的方式读取，所以具体汇编指令如下，假设<code>*a</code>保存在<code>%rdi</code>上，<code>*b</code>保存在<code>%rsi</code>上：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">movsbl\t(%rdi), %rax\t// 从(%rdi)读取一个字节复制到%rax上然后进行符号填充</span><br><span class=\"line\">movl\t%rax, (%rsi)\t// 读取4字节到(%rsi)内存</span><br></pre></td></tr></table></figure>\n<p>因为<code>char</code>类型默认是有符号的，因此扩展时需要进行有符号扩展，使用<code>movsbl</code>指令</p>\n<h4 id=\"压入和弹出栈数据\"><a href=\"#压入和弹出栈数据\" class=\"headerlink\" title=\"压入和弹出栈数据\"></a>压入和弹出栈数据</h4><p>计算机系统使用<code>栈</code>这个数据结构来实现函数的调用过程，涉及到<code>入栈(push)</code>和<code>出栈(pop)</code>的指令，每次入栈或者出栈操作都是对栈顶进行操作</p>\n<ul>\n<li><code>pushq</code>：将8字节的数字压入栈顶，对应一个操作数即需要压入的数据源</li>\n<li><code>popq</code>：将8字节的数字弹出栈顶，也是只有一个操作数即弹出的数据的目的地</li>\n</ul>\n<p>内存中<code>栈</code>这个数据结构可以当成一个数组，方向是由上往下的，栈顶在底部，地址最小，栈底在顶部，地址最大，因此如果是需要对某个8字节的数字进行<code>入栈</code>操作，就得先获取栈顶地址，然后将地址减去8得到一个新的地址，然后把数字放入这个新地址</p>\n<p>假设，我们现在有个数字存放于<code>%rax</code>上，我们先将他入栈，执行的指令是<code>%pushq  %rax</code>，然后将他出栈放到<code>%rdx</code>，执行指令<code>%pushq  %rdx</code>，栈顶指针保存于<code>%rsp</code>，具体过程如下：</p>\n<p><img src=\"http://img.mantian.site/201909171557_719.png\" alt></p>\n<ol>\n<li>首先，需要找到压栈后数据在栈中的地址，也就是在原栈顶<code>0x108</code>的基础上减去8，得到新栈顶的地址<code>0x100</code></li>\n<li>然后，将<code>%rax</code>的数据复制到栈顶，也就是<code>0x100</code>这个位置，入栈操作就完成了</li>\n<li>最后，将<code>0x100</code>位置的数据复制到<code>%rdx</code>，将栈顶地址加上8，出栈操作也就完成了</li>\n</ol>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 3(3)","author":"天渊","date":"2019-10-12T03:50:00.000Z","_content":"### 控制语句的实现\n\n程序中的条件，循环和分支语句，需要有条件的执行，此时就不能按照传统方式将指令一条接一条地执行，而是需要根据条件从当前指令跳转到其他指令进行执行\n\n计算机提供了两种机制来实现指令的有条件跳转：\n\n1. 测试数据值\n2. 根据测试结果改变控制流或数据流\n\n#### 条件码寄存器\n\nCPU维护了一种单个位`条件码`寄存器，这种寄存器只有0和1两种值，保存最近的运算操作产生结果的状态，通过检测这些寄存器来执行条件分支的跳转指令：\n\n1. CF：进位标志，最近的操作是否使最高位产生了进位（无符号溢出）\n2. ZF：零标志，最近的操作结果是否为0\n3. SF：符号标志，最近的操作结果是否为负数\n4. OF：溢出标志，与CF的区别是OF是有符号的补码溢出\n\n之前描述的所有算术和逻辑运算指令在计算结果后，都会同时设置`条件码`\n\n除此之外还有两个指令是专门用于设置`条件码`寄存器，而不会改变操作数：\n\n1. CMP指令：CMP指令的操作和`SUB`指令都是一样的，都是做减法，不过CMP指令只修改条件码寄存器（ZF或者SF），用以比较两个数的大小，而不用修改任何一个操作数\n2. TEST指令：TEST指令的操作和`AND`指令是一样的，都是作`&`操作，可以用来判断某数的符号\n\n#### 如何访问条件码\n\n条件码设置好后，需要读取条件码的状态来决定如何跳转，但是条件码寄存器的状态不能直接读取，可以通过特殊的指令读取多个条件吗寄存器的组合值，来确定某个条件\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-3-3.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 3(3)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-10-12 11:50:00\n---\n### 控制语句的实现\n\n程序中的条件，循环和分支语句，需要有条件的执行，此时就不能按照传统方式将指令一条接一条地执行，而是需要根据条件从当前指令跳转到其他指令进行执行\n\n计算机提供了两种机制来实现指令的有条件跳转：\n\n1. 测试数据值\n2. 根据测试结果改变控制流或数据流\n\n#### 条件码寄存器\n\nCPU维护了一种单个位`条件码`寄存器，这种寄存器只有0和1两种值，保存最近的运算操作产生结果的状态，通过检测这些寄存器来执行条件分支的跳转指令：\n\n1. CF：进位标志，最近的操作是否使最高位产生了进位（无符号溢出）\n2. ZF：零标志，最近的操作结果是否为0\n3. SF：符号标志，最近的操作结果是否为负数\n4. OF：溢出标志，与CF的区别是OF是有符号的补码溢出\n\n之前描述的所有算术和逻辑运算指令在计算结果后，都会同时设置`条件码`\n\n除此之外还有两个指令是专门用于设置`条件码`寄存器，而不会改变操作数：\n\n1. CMP指令：CMP指令的操作和`SUB`指令都是一样的，都是做减法，不过CMP指令只修改条件码寄存器（ZF或者SF），用以比较两个数的大小，而不用修改任何一个操作数\n2. TEST指令：TEST指令的操作和`AND`指令是一样的，都是作`&`操作，可以用来判断某数的符号\n\n#### 如何访问条件码\n\n条件码设置好后，需要读取条件码的状态来决定如何跳转，但是条件码寄存器的状态不能直接读取，可以通过特殊的指令读取多个条件吗寄存器的组合值，来确定某个条件\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"《深入理解计算机系统》读书笔记——Chapter-3-3","published":1,"updated":"2019-10-12T03:50:57.954Z","_id":"ckf0h31ij002dacts45uhowzm","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"控制语句的实现\"><a href=\"#控制语句的实现\" class=\"headerlink\" title=\"控制语句的实现\"></a>控制语句的实现</h3><p>程序中的条件，循环和分支语句，需要有条件的执行，此时就不能按照传统方式将指令一条接一条地执行，而是需要根据条件从当前指令跳转到其他指令进行执行</p>\n<p>计算机提供了两种机制来实现指令的有条件跳转：</p>\n<ol>\n<li>测试数据值</li>\n<li>根据测试结果改变控制流或数据流</li>\n</ol>\n<h4 id=\"条件码寄存器\"><a href=\"#条件码寄存器\" class=\"headerlink\" title=\"条件码寄存器\"></a>条件码寄存器</h4><p>CPU维护了一种单个位<code>条件码</code>寄存器，这种寄存器只有0和1两种值，保存最近的运算操作产生结果的状态，通过检测这些寄存器来执行条件分支的跳转指令：</p>\n<ol>\n<li>CF：进位标志，最近的操作是否使最高位产生了进位（无符号溢出）</li>\n<li>ZF：零标志，最近的操作结果是否为0</li>\n<li>SF：符号标志，最近的操作结果是否为负数</li>\n<li>OF：溢出标志，与CF的区别是OF是有符号的补码溢出</li>\n</ol>\n<p>之前描述的所有算术和逻辑运算指令在计算结果后，都会同时设置<code>条件码</code></p>\n<p>除此之外还有两个指令是专门用于设置<code>条件码</code>寄存器，而不会改变操作数：</p>\n<ol>\n<li>CMP指令：CMP指令的操作和<code>SUB</code>指令都是一样的，都是做减法，不过CMP指令只修改条件码寄存器（ZF或者SF），用以比较两个数的大小，而不用修改任何一个操作数</li>\n<li>TEST指令：TEST指令的操作和<code>AND</code>指令是一样的，都是作<code>&amp;</code>操作，可以用来判断某数的符号</li>\n</ol>\n<h4 id=\"如何访问条件码\"><a href=\"#如何访问条件码\" class=\"headerlink\" title=\"如何访问条件码\"></a>如何访问条件码</h4><p>条件码设置好后，需要读取条件码的状态来决定如何跳转，但是条件码寄存器的状态不能直接读取，可以通过特殊的指令读取多个条件吗寄存器的组合值，来确定某个条件</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"控制语句的实现\"><a href=\"#控制语句的实现\" class=\"headerlink\" title=\"控制语句的实现\"></a>控制语句的实现</h3><p>程序中的条件，循环和分支语句，需要有条件的执行，此时就不能按照传统方式将指令一条接一条地执行，而是需要根据条件从当前指令跳转到其他指令进行执行</p>\n<p>计算机提供了两种机制来实现指令的有条件跳转：</p>\n<ol>\n<li>测试数据值</li>\n<li>根据测试结果改变控制流或数据流</li>\n</ol>\n<h4 id=\"条件码寄存器\"><a href=\"#条件码寄存器\" class=\"headerlink\" title=\"条件码寄存器\"></a>条件码寄存器</h4><p>CPU维护了一种单个位<code>条件码</code>寄存器，这种寄存器只有0和1两种值，保存最近的运算操作产生结果的状态，通过检测这些寄存器来执行条件分支的跳转指令：</p>\n<ol>\n<li>CF：进位标志，最近的操作是否使最高位产生了进位（无符号溢出）</li>\n<li>ZF：零标志，最近的操作结果是否为0</li>\n<li>SF：符号标志，最近的操作结果是否为负数</li>\n<li>OF：溢出标志，与CF的区别是OF是有符号的补码溢出</li>\n</ol>\n<p>之前描述的所有算术和逻辑运算指令在计算结果后，都会同时设置<code>条件码</code></p>\n<p>除此之外还有两个指令是专门用于设置<code>条件码</code>寄存器，而不会改变操作数：</p>\n<ol>\n<li>CMP指令：CMP指令的操作和<code>SUB</code>指令都是一样的，都是做减法，不过CMP指令只修改条件码寄存器（ZF或者SF），用以比较两个数的大小，而不用修改任何一个操作数</li>\n<li>TEST指令：TEST指令的操作和<code>AND</code>指令是一样的，都是作<code>&amp;</code>操作，可以用来判断某数的符号</li>\n</ol>\n<h4 id=\"如何访问条件码\"><a href=\"#如何访问条件码\" class=\"headerlink\" title=\"如何访问条件码\"></a>如何访问条件码</h4><p>条件码设置好后，需要读取条件码的状态来决定如何跳转，但是条件码寄存器的状态不能直接读取，可以通过特殊的指令读取多个条件吗寄存器的组合值，来确定某个条件</p>\n"},{"title":"《深入理解计算机系统》读书笔记——Chapter 8(2)","author":"天渊","date":"2019-11-03T13:50:00.000Z","_content":"第七章`异常`的第二部分读书笔记\n\n\n### 进程\n\n`进程(process)`这个概念，为一个程序提供了一个虚拟的隔离空间，会造成一种假象，让程序以为自己是系统中运行的唯一一个应用\n<!--more-->\n\n**进程上下文**：即`context`，操作系统为每个进程都分配了上下文，每个程序运行在自己的上下文context中；这些context代表程序正确运行的状态，包括代码和数据，分配的调用栈，寄存器内容，程序计数器，环境变量以及打开的文件描述符\n\n操作系统提供了两个关键的抽象用以实现进程的特性：`独立逻辑控制流`，`私有地址空间`\n\n#### 独立逻辑控制流\n\n每个进程为当前运行的这个程序构造了一个假象，即它是独立运行在操作系统中的，实现这种功能的关键就是`程序计数器(PC)`，每个进程独占一个PC，它的值与程序指令唯一对应，PC的一系列值组成的执行序列就叫做`逻辑控制流`\n\n实际运行过程中，在单个核心的CPU上，同一时间有多个进程在一起运行，在外界看来这些进程在交错着运行，当某个进程运行了一段时间后即被挂起，CPU去执行其他进程\n\n![](http://img.mantian.site/201910291132_70.png)\n\n如上图，同一时间单个核心CPU上只能有一个进程运行，但在程序看来它的逻辑控制流却是连贯不间断的\n\n**并发**：两个逻辑控制流执行时间有重叠，称为`并发流`，如上图的进程A和C，进程A运行过程中，进程C开始运行\n\n并发流中的多个程序并不限制是在单个核或者多个核上运行，如果严格要求在不同核心上同时运行的程序，称之为`并行流`\n\n#### 私有地址空间\n\n每个进程为当前的程序提供了另一种重要的假象就是，让程序以为自己独占整个系统的地址空间，这种技术就是`虚拟内存`技术\n\n每个进程的私有地址空间都具有同样的结构：\n\n![](http://img.mantian.site/201910292116_973.png)\n\n每个虚拟的私有地址的空间都有内核区域和用户区域，最下层的代码段地址总是从0x0040000开始\n\n#### 用户模式和内核模式\n\n操作系统使用`用户模式`和`内核模式`来隔离和区分用户程序和内核程序，这种机制限制了用户程序只能访问操作系统的一部分资源，例如`用户模式`下的程序只能访问一部分内存区域和系统调用，而`内核模式`下的程序拥有访问所有资源的权限，所以`内核模式`又称为`超级用户模式`，典型的与计算机硬件打交道的操作就必须运行在内核模式下，这样最大程度保证计算机系统运行的稳定性，不至于被用户错误的程序所影响\n\n**模式位**：CPU通过`模式位`寄存器来限定当前程序是工作在哪种模式下\n\n**/proc文件系统**：这种文件系统为用户模式下的程序提供了一种访问内核数据结构的途径，比如像CPU具体信息就可以访问这个文件系统；在Linux 2.6后引入了`/sys`文件系统，能够访问系统总线和设备的一些信息\n\n#### 上下文切换\n\n操作系统使用`上下文切换`的机制来实现多进程并发地运行在单个核心的CPU上，由于每个进程都有自己独立的逻辑控制流，对应一个特定的状态即`上下文(context)`，内核调度器在进行进程（或者线程）调度（scheduling）时，为了让各个进程平衡地运行，做了以下工作：\n\n1. 内核选择一个新的进程运行，开始上下文切换，准备抢占当前运行进程\n2. 内核调度器保存当前进程的上下文，恢复要运行的进程被保存的上下文\n3. 将控制传递给新进程，CPU开始根据PC执行新进程还没执行的指令\n\n哪几种情况会导致上下文切换呢？\n\n1. 进程一些耗时的系统调用（例如磁盘IO操作）时，调度器可能会产生一次上下文切换，让当前进程暂时休眠，运行其他进程，待系统调用完成后再恢复之前休眠的进程\n2. 当前进程主动执行sleep系统调用进行休眠；类似的像Java抢占锁失败也会让调度器执行上下文切换，休眠当前线程\n3. 中断也会引发上下文切换\n\n### 进程控制\n\n##### 如何获取PID\n\n`PID`即`Process Id`，每个进程在操作系统种运行时都有这么一个唯一的整数Id，用以标识某个进程的身份，在类Unix系统上用C语言获取当前进程PID和父进程PID的方法如下：\n\n```c\nint pid = getpid();\nint parent_pid = getppid();\nprintf(\"pid: %d\\n\", pid);\nprintf(\"parent_pid: %d\\n\", parent_pid);\n```\n\n#### 进程的生命周期\n\n在计算机系统中，进程一共有三种状态：\n\n- `运行`：处理`运行`状态的进程是可以被调度器调度的进程，要么正在执行要么等待执行\n- `停止`：进程处于挂起状态，一般是收到中断类信号后进入这个状态，在收到中断恢复信号后可以重新进入`运行`状态\n- `终止`：进程停止，一般是收到一个终止信号，程序本身调用了exit函数或者直接从主程序返回\n\n**父子进程 & fork** ：系统使用`fork`函数从父进程中创建一个新的运行的子进程，fork函数会返回子进程的PID，操作系统会为子进程产生一份父进程context的副本，包括一模一样的虚拟地址空间以及同样的文件描述符的副本，除了PID不同，子进程和父进程基本上一样；类Unix系统中，所有新启动的进程的父进程PID都是1","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-7-2.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 8(2)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-11-03 21:50:00\n---\n第七章`异常`的第二部分读书笔记\n\n\n### 进程\n\n`进程(process)`这个概念，为一个程序提供了一个虚拟的隔离空间，会造成一种假象，让程序以为自己是系统中运行的唯一一个应用\n<!--more-->\n\n**进程上下文**：即`context`，操作系统为每个进程都分配了上下文，每个程序运行在自己的上下文context中；这些context代表程序正确运行的状态，包括代码和数据，分配的调用栈，寄存器内容，程序计数器，环境变量以及打开的文件描述符\n\n操作系统提供了两个关键的抽象用以实现进程的特性：`独立逻辑控制流`，`私有地址空间`\n\n#### 独立逻辑控制流\n\n每个进程为当前运行的这个程序构造了一个假象，即它是独立运行在操作系统中的，实现这种功能的关键就是`程序计数器(PC)`，每个进程独占一个PC，它的值与程序指令唯一对应，PC的一系列值组成的执行序列就叫做`逻辑控制流`\n\n实际运行过程中，在单个核心的CPU上，同一时间有多个进程在一起运行，在外界看来这些进程在交错着运行，当某个进程运行了一段时间后即被挂起，CPU去执行其他进程\n\n![](http://img.mantian.site/201910291132_70.png)\n\n如上图，同一时间单个核心CPU上只能有一个进程运行，但在程序看来它的逻辑控制流却是连贯不间断的\n\n**并发**：两个逻辑控制流执行时间有重叠，称为`并发流`，如上图的进程A和C，进程A运行过程中，进程C开始运行\n\n并发流中的多个程序并不限制是在单个核或者多个核上运行，如果严格要求在不同核心上同时运行的程序，称之为`并行流`\n\n#### 私有地址空间\n\n每个进程为当前的程序提供了另一种重要的假象就是，让程序以为自己独占整个系统的地址空间，这种技术就是`虚拟内存`技术\n\n每个进程的私有地址空间都具有同样的结构：\n\n![](http://img.mantian.site/201910292116_973.png)\n\n每个虚拟的私有地址的空间都有内核区域和用户区域，最下层的代码段地址总是从0x0040000开始\n\n#### 用户模式和内核模式\n\n操作系统使用`用户模式`和`内核模式`来隔离和区分用户程序和内核程序，这种机制限制了用户程序只能访问操作系统的一部分资源，例如`用户模式`下的程序只能访问一部分内存区域和系统调用，而`内核模式`下的程序拥有访问所有资源的权限，所以`内核模式`又称为`超级用户模式`，典型的与计算机硬件打交道的操作就必须运行在内核模式下，这样最大程度保证计算机系统运行的稳定性，不至于被用户错误的程序所影响\n\n**模式位**：CPU通过`模式位`寄存器来限定当前程序是工作在哪种模式下\n\n**/proc文件系统**：这种文件系统为用户模式下的程序提供了一种访问内核数据结构的途径，比如像CPU具体信息就可以访问这个文件系统；在Linux 2.6后引入了`/sys`文件系统，能够访问系统总线和设备的一些信息\n\n#### 上下文切换\n\n操作系统使用`上下文切换`的机制来实现多进程并发地运行在单个核心的CPU上，由于每个进程都有自己独立的逻辑控制流，对应一个特定的状态即`上下文(context)`，内核调度器在进行进程（或者线程）调度（scheduling）时，为了让各个进程平衡地运行，做了以下工作：\n\n1. 内核选择一个新的进程运行，开始上下文切换，准备抢占当前运行进程\n2. 内核调度器保存当前进程的上下文，恢复要运行的进程被保存的上下文\n3. 将控制传递给新进程，CPU开始根据PC执行新进程还没执行的指令\n\n哪几种情况会导致上下文切换呢？\n\n1. 进程一些耗时的系统调用（例如磁盘IO操作）时，调度器可能会产生一次上下文切换，让当前进程暂时休眠，运行其他进程，待系统调用完成后再恢复之前休眠的进程\n2. 当前进程主动执行sleep系统调用进行休眠；类似的像Java抢占锁失败也会让调度器执行上下文切换，休眠当前线程\n3. 中断也会引发上下文切换\n\n### 进程控制\n\n##### 如何获取PID\n\n`PID`即`Process Id`，每个进程在操作系统种运行时都有这么一个唯一的整数Id，用以标识某个进程的身份，在类Unix系统上用C语言获取当前进程PID和父进程PID的方法如下：\n\n```c\nint pid = getpid();\nint parent_pid = getppid();\nprintf(\"pid: %d\\n\", pid);\nprintf(\"parent_pid: %d\\n\", parent_pid);\n```\n\n#### 进程的生命周期\n\n在计算机系统中，进程一共有三种状态：\n\n- `运行`：处理`运行`状态的进程是可以被调度器调度的进程，要么正在执行要么等待执行\n- `停止`：进程处于挂起状态，一般是收到中断类信号后进入这个状态，在收到中断恢复信号后可以重新进入`运行`状态\n- `终止`：进程停止，一般是收到一个终止信号，程序本身调用了exit函数或者直接从主程序返回\n\n**父子进程 & fork** ：系统使用`fork`函数从父进程中创建一个新的运行的子进程，fork函数会返回子进程的PID，操作系统会为子进程产生一份父进程context的副本，包括一模一样的虚拟地址空间以及同样的文件描述符的副本，除了PID不同，子进程和父进程基本上一样；类Unix系统中，所有新启动的进程的父进程PID都是1","slug":"《深入理解计算机系统》读书笔记——Chapter-7-2","published":1,"updated":"2021-05-31T03:06:33.201Z","_id":"ckf0h31il002gactsbb10unf8","comments":1,"layout":"post","photos":[],"link":"","content":"<p>第七章<code>异常</code>的第二部分读书笔记</p>\n<h3 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h3><p><code>进程(process)</code>这个概念，为一个程序提供了一个虚拟的隔离空间，会造成一种假象，让程序以为自己是系统中运行的唯一一个应用<br><a id=\"more\"></a></p>\n<p><strong>进程上下文</strong>：即<code>context</code>，操作系统为每个进程都分配了上下文，每个程序运行在自己的上下文context中；这些context代表程序正确运行的状态，包括代码和数据，分配的调用栈，寄存器内容，程序计数器，环境变量以及打开的文件描述符</p>\n<p>操作系统提供了两个关键的抽象用以实现进程的特性：<code>独立逻辑控制流</code>，<code>私有地址空间</code></p>\n<h4 id=\"独立逻辑控制流\"><a href=\"#独立逻辑控制流\" class=\"headerlink\" title=\"独立逻辑控制流\"></a>独立逻辑控制流</h4><p>每个进程为当前运行的这个程序构造了一个假象，即它是独立运行在操作系统中的，实现这种功能的关键就是<code>程序计数器(PC)</code>，每个进程独占一个PC，它的值与程序指令唯一对应，PC的一系列值组成的执行序列就叫做<code>逻辑控制流</code></p>\n<p>实际运行过程中，在单个核心的CPU上，同一时间有多个进程在一起运行，在外界看来这些进程在交错着运行，当某个进程运行了一段时间后即被挂起，CPU去执行其他进程</p>\n<p><img src=\"http://img.mantian.site/201910291132_70.png\" alt></p>\n<p>如上图，同一时间单个核心CPU上只能有一个进程运行，但在程序看来它的逻辑控制流却是连贯不间断的</p>\n<p><strong>并发</strong>：两个逻辑控制流执行时间有重叠，称为<code>并发流</code>，如上图的进程A和C，进程A运行过程中，进程C开始运行</p>\n<p>并发流中的多个程序并不限制是在单个核或者多个核上运行，如果严格要求在不同核心上同时运行的程序，称之为<code>并行流</code></p>\n<h4 id=\"私有地址空间\"><a href=\"#私有地址空间\" class=\"headerlink\" title=\"私有地址空间\"></a>私有地址空间</h4><p>每个进程为当前的程序提供了另一种重要的假象就是，让程序以为自己独占整个系统的地址空间，这种技术就是<code>虚拟内存</code>技术</p>\n<p>每个进程的私有地址空间都具有同样的结构：</p>\n<p><img src=\"http://img.mantian.site/201910292116_973.png\" alt></p>\n<p>每个虚拟的私有地址的空间都有内核区域和用户区域，最下层的代码段地址总是从0x0040000开始</p>\n<h4 id=\"用户模式和内核模式\"><a href=\"#用户模式和内核模式\" class=\"headerlink\" title=\"用户模式和内核模式\"></a>用户模式和内核模式</h4><p>操作系统使用<code>用户模式</code>和<code>内核模式</code>来隔离和区分用户程序和内核程序，这种机制限制了用户程序只能访问操作系统的一部分资源，例如<code>用户模式</code>下的程序只能访问一部分内存区域和系统调用，而<code>内核模式</code>下的程序拥有访问所有资源的权限，所以<code>内核模式</code>又称为<code>超级用户模式</code>，典型的与计算机硬件打交道的操作就必须运行在内核模式下，这样最大程度保证计算机系统运行的稳定性，不至于被用户错误的程序所影响</p>\n<p><strong>模式位</strong>：CPU通过<code>模式位</code>寄存器来限定当前程序是工作在哪种模式下</p>\n<p><strong>/proc文件系统</strong>：这种文件系统为用户模式下的程序提供了一种访问内核数据结构的途径，比如像CPU具体信息就可以访问这个文件系统；在Linux 2.6后引入了<code>/sys</code>文件系统，能够访问系统总线和设备的一些信息</p>\n<h4 id=\"上下文切换\"><a href=\"#上下文切换\" class=\"headerlink\" title=\"上下文切换\"></a>上下文切换</h4><p>操作系统使用<code>上下文切换</code>的机制来实现多进程并发地运行在单个核心的CPU上，由于每个进程都有自己独立的逻辑控制流，对应一个特定的状态即<code>上下文(context)</code>，内核调度器在进行进程（或者线程）调度（scheduling）时，为了让各个进程平衡地运行，做了以下工作：</p>\n<ol>\n<li>内核选择一个新的进程运行，开始上下文切换，准备抢占当前运行进程</li>\n<li>内核调度器保存当前进程的上下文，恢复要运行的进程被保存的上下文</li>\n<li>将控制传递给新进程，CPU开始根据PC执行新进程还没执行的指令</li>\n</ol>\n<p>哪几种情况会导致上下文切换呢？</p>\n<ol>\n<li>进程一些耗时的系统调用（例如磁盘IO操作）时，调度器可能会产生一次上下文切换，让当前进程暂时休眠，运行其他进程，待系统调用完成后再恢复之前休眠的进程</li>\n<li>当前进程主动执行sleep系统调用进行休眠；类似的像Java抢占锁失败也会让调度器执行上下文切换，休眠当前线程</li>\n<li>中断也会引发上下文切换</li>\n</ol>\n<h3 id=\"进程控制\"><a href=\"#进程控制\" class=\"headerlink\" title=\"进程控制\"></a>进程控制</h3><h5 id=\"如何获取PID\"><a href=\"#如何获取PID\" class=\"headerlink\" title=\"如何获取PID\"></a>如何获取PID</h5><p><code>PID</code>即<code>Process Id</code>，每个进程在操作系统种运行时都有这么一个唯一的整数Id，用以标识某个进程的身份，在类Unix系统上用C语言获取当前进程PID和父进程PID的方法如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> pid = getpid();</span><br><span class=\"line\"><span class=\"keyword\">int</span> parent_pid = getppid();</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"pid: %d\\n\"</span>, pid);</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"parent_pid: %d\\n\"</span>, parent_pid);</span><br></pre></td></tr></table></figure>\n<h4 id=\"进程的生命周期\"><a href=\"#进程的生命周期\" class=\"headerlink\" title=\"进程的生命周期\"></a>进程的生命周期</h4><p>在计算机系统中，进程一共有三种状态：</p>\n<ul>\n<li><code>运行</code>：处理<code>运行</code>状态的进程是可以被调度器调度的进程，要么正在执行要么等待执行</li>\n<li><code>停止</code>：进程处于挂起状态，一般是收到中断类信号后进入这个状态，在收到中断恢复信号后可以重新进入<code>运行</code>状态</li>\n<li><code>终止</code>：进程停止，一般是收到一个终止信号，程序本身调用了exit函数或者直接从主程序返回</li>\n</ul>\n<p><strong>父子进程 &amp; fork</strong> ：系统使用<code>fork</code>函数从父进程中创建一个新的运行的子进程，fork函数会返回子进程的PID，操作系统会为子进程产生一份父进程context的副本，包括一模一样的虚拟地址空间以及同样的文件描述符的副本，除了PID不同，子进程和父进程基本上一样；类Unix系统中，所有新启动的进程的父进程PID都是1</p>\n","site":{"data":{}},"excerpt":"<p>第七章<code>异常</code>的第二部分读书笔记</p>\n<h3 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h3><p><code>进程(process)</code>这个概念，为一个程序提供了一个虚拟的隔离空间，会造成一种假象，让程序以为自己是系统中运行的唯一一个应用<br>","more":"</p>\n<p><strong>进程上下文</strong>：即<code>context</code>，操作系统为每个进程都分配了上下文，每个程序运行在自己的上下文context中；这些context代表程序正确运行的状态，包括代码和数据，分配的调用栈，寄存器内容，程序计数器，环境变量以及打开的文件描述符</p>\n<p>操作系统提供了两个关键的抽象用以实现进程的特性：<code>独立逻辑控制流</code>，<code>私有地址空间</code></p>\n<h4 id=\"独立逻辑控制流\"><a href=\"#独立逻辑控制流\" class=\"headerlink\" title=\"独立逻辑控制流\"></a>独立逻辑控制流</h4><p>每个进程为当前运行的这个程序构造了一个假象，即它是独立运行在操作系统中的，实现这种功能的关键就是<code>程序计数器(PC)</code>，每个进程独占一个PC，它的值与程序指令唯一对应，PC的一系列值组成的执行序列就叫做<code>逻辑控制流</code></p>\n<p>实际运行过程中，在单个核心的CPU上，同一时间有多个进程在一起运行，在外界看来这些进程在交错着运行，当某个进程运行了一段时间后即被挂起，CPU去执行其他进程</p>\n<p><img src=\"http://img.mantian.site/201910291132_70.png\" alt></p>\n<p>如上图，同一时间单个核心CPU上只能有一个进程运行，但在程序看来它的逻辑控制流却是连贯不间断的</p>\n<p><strong>并发</strong>：两个逻辑控制流执行时间有重叠，称为<code>并发流</code>，如上图的进程A和C，进程A运行过程中，进程C开始运行</p>\n<p>并发流中的多个程序并不限制是在单个核或者多个核上运行，如果严格要求在不同核心上同时运行的程序，称之为<code>并行流</code></p>\n<h4 id=\"私有地址空间\"><a href=\"#私有地址空间\" class=\"headerlink\" title=\"私有地址空间\"></a>私有地址空间</h4><p>每个进程为当前的程序提供了另一种重要的假象就是，让程序以为自己独占整个系统的地址空间，这种技术就是<code>虚拟内存</code>技术</p>\n<p>每个进程的私有地址空间都具有同样的结构：</p>\n<p><img src=\"http://img.mantian.site/201910292116_973.png\" alt></p>\n<p>每个虚拟的私有地址的空间都有内核区域和用户区域，最下层的代码段地址总是从0x0040000开始</p>\n<h4 id=\"用户模式和内核模式\"><a href=\"#用户模式和内核模式\" class=\"headerlink\" title=\"用户模式和内核模式\"></a>用户模式和内核模式</h4><p>操作系统使用<code>用户模式</code>和<code>内核模式</code>来隔离和区分用户程序和内核程序，这种机制限制了用户程序只能访问操作系统的一部分资源，例如<code>用户模式</code>下的程序只能访问一部分内存区域和系统调用，而<code>内核模式</code>下的程序拥有访问所有资源的权限，所以<code>内核模式</code>又称为<code>超级用户模式</code>，典型的与计算机硬件打交道的操作就必须运行在内核模式下，这样最大程度保证计算机系统运行的稳定性，不至于被用户错误的程序所影响</p>\n<p><strong>模式位</strong>：CPU通过<code>模式位</code>寄存器来限定当前程序是工作在哪种模式下</p>\n<p><strong>/proc文件系统</strong>：这种文件系统为用户模式下的程序提供了一种访问内核数据结构的途径，比如像CPU具体信息就可以访问这个文件系统；在Linux 2.6后引入了<code>/sys</code>文件系统，能够访问系统总线和设备的一些信息</p>\n<h4 id=\"上下文切换\"><a href=\"#上下文切换\" class=\"headerlink\" title=\"上下文切换\"></a>上下文切换</h4><p>操作系统使用<code>上下文切换</code>的机制来实现多进程并发地运行在单个核心的CPU上，由于每个进程都有自己独立的逻辑控制流，对应一个特定的状态即<code>上下文(context)</code>，内核调度器在进行进程（或者线程）调度（scheduling）时，为了让各个进程平衡地运行，做了以下工作：</p>\n<ol>\n<li>内核选择一个新的进程运行，开始上下文切换，准备抢占当前运行进程</li>\n<li>内核调度器保存当前进程的上下文，恢复要运行的进程被保存的上下文</li>\n<li>将控制传递给新进程，CPU开始根据PC执行新进程还没执行的指令</li>\n</ol>\n<p>哪几种情况会导致上下文切换呢？</p>\n<ol>\n<li>进程一些耗时的系统调用（例如磁盘IO操作）时，调度器可能会产生一次上下文切换，让当前进程暂时休眠，运行其他进程，待系统调用完成后再恢复之前休眠的进程</li>\n<li>当前进程主动执行sleep系统调用进行休眠；类似的像Java抢占锁失败也会让调度器执行上下文切换，休眠当前线程</li>\n<li>中断也会引发上下文切换</li>\n</ol>\n<h3 id=\"进程控制\"><a href=\"#进程控制\" class=\"headerlink\" title=\"进程控制\"></a>进程控制</h3><h5 id=\"如何获取PID\"><a href=\"#如何获取PID\" class=\"headerlink\" title=\"如何获取PID\"></a>如何获取PID</h5><p><code>PID</code>即<code>Process Id</code>，每个进程在操作系统种运行时都有这么一个唯一的整数Id，用以标识某个进程的身份，在类Unix系统上用C语言获取当前进程PID和父进程PID的方法如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> pid = getpid();</span><br><span class=\"line\"><span class=\"keyword\">int</span> parent_pid = getppid();</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"pid: %d\\n\"</span>, pid);</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"parent_pid: %d\\n\"</span>, parent_pid);</span><br></pre></td></tr></table></figure>\n<h4 id=\"进程的生命周期\"><a href=\"#进程的生命周期\" class=\"headerlink\" title=\"进程的生命周期\"></a>进程的生命周期</h4><p>在计算机系统中，进程一共有三种状态：</p>\n<ul>\n<li><code>运行</code>：处理<code>运行</code>状态的进程是可以被调度器调度的进程，要么正在执行要么等待执行</li>\n<li><code>停止</code>：进程处于挂起状态，一般是收到中断类信号后进入这个状态，在收到中断恢复信号后可以重新进入<code>运行</code>状态</li>\n<li><code>终止</code>：进程停止，一般是收到一个终止信号，程序本身调用了exit函数或者直接从主程序返回</li>\n</ul>\n<p><strong>父子进程 &amp; fork</strong> ：系统使用<code>fork</code>函数从父进程中创建一个新的运行的子进程，fork函数会返回子进程的PID，操作系统会为子进程产生一份父进程context的副本，包括一模一样的虚拟地址空间以及同样的文件描述符的副本，除了PID不同，子进程和父进程基本上一样；类Unix系统中，所有新启动的进程的父进程PID都是1</p>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 8(1)","author":"天渊","date":"2019-10-28T15:24:00.000Z","_content":"本章主要介绍计算机系统中的异常处理流，当程序执行出错出现异常后，由硬件层，操作系统或者应用程序产生异常控制流对异常进行处理\n<!--more-->\n\n### 异常\n\n计算机系统中使用`异常`（exception）的形式来实现异常控制流，比较简单的例子是，当CPU执行到某个指令后，执行状态发生变化，立即产生一个异常事件，这种事件有可能是内存缺页，甚至是某个指令试图除以0。产生事件后，CPU会通过`异常表`进行`异常过程调用`，由`Exception Handler`来专门处理这个异常事件\n\n#### 异常表\n\n系统中为每种类型的异常都分配了`异常号`，产生异常事件后，处理器执行异常过程调用时需要用这个异常号来从异常表中检索相应的`异常处理程序`，然后根据检索到的`异常处理程序`来执行相应的命令，跟一般的过程调用大同小异，不过还是有些区别：\n\n- 异常过程调用的返回地址会根据异常的类型来判断，要么是返回当前正在执行的指令地址，要么是下一条指令的地址\n- CPU会把一些额外的处理器状态压到栈里\n- CPU在内核态中执行异常过程调用，会将上下文全部压到`内核栈`中\n- 由于异常过程调用是运行在`内核态`下，因此这个过程对所有系统资源都有完全的访问权限\n\n异常过程调用完成后，执行一条`从中断返回`的指令，将适当的状态弹回到处理器的控制和数据寄存器，如果中断的是用户态程序，则将上下文切换回用户态，控制返回给被中断的用户态应用程序\n\n#### 四种异常类型\n\n计算机系统将可能出现的异常分为四类：\n\n- `中断`：对外部IO设备信号的响应，相对于正在执行的指令来说是异步发生的，由专门的`中断处理器(interrupt handler)`来处理这类中断信号\n\n  中断类型跟其他三种异常还不太一样，中断不是由当前执行的指令产生的，IO设备通过向CPU的中断引脚发信号并将中断号发到总线上，CPU执行完当前指令后注意到中断引脚的电压变高，从系统总线读取中断号然后调用对应的中断处理器，调用完成后**返回到下一条指令**，就当这个中断从未发生过\n\n- `陷阱`：这类异常通常是作为在用户程序和内核之间提供一个接口，即`系统调用`\n\n  CPU提供了一个特殊的指令`syscall n`，`n`是用户需要请求的系统调用号，当用户执行这个指令时，控制传递给相应的内核处理程序即`陷阱处理程序`，处理完成后返回到用户代码的**下一条指令**\n\n- `故障`：这个就是通常意义上的异常类型，当程序发生错误产生故障后，CPU将控制转移给对应的exception handler，此时有两种情况，如果故障处理器能够修正这个错误，就可以返回到**之前故障的指令**重新执行，如果处理不了，内核的abort程序就会中止这段应用\n\n  比如调用内存缺页后，就会产生一个故障，缺页处理程序会从磁盘中加载对应的内存页到内存中，指令可以继续执行\n\n- `终止`：这类异常时不可恢复的致命错误，这类异常发生后，对应的exception handler为终止处理程序，它**不会将控制返还给出错的应用**，而是直接返回给abort例程进行程序的终止\n\n  计算机中一些致命的机器故障就会触发终止\n\nx86-64架构中有256个异常号，其中0~31号是Intel设计师定义的系统异常，包括除以0，缺页或者segment fault等异常；剩下从32到255号是操作系统自己定义的中断号和陷阱号\n\n> C程序调用某个系统函数时，在编译后的汇编指令中，一般将系统调用号存放于%rax寄存器，将过程调用参数列表存放于%rdi, %rsi, %rdx, %r10, %r8, %r9，一共6个，参数列表按照顺序存放在寄存器\n>\n> 调用返回值仍旧存放在%rax寄存器，如果返回值是负数，说明发生了错误","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-7-1.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 8(1)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-10-28 23:24:00\n---\n本章主要介绍计算机系统中的异常处理流，当程序执行出错出现异常后，由硬件层，操作系统或者应用程序产生异常控制流对异常进行处理\n<!--more-->\n\n### 异常\n\n计算机系统中使用`异常`（exception）的形式来实现异常控制流，比较简单的例子是，当CPU执行到某个指令后，执行状态发生变化，立即产生一个异常事件，这种事件有可能是内存缺页，甚至是某个指令试图除以0。产生事件后，CPU会通过`异常表`进行`异常过程调用`，由`Exception Handler`来专门处理这个异常事件\n\n#### 异常表\n\n系统中为每种类型的异常都分配了`异常号`，产生异常事件后，处理器执行异常过程调用时需要用这个异常号来从异常表中检索相应的`异常处理程序`，然后根据检索到的`异常处理程序`来执行相应的命令，跟一般的过程调用大同小异，不过还是有些区别：\n\n- 异常过程调用的返回地址会根据异常的类型来判断，要么是返回当前正在执行的指令地址，要么是下一条指令的地址\n- CPU会把一些额外的处理器状态压到栈里\n- CPU在内核态中执行异常过程调用，会将上下文全部压到`内核栈`中\n- 由于异常过程调用是运行在`内核态`下，因此这个过程对所有系统资源都有完全的访问权限\n\n异常过程调用完成后，执行一条`从中断返回`的指令，将适当的状态弹回到处理器的控制和数据寄存器，如果中断的是用户态程序，则将上下文切换回用户态，控制返回给被中断的用户态应用程序\n\n#### 四种异常类型\n\n计算机系统将可能出现的异常分为四类：\n\n- `中断`：对外部IO设备信号的响应，相对于正在执行的指令来说是异步发生的，由专门的`中断处理器(interrupt handler)`来处理这类中断信号\n\n  中断类型跟其他三种异常还不太一样，中断不是由当前执行的指令产生的，IO设备通过向CPU的中断引脚发信号并将中断号发到总线上，CPU执行完当前指令后注意到中断引脚的电压变高，从系统总线读取中断号然后调用对应的中断处理器，调用完成后**返回到下一条指令**，就当这个中断从未发生过\n\n- `陷阱`：这类异常通常是作为在用户程序和内核之间提供一个接口，即`系统调用`\n\n  CPU提供了一个特殊的指令`syscall n`，`n`是用户需要请求的系统调用号，当用户执行这个指令时，控制传递给相应的内核处理程序即`陷阱处理程序`，处理完成后返回到用户代码的**下一条指令**\n\n- `故障`：这个就是通常意义上的异常类型，当程序发生错误产生故障后，CPU将控制转移给对应的exception handler，此时有两种情况，如果故障处理器能够修正这个错误，就可以返回到**之前故障的指令**重新执行，如果处理不了，内核的abort程序就会中止这段应用\n\n  比如调用内存缺页后，就会产生一个故障，缺页处理程序会从磁盘中加载对应的内存页到内存中，指令可以继续执行\n\n- `终止`：这类异常时不可恢复的致命错误，这类异常发生后，对应的exception handler为终止处理程序，它**不会将控制返还给出错的应用**，而是直接返回给abort例程进行程序的终止\n\n  计算机中一些致命的机器故障就会触发终止\n\nx86-64架构中有256个异常号，其中0~31号是Intel设计师定义的系统异常，包括除以0，缺页或者segment fault等异常；剩下从32到255号是操作系统自己定义的中断号和陷阱号\n\n> C程序调用某个系统函数时，在编译后的汇编指令中，一般将系统调用号存放于%rax寄存器，将过程调用参数列表存放于%rdi, %rsi, %rdx, %r10, %r8, %r9，一共6个，参数列表按照顺序存放在寄存器\n>\n> 调用返回值仍旧存放在%rax寄存器，如果返回值是负数，说明发生了错误","slug":"《深入理解计算机系统》读书笔记——Chapter-7-1","published":1,"updated":"2021-05-31T03:06:33.201Z","_id":"ckf0h31im002kactsb9em4q8c","comments":1,"layout":"post","photos":[],"link":"","content":"<p>本章主要介绍计算机系统中的异常处理流，当程序执行出错出现异常后，由硬件层，操作系统或者应用程序产生异常控制流对异常进行处理<br><a id=\"more\"></a></p>\n<h3 id=\"异常\"><a href=\"#异常\" class=\"headerlink\" title=\"异常\"></a>异常</h3><p>计算机系统中使用<code>异常</code>（exception）的形式来实现异常控制流，比较简单的例子是，当CPU执行到某个指令后，执行状态发生变化，立即产生一个异常事件，这种事件有可能是内存缺页，甚至是某个指令试图除以0。产生事件后，CPU会通过<code>异常表</code>进行<code>异常过程调用</code>，由<code>Exception Handler</code>来专门处理这个异常事件</p>\n<h4 id=\"异常表\"><a href=\"#异常表\" class=\"headerlink\" title=\"异常表\"></a>异常表</h4><p>系统中为每种类型的异常都分配了<code>异常号</code>，产生异常事件后，处理器执行异常过程调用时需要用这个异常号来从异常表中检索相应的<code>异常处理程序</code>，然后根据检索到的<code>异常处理程序</code>来执行相应的命令，跟一般的过程调用大同小异，不过还是有些区别：</p>\n<ul>\n<li>异常过程调用的返回地址会根据异常的类型来判断，要么是返回当前正在执行的指令地址，要么是下一条指令的地址</li>\n<li>CPU会把一些额外的处理器状态压到栈里</li>\n<li>CPU在内核态中执行异常过程调用，会将上下文全部压到<code>内核栈</code>中</li>\n<li>由于异常过程调用是运行在<code>内核态</code>下，因此这个过程对所有系统资源都有完全的访问权限</li>\n</ul>\n<p>异常过程调用完成后，执行一条<code>从中断返回</code>的指令，将适当的状态弹回到处理器的控制和数据寄存器，如果中断的是用户态程序，则将上下文切换回用户态，控制返回给被中断的用户态应用程序</p>\n<h4 id=\"四种异常类型\"><a href=\"#四种异常类型\" class=\"headerlink\" title=\"四种异常类型\"></a>四种异常类型</h4><p>计算机系统将可能出现的异常分为四类：</p>\n<ul>\n<li><p><code>中断</code>：对外部IO设备信号的响应，相对于正在执行的指令来说是异步发生的，由专门的<code>中断处理器(interrupt handler)</code>来处理这类中断信号</p>\n<p>中断类型跟其他三种异常还不太一样，中断不是由当前执行的指令产生的，IO设备通过向CPU的中断引脚发信号并将中断号发到总线上，CPU执行完当前指令后注意到中断引脚的电压变高，从系统总线读取中断号然后调用对应的中断处理器，调用完成后<strong>返回到下一条指令</strong>，就当这个中断从未发生过</p>\n</li>\n<li><p><code>陷阱</code>：这类异常通常是作为在用户程序和内核之间提供一个接口，即<code>系统调用</code></p>\n<p>CPU提供了一个特殊的指令<code>syscall n</code>，<code>n</code>是用户需要请求的系统调用号，当用户执行这个指令时，控制传递给相应的内核处理程序即<code>陷阱处理程序</code>，处理完成后返回到用户代码的<strong>下一条指令</strong></p>\n</li>\n<li><p><code>故障</code>：这个就是通常意义上的异常类型，当程序发生错误产生故障后，CPU将控制转移给对应的exception handler，此时有两种情况，如果故障处理器能够修正这个错误，就可以返回到<strong>之前故障的指令</strong>重新执行，如果处理不了，内核的abort程序就会中止这段应用</p>\n<p>比如调用内存缺页后，就会产生一个故障，缺页处理程序会从磁盘中加载对应的内存页到内存中，指令可以继续执行</p>\n</li>\n<li><p><code>终止</code>：这类异常时不可恢复的致命错误，这类异常发生后，对应的exception handler为终止处理程序，它<strong>不会将控制返还给出错的应用</strong>，而是直接返回给abort例程进行程序的终止</p>\n<p>计算机中一些致命的机器故障就会触发终止</p>\n</li>\n</ul>\n<p>x86-64架构中有256个异常号，其中0~31号是Intel设计师定义的系统异常，包括除以0，缺页或者segment fault等异常；剩下从32到255号是操作系统自己定义的中断号和陷阱号</p>\n<blockquote>\n<p>C程序调用某个系统函数时，在编译后的汇编指令中，一般将系统调用号存放于%rax寄存器，将过程调用参数列表存放于%rdi, %rsi, %rdx, %r10, %r8, %r9，一共6个，参数列表按照顺序存放在寄存器</p>\n<p>调用返回值仍旧存放在%rax寄存器，如果返回值是负数，说明发生了错误</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<p>本章主要介绍计算机系统中的异常处理流，当程序执行出错出现异常后，由硬件层，操作系统或者应用程序产生异常控制流对异常进行处理<br>","more":"</p>\n<h3 id=\"异常\"><a href=\"#异常\" class=\"headerlink\" title=\"异常\"></a>异常</h3><p>计算机系统中使用<code>异常</code>（exception）的形式来实现异常控制流，比较简单的例子是，当CPU执行到某个指令后，执行状态发生变化，立即产生一个异常事件，这种事件有可能是内存缺页，甚至是某个指令试图除以0。产生事件后，CPU会通过<code>异常表</code>进行<code>异常过程调用</code>，由<code>Exception Handler</code>来专门处理这个异常事件</p>\n<h4 id=\"异常表\"><a href=\"#异常表\" class=\"headerlink\" title=\"异常表\"></a>异常表</h4><p>系统中为每种类型的异常都分配了<code>异常号</code>，产生异常事件后，处理器执行异常过程调用时需要用这个异常号来从异常表中检索相应的<code>异常处理程序</code>，然后根据检索到的<code>异常处理程序</code>来执行相应的命令，跟一般的过程调用大同小异，不过还是有些区别：</p>\n<ul>\n<li>异常过程调用的返回地址会根据异常的类型来判断，要么是返回当前正在执行的指令地址，要么是下一条指令的地址</li>\n<li>CPU会把一些额外的处理器状态压到栈里</li>\n<li>CPU在内核态中执行异常过程调用，会将上下文全部压到<code>内核栈</code>中</li>\n<li>由于异常过程调用是运行在<code>内核态</code>下，因此这个过程对所有系统资源都有完全的访问权限</li>\n</ul>\n<p>异常过程调用完成后，执行一条<code>从中断返回</code>的指令，将适当的状态弹回到处理器的控制和数据寄存器，如果中断的是用户态程序，则将上下文切换回用户态，控制返回给被中断的用户态应用程序</p>\n<h4 id=\"四种异常类型\"><a href=\"#四种异常类型\" class=\"headerlink\" title=\"四种异常类型\"></a>四种异常类型</h4><p>计算机系统将可能出现的异常分为四类：</p>\n<ul>\n<li><p><code>中断</code>：对外部IO设备信号的响应，相对于正在执行的指令来说是异步发生的，由专门的<code>中断处理器(interrupt handler)</code>来处理这类中断信号</p>\n<p>中断类型跟其他三种异常还不太一样，中断不是由当前执行的指令产生的，IO设备通过向CPU的中断引脚发信号并将中断号发到总线上，CPU执行完当前指令后注意到中断引脚的电压变高，从系统总线读取中断号然后调用对应的中断处理器，调用完成后<strong>返回到下一条指令</strong>，就当这个中断从未发生过</p>\n</li>\n<li><p><code>陷阱</code>：这类异常通常是作为在用户程序和内核之间提供一个接口，即<code>系统调用</code></p>\n<p>CPU提供了一个特殊的指令<code>syscall n</code>，<code>n</code>是用户需要请求的系统调用号，当用户执行这个指令时，控制传递给相应的内核处理程序即<code>陷阱处理程序</code>，处理完成后返回到用户代码的<strong>下一条指令</strong></p>\n</li>\n<li><p><code>故障</code>：这个就是通常意义上的异常类型，当程序发生错误产生故障后，CPU将控制转移给对应的exception handler，此时有两种情况，如果故障处理器能够修正这个错误，就可以返回到<strong>之前故障的指令</strong>重新执行，如果处理不了，内核的abort程序就会中止这段应用</p>\n<p>比如调用内存缺页后，就会产生一个故障，缺页处理程序会从磁盘中加载对应的内存页到内存中，指令可以继续执行</p>\n</li>\n<li><p><code>终止</code>：这类异常时不可恢复的致命错误，这类异常发生后，对应的exception handler为终止处理程序，它<strong>不会将控制返还给出错的应用</strong>，而是直接返回给abort例程进行程序的终止</p>\n<p>计算机中一些致命的机器故障就会触发终止</p>\n</li>\n</ul>\n<p>x86-64架构中有256个异常号，其中0~31号是Intel设计师定义的系统异常，包括除以0，缺页或者segment fault等异常；剩下从32到255号是操作系统自己定义的中断号和陷阱号</p>\n<blockquote>\n<p>C程序调用某个系统函数时，在编译后的汇编指令中，一般将系统调用号存放于%rax寄存器，将过程调用参数列表存放于%rdi, %rsi, %rdx, %r10, %r8, %r9，一共6个，参数列表按照顺序存放在寄存器</p>\n<p>调用返回值仍旧存放在%rax寄存器，如果返回值是负数，说明发生了错误</p>\n</blockquote>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 9(2)","author":"天渊","date":"2019-11-22T09:50:00.000Z","_content":"第九章：`虚拟内存`（2）\n\n这一部分主要学习虚拟内存地址翻译的一些知识点\n\n<!--more-->\n\n### 虚拟地址翻译的基本知识\n\n虚拟地址和物理地址的信息映射主要体现在页表上，因此进行地址翻译主要就是借助页表中的PTE页表项中记录的信息（有效位，物理页地址或者磁盘地址）\n\nn位的虚拟地址由两部分组成：\n\n- **虚拟页号（VPN）**：表示该地址对应的虚拟页的index，用于在页表中找到对应的PTE\n- **虚拟页偏移量（VPO）**：表示该地址在虚拟页中的偏移位置，VPO与具体的物理页偏移量PPO是相同的，用于在物理页中找到具体的数据位置\n\n如下图所示：\n\n![](http://img.mantian.site/201911221128_827.png)\n\n在进行虚拟寻址的过程中，`页表基址寄存器（PTBR）`中存储了当前进程的页表位置，` 内存管理单元(MMU) `通过VPN找到该虚拟地址对应的页表PTE项，首先判断有效位，如果**不缺页**的话就取出存储的物理页号PPN，物理页号加上物理页偏移量PPO（也就是虚拟页号VPO）就是具体的物理内存地址，下图就是MMU取数据时的整个流程：\n\n![](http://img.mantian.site/201911221139_752.png)\n\n其中MMU通过步骤3拿到PTE的数据后会判断是否命中页面，如果没有的话就要触发缺页异常：\n\n![](http://img.mantian.site/201911221327_876.png)\n\nMMU触发缺页异常，将控制权交给缺页处理程序，缺页处理程序进行换页操作，将需要的页换回主存，控制权交回给MMU重新执行步骤3，后续就跟之前相同了\n\n**通过L1高速缓存加速获取PTE**：上图中，MMU通过虚拟地址获取PTE的过程，既可以从物理内存中获取，也可以从SRAM高速缓存中获取，如果能够命中的话能够将整个过程的时钟周期从上百个减少到一两个\n\n**通过TLB高速缓存加速获取PTE**：现在很多主流CPU在MMU中集成了一个特有的专门用于存放PTE信息的缓存，叫做`翻译后备缓冲器TLB（Translation Lookaside Buffer）`，能够极大的加速获取PTE信息的过程，步骤如下\n\n1. MMU接收到虚拟地址，MMU使用虚拟地址的虚拟页号VPN从TLB中寻找具体的PTE，VPN由`TLB索引`和`TLB标记`组成\n2. MMU使用PTE取出找到数据的物理地址，从高速缓存或者内存中取出数据\n\n如果MMU在TLB中没有找到对应的PTE，则需要从高速缓存或者内存中获取PTE，存放到TLB中，再从内存中获取数据：\n\n![](http://img.mantian.site/201911221550_41.png)\n\n\n\n#### 多级页表\n\n> **为什么需要多级页表?**\n>\n> 每一个进程启动后，系统都会给它分配一个常驻的页表，如果是32位系统，每个PTE大小位4 bytes，那","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-9-2.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 9(2)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-11-22 17:50:00\n---\n第九章：`虚拟内存`（2）\n\n这一部分主要学习虚拟内存地址翻译的一些知识点\n\n<!--more-->\n\n### 虚拟地址翻译的基本知识\n\n虚拟地址和物理地址的信息映射主要体现在页表上，因此进行地址翻译主要就是借助页表中的PTE页表项中记录的信息（有效位，物理页地址或者磁盘地址）\n\nn位的虚拟地址由两部分组成：\n\n- **虚拟页号（VPN）**：表示该地址对应的虚拟页的index，用于在页表中找到对应的PTE\n- **虚拟页偏移量（VPO）**：表示该地址在虚拟页中的偏移位置，VPO与具体的物理页偏移量PPO是相同的，用于在物理页中找到具体的数据位置\n\n如下图所示：\n\n![](http://img.mantian.site/201911221128_827.png)\n\n在进行虚拟寻址的过程中，`页表基址寄存器（PTBR）`中存储了当前进程的页表位置，` 内存管理单元(MMU) `通过VPN找到该虚拟地址对应的页表PTE项，首先判断有效位，如果**不缺页**的话就取出存储的物理页号PPN，物理页号加上物理页偏移量PPO（也就是虚拟页号VPO）就是具体的物理内存地址，下图就是MMU取数据时的整个流程：\n\n![](http://img.mantian.site/201911221139_752.png)\n\n其中MMU通过步骤3拿到PTE的数据后会判断是否命中页面，如果没有的话就要触发缺页异常：\n\n![](http://img.mantian.site/201911221327_876.png)\n\nMMU触发缺页异常，将控制权交给缺页处理程序，缺页处理程序进行换页操作，将需要的页换回主存，控制权交回给MMU重新执行步骤3，后续就跟之前相同了\n\n**通过L1高速缓存加速获取PTE**：上图中，MMU通过虚拟地址获取PTE的过程，既可以从物理内存中获取，也可以从SRAM高速缓存中获取，如果能够命中的话能够将整个过程的时钟周期从上百个减少到一两个\n\n**通过TLB高速缓存加速获取PTE**：现在很多主流CPU在MMU中集成了一个特有的专门用于存放PTE信息的缓存，叫做`翻译后备缓冲器TLB（Translation Lookaside Buffer）`，能够极大的加速获取PTE信息的过程，步骤如下\n\n1. MMU接收到虚拟地址，MMU使用虚拟地址的虚拟页号VPN从TLB中寻找具体的PTE，VPN由`TLB索引`和`TLB标记`组成\n2. MMU使用PTE取出找到数据的物理地址，从高速缓存或者内存中取出数据\n\n如果MMU在TLB中没有找到对应的PTE，则需要从高速缓存或者内存中获取PTE，存放到TLB中，再从内存中获取数据：\n\n![](http://img.mantian.site/201911221550_41.png)\n\n\n\n#### 多级页表\n\n> **为什么需要多级页表?**\n>\n> 每一个进程启动后，系统都会给它分配一个常驻的页表，如果是32位系统，每个PTE大小位4 bytes，那","slug":"《深入理解计算机系统》读书笔记——Chapter-9-2","published":1,"updated":"2021-05-31T03:06:33.201Z","_id":"ckf0h31io002nactsjc5c0mg6","comments":1,"layout":"post","photos":[],"link":"","content":"<p>第九章：<code>虚拟内存</code>（2）</p>\n<p>这一部分主要学习虚拟内存地址翻译的一些知识点</p>\n<a id=\"more\"></a>\n<h3 id=\"虚拟地址翻译的基本知识\"><a href=\"#虚拟地址翻译的基本知识\" class=\"headerlink\" title=\"虚拟地址翻译的基本知识\"></a>虚拟地址翻译的基本知识</h3><p>虚拟地址和物理地址的信息映射主要体现在页表上，因此进行地址翻译主要就是借助页表中的PTE页表项中记录的信息（有效位，物理页地址或者磁盘地址）</p>\n<p>n位的虚拟地址由两部分组成：</p>\n<ul>\n<li><strong>虚拟页号（VPN）</strong>：表示该地址对应的虚拟页的index，用于在页表中找到对应的PTE</li>\n<li><strong>虚拟页偏移量（VPO）</strong>：表示该地址在虚拟页中的偏移位置，VPO与具体的物理页偏移量PPO是相同的，用于在物理页中找到具体的数据位置</li>\n</ul>\n<p>如下图所示：</p>\n<p><img src=\"http://img.mantian.site/201911221128_827.png\" alt></p>\n<p>在进行虚拟寻址的过程中，<code>页表基址寄存器（PTBR）</code>中存储了当前进程的页表位置，<code>内存管理单元(MMU)</code>通过VPN找到该虚拟地址对应的页表PTE项，首先判断有效位，如果<strong>不缺页</strong>的话就取出存储的物理页号PPN，物理页号加上物理页偏移量PPO（也就是虚拟页号VPO）就是具体的物理内存地址，下图就是MMU取数据时的整个流程：</p>\n<p><img src=\"http://img.mantian.site/201911221139_752.png\" alt></p>\n<p>其中MMU通过步骤3拿到PTE的数据后会判断是否命中页面，如果没有的话就要触发缺页异常：</p>\n<p><img src=\"http://img.mantian.site/201911221327_876.png\" alt></p>\n<p>MMU触发缺页异常，将控制权交给缺页处理程序，缺页处理程序进行换页操作，将需要的页换回主存，控制权交回给MMU重新执行步骤3，后续就跟之前相同了</p>\n<p><strong>通过L1高速缓存加速获取PTE</strong>：上图中，MMU通过虚拟地址获取PTE的过程，既可以从物理内存中获取，也可以从SRAM高速缓存中获取，如果能够命中的话能够将整个过程的时钟周期从上百个减少到一两个</p>\n<p><strong>通过TLB高速缓存加速获取PTE</strong>：现在很多主流CPU在MMU中集成了一个特有的专门用于存放PTE信息的缓存，叫做<code>翻译后备缓冲器TLB（Translation Lookaside Buffer）</code>，能够极大的加速获取PTE信息的过程，步骤如下</p>\n<ol>\n<li>MMU接收到虚拟地址，MMU使用虚拟地址的虚拟页号VPN从TLB中寻找具体的PTE，VPN由<code>TLB索引</code>和<code>TLB标记</code>组成</li>\n<li>MMU使用PTE取出找到数据的物理地址，从高速缓存或者内存中取出数据</li>\n</ol>\n<p>如果MMU在TLB中没有找到对应的PTE，则需要从高速缓存或者内存中获取PTE，存放到TLB中，再从内存中获取数据：</p>\n<p><img src=\"http://img.mantian.site/201911221550_41.png\" alt></p>\n<h4 id=\"多级页表\"><a href=\"#多级页表\" class=\"headerlink\" title=\"多级页表\"></a>多级页表</h4><blockquote>\n<p><strong>为什么需要多级页表?</strong></p>\n<p>每一个进程启动后，系统都会给它分配一个常驻的页表，如果是32位系统，每个PTE大小位4 bytes，那</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<p>第九章：<code>虚拟内存</code>（2）</p>\n<p>这一部分主要学习虚拟内存地址翻译的一些知识点</p>","more":"<h3 id=\"虚拟地址翻译的基本知识\"><a href=\"#虚拟地址翻译的基本知识\" class=\"headerlink\" title=\"虚拟地址翻译的基本知识\"></a>虚拟地址翻译的基本知识</h3><p>虚拟地址和物理地址的信息映射主要体现在页表上，因此进行地址翻译主要就是借助页表中的PTE页表项中记录的信息（有效位，物理页地址或者磁盘地址）</p>\n<p>n位的虚拟地址由两部分组成：</p>\n<ul>\n<li><strong>虚拟页号（VPN）</strong>：表示该地址对应的虚拟页的index，用于在页表中找到对应的PTE</li>\n<li><strong>虚拟页偏移量（VPO）</strong>：表示该地址在虚拟页中的偏移位置，VPO与具体的物理页偏移量PPO是相同的，用于在物理页中找到具体的数据位置</li>\n</ul>\n<p>如下图所示：</p>\n<p><img src=\"http://img.mantian.site/201911221128_827.png\" alt></p>\n<p>在进行虚拟寻址的过程中，<code>页表基址寄存器（PTBR）</code>中存储了当前进程的页表位置，<code>内存管理单元(MMU)</code>通过VPN找到该虚拟地址对应的页表PTE项，首先判断有效位，如果<strong>不缺页</strong>的话就取出存储的物理页号PPN，物理页号加上物理页偏移量PPO（也就是虚拟页号VPO）就是具体的物理内存地址，下图就是MMU取数据时的整个流程：</p>\n<p><img src=\"http://img.mantian.site/201911221139_752.png\" alt></p>\n<p>其中MMU通过步骤3拿到PTE的数据后会判断是否命中页面，如果没有的话就要触发缺页异常：</p>\n<p><img src=\"http://img.mantian.site/201911221327_876.png\" alt></p>\n<p>MMU触发缺页异常，将控制权交给缺页处理程序，缺页处理程序进行换页操作，将需要的页换回主存，控制权交回给MMU重新执行步骤3，后续就跟之前相同了</p>\n<p><strong>通过L1高速缓存加速获取PTE</strong>：上图中，MMU通过虚拟地址获取PTE的过程，既可以从物理内存中获取，也可以从SRAM高速缓存中获取，如果能够命中的话能够将整个过程的时钟周期从上百个减少到一两个</p>\n<p><strong>通过TLB高速缓存加速获取PTE</strong>：现在很多主流CPU在MMU中集成了一个特有的专门用于存放PTE信息的缓存，叫做<code>翻译后备缓冲器TLB（Translation Lookaside Buffer）</code>，能够极大的加速获取PTE信息的过程，步骤如下</p>\n<ol>\n<li>MMU接收到虚拟地址，MMU使用虚拟地址的虚拟页号VPN从TLB中寻找具体的PTE，VPN由<code>TLB索引</code>和<code>TLB标记</code>组成</li>\n<li>MMU使用PTE取出找到数据的物理地址，从高速缓存或者内存中取出数据</li>\n</ol>\n<p>如果MMU在TLB中没有找到对应的PTE，则需要从高速缓存或者内存中获取PTE，存放到TLB中，再从内存中获取数据：</p>\n<p><img src=\"http://img.mantian.site/201911221550_41.png\" alt></p>\n<h4 id=\"多级页表\"><a href=\"#多级页表\" class=\"headerlink\" title=\"多级页表\"></a>多级页表</h4><blockquote>\n<p><strong>为什么需要多级页表?</strong></p>\n<p>每一个进程启动后，系统都会给它分配一个常驻的页表，如果是32位系统，每个PTE大小位4 bytes，那</p>\n</blockquote>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 6","author":"天渊","date":"2019-10-20T16:36:00.000Z","_content":"## 计算机存储系统\n\n本章主要是介绍计算机存储体系的体系和层次结构，还对局部性原理做了简单介绍，以及重点介绍了CPU多级缓存的知识，有助于程序员深刻理解如何基于计算机多层次存储系统写出高效的应用程序\n\n<!--more-->\n\n### 几种存储技术的简介\n\n现代计算机系统中的存储器主要分为RAM（随机访问存储器）和ROM（只读存储器），RAM中又分为两种：静态RAM ` SRAM`和动态RAM `DRAM`两大类，这两类RAM在断电后数据都会丢失，其区别主要在于：\n\n- `SRAM`：静态RAM最大特点是访问速度快，抗干扰能力强，但每个位晶体管数量多，造价昂贵，一般一个静态RAM只有几个MB大小，通常作为CPU高速缓存\n- `DRAM`：动态RAM特点是访问时间相对SRAM会慢很多，但造价相对便宜很多，单个位使用晶体管数量少，因此排列更加密集，通常作为计算机主存或者显卡缓冲内存，一个SRAM通常会几百上千MB大小\n\n#### 内存模块memory module\n\nDRAM通常用于实现内存，在计算机系统中被封装于内存模块（`memory module`）中\n\n在当前Intel x86-64系统中，使用一种叫做`双列直插内存模块`的方式封装DRAM芯片，每个DRAM由多个保存了8个bit的超单元格组成，在读取字节信息时，`内存控制器`通过一个超单元格地址`addr(row=i, column=j)`来获取多个DRAM芯片的超单元格信息，最后将这几个超单元格信息组合成一个8字节64位的信息\n\n##### 多种类的增强DRAM\n\n传统的DRAM内存模块，其访问速度还是会受到一些限制，毕竟在传统的内存模块中，内存控制器是按照DRAM芯片一个一个地读取超单元格，每次读取DRAM都会发送一次行地址读取信号（RAS）和列地址读取信息（CAS）\n\n针对这种情况，市面会推出了多种针对性优化的增强型DRAM：","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-6.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 6\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-10-21 00:36:00\n---\n## 计算机存储系统\n\n本章主要是介绍计算机存储体系的体系和层次结构，还对局部性原理做了简单介绍，以及重点介绍了CPU多级缓存的知识，有助于程序员深刻理解如何基于计算机多层次存储系统写出高效的应用程序\n\n<!--more-->\n\n### 几种存储技术的简介\n\n现代计算机系统中的存储器主要分为RAM（随机访问存储器）和ROM（只读存储器），RAM中又分为两种：静态RAM ` SRAM`和动态RAM `DRAM`两大类，这两类RAM在断电后数据都会丢失，其区别主要在于：\n\n- `SRAM`：静态RAM最大特点是访问速度快，抗干扰能力强，但每个位晶体管数量多，造价昂贵，一般一个静态RAM只有几个MB大小，通常作为CPU高速缓存\n- `DRAM`：动态RAM特点是访问时间相对SRAM会慢很多，但造价相对便宜很多，单个位使用晶体管数量少，因此排列更加密集，通常作为计算机主存或者显卡缓冲内存，一个SRAM通常会几百上千MB大小\n\n#### 内存模块memory module\n\nDRAM通常用于实现内存，在计算机系统中被封装于内存模块（`memory module`）中\n\n在当前Intel x86-64系统中，使用一种叫做`双列直插内存模块`的方式封装DRAM芯片，每个DRAM由多个保存了8个bit的超单元格组成，在读取字节信息时，`内存控制器`通过一个超单元格地址`addr(row=i, column=j)`来获取多个DRAM芯片的超单元格信息，最后将这几个超单元格信息组合成一个8字节64位的信息\n\n##### 多种类的增强DRAM\n\n传统的DRAM内存模块，其访问速度还是会受到一些限制，毕竟在传统的内存模块中，内存控制器是按照DRAM芯片一个一个地读取超单元格，每次读取DRAM都会发送一次行地址读取信号（RAS）和列地址读取信息（CAS）\n\n针对这种情况，市面会推出了多种针对性优化的增强型DRAM：","slug":"《深入理解计算机系统》读书笔记——Chapter-6","published":1,"updated":"2021-05-31T03:06:33.200Z","_id":"ckf0h31ip002qactsroel4k7o","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"计算机存储系统\"><a href=\"#计算机存储系统\" class=\"headerlink\" title=\"计算机存储系统\"></a>计算机存储系统</h2><p>本章主要是介绍计算机存储体系的体系和层次结构，还对局部性原理做了简单介绍，以及重点介绍了CPU多级缓存的知识，有助于程序员深刻理解如何基于计算机多层次存储系统写出高效的应用程序</p>\n<a id=\"more\"></a>\n<h3 id=\"几种存储技术的简介\"><a href=\"#几种存储技术的简介\" class=\"headerlink\" title=\"几种存储技术的简介\"></a>几种存储技术的简介</h3><p>现代计算机系统中的存储器主要分为RAM（随机访问存储器）和ROM（只读存储器），RAM中又分为两种：静态RAM <code>SRAM</code>和动态RAM <code>DRAM</code>两大类，这两类RAM在断电后数据都会丢失，其区别主要在于：</p>\n<ul>\n<li><code>SRAM</code>：静态RAM最大特点是访问速度快，抗干扰能力强，但每个位晶体管数量多，造价昂贵，一般一个静态RAM只有几个MB大小，通常作为CPU高速缓存</li>\n<li><code>DRAM</code>：动态RAM特点是访问时间相对SRAM会慢很多，但造价相对便宜很多，单个位使用晶体管数量少，因此排列更加密集，通常作为计算机主存或者显卡缓冲内存，一个SRAM通常会几百上千MB大小</li>\n</ul>\n<h4 id=\"内存模块memory-module\"><a href=\"#内存模块memory-module\" class=\"headerlink\" title=\"内存模块memory module\"></a>内存模块memory module</h4><p>DRAM通常用于实现内存，在计算机系统中被封装于内存模块（<code>memory module</code>）中</p>\n<p>在当前Intel x86-64系统中，使用一种叫做<code>双列直插内存模块</code>的方式封装DRAM芯片，每个DRAM由多个保存了8个bit的超单元格组成，在读取字节信息时，<code>内存控制器</code>通过一个超单元格地址<code>addr(row=i, column=j)</code>来获取多个DRAM芯片的超单元格信息，最后将这几个超单元格信息组合成一个8字节64位的信息</p>\n<h5 id=\"多种类的增强DRAM\"><a href=\"#多种类的增强DRAM\" class=\"headerlink\" title=\"多种类的增强DRAM\"></a>多种类的增强DRAM</h5><p>传统的DRAM内存模块，其访问速度还是会受到一些限制，毕竟在传统的内存模块中，内存控制器是按照DRAM芯片一个一个地读取超单元格，每次读取DRAM都会发送一次行地址读取信号（RAS）和列地址读取信息（CAS）</p>\n<p>针对这种情况，市面会推出了多种针对性优化的增强型DRAM：</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"计算机存储系统\"><a href=\"#计算机存储系统\" class=\"headerlink\" title=\"计算机存储系统\"></a>计算机存储系统</h2><p>本章主要是介绍计算机存储体系的体系和层次结构，还对局部性原理做了简单介绍，以及重点介绍了CPU多级缓存的知识，有助于程序员深刻理解如何基于计算机多层次存储系统写出高效的应用程序</p>","more":"<h3 id=\"几种存储技术的简介\"><a href=\"#几种存储技术的简介\" class=\"headerlink\" title=\"几种存储技术的简介\"></a>几种存储技术的简介</h3><p>现代计算机系统中的存储器主要分为RAM（随机访问存储器）和ROM（只读存储器），RAM中又分为两种：静态RAM <code>SRAM</code>和动态RAM <code>DRAM</code>两大类，这两类RAM在断电后数据都会丢失，其区别主要在于：</p>\n<ul>\n<li><code>SRAM</code>：静态RAM最大特点是访问速度快，抗干扰能力强，但每个位晶体管数量多，造价昂贵，一般一个静态RAM只有几个MB大小，通常作为CPU高速缓存</li>\n<li><code>DRAM</code>：动态RAM特点是访问时间相对SRAM会慢很多，但造价相对便宜很多，单个位使用晶体管数量少，因此排列更加密集，通常作为计算机主存或者显卡缓冲内存，一个SRAM通常会几百上千MB大小</li>\n</ul>\n<h4 id=\"内存模块memory-module\"><a href=\"#内存模块memory-module\" class=\"headerlink\" title=\"内存模块memory module\"></a>内存模块memory module</h4><p>DRAM通常用于实现内存，在计算机系统中被封装于内存模块（<code>memory module</code>）中</p>\n<p>在当前Intel x86-64系统中，使用一种叫做<code>双列直插内存模块</code>的方式封装DRAM芯片，每个DRAM由多个保存了8个bit的超单元格组成，在读取字节信息时，<code>内存控制器</code>通过一个超单元格地址<code>addr(row=i, column=j)</code>来获取多个DRAM芯片的超单元格信息，最后将这几个超单元格信息组合成一个8字节64位的信息</p>\n<h5 id=\"多种类的增强DRAM\"><a href=\"#多种类的增强DRAM\" class=\"headerlink\" title=\"多种类的增强DRAM\"></a>多种类的增强DRAM</h5><p>传统的DRAM内存模块，其访问速度还是会受到一些限制，毕竟在传统的内存模块中，内存控制器是按照DRAM芯片一个一个地读取超单元格，每次读取DRAM都会发送一次行地址读取信号（RAS）和列地址读取信息（CAS）</p>\n<p>针对这种情况，市面会推出了多种针对性优化的增强型DRAM：</p>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 2(1)","author":"天渊","date":"2019-09-05T02:55:00.000Z","_content":"第二章`信息的表示和处理`\n\n本章主要是对信息在计算机系统上的表示和存储进行了详细的介绍，包括二进制位的相关知识以及整数和浮点数的存储和计算等知识\n\n<!--more-->\n目录：\n\n- 信息存储\n- 整数表示\n- 整数运算\n- 浮点\n\n\n### 1. 信息的存储\n\n**字节**：大多数计算机都使用`字节`(byte)作为系统中最小内存单位，内存就可以看作一个巨大的byte数组\n\n**虚拟地址空间**：操作系统为程序提供`虚拟内存`(virtual memory)这一概念屏蔽了底层存储系统的复杂性，其中虚拟内存中每个字节都有自己的地址，也就是`虚拟地址`(virtual address)，虚拟内存中所有可能地址的集合就是`虚拟地址空间`(virtual address space)，C语言中某个指针的值就是某个存储块第一个字节的虚拟地址\n\n> 指针：C语言的重要特性，有`值`和`类型`两个属性，`值`是某个对象的虚拟地址，`类型`是表示那个位置上存储对象的类型\n\n#### 十六进制\n\n一个字节是8位，表示成二进制是`00000000 ~ 11111111`，表示成十进制的范围是`0 ~ 255`，表示成十六进制是`00 ~ FF`，很明显十六进制的表示方式更加简洁易用，计算机系统中通常以`0x`开头表示一个以十六进制展现的内存地址\n\n#### 字长\n\n所谓`字长`，就是指针携带的地址值的标称大小，32位字长的机器其虚拟地址范围就是0 ~ 2^32^（最大虚拟地址值是2^32^-1，也就是说32位字长的系统虚拟地址空间大小就是4GB），64位字长的机器其虚拟地址范围就是0 ~ 2^64^（16EB）\n\n> 向后兼容：64位机器可以运行32位机器编译的程序，但32位机器无法运行64位机器编译的程序\n\n#### 寻址\n\n一个对象在内存中是以连续的字节序列的形式存储的，对象的地址就是这段字节序列中最低位置的地址值\n\n对象字节序列中，开始位置的字节称为`最低有效位`，结束位置称为`最高有效位`，比如对于`0x01234567`这个int，最高有效位字节就是01，最低有效位字节是67\n\n##### 字节顺序\n\n对象在内存中的字节序列是由一定的顺序进行保存的，保存对象字节序列的顺序就是字节顺序，有`大端法`和`小端法`两种：\n\n- 大端法：从最高有效位到最低有效位的顺序存储对象\n- 小端法：从最低有效位到最高有效位的顺序进行存储\n\n![](http://img.mantian.site/201909041347_779.png)\n\n如图，箭头方向就是地址顺序，左起是地址起始位置，大端法中最左侧是最高有效位字节，反之小端法中最左侧是最低有效位字节\n\n大多数Intel兼容机都是小端模式，IBM和Oracle的服务器使用大端模式，不过现在很多微处理器都是`双端模式`，兼容两种模式\n\n> 实战：使用c程序来展现不同的数据类型在内存中的字节表示\n\n```c\n#include <stdio.h>\n//定义一个指向unsigned char的指针类型byte_pointer\ntypedef unsigned char *byte_pointer;\n//将某个unsigned char按照内存中的字节顺序打印出来\nvoid show_bytes(byte_pointer start, size_t len) {\n    size_t i;\n    for (i = 0; i < len; i++) {\n        printf(\"%.2x\", start[i]);\n    }\n    printf(\"\\n\");\n}\n//将某个int按照内存中的字节顺序打印出来\nvoid show_int(int x) {\n    //使用强制类型转换将int类指针转换为unsigned char指针\n    show_bytes((byte_pointer)&x, sizeof(int));\n}\n//将某个float按照内存中的字节顺序打印出来\nvoid show_float(float x) {\n    show_bytes((byte_pointer)&x, sizeof(float));\n}\n//将某个指针数据按照内存中的字节顺序打印出来\nvoid show_pointer(void *x) {\n    show_bytes((byte_pointer)&x, sizeof(void *));\n}\nint main() {\n    char c = 'h';\n    byte_pointer start = &c;\n    show_bytes(start, sizeof(char));\n    show_int(1000);\n    show_float(19.88f);\n    show_pointer(&c);\n    return 0;\n}\n```\n\n按照内存中的顺序将各个数据类型按照字节排列顺序进行打印，可以发现：\n\nshow_bytes打印h字符结果为68，恰好就是Ascii码中h字符的字节表示\n\nshow_int打印1000结果为e8030000，因为当前windows环境下是**小端**表示，高位在后，低位在前，忽略掉高位0后其值为3e8，也就是1000的16进制表示\n\nshow_pointer打印char c指针的结果为47fe610000000000，忽略掉高位的0后就是0x61fe47，也说明64位环境下对象地址大小为8字节\n\n> 使用数组方式引用指针：\n>\n> 上述例子中`start[i]`表示从start这个指针指向的内存起始位置，以数组的形式获取数据\n\n###### 字符串的字节顺序\n\n字符串类型的字节顺序与其他类型稍有不同，在任意平台上字符串都是正序排列，如下：\n\n```c\n#include <stdio.h>\n#include <string.h>\nvoid show_string(char *str) {\n    show_bytes((byte_pointer)str, strlen(str));\n}\nint main() {\n    char str[] = \"hello\";\n    show_string(&str);\n    return 0;\n}\n```\n\n结果为`68656c6c6f`，也就是\"hello\"的正序Ascii码序列，说明字符串类型具有良好的跨平台通用性\n\n#### 布尔代数\n\n布尔运算在计算机系统中占有很重要的地位，在数值位运算中运用尤为广泛\n\n基本的布尔运算逻辑有四种`&（与）`，`|（或）`，`~（非）`，`^（异或）`，四种布尔运算逻辑表格如下：\n\n![](http://img.mantian.site/201909041553_177.png)\n\n##### 位运算\n\n布尔代数在计算机科学中一个很重要的运用就是位运算，C和Java等高级语言都支持位运算\n\n有以下程序，可以将x和y各自的地址相互对调：\n\n```c\n#include <stdio.h>\nvoid inplace_swap(int *x, int *y) {\n    *y = *x ^ *y;\n    *x = *x ^ *y;\n    *y = *x ^ *y;\n}\nint main() {\n    int x = 10;\n    int y = 9;\n    inplace_swap(&x, &y);\n    printf(\"%d\\n\", x);\n    printf(\"%d\", y);\n    return 0;\n}\n```\n\n打印结果显示x=9，y=10，因为我们通过三次异或运算将x和y的值进行了对调，由此产生了一些结论：\n\n1. 异或运算中，任何值与0的异或结果还是它本身\n2. 异或运算中，任何值与它自己的异或结果为0\n3. 异或运算支持结合律\n\n通过以下函数可以将一个数组前后颠倒：\n\n```c\nvoid reverse_array(int a[], int count) {\n    int first, last;\n    for (first = 0, last = count -1; first < last; first++, last--) {\n        inplace_swap(&a[first], &a[last]);\n    }\n}\nint main() {\n    int a[] = {1, 2, 3, 4, 5, 6};\n    int len = sizeof(a) / sizeof(a[0]);\n    printf(\"size of array is %d\\n\", len);\n    reverse_array(a, len);\n    for (int i = 0; i < len; i++) {\n        printf(\"%d\\n\", a[i]);\n    }\n    return 0;\n}\n```\n\n打印结果是\"6, 5, 4, 3, 2, 1\"\n\n##### 逻辑运算符\n\n逻辑运算符和位运算符功能相似，不过逻辑运算符针对Boolean类型，而位运算符仅仅对数字做二进制位运算\n\n##### 移位运算\n\n移位运算通常用于对数字的二进制位进行移动计算，具体的移位运算还包括`逻辑移位`和`算术移位`：\n\n![](http://img.mantian.site/201909051029_959.png)\n\n与`逻辑右移位`不同的是，`算术右移位`会在空出来的高位补足移位个数的最高有效位的值\n\n与C语言不同的是，Java中`>>`代表`算术右移位`，`>>>`代表`逻辑右移位`\n\n**注意**：移位运算符的优先级低于加减法运算符\n\n### 2. 整数表示\n\n整数类型在32位机器和64位机器上的取值范围是不一样的，int类型都是4字节编码，long类型在32位机器上是4字节编码，在64位机器上是8字节编码，此外C语言规定int类型可以用2字节长度来编码，long字节可以用4字节长度来编码，我想这应该是为了兼容32位和64位的平台\n\n#### 无符号数\n\n无符号数是没有负数编码的数字，最小值为0，在C语言中用`unsigned`进行声明，一般来说`int`表示有符号整形，`uintb`表示无符号整形 （与C语言不同，Java没有无符号数）\n\n**无符号数编码唯一性**：在计算机系统中无符号数的编码具有唯一性，比如无符号数`10`的二进制编码是`1010`，那么可以断言`1010`这个编码如果表示的是一个无符号数的话，那它对应的十进制就只能是`10`\n\n#### 有符号数\n\n学习有符号数前需要先了解`补码编码`\n\n##### 补码编码\n\n`补码`是计算机系统中表示负数必不可少的编码手段，通过补码表示的数字的最高有效位是符号位，为0则表示正数，为1则表示负数，例如二进制数`1101`中，高位的1表示该数是一个负数，通过剩下三位可以计算出该负数的绝对值是3，则该补码编码对应的十进制数是`-3`\n\n**补码转换为十进制有符号数**：以下是换算补码二进制数到十进制数的两种方式：\n\n`权重法`：换算方式与无符号二进制转十进制的方式类似，不过高位符号位需要取负号：\n\n$$\n1011: -1 * 2^3 + 0 * 2^2 + 1 * 2^1 + 1 * 2^0 = -5\n$$\n\n$$\n0101: 0 * 2^3 + 1 * 2^2 + 0 * 2^1 + 1 * 2^0 = 5\n$$\n\n`取反法`：判断最高有效位，如果最高位为0，则为正数，计算方式与无符号数一致，如果为1，则为负数，将最高位去掉，剩余位减去1后各位再取反，得到的二进制编码则是该负数的绝对值，比如上述例子中的`1011`去掉最高位后未`011`，减去1后为`010`，全部取反后为`101`，转换为十进制为`5`，则该负数是`-5`\n\n**十进制有符号数转换为补码**: 相应的，将十进制负数`-5`转换为补码形式`1011`就有以下方式\n\n```\n# 绝对值转换为二进制： 101\n# 二进制位全部取反： 010\n# 加1： 011\n# 加上符号位： 1011\n```\n\n","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-2.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 2(1)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-09-05 10:55:00\n---\n第二章`信息的表示和处理`\n\n本章主要是对信息在计算机系统上的表示和存储进行了详细的介绍，包括二进制位的相关知识以及整数和浮点数的存储和计算等知识\n\n<!--more-->\n目录：\n\n- 信息存储\n- 整数表示\n- 整数运算\n- 浮点\n\n\n### 1. 信息的存储\n\n**字节**：大多数计算机都使用`字节`(byte)作为系统中最小内存单位，内存就可以看作一个巨大的byte数组\n\n**虚拟地址空间**：操作系统为程序提供`虚拟内存`(virtual memory)这一概念屏蔽了底层存储系统的复杂性，其中虚拟内存中每个字节都有自己的地址，也就是`虚拟地址`(virtual address)，虚拟内存中所有可能地址的集合就是`虚拟地址空间`(virtual address space)，C语言中某个指针的值就是某个存储块第一个字节的虚拟地址\n\n> 指针：C语言的重要特性，有`值`和`类型`两个属性，`值`是某个对象的虚拟地址，`类型`是表示那个位置上存储对象的类型\n\n#### 十六进制\n\n一个字节是8位，表示成二进制是`00000000 ~ 11111111`，表示成十进制的范围是`0 ~ 255`，表示成十六进制是`00 ~ FF`，很明显十六进制的表示方式更加简洁易用，计算机系统中通常以`0x`开头表示一个以十六进制展现的内存地址\n\n#### 字长\n\n所谓`字长`，就是指针携带的地址值的标称大小，32位字长的机器其虚拟地址范围就是0 ~ 2^32^（最大虚拟地址值是2^32^-1，也就是说32位字长的系统虚拟地址空间大小就是4GB），64位字长的机器其虚拟地址范围就是0 ~ 2^64^（16EB）\n\n> 向后兼容：64位机器可以运行32位机器编译的程序，但32位机器无法运行64位机器编译的程序\n\n#### 寻址\n\n一个对象在内存中是以连续的字节序列的形式存储的，对象的地址就是这段字节序列中最低位置的地址值\n\n对象字节序列中，开始位置的字节称为`最低有效位`，结束位置称为`最高有效位`，比如对于`0x01234567`这个int，最高有效位字节就是01，最低有效位字节是67\n\n##### 字节顺序\n\n对象在内存中的字节序列是由一定的顺序进行保存的，保存对象字节序列的顺序就是字节顺序，有`大端法`和`小端法`两种：\n\n- 大端法：从最高有效位到最低有效位的顺序存储对象\n- 小端法：从最低有效位到最高有效位的顺序进行存储\n\n![](http://img.mantian.site/201909041347_779.png)\n\n如图，箭头方向就是地址顺序，左起是地址起始位置，大端法中最左侧是最高有效位字节，反之小端法中最左侧是最低有效位字节\n\n大多数Intel兼容机都是小端模式，IBM和Oracle的服务器使用大端模式，不过现在很多微处理器都是`双端模式`，兼容两种模式\n\n> 实战：使用c程序来展现不同的数据类型在内存中的字节表示\n\n```c\n#include <stdio.h>\n//定义一个指向unsigned char的指针类型byte_pointer\ntypedef unsigned char *byte_pointer;\n//将某个unsigned char按照内存中的字节顺序打印出来\nvoid show_bytes(byte_pointer start, size_t len) {\n    size_t i;\n    for (i = 0; i < len; i++) {\n        printf(\"%.2x\", start[i]);\n    }\n    printf(\"\\n\");\n}\n//将某个int按照内存中的字节顺序打印出来\nvoid show_int(int x) {\n    //使用强制类型转换将int类指针转换为unsigned char指针\n    show_bytes((byte_pointer)&x, sizeof(int));\n}\n//将某个float按照内存中的字节顺序打印出来\nvoid show_float(float x) {\n    show_bytes((byte_pointer)&x, sizeof(float));\n}\n//将某个指针数据按照内存中的字节顺序打印出来\nvoid show_pointer(void *x) {\n    show_bytes((byte_pointer)&x, sizeof(void *));\n}\nint main() {\n    char c = 'h';\n    byte_pointer start = &c;\n    show_bytes(start, sizeof(char));\n    show_int(1000);\n    show_float(19.88f);\n    show_pointer(&c);\n    return 0;\n}\n```\n\n按照内存中的顺序将各个数据类型按照字节排列顺序进行打印，可以发现：\n\nshow_bytes打印h字符结果为68，恰好就是Ascii码中h字符的字节表示\n\nshow_int打印1000结果为e8030000，因为当前windows环境下是**小端**表示，高位在后，低位在前，忽略掉高位0后其值为3e8，也就是1000的16进制表示\n\nshow_pointer打印char c指针的结果为47fe610000000000，忽略掉高位的0后就是0x61fe47，也说明64位环境下对象地址大小为8字节\n\n> 使用数组方式引用指针：\n>\n> 上述例子中`start[i]`表示从start这个指针指向的内存起始位置，以数组的形式获取数据\n\n###### 字符串的字节顺序\n\n字符串类型的字节顺序与其他类型稍有不同，在任意平台上字符串都是正序排列，如下：\n\n```c\n#include <stdio.h>\n#include <string.h>\nvoid show_string(char *str) {\n    show_bytes((byte_pointer)str, strlen(str));\n}\nint main() {\n    char str[] = \"hello\";\n    show_string(&str);\n    return 0;\n}\n```\n\n结果为`68656c6c6f`，也就是\"hello\"的正序Ascii码序列，说明字符串类型具有良好的跨平台通用性\n\n#### 布尔代数\n\n布尔运算在计算机系统中占有很重要的地位，在数值位运算中运用尤为广泛\n\n基本的布尔运算逻辑有四种`&（与）`，`|（或）`，`~（非）`，`^（异或）`，四种布尔运算逻辑表格如下：\n\n![](http://img.mantian.site/201909041553_177.png)\n\n##### 位运算\n\n布尔代数在计算机科学中一个很重要的运用就是位运算，C和Java等高级语言都支持位运算\n\n有以下程序，可以将x和y各自的地址相互对调：\n\n```c\n#include <stdio.h>\nvoid inplace_swap(int *x, int *y) {\n    *y = *x ^ *y;\n    *x = *x ^ *y;\n    *y = *x ^ *y;\n}\nint main() {\n    int x = 10;\n    int y = 9;\n    inplace_swap(&x, &y);\n    printf(\"%d\\n\", x);\n    printf(\"%d\", y);\n    return 0;\n}\n```\n\n打印结果显示x=9，y=10，因为我们通过三次异或运算将x和y的值进行了对调，由此产生了一些结论：\n\n1. 异或运算中，任何值与0的异或结果还是它本身\n2. 异或运算中，任何值与它自己的异或结果为0\n3. 异或运算支持结合律\n\n通过以下函数可以将一个数组前后颠倒：\n\n```c\nvoid reverse_array(int a[], int count) {\n    int first, last;\n    for (first = 0, last = count -1; first < last; first++, last--) {\n        inplace_swap(&a[first], &a[last]);\n    }\n}\nint main() {\n    int a[] = {1, 2, 3, 4, 5, 6};\n    int len = sizeof(a) / sizeof(a[0]);\n    printf(\"size of array is %d\\n\", len);\n    reverse_array(a, len);\n    for (int i = 0; i < len; i++) {\n        printf(\"%d\\n\", a[i]);\n    }\n    return 0;\n}\n```\n\n打印结果是\"6, 5, 4, 3, 2, 1\"\n\n##### 逻辑运算符\n\n逻辑运算符和位运算符功能相似，不过逻辑运算符针对Boolean类型，而位运算符仅仅对数字做二进制位运算\n\n##### 移位运算\n\n移位运算通常用于对数字的二进制位进行移动计算，具体的移位运算还包括`逻辑移位`和`算术移位`：\n\n![](http://img.mantian.site/201909051029_959.png)\n\n与`逻辑右移位`不同的是，`算术右移位`会在空出来的高位补足移位个数的最高有效位的值\n\n与C语言不同的是，Java中`>>`代表`算术右移位`，`>>>`代表`逻辑右移位`\n\n**注意**：移位运算符的优先级低于加减法运算符\n\n### 2. 整数表示\n\n整数类型在32位机器和64位机器上的取值范围是不一样的，int类型都是4字节编码，long类型在32位机器上是4字节编码，在64位机器上是8字节编码，此外C语言规定int类型可以用2字节长度来编码，long字节可以用4字节长度来编码，我想这应该是为了兼容32位和64位的平台\n\n#### 无符号数\n\n无符号数是没有负数编码的数字，最小值为0，在C语言中用`unsigned`进行声明，一般来说`int`表示有符号整形，`uintb`表示无符号整形 （与C语言不同，Java没有无符号数）\n\n**无符号数编码唯一性**：在计算机系统中无符号数的编码具有唯一性，比如无符号数`10`的二进制编码是`1010`，那么可以断言`1010`这个编码如果表示的是一个无符号数的话，那它对应的十进制就只能是`10`\n\n#### 有符号数\n\n学习有符号数前需要先了解`补码编码`\n\n##### 补码编码\n\n`补码`是计算机系统中表示负数必不可少的编码手段，通过补码表示的数字的最高有效位是符号位，为0则表示正数，为1则表示负数，例如二进制数`1101`中，高位的1表示该数是一个负数，通过剩下三位可以计算出该负数的绝对值是3，则该补码编码对应的十进制数是`-3`\n\n**补码转换为十进制有符号数**：以下是换算补码二进制数到十进制数的两种方式：\n\n`权重法`：换算方式与无符号二进制转十进制的方式类似，不过高位符号位需要取负号：\n\n$$\n1011: -1 * 2^3 + 0 * 2^2 + 1 * 2^1 + 1 * 2^0 = -5\n$$\n\n$$\n0101: 0 * 2^3 + 1 * 2^2 + 0 * 2^1 + 1 * 2^0 = 5\n$$\n\n`取反法`：判断最高有效位，如果最高位为0，则为正数，计算方式与无符号数一致，如果为1，则为负数，将最高位去掉，剩余位减去1后各位再取反，得到的二进制编码则是该负数的绝对值，比如上述例子中的`1011`去掉最高位后未`011`，减去1后为`010`，全部取反后为`101`，转换为十进制为`5`，则该负数是`-5`\n\n**十进制有符号数转换为补码**: 相应的，将十进制负数`-5`转换为补码形式`1011`就有以下方式\n\n```\n# 绝对值转换为二进制： 101\n# 二进制位全部取反： 010\n# 加1： 011\n# 加上符号位： 1011\n```\n\n","slug":"《深入理解计算机系统》读书笔记——Chapter-2","published":1,"updated":"2019-09-18T14:40:18.350Z","_id":"ckf0h31ir002uactsn5q1e13v","comments":1,"layout":"post","photos":[],"link":"","content":"<p>第二章<code>信息的表示和处理</code></p>\n<p>本章主要是对信息在计算机系统上的表示和存储进行了详细的介绍，包括二进制位的相关知识以及整数和浮点数的存储和计算等知识</p>\n<a id=\"more\"></a>\n<p>目录：</p>\n<ul>\n<li>信息存储</li>\n<li>整数表示</li>\n<li>整数运算</li>\n<li>浮点</li>\n</ul>\n<h3 id=\"1-信息的存储\"><a href=\"#1-信息的存储\" class=\"headerlink\" title=\"1. 信息的存储\"></a>1. 信息的存储</h3><p><strong>字节</strong>：大多数计算机都使用<code>字节</code>(byte)作为系统中最小内存单位，内存就可以看作一个巨大的byte数组</p>\n<p><strong>虚拟地址空间</strong>：操作系统为程序提供<code>虚拟内存</code>(virtual memory)这一概念屏蔽了底层存储系统的复杂性，其中虚拟内存中每个字节都有自己的地址，也就是<code>虚拟地址</code>(virtual address)，虚拟内存中所有可能地址的集合就是<code>虚拟地址空间</code>(virtual address space)，C语言中某个指针的值就是某个存储块第一个字节的虚拟地址</p>\n<blockquote>\n<p>指针：C语言的重要特性，有<code>值</code>和<code>类型</code>两个属性，<code>值</code>是某个对象的虚拟地址，<code>类型</code>是表示那个位置上存储对象的类型</p>\n</blockquote>\n<h4 id=\"十六进制\"><a href=\"#十六进制\" class=\"headerlink\" title=\"十六进制\"></a>十六进制</h4><p>一个字节是8位，表示成二进制是<code>00000000 ~ 11111111</code>，表示成十进制的范围是<code>0 ~ 255</code>，表示成十六进制是<code>00 ~ FF</code>，很明显十六进制的表示方式更加简洁易用，计算机系统中通常以<code>0x</code>开头表示一个以十六进制展现的内存地址</p>\n<h4 id=\"字长\"><a href=\"#字长\" class=\"headerlink\" title=\"字长\"></a>字长</h4><p>所谓<code>字长</code>，就是指针携带的地址值的标称大小，32位字长的机器其虚拟地址范围就是0 ~ 2^32^（最大虚拟地址值是2^32^-1，也就是说32位字长的系统虚拟地址空间大小就是4GB），64位字长的机器其虚拟地址范围就是0 ~ 2^64^（16EB）</p>\n<blockquote>\n<p>向后兼容：64位机器可以运行32位机器编译的程序，但32位机器无法运行64位机器编译的程序</p>\n</blockquote>\n<h4 id=\"寻址\"><a href=\"#寻址\" class=\"headerlink\" title=\"寻址\"></a>寻址</h4><p>一个对象在内存中是以连续的字节序列的形式存储的，对象的地址就是这段字节序列中最低位置的地址值</p>\n<p>对象字节序列中，开始位置的字节称为<code>最低有效位</code>，结束位置称为<code>最高有效位</code>，比如对于<code>0x01234567</code>这个int，最高有效位字节就是01，最低有效位字节是67</p>\n<h5 id=\"字节顺序\"><a href=\"#字节顺序\" class=\"headerlink\" title=\"字节顺序\"></a>字节顺序</h5><p>对象在内存中的字节序列是由一定的顺序进行保存的，保存对象字节序列的顺序就是字节顺序，有<code>大端法</code>和<code>小端法</code>两种：</p>\n<ul>\n<li>大端法：从最高有效位到最低有效位的顺序存储对象</li>\n<li>小端法：从最低有效位到最高有效位的顺序进行存储</li>\n</ul>\n<p><img src=\"http://img.mantian.site/201909041347_779.png\" alt></p>\n<p>如图，箭头方向就是地址顺序，左起是地址起始位置，大端法中最左侧是最高有效位字节，反之小端法中最左侧是最低有效位字节</p>\n<p>大多数Intel兼容机都是小端模式，IBM和Oracle的服务器使用大端模式，不过现在很多微处理器都是<code>双端模式</code>，兼容两种模式</p>\n<blockquote>\n<p>实战：使用c程序来展现不同的数据类型在内存中的字节表示</p>\n</blockquote>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\">//定义一个指向unsigned char的指针类型byte_pointer</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *byte_pointer;</span><br><span class=\"line\"><span class=\"comment\">//将某个unsigned char按照内存中的字节顺序打印出来</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">show_bytes</span><span class=\"params\">(byte_pointer start, <span class=\"keyword\">size_t</span> len)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">size_t</span> i;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; len; i++) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%.2x\"</span>, start[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//将某个int按照内存中的字节顺序打印出来</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">show_int</span><span class=\"params\">(<span class=\"keyword\">int</span> x)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//使用强制类型转换将int类指针转换为unsigned char指针</span></span><br><span class=\"line\">    show_bytes((byte_pointer)&amp;x, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">int</span>));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//将某个float按照内存中的字节顺序打印出来</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">show_float</span><span class=\"params\">(<span class=\"keyword\">float</span> x)</span> </span>&#123;</span><br><span class=\"line\">    show_bytes((byte_pointer)&amp;x, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//将某个指针数据按照内存中的字节顺序打印出来</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">show_pointer</span><span class=\"params\">(<span class=\"keyword\">void</span> *x)</span> </span>&#123;</span><br><span class=\"line\">    show_bytes((byte_pointer)&amp;x, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">void</span> *));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> c = <span class=\"string\">'h'</span>;</span><br><span class=\"line\">    byte_pointer start = &amp;c;</span><br><span class=\"line\">    show_bytes(start, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">char</span>));</span><br><span class=\"line\">    show_int(<span class=\"number\">1000</span>);</span><br><span class=\"line\">    show_float(<span class=\"number\">19.88f</span>);</span><br><span class=\"line\">    show_pointer(&amp;c);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>按照内存中的顺序将各个数据类型按照字节排列顺序进行打印，可以发现：</p>\n<p>show_bytes打印h字符结果为68，恰好就是Ascii码中h字符的字节表示</p>\n<p>show_int打印1000结果为e8030000，因为当前windows环境下是<strong>小端</strong>表示，高位在后，低位在前，忽略掉高位0后其值为3e8，也就是1000的16进制表示</p>\n<p>show_pointer打印char c指针的结果为47fe610000000000，忽略掉高位的0后就是0x61fe47，也说明64位环境下对象地址大小为8字节</p>\n<blockquote>\n<p>使用数组方式引用指针：</p>\n<p>上述例子中<code>start[i]</code>表示从start这个指针指向的内存起始位置，以数组的形式获取数据</p>\n</blockquote>\n<h6 id=\"字符串的字节顺序\"><a href=\"#字符串的字节顺序\" class=\"headerlink\" title=\"字符串的字节顺序\"></a>字符串的字节顺序</h6><p>字符串类型的字节顺序与其他类型稍有不同，在任意平台上字符串都是正序排列，如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">show_string</span><span class=\"params\">(<span class=\"keyword\">char</span> *str)</span> </span>&#123;</span><br><span class=\"line\">    show_bytes((byte_pointer)str, <span class=\"built_in\">strlen</span>(str));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> str[] = <span class=\"string\">\"hello\"</span>;</span><br><span class=\"line\">    show_string(&amp;str);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>结果为<code>68656c6c6f</code>，也就是”hello”的正序Ascii码序列，说明字符串类型具有良好的跨平台通用性</p>\n<h4 id=\"布尔代数\"><a href=\"#布尔代数\" class=\"headerlink\" title=\"布尔代数\"></a>布尔代数</h4><p>布尔运算在计算机系统中占有很重要的地位，在数值位运算中运用尤为广泛</p>\n<p>基本的布尔运算逻辑有四种<code>&amp;（与）</code>，<code>|（或）</code>，<code>~（非）</code>，<code>^（异或）</code>，四种布尔运算逻辑表格如下：</p>\n<p><img src=\"http://img.mantian.site/201909041553_177.png\" alt></p>\n<h5 id=\"位运算\"><a href=\"#位运算\" class=\"headerlink\" title=\"位运算\"></a>位运算</h5><p>布尔代数在计算机科学中一个很重要的运用就是位运算，C和Java等高级语言都支持位运算</p>\n<p>有以下程序，可以将x和y各自的地址相互对调：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">inplace_swap</span><span class=\"params\">(<span class=\"keyword\">int</span> *x, <span class=\"keyword\">int</span> *y)</span> </span>&#123;</span><br><span class=\"line\">    *y = *x ^ *y;</span><br><span class=\"line\">    *x = *x ^ *y;</span><br><span class=\"line\">    *y = *x ^ *y;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> x = <span class=\"number\">10</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> y = <span class=\"number\">9</span>;</span><br><span class=\"line\">    inplace_swap(&amp;x, &amp;y);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\n\"</span>, x);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\"</span>, y);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>打印结果显示x=9，y=10，因为我们通过三次异或运算将x和y的值进行了对调，由此产生了一些结论：</p>\n<ol>\n<li>异或运算中，任何值与0的异或结果还是它本身</li>\n<li>异或运算中，任何值与它自己的异或结果为0</li>\n<li>异或运算支持结合律</li>\n</ol>\n<p>通过以下函数可以将一个数组前后颠倒：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">reverse_array</span><span class=\"params\">(<span class=\"keyword\">int</span> a[], <span class=\"keyword\">int</span> count)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> first, last;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (first = <span class=\"number\">0</span>, last = count <span class=\"number\">-1</span>; first &lt; last; first++, last--) &#123;</span><br><span class=\"line\">        inplace_swap(&amp;a[first], &amp;a[last]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a[] = &#123;<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>&#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = <span class=\"keyword\">sizeof</span>(a) / <span class=\"keyword\">sizeof</span>(a[<span class=\"number\">0</span>]);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"size of array is %d\\n\"</span>, len);</span><br><span class=\"line\">    reverse_array(a, len);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\n\"</span>, a[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>打印结果是”6, 5, 4, 3, 2, 1”</p>\n<h5 id=\"逻辑运算符\"><a href=\"#逻辑运算符\" class=\"headerlink\" title=\"逻辑运算符\"></a>逻辑运算符</h5><p>逻辑运算符和位运算符功能相似，不过逻辑运算符针对Boolean类型，而位运算符仅仅对数字做二进制位运算</p>\n<h5 id=\"移位运算\"><a href=\"#移位运算\" class=\"headerlink\" title=\"移位运算\"></a>移位运算</h5><p>移位运算通常用于对数字的二进制位进行移动计算，具体的移位运算还包括<code>逻辑移位</code>和<code>算术移位</code>：</p>\n<p><img src=\"http://img.mantian.site/201909051029_959.png\" alt></p>\n<p>与<code>逻辑右移位</code>不同的是，<code>算术右移位</code>会在空出来的高位补足移位个数的最高有效位的值</p>\n<p>与C语言不同的是，Java中<code>&gt;&gt;</code>代表<code>算术右移位</code>，<code>&gt;&gt;&gt;</code>代表<code>逻辑右移位</code></p>\n<p><strong>注意</strong>：移位运算符的优先级低于加减法运算符</p>\n<h3 id=\"2-整数表示\"><a href=\"#2-整数表示\" class=\"headerlink\" title=\"2. 整数表示\"></a>2. 整数表示</h3><p>整数类型在32位机器和64位机器上的取值范围是不一样的，int类型都是4字节编码，long类型在32位机器上是4字节编码，在64位机器上是8字节编码，此外C语言规定int类型可以用2字节长度来编码，long字节可以用4字节长度来编码，我想这应该是为了兼容32位和64位的平台</p>\n<h4 id=\"无符号数\"><a href=\"#无符号数\" class=\"headerlink\" title=\"无符号数\"></a>无符号数</h4><p>无符号数是没有负数编码的数字，最小值为0，在C语言中用<code>unsigned</code>进行声明，一般来说<code>int</code>表示有符号整形，<code>uintb</code>表示无符号整形 （与C语言不同，Java没有无符号数）</p>\n<p><strong>无符号数编码唯一性</strong>：在计算机系统中无符号数的编码具有唯一性，比如无符号数<code>10</code>的二进制编码是<code>1010</code>，那么可以断言<code>1010</code>这个编码如果表示的是一个无符号数的话，那它对应的十进制就只能是<code>10</code></p>\n<h4 id=\"有符号数\"><a href=\"#有符号数\" class=\"headerlink\" title=\"有符号数\"></a>有符号数</h4><p>学习有符号数前需要先了解<code>补码编码</code></p>\n<h5 id=\"补码编码\"><a href=\"#补码编码\" class=\"headerlink\" title=\"补码编码\"></a>补码编码</h5><p><code>补码</code>是计算机系统中表示负数必不可少的编码手段，通过补码表示的数字的最高有效位是符号位，为0则表示正数，为1则表示负数，例如二进制数<code>1101</code>中，高位的1表示该数是一个负数，通过剩下三位可以计算出该负数的绝对值是3，则该补码编码对应的十进制数是<code>-3</code></p>\n<p><strong>补码转换为十进制有符号数</strong>：以下是换算补码二进制数到十进制数的两种方式：</p>\n<p><code>权重法</code>：换算方式与无符号二进制转十进制的方式类似，不过高位符号位需要取负号：</p>\n<p>$$<br>1011: -1 <em> 2^3 + 0 </em> 2^2 + 1 <em> 2^1 + 1 </em> 2^0 = -5<br>$$</p>\n<p>$$<br>0101: 0 <em> 2^3 + 1 </em> 2^2 + 0 <em> 2^1 + 1 </em> 2^0 = 5<br>$$</p>\n<p><code>取反法</code>：判断最高有效位，如果最高位为0，则为正数，计算方式与无符号数一致，如果为1，则为负数，将最高位去掉，剩余位减去1后各位再取反，得到的二进制编码则是该负数的绝对值，比如上述例子中的<code>1011</code>去掉最高位后未<code>011</code>，减去1后为<code>010</code>，全部取反后为<code>101</code>，转换为十进制为<code>5</code>，则该负数是<code>-5</code></p>\n<p><strong>十进制有符号数转换为补码</strong>: 相应的，将十进制负数<code>-5</code>转换为补码形式<code>1011</code>就有以下方式</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 绝对值转换为二进制： 101</span><br><span class=\"line\"># 二进制位全部取反： 010</span><br><span class=\"line\"># 加1： 011</span><br><span class=\"line\"># 加上符号位： 1011</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>第二章<code>信息的表示和处理</code></p>\n<p>本章主要是对信息在计算机系统上的表示和存储进行了详细的介绍，包括二进制位的相关知识以及整数和浮点数的存储和计算等知识</p>","more":"<p>目录：</p>\n<ul>\n<li>信息存储</li>\n<li>整数表示</li>\n<li>整数运算</li>\n<li>浮点</li>\n</ul>\n<h3 id=\"1-信息的存储\"><a href=\"#1-信息的存储\" class=\"headerlink\" title=\"1. 信息的存储\"></a>1. 信息的存储</h3><p><strong>字节</strong>：大多数计算机都使用<code>字节</code>(byte)作为系统中最小内存单位，内存就可以看作一个巨大的byte数组</p>\n<p><strong>虚拟地址空间</strong>：操作系统为程序提供<code>虚拟内存</code>(virtual memory)这一概念屏蔽了底层存储系统的复杂性，其中虚拟内存中每个字节都有自己的地址，也就是<code>虚拟地址</code>(virtual address)，虚拟内存中所有可能地址的集合就是<code>虚拟地址空间</code>(virtual address space)，C语言中某个指针的值就是某个存储块第一个字节的虚拟地址</p>\n<blockquote>\n<p>指针：C语言的重要特性，有<code>值</code>和<code>类型</code>两个属性，<code>值</code>是某个对象的虚拟地址，<code>类型</code>是表示那个位置上存储对象的类型</p>\n</blockquote>\n<h4 id=\"十六进制\"><a href=\"#十六进制\" class=\"headerlink\" title=\"十六进制\"></a>十六进制</h4><p>一个字节是8位，表示成二进制是<code>00000000 ~ 11111111</code>，表示成十进制的范围是<code>0 ~ 255</code>，表示成十六进制是<code>00 ~ FF</code>，很明显十六进制的表示方式更加简洁易用，计算机系统中通常以<code>0x</code>开头表示一个以十六进制展现的内存地址</p>\n<h4 id=\"字长\"><a href=\"#字长\" class=\"headerlink\" title=\"字长\"></a>字长</h4><p>所谓<code>字长</code>，就是指针携带的地址值的标称大小，32位字长的机器其虚拟地址范围就是0 ~ 2^32^（最大虚拟地址值是2^32^-1，也就是说32位字长的系统虚拟地址空间大小就是4GB），64位字长的机器其虚拟地址范围就是0 ~ 2^64^（16EB）</p>\n<blockquote>\n<p>向后兼容：64位机器可以运行32位机器编译的程序，但32位机器无法运行64位机器编译的程序</p>\n</blockquote>\n<h4 id=\"寻址\"><a href=\"#寻址\" class=\"headerlink\" title=\"寻址\"></a>寻址</h4><p>一个对象在内存中是以连续的字节序列的形式存储的，对象的地址就是这段字节序列中最低位置的地址值</p>\n<p>对象字节序列中，开始位置的字节称为<code>最低有效位</code>，结束位置称为<code>最高有效位</code>，比如对于<code>0x01234567</code>这个int，最高有效位字节就是01，最低有效位字节是67</p>\n<h5 id=\"字节顺序\"><a href=\"#字节顺序\" class=\"headerlink\" title=\"字节顺序\"></a>字节顺序</h5><p>对象在内存中的字节序列是由一定的顺序进行保存的，保存对象字节序列的顺序就是字节顺序，有<code>大端法</code>和<code>小端法</code>两种：</p>\n<ul>\n<li>大端法：从最高有效位到最低有效位的顺序存储对象</li>\n<li>小端法：从最低有效位到最高有效位的顺序进行存储</li>\n</ul>\n<p><img src=\"http://img.mantian.site/201909041347_779.png\" alt></p>\n<p>如图，箭头方向就是地址顺序，左起是地址起始位置，大端法中最左侧是最高有效位字节，反之小端法中最左侧是最低有效位字节</p>\n<p>大多数Intel兼容机都是小端模式，IBM和Oracle的服务器使用大端模式，不过现在很多微处理器都是<code>双端模式</code>，兼容两种模式</p>\n<blockquote>\n<p>实战：使用c程序来展现不同的数据类型在内存中的字节表示</p>\n</blockquote>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\">//定义一个指向unsigned char的指针类型byte_pointer</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *byte_pointer;</span><br><span class=\"line\"><span class=\"comment\">//将某个unsigned char按照内存中的字节顺序打印出来</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">show_bytes</span><span class=\"params\">(byte_pointer start, <span class=\"keyword\">size_t</span> len)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">size_t</span> i;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; len; i++) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%.2x\"</span>, start[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//将某个int按照内存中的字节顺序打印出来</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">show_int</span><span class=\"params\">(<span class=\"keyword\">int</span> x)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//使用强制类型转换将int类指针转换为unsigned char指针</span></span><br><span class=\"line\">    show_bytes((byte_pointer)&amp;x, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">int</span>));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//将某个float按照内存中的字节顺序打印出来</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">show_float</span><span class=\"params\">(<span class=\"keyword\">float</span> x)</span> </span>&#123;</span><br><span class=\"line\">    show_bytes((byte_pointer)&amp;x, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//将某个指针数据按照内存中的字节顺序打印出来</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">show_pointer</span><span class=\"params\">(<span class=\"keyword\">void</span> *x)</span> </span>&#123;</span><br><span class=\"line\">    show_bytes((byte_pointer)&amp;x, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">void</span> *));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> c = <span class=\"string\">'h'</span>;</span><br><span class=\"line\">    byte_pointer start = &amp;c;</span><br><span class=\"line\">    show_bytes(start, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">char</span>));</span><br><span class=\"line\">    show_int(<span class=\"number\">1000</span>);</span><br><span class=\"line\">    show_float(<span class=\"number\">19.88f</span>);</span><br><span class=\"line\">    show_pointer(&amp;c);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>按照内存中的顺序将各个数据类型按照字节排列顺序进行打印，可以发现：</p>\n<p>show_bytes打印h字符结果为68，恰好就是Ascii码中h字符的字节表示</p>\n<p>show_int打印1000结果为e8030000，因为当前windows环境下是<strong>小端</strong>表示，高位在后，低位在前，忽略掉高位0后其值为3e8，也就是1000的16进制表示</p>\n<p>show_pointer打印char c指针的结果为47fe610000000000，忽略掉高位的0后就是0x61fe47，也说明64位环境下对象地址大小为8字节</p>\n<blockquote>\n<p>使用数组方式引用指针：</p>\n<p>上述例子中<code>start[i]</code>表示从start这个指针指向的内存起始位置，以数组的形式获取数据</p>\n</blockquote>\n<h6 id=\"字符串的字节顺序\"><a href=\"#字符串的字节顺序\" class=\"headerlink\" title=\"字符串的字节顺序\"></a>字符串的字节顺序</h6><p>字符串类型的字节顺序与其他类型稍有不同，在任意平台上字符串都是正序排列，如下：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">show_string</span><span class=\"params\">(<span class=\"keyword\">char</span> *str)</span> </span>&#123;</span><br><span class=\"line\">    show_bytes((byte_pointer)str, <span class=\"built_in\">strlen</span>(str));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> str[] = <span class=\"string\">\"hello\"</span>;</span><br><span class=\"line\">    show_string(&amp;str);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>结果为<code>68656c6c6f</code>，也就是”hello”的正序Ascii码序列，说明字符串类型具有良好的跨平台通用性</p>\n<h4 id=\"布尔代数\"><a href=\"#布尔代数\" class=\"headerlink\" title=\"布尔代数\"></a>布尔代数</h4><p>布尔运算在计算机系统中占有很重要的地位，在数值位运算中运用尤为广泛</p>\n<p>基本的布尔运算逻辑有四种<code>&amp;（与）</code>，<code>|（或）</code>，<code>~（非）</code>，<code>^（异或）</code>，四种布尔运算逻辑表格如下：</p>\n<p><img src=\"http://img.mantian.site/201909041553_177.png\" alt></p>\n<h5 id=\"位运算\"><a href=\"#位运算\" class=\"headerlink\" title=\"位运算\"></a>位运算</h5><p>布尔代数在计算机科学中一个很重要的运用就是位运算，C和Java等高级语言都支持位运算</p>\n<p>有以下程序，可以将x和y各自的地址相互对调：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">inplace_swap</span><span class=\"params\">(<span class=\"keyword\">int</span> *x, <span class=\"keyword\">int</span> *y)</span> </span>&#123;</span><br><span class=\"line\">    *y = *x ^ *y;</span><br><span class=\"line\">    *x = *x ^ *y;</span><br><span class=\"line\">    *y = *x ^ *y;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> x = <span class=\"number\">10</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> y = <span class=\"number\">9</span>;</span><br><span class=\"line\">    inplace_swap(&amp;x, &amp;y);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\n\"</span>, x);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\"</span>, y);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>打印结果显示x=9，y=10，因为我们通过三次异或运算将x和y的值进行了对调，由此产生了一些结论：</p>\n<ol>\n<li>异或运算中，任何值与0的异或结果还是它本身</li>\n<li>异或运算中，任何值与它自己的异或结果为0</li>\n<li>异或运算支持结合律</li>\n</ol>\n<p>通过以下函数可以将一个数组前后颠倒：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">reverse_array</span><span class=\"params\">(<span class=\"keyword\">int</span> a[], <span class=\"keyword\">int</span> count)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> first, last;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (first = <span class=\"number\">0</span>, last = count <span class=\"number\">-1</span>; first &lt; last; first++, last--) &#123;</span><br><span class=\"line\">        inplace_swap(&amp;a[first], &amp;a[last]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a[] = &#123;<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>&#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = <span class=\"keyword\">sizeof</span>(a) / <span class=\"keyword\">sizeof</span>(a[<span class=\"number\">0</span>]);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"size of array is %d\\n\"</span>, len);</span><br><span class=\"line\">    reverse_array(a, len);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\n\"</span>, a[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>打印结果是”6, 5, 4, 3, 2, 1”</p>\n<h5 id=\"逻辑运算符\"><a href=\"#逻辑运算符\" class=\"headerlink\" title=\"逻辑运算符\"></a>逻辑运算符</h5><p>逻辑运算符和位运算符功能相似，不过逻辑运算符针对Boolean类型，而位运算符仅仅对数字做二进制位运算</p>\n<h5 id=\"移位运算\"><a href=\"#移位运算\" class=\"headerlink\" title=\"移位运算\"></a>移位运算</h5><p>移位运算通常用于对数字的二进制位进行移动计算，具体的移位运算还包括<code>逻辑移位</code>和<code>算术移位</code>：</p>\n<p><img src=\"http://img.mantian.site/201909051029_959.png\" alt></p>\n<p>与<code>逻辑右移位</code>不同的是，<code>算术右移位</code>会在空出来的高位补足移位个数的最高有效位的值</p>\n<p>与C语言不同的是，Java中<code>&gt;&gt;</code>代表<code>算术右移位</code>，<code>&gt;&gt;&gt;</code>代表<code>逻辑右移位</code></p>\n<p><strong>注意</strong>：移位运算符的优先级低于加减法运算符</p>\n<h3 id=\"2-整数表示\"><a href=\"#2-整数表示\" class=\"headerlink\" title=\"2. 整数表示\"></a>2. 整数表示</h3><p>整数类型在32位机器和64位机器上的取值范围是不一样的，int类型都是4字节编码，long类型在32位机器上是4字节编码，在64位机器上是8字节编码，此外C语言规定int类型可以用2字节长度来编码，long字节可以用4字节长度来编码，我想这应该是为了兼容32位和64位的平台</p>\n<h4 id=\"无符号数\"><a href=\"#无符号数\" class=\"headerlink\" title=\"无符号数\"></a>无符号数</h4><p>无符号数是没有负数编码的数字，最小值为0，在C语言中用<code>unsigned</code>进行声明，一般来说<code>int</code>表示有符号整形，<code>uintb</code>表示无符号整形 （与C语言不同，Java没有无符号数）</p>\n<p><strong>无符号数编码唯一性</strong>：在计算机系统中无符号数的编码具有唯一性，比如无符号数<code>10</code>的二进制编码是<code>1010</code>，那么可以断言<code>1010</code>这个编码如果表示的是一个无符号数的话，那它对应的十进制就只能是<code>10</code></p>\n<h4 id=\"有符号数\"><a href=\"#有符号数\" class=\"headerlink\" title=\"有符号数\"></a>有符号数</h4><p>学习有符号数前需要先了解<code>补码编码</code></p>\n<h5 id=\"补码编码\"><a href=\"#补码编码\" class=\"headerlink\" title=\"补码编码\"></a>补码编码</h5><p><code>补码</code>是计算机系统中表示负数必不可少的编码手段，通过补码表示的数字的最高有效位是符号位，为0则表示正数，为1则表示负数，例如二进制数<code>1101</code>中，高位的1表示该数是一个负数，通过剩下三位可以计算出该负数的绝对值是3，则该补码编码对应的十进制数是<code>-3</code></p>\n<p><strong>补码转换为十进制有符号数</strong>：以下是换算补码二进制数到十进制数的两种方式：</p>\n<p><code>权重法</code>：换算方式与无符号二进制转十进制的方式类似，不过高位符号位需要取负号：</p>\n<p>$$<br>1011: -1 <em> 2^3 + 0 </em> 2^2 + 1 <em> 2^1 + 1 </em> 2^0 = -5<br>$$</p>\n<p>$$<br>0101: 0 <em> 2^3 + 1 </em> 2^2 + 0 <em> 2^1 + 1 </em> 2^0 = 5<br>$$</p>\n<p><code>取反法</code>：判断最高有效位，如果最高位为0，则为正数，计算方式与无符号数一致，如果为1，则为负数，将最高位去掉，剩余位减去1后各位再取反，得到的二进制编码则是该负数的绝对值，比如上述例子中的<code>1011</code>去掉最高位后未<code>011</code>，减去1后为<code>010</code>，全部取反后为<code>101</code>，转换为十进制为<code>5</code>，则该负数是<code>-5</code></p>\n<p><strong>十进制有符号数转换为补码</strong>: 相应的，将十进制负数<code>-5</code>转换为补码形式<code>1011</code>就有以下方式</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 绝对值转换为二进制： 101</span><br><span class=\"line\"># 二进制位全部取反： 010</span><br><span class=\"line\"># 加1： 011</span><br><span class=\"line\"># 加上符号位： 1011</span><br></pre></td></tr></table></figure>"},{"title":"RestTemplate学习","author":"天渊","date":"2019-01-21T03:18:00.000Z","_content":"`RestTemplate`是spring framework中对Http请求封装的一套方法，广泛运用于springboot和springcloud中的Http数据传输，官方文档描述如下：\n\n> `RestTemplate` is a synchronous client to perform HTTP requests. It is the original Spring REST client and exposes a simple, template-method API over underlying HTTP client libraries.\n\n<!-- more -->\n\n不过在spring 5.0发行版中推出了基于NIO的响应式Http客户端：`WebClient`，将在未来代替RestTemplate:\n\n> As of 5.0, the non-blocking, reactive `WebClient` offers a modern alternative to the `RestTemplate`, with efficient support for both synchronous and asynchronous, as well as streaming scenarios. The `RestTemplate` will be deprecated in a future version and will not have major new features added going forward.\n\n### RestTemplate的特点\n- 使用方便：可直接传递Java实体对象，无需人工配置ContentType和Charset，自动识别序列化方式和消息格式，无需用户自己encode url，并对多种http传输方法进行了相应封装\n\n- 可扩展性强：RestTemplate可配置多种底层通信框架如JDK HttpURLConnection、Apache HttpClient、OkHttp以及netty等\n\n- 可配置性强：用户可灵活多种第三方组件，除了底层通信框架，还可扩展配置消息转换器，异常处理器，uri模板解析器和请求拦截器等组件\n\n- RestTemplate的多种组件过于依赖spring-framework，如果脱离了spring环境，用起来就很不方便了\n\n\n\n# RestTemplate使用方法\n\n## 1. 初始化\nRestTemplate有两种初始化方式：`构造方法形式`，`RestTemplateBuilder形式`\n\n### 构造方法形式\n\n```java\n@Bean\npublic RestTemplate restTemplate(){\n\treturn new RestTemplate();\n}\n```\n\n\n\nRestTemplate有三种构造方法：\n\n- 无参数构造方法，也是使用得最普遍的一个：\n\n  ```java\n  public RestTemplate() {\n  \tthis.messageConverters.add(new ByteArrayHttpMessageConverter());\n  \tthis.messageConverters.add(new StringHttpMessageConverter());\n  \tthis.messageConverters.add(new ResourceHttpMessageConverter());\n  \tthis.messageConverters.add(new SourceHttpMessageConverter<Source>());\n  \tthis.messageConverters.add(new AllEncompassingFormHttpMessageConverter());\n  \tif (romePresent) {\n  \t\tthis.messageConverters.add(new AtomFeedHttpMessageConverter());\n  \t\tthis.messageConverters.add(new RssChannelHttpMessageConverter());\n  \t}\n  \tif (jaxb2Present) {\n  \t\tthis.messageConverters.add(new Jaxb2RootElementHttpMessageConverter());\n  \t}\n  \tif (jackson2Present) {\n  \t\tthis.messageConverters.add(new MappingJackson2HttpMessageConverter());\n  \t}\n  \telse if (jacksonPresent) {\n  \t\tthis.messageConverters.add(new MappingJacksonHttpMessageConverter());\n  \t}\n  }\n  ```\n\n  RestTemplate中内置了多种HttpMessageConverter，用于对不同场景下的输入输出流进行序列化和反序列化，无参数构造方法主要对HttpMessageConverter列表进行初始化\n\n- 有参数构造方法 — 初始化ClientHttpRequestFactory\n\n  ```java\n  public RestTemplate(ClientHttpRequestFactory requestFactory) {\n  \tthis();\n  \tsetRequestFactory(requestFactory);\n  }\n  ```\n\n  用户可以自己指定需要的ClientHttpRequestFactory，用于进行http连接和请求，默认是采用`SimpleClientHttpRequestFactory`，底层封装的是JDK的`HttpURLConnection`，用户可以指定其他种类的factory，比如以下几种：\n\n  - `BufferingClientHttpRequestFactory`：可在内存中建立输入数据的缓存\n\n  - `HttpComponentsClientHttpRequestFactory`：采用Apache的HttpClient进行远程调用，可以配置连接池和证书信息，不过需要在pom.xml中加入以下依赖：\n\n    ```xml\n    <dependency>\n        <groupId>org.apache.httpcomponents</groupId>\n        <artifactId>httpclient</artifactId>\n        <version>4.5.2</version>\n    </dependency>\n    ```\n\n  - `InterceptingClientHttpRequestFactory`：可以配置ClientHttpRequestInterceptor拦截器对http请求进行拦截处理，springcloud中的Ribbon就用到了这个factory用于将server name url转换为实际调用的url\n  - 基于Netty4的`Netty4ClientHttpRequestFactory`\n  - 基于OkHttp2的`OkHttpClientHttpRequestFactory`\n\n- 有参数构造方法 — 添加多个HttpMessageConverter\n\n  ```java\n  public RestTemplate(List<HttpMessageConverter<?>> messageConverters) {\n  \tAssert.notEmpty(messageConverters, \"'messageConverters' must not be empty\");\n  \tthis.messageConverters.addAll(messageConverters);\n  }\n  ```\n\n  如果用户觉得RestTemplate默认的几个序列化API无法满足要求，可以自己指定MessageConverter\n\n### RestTemplateBuilder形式\n如果用户要对RestTemplate进行多种初始化配置的话，推荐使用RestTemplateBuilder建造器，属于高级用法：\n  ```java\n    @Bean\n\tpublic RestTemplate myRestTemplate() {\n\t\tRestTemplateBuilder builder = new RestTemplateBuilder();\n\t\tRestTemplate restTemplate = builder\n            \t\t\t//配置ClientHttpRequestFactory\n\t\t\t\t\t\t.requestFactory(HttpComponentsClientHttpRequestFactory.class)\n            \t\t\t//配置MessageConverter\n\t\t\t\t\t\t.messageConverters(new MappingJackson2HttpMessageConverter())\n            \t\t\t//配置ResponseErrorHandler\n\t\t\t\t\t\t.errorHandler(new DefaultResponseErrorHandler())\n            \t\t\t//配置UriTemplateHandler\n\t\t\t\t\t\t.uriTemplateHandler(new DefaultUriTemplateHandler())\n            \t\t\t//配置连接超时时间和连接过期时间\n\t\t\t\t\t\t.setConnectTimeout(10000)\n\t\t\t\t\t\t.setReadTimeout(5000)\n\t\t\t\t\t\t.build();\n        return restTemplate;\n\t}\n  ```\n## 2. 执行Http请求\n\nRestTemplate对多种http method的请求进行了封装，用户可以直接进行使用\n\n- RestTemplate中几种常用的方法：\n\n| 方法名          | 描述                                                         |\n| --------------- | ------------------------------------------------------------ |\n| getForObject    | 通过get方法获取资源，返回用户指定的Object对象类型            |\n| getForEntity    | 通过get方法获取资源，返回一个封装好的HttpEntiry对象          |\n| postForObject   | 通过post方法发送Object对象，返回用户指定的Object对象类型     |\n| postForEntity   | 通过post方法发送Object对象，返回封装好的HttpEntiry对象       |\n| put             | 通过put方法上载资源                                          |\n| delete          | 通过delete方法删除服务器数据                                 |\n| optionsForAllow | 获取目的资源支持的method                                     |\n| exchange        | 一种比较通用的方法，接受的参数分别为url，method，response数据类型，url参数，以及一个封装了http header数据和body数据的HttpEntity对象，统一返回一个封装了所有response数据的ResponseEntity对象 |\n| execute         | 该方法是RestTemplate中通用性最强的方法，以上所有方法最终都调用的是execute方法，接受的参数包括RequestCallback对象（用于选择合适的MessageConverter对requestBody数据进行解析并将结果封装到ClientHttpRequest中，进行最终的http请求），以及ResponseExtractor对象（用于将response数据解析为用户需要的数据类型） |\n\n- get方法\n\n  发起get请求，如果只是想获取ResponseBody数据的话直接采用getForObject()的一系列重载方法：\n\n  - `Object`方式\n\n    将返回数据封装到指定的实体类CommonResponse中，RestTemplate会自动进行序列化和反序列化\n\n  ```java\n  CommonResponse response = restTemplate.getForObject(url, CommonResponse.class);\n  CommonResponse response = restTemplate.getForObject(url, CommonResponse.class, pathVariables);\n  ```\n\n\n  - `HttpEntity`方式\n\n    如果想获取更详细的数据（比如响应头和http状态码等信息）就使用getForEntity()\n\n  ```java\n  ResponseEntity<CommonResponse> responseEntity = restTemplate.getForEntity(url, CommonResponse.class, pathVariables);\n  CommonResponse responseBody = responseEntity.getBody();\n  HttpStatus status = responseEntity.getStatusCode();\n  HttpHeaders headers = responseEntity.getHeaders();\n  ```\n\n  ​\t跟Object方式类似，不过返回的结果数据封装到了一个ResponseEntity对象中\n\n  - 配置`queryParameters`和`pathVariables`\n\n    RestTemplate中没有为queryParameters设置对应的传参，需要用户自己将queryParameters写到url里面，不过RestTemplate为restful风格的pathVariables配置了专用的传参：\n\n    （看得出来RestTemplate专业服务于restful API调用）\n\n    ```java\n    url = \"http://127.0.0.1:8081/persons/{id}\"\n    Map<String, Object> urlVariables = new HashMap<>();\n    pathVariables.put(\"id\", \"0\");\n    CommonResponse response = restTemplate.getForObject(url, CommonResponse.class, pathVariables);\n    ```\n\n  - `UriTemplateHandler`（高级用法）\n\n    虽然RestTemplate中没有为queryParameters设置对应的传参，但是用户可以自己实现一个UriTemplateHandler：\n\n    ```java\n    public class QueryParamsUrlTemplateHandler extends DefaultUriTemplateHandler {\n    \n    @Override\n    public URI expand(String uriTemplate, Map<String, ?> params) {\n    \t\tUriComponentsBuilder componentsBuilder = UriComponentsBuilder.fromHttpUrl(uriTemplate);\n    \t\tfor(Map.Entry<String, ?> varEntry : params.entrySet()){\n    \t\t\tcomponentsBuilder.queryParam(varEntry.getKey(), varEntry.getValue());\n    \t\t}\n    \t\turiTemplate = componentsBuilder.build().toUriString();\n    \t\treturn super.expand(uriTemplate, params);\n    \t}\n    }\n    ```\n\n    ```java\n    restTemplate.setUriTemplateHandler(urlTemplateHandler);\n    ```\n\n    通过配置该UriTemplateHandler，就可以以Map的形式配置queryParameters了：\n\n    ```java\n    Map<String, Object> params = new HashMap<>();\n    params.put(\"name\", \"张三\");\n    ResponseEntity<CommonResponse> responseEntity = restTemplate.getForEntity(url, CommonResponse.class, params);\n    ```\n\n- post方法\n\n  发起post请求跟get很类似，唯一不同的地方在于需要设置`RequestBody`参数：\n\n  - `Object`方式：\n\n    无需自己设置contentType和charset，只需要直接传递实体对象作为RequestBody，RestTemplate会进行自动判断并选择合适的MeesageConverter\n\n  ```java\n  CommonResponse response = restTemplate.postForObject(url, person, CommonResponse.class);\n  ```\n\n  使用实体类Person封装上传数据，也可以直接使用Map封装数据\n\n  - `HttpEntity`方式\n\n    跟Object方式类似，request数据可以直接传递实体，也可以将请求头和请求体封装到一个HttpEntity对象中进行发送，返回数据都是ResponseEntity对象，可以取HttpStatus和HttpHeaders\n\n    ```java\n    //设置请求头\n    HttpHeaders headers = new HttpHeaders();\n    MediaType type = MediaType.parseMediaType(\"application/json; charset=UTF-8\");\n    headers.setContentType(type);\n    headers.set(\"headerName\", \"headerValue\");\n    //设置HttpEntity\n    HttpEntity<List<Person>> request = new HttpEntity<>(personList, headers);\n    //返回ResponseEntity对象，对Object实体数据进行封装\n    ResponseEntity<CommonResponse> response = restTemplate.postForEntity(url, request, CommonResponse.class);\n    ```\n\n  - post方法上传文件\n\n    上传文件需要用`MultiValueMap`进行文件数据的封装：\n\n  ```java\n  MultipartBodyBuilder builder = new MultipartBodyBuilder();\n  File file = new File(\"D:\\\\xxx\\\\xxx.png\");\n  builder.part(\"file\", new FileSystemResource(file));\n  MultiValueMap<String, Object> request = builder.build();\n  //上传文件\n  CommonResponse response = restTemplate.postForObject(url, request, CommonResponse.class)\n  ```\n\n- put和delete实现方式和上述方法都类似，不过这两种请求没有返回数据，不太实用\n\n  - 在RestTemplate中，对GET, POST, PUT, DELETE, OPTIONS, HEAD 这几种http方法都有相应的封装，如果不想用它封装好的方法，可以选择exchange()方法自定义http请求\n\n- exchange方法：\n\n  可以自己指定请求头和http method，其他的细节跟前面几种方法差不多\n\n  对于某些不太常见的方法（比如HEAD或者TRACE），就需要使用exchange()方法了， exchange()方法也有多种重载\n\n  以发起POST请求为例：\n\n  ```java\n  //设置requestBody数据\n  Person person = new Person();\n  //设置queryParameters和pathVariables\n  Map<String, Object> params = new HashMap<>();\n  params.put(\"name\", \"value\");\n  //设置请求头\n  HttpHeaders headers = new HttpHeaders();\n  MediaType type = MediaType.parseMediaType(\"application/json; charset=UTF-8\");\n  headers.setContentType(type);\n  headers.set(\"headerName\", \"headerValue\");\n  //配置requestEntity\n  HttpEntity<MyData> requestEntity = new HttpEntity(person, headers);\n  //发起请求\n  ResponseEntity<Map> responseEntity = restTemplate.exchange(url, HttpMethod.POST, requestEntity, Map.class, params);\n  ```\n\n- execute方法（一般不用）：\n\n  可以定制request和response的序列化和反序列化方式：\n\n  ```java\n  public <T> T execute(URI url, HttpMethod method, RequestCallback requestCallback,\n  \tResponseExtractor<T> responseExtractor) throws RestClientException {\n  \treturn doExecute(url, method, requestCallback, responseExtractor);\n  }\n  ```\n\n  - RequestCallback用于封装request信息，并对这部分信息进行解析\n  - ResponseExtractor用于对response返回数据进行解析\n\n  用户可以自由定制序列化方式，并以回调函数的形式传入execute()中；RestTemplate默认实现是两个静态内部类，默认选取RestTemplate中已经初始化完成的那部分HttpMessageConverter实现，进行序列化和反序列化操作\n\n\n\n## 3. 异常捕捉\n\nRestTemplate内部已经把http请求过程中会出现的各种异常，例如404或者500等异常，都包装为了RestClientException抛出\n\n在RestTemplate中进行异常处理的组件是`ResponseErrorHandler`，默认是`DefaultResponseErrorHandler`\n\n用户可以自己实现ResponseErrorHandler来处理http异常：\n\n```java\npublic class MyselfResponseErrorHandler extends DefaultResponseErrorHandler {\n\n\tprivate final Logger logger = LoggerFactory.getLogger(MyselfResponseErrorHandler.class);\n\n\t@Override\n\tpublic void handleError(ClientHttpResponse response) throws IOException {\n\t\tHttpStatus statusCode = getHttpStatusCode(response);\n\t\tString code = statusCode.toString();\n\t\tString msg = statusCode.getReasonPhrase();\n\t\tswitch (statusCode.series()) {\n\t\t\tcase CLIENT_ERROR:\n\t\t\t\tlogger.error(\"客户端请求错误，错误码：\" + code + \", 错误信息：\" + msg);\n\t\t\t\tbreak;\n\t\t\tcase SERVER_ERROR:\n\t\t\t\tlogger.error(\"服务器端错误，错误码：\" + code + \", 错误信息：\" + msg);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tlogger.error(\"不知道什么错误，错误码：\" + code + \", 错误信息：\" + msg);\n\t\t}\n\t}\n}\n```\n\n```java\nrestTemplate.setErrorHandler(responseErrorHandler);\n```\n\n\n\n# RestTemplate内部源码分析\n\n## doExecute方法\n\n\n以上所有方法都有一个最终方法，也是RestTemplate的核心方法：doExecute()\n\n```java\n\tprotected <T> T doExecute(URI url, HttpMethod method, RequestCallback requestCallback,\n\t\t\tResponseExtractor<T> responseExtractor) throws RestClientException {\n\t\t//url和method都不能为空\n\t\tAssert.notNull(url, \"'url' must not be null\");\n\t\tAssert.notNull(method, \"'method' must not be null\");\n\t\tClientHttpResponse response = null;\n\t\ttry {\n            //使用ClientHttpRequestFactory创建一个ClientHttpRequest对象\n\t\t\tClientHttpRequest request = createRequest(url, method);\n\t\t\tif (requestCallback != null) {\n                //调用RequestCallback对象对requestBody数据进行解析\n                //序列化后的数据封装到ClientHttpRequest对象中\n\t\t\t\trequestCallback.doWithRequest(request);\n\t\t\t}\n            //ClientHttpRequest对象执行http请求得到ClientHttpResponse对象\n\t\t\tresponse = request.execute();\n\t\t\tif (!getErrorHandler().hasError(response)) {\n\t\t\t\tlogResponseStatus(method, url, response);\n\t\t\t}\n\t\t\telse {\n\t\t\t\thandleResponseError(method, url, response);\n\t\t\t}\n\t\t\tif (responseExtractor != null) {\n                //将ClientHttpResponse对象反序列化为用户指定的数据类型\n\t\t\t\treturn responseExtractor.extractData(response);\n\t\t\t}\n\t\t\telse {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t\tcatch (IOException ex) {\n\t\t\tthrow new ResourceAccessException(\"I/O error on \" + method.name() +\n\t\t\t\t\t\" request for \\\"\" + url + \"\\\": \" + ex.getMessage(), ex);\n\t\t}\n\t\tfinally {\n\t\t\tif (response != null) {\n\t\t\t\tresponse.close();\n\t\t\t}\n\t\t}\n\t}\n```\n\n可以看出，实际执行http请求的是ClientHttpRequest，用户可以通过设置不同的ClientHttpRequestFactory自己定制http连接方式，例如HttpComponentsClientHttpRequestFactory就是基于Apache HttpClient实现：\n\n```java\n//需要将HttpComponentsClientHttpRequestFactory暴露为spring bean，因为其实现了DisposableBean，可以在bean销毁后自动关闭连接池\n@Bean\npublic HttpComponentsClientHttpRequestFactory getFactory(){\n\tHttpComponentsClientHttpRequestFactory factory = new HttpComponentsClientHttpRequestFactory();\n    //设置socket请求连接超时时间\n\tfactory.setConnectTimeout(5000);\n    //设置socket读取数据阻塞超时时间\n\tfactory.setReadTimeout(5000);\n\treturn factory;\n}\n```\n\n\n\n## MessageConverter\n\n- 当调用不同的RestTemplate方法传输数据时，RestTemplate会自动检查ContentType并采用合适的MessageConverter进行序列化和反序列化，如果找不到合适的MessageConverter，将会报错\n\n- RestTemplate里面默认的几种MessageConverter已经能够满足大多数应用场景了\n\n| MessageConverter                    | 描述                                                         |\n| ----------------------------------- | ------------------------------------------------------------ |\n| StringHttpMessageConverter          | 支持文本类型的数据格式：text/plain，text/*                    |\n| FormHttpMessageConverter            | 支持表单类型的数据格式：application/x-www-form-urlencoded    |\n| MappingJackson2HttpMessageConverter | 支持json类型的数据格式：application/json                     |\n| ResourceHttpMessageConverter        | 可用于对Resource类型的文件io流进行序列化，并支持任意的MediaType |\n| BufferedImageHttpMessageConverter | 用于读取java.awt.image.BufferedImage格式的图片文件 |\n\n- 用户可以自己定义满足自己业务需求的MessageConverter\n\n\n\n# WebClient\n\nspring 5.0全面引入了reactive响应式编程模式，同时也就有了RestTemplate的reactive版：WebClient","source":"_posts/何为RestTemplate.md","raw":"title: RestTemplate学习\ntags:\n  - spring\n  - RestTemplate\n  - Java\ncategories:\n  - 基础知识\nauthor: 天渊\ndate: 2019-01-21 11:18:00\n---\n`RestTemplate`是spring framework中对Http请求封装的一套方法，广泛运用于springboot和springcloud中的Http数据传输，官方文档描述如下：\n\n> `RestTemplate` is a synchronous client to perform HTTP requests. It is the original Spring REST client and exposes a simple, template-method API over underlying HTTP client libraries.\n\n<!-- more -->\n\n不过在spring 5.0发行版中推出了基于NIO的响应式Http客户端：`WebClient`，将在未来代替RestTemplate:\n\n> As of 5.0, the non-blocking, reactive `WebClient` offers a modern alternative to the `RestTemplate`, with efficient support for both synchronous and asynchronous, as well as streaming scenarios. The `RestTemplate` will be deprecated in a future version and will not have major new features added going forward.\n\n### RestTemplate的特点\n- 使用方便：可直接传递Java实体对象，无需人工配置ContentType和Charset，自动识别序列化方式和消息格式，无需用户自己encode url，并对多种http传输方法进行了相应封装\n\n- 可扩展性强：RestTemplate可配置多种底层通信框架如JDK HttpURLConnection、Apache HttpClient、OkHttp以及netty等\n\n- 可配置性强：用户可灵活多种第三方组件，除了底层通信框架，还可扩展配置消息转换器，异常处理器，uri模板解析器和请求拦截器等组件\n\n- RestTemplate的多种组件过于依赖spring-framework，如果脱离了spring环境，用起来就很不方便了\n\n\n\n# RestTemplate使用方法\n\n## 1. 初始化\nRestTemplate有两种初始化方式：`构造方法形式`，`RestTemplateBuilder形式`\n\n### 构造方法形式\n\n```java\n@Bean\npublic RestTemplate restTemplate(){\n\treturn new RestTemplate();\n}\n```\n\n\n\nRestTemplate有三种构造方法：\n\n- 无参数构造方法，也是使用得最普遍的一个：\n\n  ```java\n  public RestTemplate() {\n  \tthis.messageConverters.add(new ByteArrayHttpMessageConverter());\n  \tthis.messageConverters.add(new StringHttpMessageConverter());\n  \tthis.messageConverters.add(new ResourceHttpMessageConverter());\n  \tthis.messageConverters.add(new SourceHttpMessageConverter<Source>());\n  \tthis.messageConverters.add(new AllEncompassingFormHttpMessageConverter());\n  \tif (romePresent) {\n  \t\tthis.messageConverters.add(new AtomFeedHttpMessageConverter());\n  \t\tthis.messageConverters.add(new RssChannelHttpMessageConverter());\n  \t}\n  \tif (jaxb2Present) {\n  \t\tthis.messageConverters.add(new Jaxb2RootElementHttpMessageConverter());\n  \t}\n  \tif (jackson2Present) {\n  \t\tthis.messageConverters.add(new MappingJackson2HttpMessageConverter());\n  \t}\n  \telse if (jacksonPresent) {\n  \t\tthis.messageConverters.add(new MappingJacksonHttpMessageConverter());\n  \t}\n  }\n  ```\n\n  RestTemplate中内置了多种HttpMessageConverter，用于对不同场景下的输入输出流进行序列化和反序列化，无参数构造方法主要对HttpMessageConverter列表进行初始化\n\n- 有参数构造方法 — 初始化ClientHttpRequestFactory\n\n  ```java\n  public RestTemplate(ClientHttpRequestFactory requestFactory) {\n  \tthis();\n  \tsetRequestFactory(requestFactory);\n  }\n  ```\n\n  用户可以自己指定需要的ClientHttpRequestFactory，用于进行http连接和请求，默认是采用`SimpleClientHttpRequestFactory`，底层封装的是JDK的`HttpURLConnection`，用户可以指定其他种类的factory，比如以下几种：\n\n  - `BufferingClientHttpRequestFactory`：可在内存中建立输入数据的缓存\n\n  - `HttpComponentsClientHttpRequestFactory`：采用Apache的HttpClient进行远程调用，可以配置连接池和证书信息，不过需要在pom.xml中加入以下依赖：\n\n    ```xml\n    <dependency>\n        <groupId>org.apache.httpcomponents</groupId>\n        <artifactId>httpclient</artifactId>\n        <version>4.5.2</version>\n    </dependency>\n    ```\n\n  - `InterceptingClientHttpRequestFactory`：可以配置ClientHttpRequestInterceptor拦截器对http请求进行拦截处理，springcloud中的Ribbon就用到了这个factory用于将server name url转换为实际调用的url\n  - 基于Netty4的`Netty4ClientHttpRequestFactory`\n  - 基于OkHttp2的`OkHttpClientHttpRequestFactory`\n\n- 有参数构造方法 — 添加多个HttpMessageConverter\n\n  ```java\n  public RestTemplate(List<HttpMessageConverter<?>> messageConverters) {\n  \tAssert.notEmpty(messageConverters, \"'messageConverters' must not be empty\");\n  \tthis.messageConverters.addAll(messageConverters);\n  }\n  ```\n\n  如果用户觉得RestTemplate默认的几个序列化API无法满足要求，可以自己指定MessageConverter\n\n### RestTemplateBuilder形式\n如果用户要对RestTemplate进行多种初始化配置的话，推荐使用RestTemplateBuilder建造器，属于高级用法：\n  ```java\n    @Bean\n\tpublic RestTemplate myRestTemplate() {\n\t\tRestTemplateBuilder builder = new RestTemplateBuilder();\n\t\tRestTemplate restTemplate = builder\n            \t\t\t//配置ClientHttpRequestFactory\n\t\t\t\t\t\t.requestFactory(HttpComponentsClientHttpRequestFactory.class)\n            \t\t\t//配置MessageConverter\n\t\t\t\t\t\t.messageConverters(new MappingJackson2HttpMessageConverter())\n            \t\t\t//配置ResponseErrorHandler\n\t\t\t\t\t\t.errorHandler(new DefaultResponseErrorHandler())\n            \t\t\t//配置UriTemplateHandler\n\t\t\t\t\t\t.uriTemplateHandler(new DefaultUriTemplateHandler())\n            \t\t\t//配置连接超时时间和连接过期时间\n\t\t\t\t\t\t.setConnectTimeout(10000)\n\t\t\t\t\t\t.setReadTimeout(5000)\n\t\t\t\t\t\t.build();\n        return restTemplate;\n\t}\n  ```\n## 2. 执行Http请求\n\nRestTemplate对多种http method的请求进行了封装，用户可以直接进行使用\n\n- RestTemplate中几种常用的方法：\n\n| 方法名          | 描述                                                         |\n| --------------- | ------------------------------------------------------------ |\n| getForObject    | 通过get方法获取资源，返回用户指定的Object对象类型            |\n| getForEntity    | 通过get方法获取资源，返回一个封装好的HttpEntiry对象          |\n| postForObject   | 通过post方法发送Object对象，返回用户指定的Object对象类型     |\n| postForEntity   | 通过post方法发送Object对象，返回封装好的HttpEntiry对象       |\n| put             | 通过put方法上载资源                                          |\n| delete          | 通过delete方法删除服务器数据                                 |\n| optionsForAllow | 获取目的资源支持的method                                     |\n| exchange        | 一种比较通用的方法，接受的参数分别为url，method，response数据类型，url参数，以及一个封装了http header数据和body数据的HttpEntity对象，统一返回一个封装了所有response数据的ResponseEntity对象 |\n| execute         | 该方法是RestTemplate中通用性最强的方法，以上所有方法最终都调用的是execute方法，接受的参数包括RequestCallback对象（用于选择合适的MessageConverter对requestBody数据进行解析并将结果封装到ClientHttpRequest中，进行最终的http请求），以及ResponseExtractor对象（用于将response数据解析为用户需要的数据类型） |\n\n- get方法\n\n  发起get请求，如果只是想获取ResponseBody数据的话直接采用getForObject()的一系列重载方法：\n\n  - `Object`方式\n\n    将返回数据封装到指定的实体类CommonResponse中，RestTemplate会自动进行序列化和反序列化\n\n  ```java\n  CommonResponse response = restTemplate.getForObject(url, CommonResponse.class);\n  CommonResponse response = restTemplate.getForObject(url, CommonResponse.class, pathVariables);\n  ```\n\n\n  - `HttpEntity`方式\n\n    如果想获取更详细的数据（比如响应头和http状态码等信息）就使用getForEntity()\n\n  ```java\n  ResponseEntity<CommonResponse> responseEntity = restTemplate.getForEntity(url, CommonResponse.class, pathVariables);\n  CommonResponse responseBody = responseEntity.getBody();\n  HttpStatus status = responseEntity.getStatusCode();\n  HttpHeaders headers = responseEntity.getHeaders();\n  ```\n\n  ​\t跟Object方式类似，不过返回的结果数据封装到了一个ResponseEntity对象中\n\n  - 配置`queryParameters`和`pathVariables`\n\n    RestTemplate中没有为queryParameters设置对应的传参，需要用户自己将queryParameters写到url里面，不过RestTemplate为restful风格的pathVariables配置了专用的传参：\n\n    （看得出来RestTemplate专业服务于restful API调用）\n\n    ```java\n    url = \"http://127.0.0.1:8081/persons/{id}\"\n    Map<String, Object> urlVariables = new HashMap<>();\n    pathVariables.put(\"id\", \"0\");\n    CommonResponse response = restTemplate.getForObject(url, CommonResponse.class, pathVariables);\n    ```\n\n  - `UriTemplateHandler`（高级用法）\n\n    虽然RestTemplate中没有为queryParameters设置对应的传参，但是用户可以自己实现一个UriTemplateHandler：\n\n    ```java\n    public class QueryParamsUrlTemplateHandler extends DefaultUriTemplateHandler {\n    \n    @Override\n    public URI expand(String uriTemplate, Map<String, ?> params) {\n    \t\tUriComponentsBuilder componentsBuilder = UriComponentsBuilder.fromHttpUrl(uriTemplate);\n    \t\tfor(Map.Entry<String, ?> varEntry : params.entrySet()){\n    \t\t\tcomponentsBuilder.queryParam(varEntry.getKey(), varEntry.getValue());\n    \t\t}\n    \t\turiTemplate = componentsBuilder.build().toUriString();\n    \t\treturn super.expand(uriTemplate, params);\n    \t}\n    }\n    ```\n\n    ```java\n    restTemplate.setUriTemplateHandler(urlTemplateHandler);\n    ```\n\n    通过配置该UriTemplateHandler，就可以以Map的形式配置queryParameters了：\n\n    ```java\n    Map<String, Object> params = new HashMap<>();\n    params.put(\"name\", \"张三\");\n    ResponseEntity<CommonResponse> responseEntity = restTemplate.getForEntity(url, CommonResponse.class, params);\n    ```\n\n- post方法\n\n  发起post请求跟get很类似，唯一不同的地方在于需要设置`RequestBody`参数：\n\n  - `Object`方式：\n\n    无需自己设置contentType和charset，只需要直接传递实体对象作为RequestBody，RestTemplate会进行自动判断并选择合适的MeesageConverter\n\n  ```java\n  CommonResponse response = restTemplate.postForObject(url, person, CommonResponse.class);\n  ```\n\n  使用实体类Person封装上传数据，也可以直接使用Map封装数据\n\n  - `HttpEntity`方式\n\n    跟Object方式类似，request数据可以直接传递实体，也可以将请求头和请求体封装到一个HttpEntity对象中进行发送，返回数据都是ResponseEntity对象，可以取HttpStatus和HttpHeaders\n\n    ```java\n    //设置请求头\n    HttpHeaders headers = new HttpHeaders();\n    MediaType type = MediaType.parseMediaType(\"application/json; charset=UTF-8\");\n    headers.setContentType(type);\n    headers.set(\"headerName\", \"headerValue\");\n    //设置HttpEntity\n    HttpEntity<List<Person>> request = new HttpEntity<>(personList, headers);\n    //返回ResponseEntity对象，对Object实体数据进行封装\n    ResponseEntity<CommonResponse> response = restTemplate.postForEntity(url, request, CommonResponse.class);\n    ```\n\n  - post方法上传文件\n\n    上传文件需要用`MultiValueMap`进行文件数据的封装：\n\n  ```java\n  MultipartBodyBuilder builder = new MultipartBodyBuilder();\n  File file = new File(\"D:\\\\xxx\\\\xxx.png\");\n  builder.part(\"file\", new FileSystemResource(file));\n  MultiValueMap<String, Object> request = builder.build();\n  //上传文件\n  CommonResponse response = restTemplate.postForObject(url, request, CommonResponse.class)\n  ```\n\n- put和delete实现方式和上述方法都类似，不过这两种请求没有返回数据，不太实用\n\n  - 在RestTemplate中，对GET, POST, PUT, DELETE, OPTIONS, HEAD 这几种http方法都有相应的封装，如果不想用它封装好的方法，可以选择exchange()方法自定义http请求\n\n- exchange方法：\n\n  可以自己指定请求头和http method，其他的细节跟前面几种方法差不多\n\n  对于某些不太常见的方法（比如HEAD或者TRACE），就需要使用exchange()方法了， exchange()方法也有多种重载\n\n  以发起POST请求为例：\n\n  ```java\n  //设置requestBody数据\n  Person person = new Person();\n  //设置queryParameters和pathVariables\n  Map<String, Object> params = new HashMap<>();\n  params.put(\"name\", \"value\");\n  //设置请求头\n  HttpHeaders headers = new HttpHeaders();\n  MediaType type = MediaType.parseMediaType(\"application/json; charset=UTF-8\");\n  headers.setContentType(type);\n  headers.set(\"headerName\", \"headerValue\");\n  //配置requestEntity\n  HttpEntity<MyData> requestEntity = new HttpEntity(person, headers);\n  //发起请求\n  ResponseEntity<Map> responseEntity = restTemplate.exchange(url, HttpMethod.POST, requestEntity, Map.class, params);\n  ```\n\n- execute方法（一般不用）：\n\n  可以定制request和response的序列化和反序列化方式：\n\n  ```java\n  public <T> T execute(URI url, HttpMethod method, RequestCallback requestCallback,\n  \tResponseExtractor<T> responseExtractor) throws RestClientException {\n  \treturn doExecute(url, method, requestCallback, responseExtractor);\n  }\n  ```\n\n  - RequestCallback用于封装request信息，并对这部分信息进行解析\n  - ResponseExtractor用于对response返回数据进行解析\n\n  用户可以自由定制序列化方式，并以回调函数的形式传入execute()中；RestTemplate默认实现是两个静态内部类，默认选取RestTemplate中已经初始化完成的那部分HttpMessageConverter实现，进行序列化和反序列化操作\n\n\n\n## 3. 异常捕捉\n\nRestTemplate内部已经把http请求过程中会出现的各种异常，例如404或者500等异常，都包装为了RestClientException抛出\n\n在RestTemplate中进行异常处理的组件是`ResponseErrorHandler`，默认是`DefaultResponseErrorHandler`\n\n用户可以自己实现ResponseErrorHandler来处理http异常：\n\n```java\npublic class MyselfResponseErrorHandler extends DefaultResponseErrorHandler {\n\n\tprivate final Logger logger = LoggerFactory.getLogger(MyselfResponseErrorHandler.class);\n\n\t@Override\n\tpublic void handleError(ClientHttpResponse response) throws IOException {\n\t\tHttpStatus statusCode = getHttpStatusCode(response);\n\t\tString code = statusCode.toString();\n\t\tString msg = statusCode.getReasonPhrase();\n\t\tswitch (statusCode.series()) {\n\t\t\tcase CLIENT_ERROR:\n\t\t\t\tlogger.error(\"客户端请求错误，错误码：\" + code + \", 错误信息：\" + msg);\n\t\t\t\tbreak;\n\t\t\tcase SERVER_ERROR:\n\t\t\t\tlogger.error(\"服务器端错误，错误码：\" + code + \", 错误信息：\" + msg);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tlogger.error(\"不知道什么错误，错误码：\" + code + \", 错误信息：\" + msg);\n\t\t}\n\t}\n}\n```\n\n```java\nrestTemplate.setErrorHandler(responseErrorHandler);\n```\n\n\n\n# RestTemplate内部源码分析\n\n## doExecute方法\n\n\n以上所有方法都有一个最终方法，也是RestTemplate的核心方法：doExecute()\n\n```java\n\tprotected <T> T doExecute(URI url, HttpMethod method, RequestCallback requestCallback,\n\t\t\tResponseExtractor<T> responseExtractor) throws RestClientException {\n\t\t//url和method都不能为空\n\t\tAssert.notNull(url, \"'url' must not be null\");\n\t\tAssert.notNull(method, \"'method' must not be null\");\n\t\tClientHttpResponse response = null;\n\t\ttry {\n            //使用ClientHttpRequestFactory创建一个ClientHttpRequest对象\n\t\t\tClientHttpRequest request = createRequest(url, method);\n\t\t\tif (requestCallback != null) {\n                //调用RequestCallback对象对requestBody数据进行解析\n                //序列化后的数据封装到ClientHttpRequest对象中\n\t\t\t\trequestCallback.doWithRequest(request);\n\t\t\t}\n            //ClientHttpRequest对象执行http请求得到ClientHttpResponse对象\n\t\t\tresponse = request.execute();\n\t\t\tif (!getErrorHandler().hasError(response)) {\n\t\t\t\tlogResponseStatus(method, url, response);\n\t\t\t}\n\t\t\telse {\n\t\t\t\thandleResponseError(method, url, response);\n\t\t\t}\n\t\t\tif (responseExtractor != null) {\n                //将ClientHttpResponse对象反序列化为用户指定的数据类型\n\t\t\t\treturn responseExtractor.extractData(response);\n\t\t\t}\n\t\t\telse {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t\tcatch (IOException ex) {\n\t\t\tthrow new ResourceAccessException(\"I/O error on \" + method.name() +\n\t\t\t\t\t\" request for \\\"\" + url + \"\\\": \" + ex.getMessage(), ex);\n\t\t}\n\t\tfinally {\n\t\t\tif (response != null) {\n\t\t\t\tresponse.close();\n\t\t\t}\n\t\t}\n\t}\n```\n\n可以看出，实际执行http请求的是ClientHttpRequest，用户可以通过设置不同的ClientHttpRequestFactory自己定制http连接方式，例如HttpComponentsClientHttpRequestFactory就是基于Apache HttpClient实现：\n\n```java\n//需要将HttpComponentsClientHttpRequestFactory暴露为spring bean，因为其实现了DisposableBean，可以在bean销毁后自动关闭连接池\n@Bean\npublic HttpComponentsClientHttpRequestFactory getFactory(){\n\tHttpComponentsClientHttpRequestFactory factory = new HttpComponentsClientHttpRequestFactory();\n    //设置socket请求连接超时时间\n\tfactory.setConnectTimeout(5000);\n    //设置socket读取数据阻塞超时时间\n\tfactory.setReadTimeout(5000);\n\treturn factory;\n}\n```\n\n\n\n## MessageConverter\n\n- 当调用不同的RestTemplate方法传输数据时，RestTemplate会自动检查ContentType并采用合适的MessageConverter进行序列化和反序列化，如果找不到合适的MessageConverter，将会报错\n\n- RestTemplate里面默认的几种MessageConverter已经能够满足大多数应用场景了\n\n| MessageConverter                    | 描述                                                         |\n| ----------------------------------- | ------------------------------------------------------------ |\n| StringHttpMessageConverter          | 支持文本类型的数据格式：text/plain，text/*                    |\n| FormHttpMessageConverter            | 支持表单类型的数据格式：application/x-www-form-urlencoded    |\n| MappingJackson2HttpMessageConverter | 支持json类型的数据格式：application/json                     |\n| ResourceHttpMessageConverter        | 可用于对Resource类型的文件io流进行序列化，并支持任意的MediaType |\n| BufferedImageHttpMessageConverter | 用于读取java.awt.image.BufferedImage格式的图片文件 |\n\n- 用户可以自己定义满足自己业务需求的MessageConverter\n\n\n\n# WebClient\n\nspring 5.0全面引入了reactive响应式编程模式，同时也就有了RestTemplate的reactive版：WebClient","slug":"何为RestTemplate","published":1,"updated":"2021-05-31T03:06:33.202Z","_id":"ckf0h31is002xactsub83f5ja","comments":1,"layout":"post","photos":[],"link":"","content":"<p><code>RestTemplate</code>是spring framework中对Http请求封装的一套方法，广泛运用于springboot和springcloud中的Http数据传输，官方文档描述如下：</p>\n<blockquote>\n<p><code>RestTemplate</code> is a synchronous client to perform HTTP requests. It is the original Spring REST client and exposes a simple, template-method API over underlying HTTP client libraries.</p>\n</blockquote>\n<a id=\"more\"></a>\n<p>不过在spring 5.0发行版中推出了基于NIO的响应式Http客户端：<code>WebClient</code>，将在未来代替RestTemplate:</p>\n<blockquote>\n<p>As of 5.0, the non-blocking, reactive <code>WebClient</code> offers a modern alternative to the <code>RestTemplate</code>, with efficient support for both synchronous and asynchronous, as well as streaming scenarios. The <code>RestTemplate</code> will be deprecated in a future version and will not have major new features added going forward.</p>\n</blockquote>\n<h3 id=\"RestTemplate的特点\"><a href=\"#RestTemplate的特点\" class=\"headerlink\" title=\"RestTemplate的特点\"></a>RestTemplate的特点</h3><ul>\n<li><p>使用方便：可直接传递Java实体对象，无需人工配置ContentType和Charset，自动识别序列化方式和消息格式，无需用户自己encode url，并对多种http传输方法进行了相应封装</p>\n</li>\n<li><p>可扩展性强：RestTemplate可配置多种底层通信框架如JDK HttpURLConnection、Apache HttpClient、OkHttp以及netty等</p>\n</li>\n<li><p>可配置性强：用户可灵活多种第三方组件，除了底层通信框架，还可扩展配置消息转换器，异常处理器，uri模板解析器和请求拦截器等组件</p>\n</li>\n<li><p>RestTemplate的多种组件过于依赖spring-framework，如果脱离了spring环境，用起来就很不方便了</p>\n</li>\n</ul>\n<h1 id=\"RestTemplate使用方法\"><a href=\"#RestTemplate使用方法\" class=\"headerlink\" title=\"RestTemplate使用方法\"></a>RestTemplate使用方法</h1><h2 id=\"1-初始化\"><a href=\"#1-初始化\" class=\"headerlink\" title=\"1. 初始化\"></a>1. 初始化</h2><p>RestTemplate有两种初始化方式：<code>构造方法形式</code>，<code>RestTemplateBuilder形式</code></p>\n<h3 id=\"构造方法形式\"><a href=\"#构造方法形式\" class=\"headerlink\" title=\"构造方法形式\"></a>构造方法形式</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Bean</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> RestTemplate <span class=\"title\">restTemplate</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"keyword\">new</span> RestTemplate();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>RestTemplate有三种构造方法：</p>\n<ul>\n<li><p>无参数构造方法，也是使用得最普遍的一个：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">RestTemplate</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> ByteArrayHttpMessageConverter());</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> StringHttpMessageConverter());</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> ResourceHttpMessageConverter());</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> SourceHttpMessageConverter&lt;Source&gt;());</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> AllEncompassingFormHttpMessageConverter());</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (romePresent) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> AtomFeedHttpMessageConverter());</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> RssChannelHttpMessageConverter());</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (jaxb2Present) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> Jaxb2RootElementHttpMessageConverter());</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (jackson2Present) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> MappingJackson2HttpMessageConverter());</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (jacksonPresent) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> MappingJacksonHttpMessageConverter());</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>RestTemplate中内置了多种HttpMessageConverter，用于对不同场景下的输入输出流进行序列化和反序列化，无参数构造方法主要对HttpMessageConverter列表进行初始化</p>\n</li>\n<li><p>有参数构造方法 — 初始化ClientHttpRequestFactory</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">RestTemplate</span><span class=\"params\">(ClientHttpRequestFactory requestFactory)</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>();</span><br><span class=\"line\">\tsetRequestFactory(requestFactory);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>用户可以自己指定需要的ClientHttpRequestFactory，用于进行http连接和请求，默认是采用<code>SimpleClientHttpRequestFactory</code>，底层封装的是JDK的<code>HttpURLConnection</code>，用户可以指定其他种类的factory，比如以下几种：</p>\n<ul>\n<li><p><code>BufferingClientHttpRequestFactory</code>：可在内存中建立输入数据的缓存</p>\n</li>\n<li><p><code>HttpComponentsClientHttpRequestFactory</code>：采用Apache的HttpClient进行远程调用，可以配置连接池和证书信息，不过需要在pom.xml中加入以下依赖：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.httpcomponents<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>httpclient<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>4.5.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>InterceptingClientHttpRequestFactory</code>：可以配置ClientHttpRequestInterceptor拦截器对http请求进行拦截处理，springcloud中的Ribbon就用到了这个factory用于将server name url转换为实际调用的url</p>\n</li>\n<li>基于Netty4的<code>Netty4ClientHttpRequestFactory</code></li>\n<li>基于OkHttp2的<code>OkHttpClientHttpRequestFactory</code></li>\n</ul>\n</li>\n<li><p>有参数构造方法 — 添加多个HttpMessageConverter</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">RestTemplate</span><span class=\"params\">(List&lt;HttpMessageConverter&lt;?&gt;&gt; messageConverters)</span> </span>&#123;</span><br><span class=\"line\">\tAssert.notEmpty(messageConverters, <span class=\"string\">\"'messageConverters' must not be empty\"</span>);</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.messageConverters.addAll(messageConverters);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如果用户觉得RestTemplate默认的几个序列化API无法满足要求，可以自己指定MessageConverter</p>\n</li>\n</ul>\n<h3 id=\"RestTemplateBuilder形式\"><a href=\"#RestTemplateBuilder形式\" class=\"headerlink\" title=\"RestTemplateBuilder形式\"></a>RestTemplateBuilder形式</h3><p>如果用户要对RestTemplate进行多种初始化配置的话，推荐使用RestTemplateBuilder建造器，属于高级用法：<br>  <figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">   <span class=\"meta\">@Bean</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> RestTemplate <span class=\"title\">myRestTemplate</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\tRestTemplateBuilder builder = <span class=\"keyword\">new</span> RestTemplateBuilder();</span><br><span class=\"line\">\tRestTemplate restTemplate = builder</span><br><span class=\"line\">           \t\t\t<span class=\"comment\">//配置ClientHttpRequestFactory</span></span><br><span class=\"line\">\t\t\t\t\t.requestFactory(HttpComponentsClientHttpRequestFactory.class)</span><br><span class=\"line\">           \t\t\t<span class=\"comment\">//配置MessageConverter</span></span><br><span class=\"line\">\t\t\t\t\t.messageConverters(<span class=\"keyword\">new</span> MappingJackson2HttpMessageConverter())</span><br><span class=\"line\">           \t\t\t<span class=\"comment\">//配置ResponseErrorHandler</span></span><br><span class=\"line\">\t\t\t\t\t.errorHandler(<span class=\"keyword\">new</span> DefaultResponseErrorHandler())</span><br><span class=\"line\">           \t\t\t<span class=\"comment\">//配置UriTemplateHandler</span></span><br><span class=\"line\">\t\t\t\t\t.uriTemplateHandler(<span class=\"keyword\">new</span> DefaultUriTemplateHandler())</span><br><span class=\"line\">           \t\t\t<span class=\"comment\">//配置连接超时时间和连接过期时间</span></span><br><span class=\"line\">\t\t\t\t\t.setConnectTimeout(<span class=\"number\">10000</span>)</span><br><span class=\"line\">\t\t\t\t\t.setReadTimeout(<span class=\"number\">5000</span>)</span><br><span class=\"line\">\t\t\t\t\t.build();</span><br><span class=\"line\">       <span class=\"keyword\">return</span> restTemplate;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-执行Http请求\"><a href=\"#2-执行Http请求\" class=\"headerlink\" title=\"2. 执行Http请求\"></a>2. 执行Http请求</h2><p>RestTemplate对多种http method的请求进行了封装，用户可以直接进行使用</p>\n<ul>\n<li>RestTemplate中几种常用的方法：</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>方法名</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>getForObject</td>\n<td>通过get方法获取资源，返回用户指定的Object对象类型</td>\n</tr>\n<tr>\n<td>getForEntity</td>\n<td>通过get方法获取资源，返回一个封装好的HttpEntiry对象</td>\n</tr>\n<tr>\n<td>postForObject</td>\n<td>通过post方法发送Object对象，返回用户指定的Object对象类型</td>\n</tr>\n<tr>\n<td>postForEntity</td>\n<td>通过post方法发送Object对象，返回封装好的HttpEntiry对象</td>\n</tr>\n<tr>\n<td>put</td>\n<td>通过put方法上载资源</td>\n</tr>\n<tr>\n<td>delete</td>\n<td>通过delete方法删除服务器数据</td>\n</tr>\n<tr>\n<td>optionsForAllow</td>\n<td>获取目的资源支持的method</td>\n</tr>\n<tr>\n<td>exchange</td>\n<td>一种比较通用的方法，接受的参数分别为url，method，response数据类型，url参数，以及一个封装了http header数据和body数据的HttpEntity对象，统一返回一个封装了所有response数据的ResponseEntity对象</td>\n</tr>\n<tr>\n<td>execute</td>\n<td>该方法是RestTemplate中通用性最强的方法，以上所有方法最终都调用的是execute方法，接受的参数包括RequestCallback对象（用于选择合适的MessageConverter对requestBody数据进行解析并将结果封装到ClientHttpRequest中，进行最终的http请求），以及ResponseExtractor对象（用于将response数据解析为用户需要的数据类型）</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li><p>get方法</p>\n<p>发起get请求，如果只是想获取ResponseBody数据的话直接采用getForObject()的一系列重载方法：</p>\n<ul>\n<li><p><code>Object</code>方式</p>\n<p>将返回数据封装到指定的实体类CommonResponse中，RestTemplate会自动进行序列化和反序列化</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CommonResponse response = restTemplate.getForObject(url, CommonResponse.class);</span><br><span class=\"line\">CommonResponse response = restTemplate.getForObject(url, CommonResponse.class, pathVariables);</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p><code>HttpEntity</code>方式</p>\n<p>如果想获取更详细的数据（比如响应头和http状态码等信息）就使用getForEntity()</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ResponseEntity&lt;CommonResponse&gt; responseEntity = restTemplate.getForEntity(url, CommonResponse.class, pathVariables);</span><br><span class=\"line\">CommonResponse responseBody = responseEntity.getBody();</span><br><span class=\"line\">HttpStatus status = responseEntity.getStatusCode();</span><br><span class=\"line\">HttpHeaders headers = responseEntity.getHeaders();</span><br></pre></td></tr></table></figure>\n<p>​    跟Object方式类似，不过返回的结果数据封装到了一个ResponseEntity对象中</p>\n<ul>\n<li><p>配置<code>queryParameters</code>和<code>pathVariables</code></p>\n<p>RestTemplate中没有为queryParameters设置对应的传参，需要用户自己将queryParameters写到url里面，不过RestTemplate为restful风格的pathVariables配置了专用的传参：</p>\n<p>（看得出来RestTemplate专业服务于restful API调用）</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">url = <span class=\"string\">\"http://127.0.0.1:8081/persons/&#123;id&#125;\"</span></span><br><span class=\"line\">Map&lt;String, Object&gt; urlVariables = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">pathVariables.put(<span class=\"string\">\"id\"</span>, <span class=\"string\">\"0\"</span>);</span><br><span class=\"line\">CommonResponse response = restTemplate.getForObject(url, CommonResponse.class, pathVariables);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>UriTemplateHandler</code>（高级用法）</p>\n<p>虽然RestTemplate中没有为queryParameters设置对应的传参，但是用户可以自己实现一个UriTemplateHandler：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">QueryParamsUrlTemplateHandler</span> <span class=\"keyword\">extends</span> <span class=\"title\">DefaultUriTemplateHandler</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> URI <span class=\"title\">expand</span><span class=\"params\">(String uriTemplate, Map&lt;String, ?&gt; params)</span> </span>&#123;</span><br><span class=\"line\">\t\tUriComponentsBuilder componentsBuilder = UriComponentsBuilder.fromHttpUrl(uriTemplate);</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(Map.Entry&lt;String, ?&gt; varEntry : params.entrySet())&#123;</span><br><span class=\"line\">\t\t\tcomponentsBuilder.queryParam(varEntry.getKey(), varEntry.getValue());</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\turiTemplate = componentsBuilder.build().toUriString();</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">super</span>.expand(uriTemplate, params);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">restTemplate.setUriTemplateHandler(urlTemplateHandler);</span><br></pre></td></tr></table></figure>\n<p>通过配置该UriTemplateHandler，就可以以Map的形式配置queryParameters了：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Map&lt;String, Object&gt; params = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">params.put(<span class=\"string\">\"name\"</span>, <span class=\"string\">\"张三\"</span>);</span><br><span class=\"line\">ResponseEntity&lt;CommonResponse&gt; responseEntity = restTemplate.getForEntity(url, CommonResponse.class, params);</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>post方法</p>\n<p>发起post请求跟get很类似，唯一不同的地方在于需要设置<code>RequestBody</code>参数：</p>\n<ul>\n<li><p><code>Object</code>方式：</p>\n<p>无需自己设置contentType和charset，只需要直接传递实体对象作为RequestBody，RestTemplate会进行自动判断并选择合适的MeesageConverter</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CommonResponse response = restTemplate.postForObject(url, person, CommonResponse.class);</span><br></pre></td></tr></table></figure>\n<p>使用实体类Person封装上传数据，也可以直接使用Map封装数据</p>\n<ul>\n<li><p><code>HttpEntity</code>方式</p>\n<p>跟Object方式类似，request数据可以直接传递实体，也可以将请求头和请求体封装到一个HttpEntity对象中进行发送，返回数据都是ResponseEntity对象，可以取HttpStatus和HttpHeaders</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//设置请求头</span></span><br><span class=\"line\">HttpHeaders headers = <span class=\"keyword\">new</span> HttpHeaders();</span><br><span class=\"line\">MediaType type = MediaType.parseMediaType(<span class=\"string\">\"application/json; charset=UTF-8\"</span>);</span><br><span class=\"line\">headers.setContentType(type);</span><br><span class=\"line\">headers.set(<span class=\"string\">\"headerName\"</span>, <span class=\"string\">\"headerValue\"</span>);</span><br><span class=\"line\"><span class=\"comment\">//设置HttpEntity</span></span><br><span class=\"line\">HttpEntity&lt;List&lt;Person&gt;&gt; request = <span class=\"keyword\">new</span> HttpEntity&lt;&gt;(personList, headers);</span><br><span class=\"line\"><span class=\"comment\">//返回ResponseEntity对象，对Object实体数据进行封装</span></span><br><span class=\"line\">ResponseEntity&lt;CommonResponse&gt; response = restTemplate.postForEntity(url, request, CommonResponse.class);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>post方法上传文件</p>\n<p>上传文件需要用<code>MultiValueMap</code>进行文件数据的封装：</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MultipartBodyBuilder builder = <span class=\"keyword\">new</span> MultipartBodyBuilder();</span><br><span class=\"line\">File file = <span class=\"keyword\">new</span> File(<span class=\"string\">\"D:\\\\xxx\\\\xxx.png\"</span>);</span><br><span class=\"line\">builder.part(<span class=\"string\">\"file\"</span>, <span class=\"keyword\">new</span> FileSystemResource(file));</span><br><span class=\"line\">MultiValueMap&lt;String, Object&gt; request = builder.build();</span><br><span class=\"line\"><span class=\"comment\">//上传文件</span></span><br><span class=\"line\">CommonResponse response = restTemplate.postForObject(url, request, CommonResponse.class)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>put和delete实现方式和上述方法都类似，不过这两种请求没有返回数据，不太实用</p>\n<ul>\n<li>在RestTemplate中，对GET, POST, PUT, DELETE, OPTIONS, HEAD 这几种http方法都有相应的封装，如果不想用它封装好的方法，可以选择exchange()方法自定义http请求</li>\n</ul>\n</li>\n<li><p>exchange方法：</p>\n<p>可以自己指定请求头和http method，其他的细节跟前面几种方法差不多</p>\n<p>对于某些不太常见的方法（比如HEAD或者TRACE），就需要使用exchange()方法了， exchange()方法也有多种重载</p>\n<p>以发起POST请求为例：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//设置requestBody数据</span></span><br><span class=\"line\">Person person = <span class=\"keyword\">new</span> Person();</span><br><span class=\"line\"><span class=\"comment\">//设置queryParameters和pathVariables</span></span><br><span class=\"line\">Map&lt;String, Object&gt; params = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">params.put(<span class=\"string\">\"name\"</span>, <span class=\"string\">\"value\"</span>);</span><br><span class=\"line\"><span class=\"comment\">//设置请求头</span></span><br><span class=\"line\">HttpHeaders headers = <span class=\"keyword\">new</span> HttpHeaders();</span><br><span class=\"line\">MediaType type = MediaType.parseMediaType(<span class=\"string\">\"application/json; charset=UTF-8\"</span>);</span><br><span class=\"line\">headers.setContentType(type);</span><br><span class=\"line\">headers.set(<span class=\"string\">\"headerName\"</span>, <span class=\"string\">\"headerValue\"</span>);</span><br><span class=\"line\"><span class=\"comment\">//配置requestEntity</span></span><br><span class=\"line\">HttpEntity&lt;MyData&gt; requestEntity = <span class=\"keyword\">new</span> HttpEntity(person, headers);</span><br><span class=\"line\"><span class=\"comment\">//发起请求</span></span><br><span class=\"line\">ResponseEntity&lt;Map&gt; responseEntity = restTemplate.exchange(url, HttpMethod.POST, requestEntity, Map.class, params);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>execute方法（一般不用）：</p>\n<p>可以定制request和response的序列化和反序列化方式：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> &lt;T&gt; <span class=\"function\">T <span class=\"title\">execute</span><span class=\"params\">(URI url, HttpMethod method, RequestCallback requestCallback,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">\tResponseExtractor&lt;T&gt; responseExtractor)</span> <span class=\"keyword\">throws</span> RestClientException </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> doExecute(url, method, requestCallback, responseExtractor);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>RequestCallback用于封装request信息，并对这部分信息进行解析</li>\n<li>ResponseExtractor用于对response返回数据进行解析</li>\n</ul>\n<p>用户可以自由定制序列化方式，并以回调函数的形式传入execute()中；RestTemplate默认实现是两个静态内部类，默认选取RestTemplate中已经初始化完成的那部分HttpMessageConverter实现，进行序列化和反序列化操作</p>\n</li>\n</ul>\n<h2 id=\"3-异常捕捉\"><a href=\"#3-异常捕捉\" class=\"headerlink\" title=\"3. 异常捕捉\"></a>3. 异常捕捉</h2><p>RestTemplate内部已经把http请求过程中会出现的各种异常，例如404或者500等异常，都包装为了RestClientException抛出</p>\n<p>在RestTemplate中进行异常处理的组件是<code>ResponseErrorHandler</code>，默认是<code>DefaultResponseErrorHandler</code></p>\n<p>用户可以自己实现ResponseErrorHandler来处理http异常：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MyselfResponseErrorHandler</span> <span class=\"keyword\">extends</span> <span class=\"title\">DefaultResponseErrorHandler</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">final</span> Logger logger = LoggerFactory.getLogger(MyselfResponseErrorHandler.class);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">handleError</span><span class=\"params\">(ClientHttpResponse response)</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">\t\tHttpStatus statusCode = getHttpStatusCode(response);</span><br><span class=\"line\">\t\tString code = statusCode.toString();</span><br><span class=\"line\">\t\tString msg = statusCode.getReasonPhrase();</span><br><span class=\"line\">\t\t<span class=\"keyword\">switch</span> (statusCode.series()) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">case</span> CLIENT_ERROR:</span><br><span class=\"line\">\t\t\t\tlogger.error(<span class=\"string\">\"客户端请求错误，错误码：\"</span> + code + <span class=\"string\">\", 错误信息：\"</span> + msg);</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">break</span>;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">case</span> SERVER_ERROR:</span><br><span class=\"line\">\t\t\t\tlogger.error(<span class=\"string\">\"服务器端错误，错误码：\"</span> + code + <span class=\"string\">\", 错误信息：\"</span> + msg);</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">break</span>;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">default</span>:</span><br><span class=\"line\">\t\t\t\tlogger.error(<span class=\"string\">\"不知道什么错误，错误码：\"</span> + code + <span class=\"string\">\", 错误信息：\"</span> + msg);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">restTemplate.setErrorHandler(responseErrorHandler);</span><br></pre></td></tr></table></figure>\n<h1 id=\"RestTemplate内部源码分析\"><a href=\"#RestTemplate内部源码分析\" class=\"headerlink\" title=\"RestTemplate内部源码分析\"></a>RestTemplate内部源码分析</h1><h2 id=\"doExecute方法\"><a href=\"#doExecute方法\" class=\"headerlink\" title=\"doExecute方法\"></a>doExecute方法</h2><p>以上所有方法都有一个最终方法，也是RestTemplate的核心方法：doExecute()</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">protected</span> &lt;T&gt; <span class=\"function\">T <span class=\"title\">doExecute</span><span class=\"params\">(URI url, HttpMethod method, RequestCallback requestCallback,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">\t\tResponseExtractor&lt;T&gt; responseExtractor)</span> <span class=\"keyword\">throws</span> RestClientException </span>&#123;</span><br><span class=\"line\">\t<span class=\"comment\">//url和method都不能为空</span></span><br><span class=\"line\">\tAssert.notNull(url, <span class=\"string\">\"'url' must not be null\"</span>);</span><br><span class=\"line\">\tAssert.notNull(method, <span class=\"string\">\"'method' must not be null\"</span>);</span><br><span class=\"line\">\tClientHttpResponse response = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">           <span class=\"comment\">//使用ClientHttpRequestFactory创建一个ClientHttpRequest对象</span></span><br><span class=\"line\">\t\tClientHttpRequest request = createRequest(url, method);</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (requestCallback != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">               <span class=\"comment\">//调用RequestCallback对象对requestBody数据进行解析</span></span><br><span class=\"line\">               <span class=\"comment\">//序列化后的数据封装到ClientHttpRequest对象中</span></span><br><span class=\"line\">\t\t\trequestCallback.doWithRequest(request);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">           <span class=\"comment\">//ClientHttpRequest对象执行http请求得到ClientHttpResponse对象</span></span><br><span class=\"line\">\t\tresponse = request.execute();</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (!getErrorHandler().hasError(response)) &#123;</span><br><span class=\"line\">\t\t\tlogResponseStatus(method, url, response);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\t\thandleResponseError(method, url, response);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (responseExtractor != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">               <span class=\"comment\">//将ClientHttpResponse对象反序列化为用户指定的数据类型</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> responseExtractor.extractData(response);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">catch</span> (IOException ex) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ResourceAccessException(<span class=\"string\">\"I/O error on \"</span> + method.name() +</span><br><span class=\"line\">\t\t\t\t<span class=\"string\">\" request for \\\"\"</span> + url + <span class=\"string\">\"\\\": \"</span> + ex.getMessage(), ex);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (response != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">\t\t\tresponse.close();</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以看出，实际执行http请求的是ClientHttpRequest，用户可以通过设置不同的ClientHttpRequestFactory自己定制http连接方式，例如HttpComponentsClientHttpRequestFactory就是基于Apache HttpClient实现：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//需要将HttpComponentsClientHttpRequestFactory暴露为spring bean，因为其实现了DisposableBean，可以在bean销毁后自动关闭连接池</span></span><br><span class=\"line\"><span class=\"meta\">@Bean</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> HttpComponentsClientHttpRequestFactory <span class=\"title\">getFactory</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\tHttpComponentsClientHttpRequestFactory factory = <span class=\"keyword\">new</span> HttpComponentsClientHttpRequestFactory();</span><br><span class=\"line\">    <span class=\"comment\">//设置socket请求连接超时时间</span></span><br><span class=\"line\">\tfactory.setConnectTimeout(<span class=\"number\">5000</span>);</span><br><span class=\"line\">    <span class=\"comment\">//设置socket读取数据阻塞超时时间</span></span><br><span class=\"line\">\tfactory.setReadTimeout(<span class=\"number\">5000</span>);</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> factory;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"MessageConverter\"><a href=\"#MessageConverter\" class=\"headerlink\" title=\"MessageConverter\"></a>MessageConverter</h2><ul>\n<li><p>当调用不同的RestTemplate方法传输数据时，RestTemplate会自动检查ContentType并采用合适的MessageConverter进行序列化和反序列化，如果找不到合适的MessageConverter，将会报错</p>\n</li>\n<li><p>RestTemplate里面默认的几种MessageConverter已经能够满足大多数应用场景了</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>MessageConverter</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>StringHttpMessageConverter</td>\n<td>支持文本类型的数据格式：text/plain，text/*</td>\n</tr>\n<tr>\n<td>FormHttpMessageConverter</td>\n<td>支持表单类型的数据格式：application/x-www-form-urlencoded</td>\n</tr>\n<tr>\n<td>MappingJackson2HttpMessageConverter</td>\n<td>支持json类型的数据格式：application/json</td>\n</tr>\n<tr>\n<td>ResourceHttpMessageConverter</td>\n<td>可用于对Resource类型的文件io流进行序列化，并支持任意的MediaType</td>\n</tr>\n<tr>\n<td>BufferedImageHttpMessageConverter</td>\n<td>用于读取java.awt.image.BufferedImage格式的图片文件</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>用户可以自己定义满足自己业务需求的MessageConverter</li>\n</ul>\n<h1 id=\"WebClient\"><a href=\"#WebClient\" class=\"headerlink\" title=\"WebClient\"></a>WebClient</h1><p>spring 5.0全面引入了reactive响应式编程模式，同时也就有了RestTemplate的reactive版：WebClient</p>\n","site":{"data":{}},"excerpt":"<p><code>RestTemplate</code>是spring framework中对Http请求封装的一套方法，广泛运用于springboot和springcloud中的Http数据传输，官方文档描述如下：</p>\n<blockquote>\n<p><code>RestTemplate</code> is a synchronous client to perform HTTP requests. It is the original Spring REST client and exposes a simple, template-method API over underlying HTTP client libraries.</p>\n</blockquote>","more":"<p>不过在spring 5.0发行版中推出了基于NIO的响应式Http客户端：<code>WebClient</code>，将在未来代替RestTemplate:</p>\n<blockquote>\n<p>As of 5.0, the non-blocking, reactive <code>WebClient</code> offers a modern alternative to the <code>RestTemplate</code>, with efficient support for both synchronous and asynchronous, as well as streaming scenarios. The <code>RestTemplate</code> will be deprecated in a future version and will not have major new features added going forward.</p>\n</blockquote>\n<h3 id=\"RestTemplate的特点\"><a href=\"#RestTemplate的特点\" class=\"headerlink\" title=\"RestTemplate的特点\"></a>RestTemplate的特点</h3><ul>\n<li><p>使用方便：可直接传递Java实体对象，无需人工配置ContentType和Charset，自动识别序列化方式和消息格式，无需用户自己encode url，并对多种http传输方法进行了相应封装</p>\n</li>\n<li><p>可扩展性强：RestTemplate可配置多种底层通信框架如JDK HttpURLConnection、Apache HttpClient、OkHttp以及netty等</p>\n</li>\n<li><p>可配置性强：用户可灵活多种第三方组件，除了底层通信框架，还可扩展配置消息转换器，异常处理器，uri模板解析器和请求拦截器等组件</p>\n</li>\n<li><p>RestTemplate的多种组件过于依赖spring-framework，如果脱离了spring环境，用起来就很不方便了</p>\n</li>\n</ul>\n<h1 id=\"RestTemplate使用方法\"><a href=\"#RestTemplate使用方法\" class=\"headerlink\" title=\"RestTemplate使用方法\"></a>RestTemplate使用方法</h1><h2 id=\"1-初始化\"><a href=\"#1-初始化\" class=\"headerlink\" title=\"1. 初始化\"></a>1. 初始化</h2><p>RestTemplate有两种初始化方式：<code>构造方法形式</code>，<code>RestTemplateBuilder形式</code></p>\n<h3 id=\"构造方法形式\"><a href=\"#构造方法形式\" class=\"headerlink\" title=\"构造方法形式\"></a>构造方法形式</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Bean</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> RestTemplate <span class=\"title\">restTemplate</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"keyword\">new</span> RestTemplate();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>RestTemplate有三种构造方法：</p>\n<ul>\n<li><p>无参数构造方法，也是使用得最普遍的一个：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">RestTemplate</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> ByteArrayHttpMessageConverter());</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> StringHttpMessageConverter());</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> ResourceHttpMessageConverter());</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> SourceHttpMessageConverter&lt;Source&gt;());</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> AllEncompassingFormHttpMessageConverter());</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (romePresent) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> AtomFeedHttpMessageConverter());</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> RssChannelHttpMessageConverter());</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (jaxb2Present) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> Jaxb2RootElementHttpMessageConverter());</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (jackson2Present) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> MappingJackson2HttpMessageConverter());</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (jacksonPresent) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.messageConverters.add(<span class=\"keyword\">new</span> MappingJacksonHttpMessageConverter());</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>RestTemplate中内置了多种HttpMessageConverter，用于对不同场景下的输入输出流进行序列化和反序列化，无参数构造方法主要对HttpMessageConverter列表进行初始化</p>\n</li>\n<li><p>有参数构造方法 — 初始化ClientHttpRequestFactory</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">RestTemplate</span><span class=\"params\">(ClientHttpRequestFactory requestFactory)</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>();</span><br><span class=\"line\">\tsetRequestFactory(requestFactory);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>用户可以自己指定需要的ClientHttpRequestFactory，用于进行http连接和请求，默认是采用<code>SimpleClientHttpRequestFactory</code>，底层封装的是JDK的<code>HttpURLConnection</code>，用户可以指定其他种类的factory，比如以下几种：</p>\n<ul>\n<li><p><code>BufferingClientHttpRequestFactory</code>：可在内存中建立输入数据的缓存</p>\n</li>\n<li><p><code>HttpComponentsClientHttpRequestFactory</code>：采用Apache的HttpClient进行远程调用，可以配置连接池和证书信息，不过需要在pom.xml中加入以下依赖：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.httpcomponents<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>httpclient<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>4.5.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>InterceptingClientHttpRequestFactory</code>：可以配置ClientHttpRequestInterceptor拦截器对http请求进行拦截处理，springcloud中的Ribbon就用到了这个factory用于将server name url转换为实际调用的url</p>\n</li>\n<li>基于Netty4的<code>Netty4ClientHttpRequestFactory</code></li>\n<li>基于OkHttp2的<code>OkHttpClientHttpRequestFactory</code></li>\n</ul>\n</li>\n<li><p>有参数构造方法 — 添加多个HttpMessageConverter</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">RestTemplate</span><span class=\"params\">(List&lt;HttpMessageConverter&lt;?&gt;&gt; messageConverters)</span> </span>&#123;</span><br><span class=\"line\">\tAssert.notEmpty(messageConverters, <span class=\"string\">\"'messageConverters' must not be empty\"</span>);</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.messageConverters.addAll(messageConverters);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如果用户觉得RestTemplate默认的几个序列化API无法满足要求，可以自己指定MessageConverter</p>\n</li>\n</ul>\n<h3 id=\"RestTemplateBuilder形式\"><a href=\"#RestTemplateBuilder形式\" class=\"headerlink\" title=\"RestTemplateBuilder形式\"></a>RestTemplateBuilder形式</h3><p>如果用户要对RestTemplate进行多种初始化配置的话，推荐使用RestTemplateBuilder建造器，属于高级用法：<br>  <figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">   <span class=\"meta\">@Bean</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> RestTemplate <span class=\"title\">myRestTemplate</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\tRestTemplateBuilder builder = <span class=\"keyword\">new</span> RestTemplateBuilder();</span><br><span class=\"line\">\tRestTemplate restTemplate = builder</span><br><span class=\"line\">           \t\t\t<span class=\"comment\">//配置ClientHttpRequestFactory</span></span><br><span class=\"line\">\t\t\t\t\t.requestFactory(HttpComponentsClientHttpRequestFactory.class)</span><br><span class=\"line\">           \t\t\t<span class=\"comment\">//配置MessageConverter</span></span><br><span class=\"line\">\t\t\t\t\t.messageConverters(<span class=\"keyword\">new</span> MappingJackson2HttpMessageConverter())</span><br><span class=\"line\">           \t\t\t<span class=\"comment\">//配置ResponseErrorHandler</span></span><br><span class=\"line\">\t\t\t\t\t.errorHandler(<span class=\"keyword\">new</span> DefaultResponseErrorHandler())</span><br><span class=\"line\">           \t\t\t<span class=\"comment\">//配置UriTemplateHandler</span></span><br><span class=\"line\">\t\t\t\t\t.uriTemplateHandler(<span class=\"keyword\">new</span> DefaultUriTemplateHandler())</span><br><span class=\"line\">           \t\t\t<span class=\"comment\">//配置连接超时时间和连接过期时间</span></span><br><span class=\"line\">\t\t\t\t\t.setConnectTimeout(<span class=\"number\">10000</span>)</span><br><span class=\"line\">\t\t\t\t\t.setReadTimeout(<span class=\"number\">5000</span>)</span><br><span class=\"line\">\t\t\t\t\t.build();</span><br><span class=\"line\">       <span class=\"keyword\">return</span> restTemplate;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-执行Http请求\"><a href=\"#2-执行Http请求\" class=\"headerlink\" title=\"2. 执行Http请求\"></a>2. 执行Http请求</h2><p>RestTemplate对多种http method的请求进行了封装，用户可以直接进行使用</p>\n<ul>\n<li>RestTemplate中几种常用的方法：</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>方法名</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>getForObject</td>\n<td>通过get方法获取资源，返回用户指定的Object对象类型</td>\n</tr>\n<tr>\n<td>getForEntity</td>\n<td>通过get方法获取资源，返回一个封装好的HttpEntiry对象</td>\n</tr>\n<tr>\n<td>postForObject</td>\n<td>通过post方法发送Object对象，返回用户指定的Object对象类型</td>\n</tr>\n<tr>\n<td>postForEntity</td>\n<td>通过post方法发送Object对象，返回封装好的HttpEntiry对象</td>\n</tr>\n<tr>\n<td>put</td>\n<td>通过put方法上载资源</td>\n</tr>\n<tr>\n<td>delete</td>\n<td>通过delete方法删除服务器数据</td>\n</tr>\n<tr>\n<td>optionsForAllow</td>\n<td>获取目的资源支持的method</td>\n</tr>\n<tr>\n<td>exchange</td>\n<td>一种比较通用的方法，接受的参数分别为url，method，response数据类型，url参数，以及一个封装了http header数据和body数据的HttpEntity对象，统一返回一个封装了所有response数据的ResponseEntity对象</td>\n</tr>\n<tr>\n<td>execute</td>\n<td>该方法是RestTemplate中通用性最强的方法，以上所有方法最终都调用的是execute方法，接受的参数包括RequestCallback对象（用于选择合适的MessageConverter对requestBody数据进行解析并将结果封装到ClientHttpRequest中，进行最终的http请求），以及ResponseExtractor对象（用于将response数据解析为用户需要的数据类型）</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li><p>get方法</p>\n<p>发起get请求，如果只是想获取ResponseBody数据的话直接采用getForObject()的一系列重载方法：</p>\n<ul>\n<li><p><code>Object</code>方式</p>\n<p>将返回数据封装到指定的实体类CommonResponse中，RestTemplate会自动进行序列化和反序列化</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CommonResponse response = restTemplate.getForObject(url, CommonResponse.class);</span><br><span class=\"line\">CommonResponse response = restTemplate.getForObject(url, CommonResponse.class, pathVariables);</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p><code>HttpEntity</code>方式</p>\n<p>如果想获取更详细的数据（比如响应头和http状态码等信息）就使用getForEntity()</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ResponseEntity&lt;CommonResponse&gt; responseEntity = restTemplate.getForEntity(url, CommonResponse.class, pathVariables);</span><br><span class=\"line\">CommonResponse responseBody = responseEntity.getBody();</span><br><span class=\"line\">HttpStatus status = responseEntity.getStatusCode();</span><br><span class=\"line\">HttpHeaders headers = responseEntity.getHeaders();</span><br></pre></td></tr></table></figure>\n<p>​    跟Object方式类似，不过返回的结果数据封装到了一个ResponseEntity对象中</p>\n<ul>\n<li><p>配置<code>queryParameters</code>和<code>pathVariables</code></p>\n<p>RestTemplate中没有为queryParameters设置对应的传参，需要用户自己将queryParameters写到url里面，不过RestTemplate为restful风格的pathVariables配置了专用的传参：</p>\n<p>（看得出来RestTemplate专业服务于restful API调用）</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">url = <span class=\"string\">\"http://127.0.0.1:8081/persons/&#123;id&#125;\"</span></span><br><span class=\"line\">Map&lt;String, Object&gt; urlVariables = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">pathVariables.put(<span class=\"string\">\"id\"</span>, <span class=\"string\">\"0\"</span>);</span><br><span class=\"line\">CommonResponse response = restTemplate.getForObject(url, CommonResponse.class, pathVariables);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>UriTemplateHandler</code>（高级用法）</p>\n<p>虽然RestTemplate中没有为queryParameters设置对应的传参，但是用户可以自己实现一个UriTemplateHandler：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">QueryParamsUrlTemplateHandler</span> <span class=\"keyword\">extends</span> <span class=\"title\">DefaultUriTemplateHandler</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> URI <span class=\"title\">expand</span><span class=\"params\">(String uriTemplate, Map&lt;String, ?&gt; params)</span> </span>&#123;</span><br><span class=\"line\">\t\tUriComponentsBuilder componentsBuilder = UriComponentsBuilder.fromHttpUrl(uriTemplate);</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(Map.Entry&lt;String, ?&gt; varEntry : params.entrySet())&#123;</span><br><span class=\"line\">\t\t\tcomponentsBuilder.queryParam(varEntry.getKey(), varEntry.getValue());</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\turiTemplate = componentsBuilder.build().toUriString();</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">super</span>.expand(uriTemplate, params);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">restTemplate.setUriTemplateHandler(urlTemplateHandler);</span><br></pre></td></tr></table></figure>\n<p>通过配置该UriTemplateHandler，就可以以Map的形式配置queryParameters了：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Map&lt;String, Object&gt; params = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">params.put(<span class=\"string\">\"name\"</span>, <span class=\"string\">\"张三\"</span>);</span><br><span class=\"line\">ResponseEntity&lt;CommonResponse&gt; responseEntity = restTemplate.getForEntity(url, CommonResponse.class, params);</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>post方法</p>\n<p>发起post请求跟get很类似，唯一不同的地方在于需要设置<code>RequestBody</code>参数：</p>\n<ul>\n<li><p><code>Object</code>方式：</p>\n<p>无需自己设置contentType和charset，只需要直接传递实体对象作为RequestBody，RestTemplate会进行自动判断并选择合适的MeesageConverter</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CommonResponse response = restTemplate.postForObject(url, person, CommonResponse.class);</span><br></pre></td></tr></table></figure>\n<p>使用实体类Person封装上传数据，也可以直接使用Map封装数据</p>\n<ul>\n<li><p><code>HttpEntity</code>方式</p>\n<p>跟Object方式类似，request数据可以直接传递实体，也可以将请求头和请求体封装到一个HttpEntity对象中进行发送，返回数据都是ResponseEntity对象，可以取HttpStatus和HttpHeaders</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//设置请求头</span></span><br><span class=\"line\">HttpHeaders headers = <span class=\"keyword\">new</span> HttpHeaders();</span><br><span class=\"line\">MediaType type = MediaType.parseMediaType(<span class=\"string\">\"application/json; charset=UTF-8\"</span>);</span><br><span class=\"line\">headers.setContentType(type);</span><br><span class=\"line\">headers.set(<span class=\"string\">\"headerName\"</span>, <span class=\"string\">\"headerValue\"</span>);</span><br><span class=\"line\"><span class=\"comment\">//设置HttpEntity</span></span><br><span class=\"line\">HttpEntity&lt;List&lt;Person&gt;&gt; request = <span class=\"keyword\">new</span> HttpEntity&lt;&gt;(personList, headers);</span><br><span class=\"line\"><span class=\"comment\">//返回ResponseEntity对象，对Object实体数据进行封装</span></span><br><span class=\"line\">ResponseEntity&lt;CommonResponse&gt; response = restTemplate.postForEntity(url, request, CommonResponse.class);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>post方法上传文件</p>\n<p>上传文件需要用<code>MultiValueMap</code>进行文件数据的封装：</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MultipartBodyBuilder builder = <span class=\"keyword\">new</span> MultipartBodyBuilder();</span><br><span class=\"line\">File file = <span class=\"keyword\">new</span> File(<span class=\"string\">\"D:\\\\xxx\\\\xxx.png\"</span>);</span><br><span class=\"line\">builder.part(<span class=\"string\">\"file\"</span>, <span class=\"keyword\">new</span> FileSystemResource(file));</span><br><span class=\"line\">MultiValueMap&lt;String, Object&gt; request = builder.build();</span><br><span class=\"line\"><span class=\"comment\">//上传文件</span></span><br><span class=\"line\">CommonResponse response = restTemplate.postForObject(url, request, CommonResponse.class)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>put和delete实现方式和上述方法都类似，不过这两种请求没有返回数据，不太实用</p>\n<ul>\n<li>在RestTemplate中，对GET, POST, PUT, DELETE, OPTIONS, HEAD 这几种http方法都有相应的封装，如果不想用它封装好的方法，可以选择exchange()方法自定义http请求</li>\n</ul>\n</li>\n<li><p>exchange方法：</p>\n<p>可以自己指定请求头和http method，其他的细节跟前面几种方法差不多</p>\n<p>对于某些不太常见的方法（比如HEAD或者TRACE），就需要使用exchange()方法了， exchange()方法也有多种重载</p>\n<p>以发起POST请求为例：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//设置requestBody数据</span></span><br><span class=\"line\">Person person = <span class=\"keyword\">new</span> Person();</span><br><span class=\"line\"><span class=\"comment\">//设置queryParameters和pathVariables</span></span><br><span class=\"line\">Map&lt;String, Object&gt; params = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">params.put(<span class=\"string\">\"name\"</span>, <span class=\"string\">\"value\"</span>);</span><br><span class=\"line\"><span class=\"comment\">//设置请求头</span></span><br><span class=\"line\">HttpHeaders headers = <span class=\"keyword\">new</span> HttpHeaders();</span><br><span class=\"line\">MediaType type = MediaType.parseMediaType(<span class=\"string\">\"application/json; charset=UTF-8\"</span>);</span><br><span class=\"line\">headers.setContentType(type);</span><br><span class=\"line\">headers.set(<span class=\"string\">\"headerName\"</span>, <span class=\"string\">\"headerValue\"</span>);</span><br><span class=\"line\"><span class=\"comment\">//配置requestEntity</span></span><br><span class=\"line\">HttpEntity&lt;MyData&gt; requestEntity = <span class=\"keyword\">new</span> HttpEntity(person, headers);</span><br><span class=\"line\"><span class=\"comment\">//发起请求</span></span><br><span class=\"line\">ResponseEntity&lt;Map&gt; responseEntity = restTemplate.exchange(url, HttpMethod.POST, requestEntity, Map.class, params);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>execute方法（一般不用）：</p>\n<p>可以定制request和response的序列化和反序列化方式：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> &lt;T&gt; <span class=\"function\">T <span class=\"title\">execute</span><span class=\"params\">(URI url, HttpMethod method, RequestCallback requestCallback,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">\tResponseExtractor&lt;T&gt; responseExtractor)</span> <span class=\"keyword\">throws</span> RestClientException </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> doExecute(url, method, requestCallback, responseExtractor);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>RequestCallback用于封装request信息，并对这部分信息进行解析</li>\n<li>ResponseExtractor用于对response返回数据进行解析</li>\n</ul>\n<p>用户可以自由定制序列化方式，并以回调函数的形式传入execute()中；RestTemplate默认实现是两个静态内部类，默认选取RestTemplate中已经初始化完成的那部分HttpMessageConverter实现，进行序列化和反序列化操作</p>\n</li>\n</ul>\n<h2 id=\"3-异常捕捉\"><a href=\"#3-异常捕捉\" class=\"headerlink\" title=\"3. 异常捕捉\"></a>3. 异常捕捉</h2><p>RestTemplate内部已经把http请求过程中会出现的各种异常，例如404或者500等异常，都包装为了RestClientException抛出</p>\n<p>在RestTemplate中进行异常处理的组件是<code>ResponseErrorHandler</code>，默认是<code>DefaultResponseErrorHandler</code></p>\n<p>用户可以自己实现ResponseErrorHandler来处理http异常：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MyselfResponseErrorHandler</span> <span class=\"keyword\">extends</span> <span class=\"title\">DefaultResponseErrorHandler</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">private</span> <span class=\"keyword\">final</span> Logger logger = LoggerFactory.getLogger(MyselfResponseErrorHandler.class);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">handleError</span><span class=\"params\">(ClientHttpResponse response)</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">\t\tHttpStatus statusCode = getHttpStatusCode(response);</span><br><span class=\"line\">\t\tString code = statusCode.toString();</span><br><span class=\"line\">\t\tString msg = statusCode.getReasonPhrase();</span><br><span class=\"line\">\t\t<span class=\"keyword\">switch</span> (statusCode.series()) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">case</span> CLIENT_ERROR:</span><br><span class=\"line\">\t\t\t\tlogger.error(<span class=\"string\">\"客户端请求错误，错误码：\"</span> + code + <span class=\"string\">\", 错误信息：\"</span> + msg);</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">break</span>;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">case</span> SERVER_ERROR:</span><br><span class=\"line\">\t\t\t\tlogger.error(<span class=\"string\">\"服务器端错误，错误码：\"</span> + code + <span class=\"string\">\", 错误信息：\"</span> + msg);</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">break</span>;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">default</span>:</span><br><span class=\"line\">\t\t\t\tlogger.error(<span class=\"string\">\"不知道什么错误，错误码：\"</span> + code + <span class=\"string\">\", 错误信息：\"</span> + msg);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">restTemplate.setErrorHandler(responseErrorHandler);</span><br></pre></td></tr></table></figure>\n<h1 id=\"RestTemplate内部源码分析\"><a href=\"#RestTemplate内部源码分析\" class=\"headerlink\" title=\"RestTemplate内部源码分析\"></a>RestTemplate内部源码分析</h1><h2 id=\"doExecute方法\"><a href=\"#doExecute方法\" class=\"headerlink\" title=\"doExecute方法\"></a>doExecute方法</h2><p>以上所有方法都有一个最终方法，也是RestTemplate的核心方法：doExecute()</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">protected</span> &lt;T&gt; <span class=\"function\">T <span class=\"title\">doExecute</span><span class=\"params\">(URI url, HttpMethod method, RequestCallback requestCallback,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">\t\tResponseExtractor&lt;T&gt; responseExtractor)</span> <span class=\"keyword\">throws</span> RestClientException </span>&#123;</span><br><span class=\"line\">\t<span class=\"comment\">//url和method都不能为空</span></span><br><span class=\"line\">\tAssert.notNull(url, <span class=\"string\">\"'url' must not be null\"</span>);</span><br><span class=\"line\">\tAssert.notNull(method, <span class=\"string\">\"'method' must not be null\"</span>);</span><br><span class=\"line\">\tClientHttpResponse response = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">           <span class=\"comment\">//使用ClientHttpRequestFactory创建一个ClientHttpRequest对象</span></span><br><span class=\"line\">\t\tClientHttpRequest request = createRequest(url, method);</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (requestCallback != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">               <span class=\"comment\">//调用RequestCallback对象对requestBody数据进行解析</span></span><br><span class=\"line\">               <span class=\"comment\">//序列化后的数据封装到ClientHttpRequest对象中</span></span><br><span class=\"line\">\t\t\trequestCallback.doWithRequest(request);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">           <span class=\"comment\">//ClientHttpRequest对象执行http请求得到ClientHttpResponse对象</span></span><br><span class=\"line\">\t\tresponse = request.execute();</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (!getErrorHandler().hasError(response)) &#123;</span><br><span class=\"line\">\t\t\tlogResponseStatus(method, url, response);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\t\thandleResponseError(method, url, response);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (responseExtractor != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">               <span class=\"comment\">//将ClientHttpResponse对象反序列化为用户指定的数据类型</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> responseExtractor.extractData(response);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">catch</span> (IOException ex) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ResourceAccessException(<span class=\"string\">\"I/O error on \"</span> + method.name() +</span><br><span class=\"line\">\t\t\t\t<span class=\"string\">\" request for \\\"\"</span> + url + <span class=\"string\">\"\\\": \"</span> + ex.getMessage(), ex);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (response != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">\t\t\tresponse.close();</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以看出，实际执行http请求的是ClientHttpRequest，用户可以通过设置不同的ClientHttpRequestFactory自己定制http连接方式，例如HttpComponentsClientHttpRequestFactory就是基于Apache HttpClient实现：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//需要将HttpComponentsClientHttpRequestFactory暴露为spring bean，因为其实现了DisposableBean，可以在bean销毁后自动关闭连接池</span></span><br><span class=\"line\"><span class=\"meta\">@Bean</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> HttpComponentsClientHttpRequestFactory <span class=\"title\">getFactory</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\tHttpComponentsClientHttpRequestFactory factory = <span class=\"keyword\">new</span> HttpComponentsClientHttpRequestFactory();</span><br><span class=\"line\">    <span class=\"comment\">//设置socket请求连接超时时间</span></span><br><span class=\"line\">\tfactory.setConnectTimeout(<span class=\"number\">5000</span>);</span><br><span class=\"line\">    <span class=\"comment\">//设置socket读取数据阻塞超时时间</span></span><br><span class=\"line\">\tfactory.setReadTimeout(<span class=\"number\">5000</span>);</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> factory;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"MessageConverter\"><a href=\"#MessageConverter\" class=\"headerlink\" title=\"MessageConverter\"></a>MessageConverter</h2><ul>\n<li><p>当调用不同的RestTemplate方法传输数据时，RestTemplate会自动检查ContentType并采用合适的MessageConverter进行序列化和反序列化，如果找不到合适的MessageConverter，将会报错</p>\n</li>\n<li><p>RestTemplate里面默认的几种MessageConverter已经能够满足大多数应用场景了</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>MessageConverter</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>StringHttpMessageConverter</td>\n<td>支持文本类型的数据格式：text/plain，text/*</td>\n</tr>\n<tr>\n<td>FormHttpMessageConverter</td>\n<td>支持表单类型的数据格式：application/x-www-form-urlencoded</td>\n</tr>\n<tr>\n<td>MappingJackson2HttpMessageConverter</td>\n<td>支持json类型的数据格式：application/json</td>\n</tr>\n<tr>\n<td>ResourceHttpMessageConverter</td>\n<td>可用于对Resource类型的文件io流进行序列化，并支持任意的MediaType</td>\n</tr>\n<tr>\n<td>BufferedImageHttpMessageConverter</td>\n<td>用于读取java.awt.image.BufferedImage格式的图片文件</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>用户可以自己定义满足自己业务需求的MessageConverter</li>\n</ul>\n<h1 id=\"WebClient\"><a href=\"#WebClient\" class=\"headerlink\" title=\"WebClient\"></a>WebClient</h1><p>spring 5.0全面引入了reactive响应式编程模式，同时也就有了RestTemplate的reactive版：WebClient</p>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 9(1)","author":"天渊","date":"2019-11-06T15:10:00.000Z","_content":"第九章：虚拟内存\n\n本章对虚拟内存的知识进行了讲解，虚拟内存是操作系统为进程访问内存数据提供的一层抽象，便于程序更方便地管理属于自己的内存数据\n<!--more-->\n\n#### 为什么需要虚拟内存\n\n 在以往的认知中，通常都以为程序使用的内存直接就是计算机硬件的那个内存，但如果所有运行的程序直接使用共享内存的话会出现一些问题：\n\n- 程序如果能直接访问内存不安全，比如一个进程操作了另一个进程申请的内存，则会发生不可预知的错误，操作系统并不希望一个用户应用程序拥有直接访问内存的权利\n- 系统中运行的程序太多的话，很容易就会把内存占满了，如果有新启动的程序则无法顺利的获得内存空间，这是需要避免的\n\n因此，操作系统使用`虚拟内存（Vitual Memory）`这一概念，对屏蔽了底层实际物理内存，抽象出一层来让用户访问，用户操作的只能是这个虚拟内存地址空间\n\n在程序看来，就好像自己拥有整个内存空间，而在操作系统的角度看，用户申请和使用哪块内存完全是操作系统虚拟化后的结果，对此，操作系统虚拟内存做了以下工作，来更好的服务于应用程序：\n\n- 虚拟内存管理的辖区**不仅限于物理内存**，而且还包括**一部分磁盘空间**，它把物理内存当作磁盘地址空间的一个大型缓存，应用程序的一些不活跃的内存数据会被转移到磁盘上进行存储，也不会存在用户新启动程序而没有足够的内存进行申请的情况，操作系统根据需要在磁盘和内存之间来回传送数据，而这个过程是对用户程序屏蔽的\n- 虚拟内存为每个进程提供了**一致的地址空间**，简化了应用程序管理内存的过程\n- 每个进程拥有自己**单独隔离的虚拟地址空间**，不会被其他进程影响\n\n### 物理寻址和虚拟寻址\n\n可以把物理内存看成一个很大的字节数组，每个字节都有一个唯一的数组索引，也就是字节的`物理地址`，早期计算机都使用物理地址来进行寻址，现代计算机在物理地址空间之上做了一层虚拟话，称之为虚拟内存，现在的程序都是使用`虚拟地址（Vitual Address）`来管理虚拟内存上存储的字节数据\n\n![](http://img.mantian.site/201911071134_260.png)\n\nCPU使用寻你地址发起发起虚拟寻址，需要通过CPU芯片上自带的`内存管理单元(MMU)`来将虚拟地址翻译为实际的物理地址，而这个地址映射关系存放在主内存中（称之为`页表（Page Table）`）\n\n### 地址空间\n\n把物理内存比喻成字节数组，那这个数组索引的有序集合就叫`物理地址空间`，而相应的，虚拟内存地址对应的字节数组的索引有序集合就叫`虚拟地址空间`，每个进程都有自己对应的`虚拟地址空间`\n\n系统中允许每个字节数据拥有不同的独立的地址，对应不同的地址空间，比如一个字节数据可以有一个对应物理地址空间的物理地址以及一个对应某个进程虚拟地址空间的虚拟内存地址\n\n### 虚拟内存的页缓存\n\n操作系统将虚拟内存以`虚拟页（Vitual Page）`的方式进行组织，每一页都是一个大小固定的数据块\n\n总体上来看，虚拟内存机制是把磁盘作为主要存储区域，而把物理内存作为缓存，相应的，在磁盘和物理内存中就以`物理页（Physical Page）`的方式来存储虚拟内存保存的页数据，因此一个进程的虚拟地址空间同一时间总会有三个不同的部分：\n\n1. `未分配的虚拟内存`：这部分空间是还没有被程序使用的地址空间，从物理上来讲没有与任何一块数据相关联\n2. `缓存的虚拟内存页`：这部分虚拟页保存在物理内存上\n3. `未缓存的虚拟内存页`：这部分虚拟页保存在磁盘上\n\n下图就是描述虚拟内存是如何在磁盘和硬盘上进行组织的，每一格都代表一个虚拟页：\n\n![](http://img.mantian.site/201911071352_505.png)\n\n其中`未分配的`虚拟页不占有任何存储空间，`已缓存的`虚拟页存储在物理内存上，而剩下的`未缓存的`虚拟页仍旧保存在磁盘上\n\n#### 页表\n\n前文提到，CPU的MMU是根据`页表`将虚拟地址翻译为具体的物理地址，再根据物理地址寻找具体的数据，操作系统会为每一个进程维护一份与之配套的虚拟地址空间的`页表`\n\n页表由多个`页表条目（Page Table Entry）`以及每个条目对应的`有效位 `组成，其中`页表条目`简称`PTE`，条目中存储了某个虚拟页的物理地址，而有效位如果为1表示该PTE地址表示的物理内存的地址，为0则表示要么还未分配，要么保存于磁盘上\n\n##### 页命中\n\nMMU如何根据页表来寻找虚拟页对应的具体地址？这就是页命中的过程\n\n页表和当前进程的虚拟内存地址空间总是一一对应的，每一个PTE都对应一个虚拟页（VP），如果想找到虚拟页VP2的具体物理地址，过程如下：\n\n![](http://img.mantian.site/201911071445_849.png)\n\n首先找到VP2地址所对应的页表PTE，发现当前有效位是1，表示VP2已经缓存在了物理内存上，则该PTE存储的地址就是VP2虚拟页所对应的物理页的具体地址\n\n##### 缺页交换\n\n那如果当前PTE有效位为1呢？表示当前VP不在物理内存中，而存储在磁盘上，这就是通常所说的`缺页`，需要根据PTE存储的当前VP的磁盘地址去找到具体的页数据，然后将磁盘上的VP复制回物理内存中，最后修改PTE的有效位和存储的地址值，再交给MMU处理，此时MMU就能正常命中该VP了\n\n具体的缺页处理过程示例如下：\n\n1. MMU需要寻找VP3的具体地址，但有效位是0，触发缺页中断，交给缺页异常处理程序进行处理\n\n![](http://img.mantian.site/201911071501_172.png)\n\n2. 缺页异常处理程序会选择一个牺牲页VP4，将VP4复制到磁盘并修改VP4对应的PTE，将有效位修改为0，并保存VP4的磁盘地址\n3. 随后，异常处理程序将VP3复制到之前存放VP4的物理地址位置，并修改VP3的PTE的有效位和地址值，完成后如下：\n\n![](http://img.mantian.site/201911071508_51.png)\n\n4. 处理完成后，异常处理程序将控制权交还给用户程序，MMU就能正常的命中VP3的物理内存地址了\n\n以上缺页处理的过程称为**按需页面调度**\n\n那向系统新申请一个内存页是什么过程呢？系统会直接在当前虚拟内存对应的磁盘空间上新创建一块区域，并更新这块虚拟内存页对应的PTE，将有效位设置为0并保存对应的磁盘位置，待真正使用这块内存时才进行上述的页面调度过程将需要的虚拟页交换出来\n\n> **局部性原理**：\n>\n> 虚拟内存的页面调度机制看上去性能会很差，毕竟缺页处理的开销很大，其实操作系统利用局部性原理可以将开销压缩到最小，因为在任意时刻应用程序都趋向于在一个较小的工作集（working set）上工作，这个工作集包含了程序使用频率最高的一部分虚拟页，经过一段初始开销后工作集中的虚拟页都被调度到了物理内存中，大部分时候都能命中\n\n#### 多进程的虚拟页管理\n\n操作系统为每个进程单独管理自己的虚拟地址空间和页表，多个进程的不同的虚拟页面还可以映射到同一个共享的物理内存页面上\n\n虚拟地址机制对多进程的内存管理有显而易见的好处：\n\n- 简化程序内存管理：每个进程的虚拟地址空间都具有**相同的内存格式**，比如代码段和数据段等地址段的大小和起始位置都是相同的，不会与其他进程的内存管理产生冲突，并且链接器生成的可执行文件（包含指令的具体地址）也可以独立于物理内存实际的代码和数据位置，提高了可执行文件的移植性\n- 简化加载：操作系统加载文件时，加载器为代码和数据分配虚拟页，将对应页表PTE的有效位设置为0，此时加载器并没有加载实际的数据，待真正使用这部分数据时才从磁盘调用需要的数据页\n- 简化共享：有一部分系统调用代码保存于内核中一个共享的内存区域，并将所有进程虚拟地址空间中适当的虚拟页映射到这块共享的内存区域，这样就避免了每个虚拟内存必须得保存同样的内核代码\n- 简化内存分配：程序调用malloc等申请内存的系统调用时，系统会直接在虚拟内存空间上分配一系列连续的虚拟页给程序，而这部分虚拟页在实际物理内存上极有可能是分散的\n\n#### 内存访问许可\n\n虚拟内存作为程序到真实内存区域的访问媒介，自然就提供了一种保护机制，限制程序对某些内存的访问权限，比如可读或者可写，这些信息以`许可位`的形式保存在页表的PTE中：\n\n![](http://img.mantian.site/201911071640_705.png)\n\n如上，`SUP`表示进程是否必须运行在内核模式下才能访问该页，`READ`表示当前页对进程是否可读，`WRITE`表示当前页对进程是否可写，比如进程j如果运行在用户模式下，就拥有读VP0以及读写VP2的权限，但没有访问VP1的权限\n\n如果某条指令违反许可操作了某页，将会产生`短错误（segmentation fault）`异常\n\n### 地址翻译\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-8.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 9(1)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-11-06 23:10:00\n---\n第九章：虚拟内存\n\n本章对虚拟内存的知识进行了讲解，虚拟内存是操作系统为进程访问内存数据提供的一层抽象，便于程序更方便地管理属于自己的内存数据\n<!--more-->\n\n#### 为什么需要虚拟内存\n\n 在以往的认知中，通常都以为程序使用的内存直接就是计算机硬件的那个内存，但如果所有运行的程序直接使用共享内存的话会出现一些问题：\n\n- 程序如果能直接访问内存不安全，比如一个进程操作了另一个进程申请的内存，则会发生不可预知的错误，操作系统并不希望一个用户应用程序拥有直接访问内存的权利\n- 系统中运行的程序太多的话，很容易就会把内存占满了，如果有新启动的程序则无法顺利的获得内存空间，这是需要避免的\n\n因此，操作系统使用`虚拟内存（Vitual Memory）`这一概念，对屏蔽了底层实际物理内存，抽象出一层来让用户访问，用户操作的只能是这个虚拟内存地址空间\n\n在程序看来，就好像自己拥有整个内存空间，而在操作系统的角度看，用户申请和使用哪块内存完全是操作系统虚拟化后的结果，对此，操作系统虚拟内存做了以下工作，来更好的服务于应用程序：\n\n- 虚拟内存管理的辖区**不仅限于物理内存**，而且还包括**一部分磁盘空间**，它把物理内存当作磁盘地址空间的一个大型缓存，应用程序的一些不活跃的内存数据会被转移到磁盘上进行存储，也不会存在用户新启动程序而没有足够的内存进行申请的情况，操作系统根据需要在磁盘和内存之间来回传送数据，而这个过程是对用户程序屏蔽的\n- 虚拟内存为每个进程提供了**一致的地址空间**，简化了应用程序管理内存的过程\n- 每个进程拥有自己**单独隔离的虚拟地址空间**，不会被其他进程影响\n\n### 物理寻址和虚拟寻址\n\n可以把物理内存看成一个很大的字节数组，每个字节都有一个唯一的数组索引，也就是字节的`物理地址`，早期计算机都使用物理地址来进行寻址，现代计算机在物理地址空间之上做了一层虚拟话，称之为虚拟内存，现在的程序都是使用`虚拟地址（Vitual Address）`来管理虚拟内存上存储的字节数据\n\n![](http://img.mantian.site/201911071134_260.png)\n\nCPU使用寻你地址发起发起虚拟寻址，需要通过CPU芯片上自带的`内存管理单元(MMU)`来将虚拟地址翻译为实际的物理地址，而这个地址映射关系存放在主内存中（称之为`页表（Page Table）`）\n\n### 地址空间\n\n把物理内存比喻成字节数组，那这个数组索引的有序集合就叫`物理地址空间`，而相应的，虚拟内存地址对应的字节数组的索引有序集合就叫`虚拟地址空间`，每个进程都有自己对应的`虚拟地址空间`\n\n系统中允许每个字节数据拥有不同的独立的地址，对应不同的地址空间，比如一个字节数据可以有一个对应物理地址空间的物理地址以及一个对应某个进程虚拟地址空间的虚拟内存地址\n\n### 虚拟内存的页缓存\n\n操作系统将虚拟内存以`虚拟页（Vitual Page）`的方式进行组织，每一页都是一个大小固定的数据块\n\n总体上来看，虚拟内存机制是把磁盘作为主要存储区域，而把物理内存作为缓存，相应的，在磁盘和物理内存中就以`物理页（Physical Page）`的方式来存储虚拟内存保存的页数据，因此一个进程的虚拟地址空间同一时间总会有三个不同的部分：\n\n1. `未分配的虚拟内存`：这部分空间是还没有被程序使用的地址空间，从物理上来讲没有与任何一块数据相关联\n2. `缓存的虚拟内存页`：这部分虚拟页保存在物理内存上\n3. `未缓存的虚拟内存页`：这部分虚拟页保存在磁盘上\n\n下图就是描述虚拟内存是如何在磁盘和硬盘上进行组织的，每一格都代表一个虚拟页：\n\n![](http://img.mantian.site/201911071352_505.png)\n\n其中`未分配的`虚拟页不占有任何存储空间，`已缓存的`虚拟页存储在物理内存上，而剩下的`未缓存的`虚拟页仍旧保存在磁盘上\n\n#### 页表\n\n前文提到，CPU的MMU是根据`页表`将虚拟地址翻译为具体的物理地址，再根据物理地址寻找具体的数据，操作系统会为每一个进程维护一份与之配套的虚拟地址空间的`页表`\n\n页表由多个`页表条目（Page Table Entry）`以及每个条目对应的`有效位 `组成，其中`页表条目`简称`PTE`，条目中存储了某个虚拟页的物理地址，而有效位如果为1表示该PTE地址表示的物理内存的地址，为0则表示要么还未分配，要么保存于磁盘上\n\n##### 页命中\n\nMMU如何根据页表来寻找虚拟页对应的具体地址？这就是页命中的过程\n\n页表和当前进程的虚拟内存地址空间总是一一对应的，每一个PTE都对应一个虚拟页（VP），如果想找到虚拟页VP2的具体物理地址，过程如下：\n\n![](http://img.mantian.site/201911071445_849.png)\n\n首先找到VP2地址所对应的页表PTE，发现当前有效位是1，表示VP2已经缓存在了物理内存上，则该PTE存储的地址就是VP2虚拟页所对应的物理页的具体地址\n\n##### 缺页交换\n\n那如果当前PTE有效位为1呢？表示当前VP不在物理内存中，而存储在磁盘上，这就是通常所说的`缺页`，需要根据PTE存储的当前VP的磁盘地址去找到具体的页数据，然后将磁盘上的VP复制回物理内存中，最后修改PTE的有效位和存储的地址值，再交给MMU处理，此时MMU就能正常命中该VP了\n\n具体的缺页处理过程示例如下：\n\n1. MMU需要寻找VP3的具体地址，但有效位是0，触发缺页中断，交给缺页异常处理程序进行处理\n\n![](http://img.mantian.site/201911071501_172.png)\n\n2. 缺页异常处理程序会选择一个牺牲页VP4，将VP4复制到磁盘并修改VP4对应的PTE，将有效位修改为0，并保存VP4的磁盘地址\n3. 随后，异常处理程序将VP3复制到之前存放VP4的物理地址位置，并修改VP3的PTE的有效位和地址值，完成后如下：\n\n![](http://img.mantian.site/201911071508_51.png)\n\n4. 处理完成后，异常处理程序将控制权交还给用户程序，MMU就能正常的命中VP3的物理内存地址了\n\n以上缺页处理的过程称为**按需页面调度**\n\n那向系统新申请一个内存页是什么过程呢？系统会直接在当前虚拟内存对应的磁盘空间上新创建一块区域，并更新这块虚拟内存页对应的PTE，将有效位设置为0并保存对应的磁盘位置，待真正使用这块内存时才进行上述的页面调度过程将需要的虚拟页交换出来\n\n> **局部性原理**：\n>\n> 虚拟内存的页面调度机制看上去性能会很差，毕竟缺页处理的开销很大，其实操作系统利用局部性原理可以将开销压缩到最小，因为在任意时刻应用程序都趋向于在一个较小的工作集（working set）上工作，这个工作集包含了程序使用频率最高的一部分虚拟页，经过一段初始开销后工作集中的虚拟页都被调度到了物理内存中，大部分时候都能命中\n\n#### 多进程的虚拟页管理\n\n操作系统为每个进程单独管理自己的虚拟地址空间和页表，多个进程的不同的虚拟页面还可以映射到同一个共享的物理内存页面上\n\n虚拟地址机制对多进程的内存管理有显而易见的好处：\n\n- 简化程序内存管理：每个进程的虚拟地址空间都具有**相同的内存格式**，比如代码段和数据段等地址段的大小和起始位置都是相同的，不会与其他进程的内存管理产生冲突，并且链接器生成的可执行文件（包含指令的具体地址）也可以独立于物理内存实际的代码和数据位置，提高了可执行文件的移植性\n- 简化加载：操作系统加载文件时，加载器为代码和数据分配虚拟页，将对应页表PTE的有效位设置为0，此时加载器并没有加载实际的数据，待真正使用这部分数据时才从磁盘调用需要的数据页\n- 简化共享：有一部分系统调用代码保存于内核中一个共享的内存区域，并将所有进程虚拟地址空间中适当的虚拟页映射到这块共享的内存区域，这样就避免了每个虚拟内存必须得保存同样的内核代码\n- 简化内存分配：程序调用malloc等申请内存的系统调用时，系统会直接在虚拟内存空间上分配一系列连续的虚拟页给程序，而这部分虚拟页在实际物理内存上极有可能是分散的\n\n#### 内存访问许可\n\n虚拟内存作为程序到真实内存区域的访问媒介，自然就提供了一种保护机制，限制程序对某些内存的访问权限，比如可读或者可写，这些信息以`许可位`的形式保存在页表的PTE中：\n\n![](http://img.mantian.site/201911071640_705.png)\n\n如上，`SUP`表示进程是否必须运行在内核模式下才能访问该页，`READ`表示当前页对进程是否可读，`WRITE`表示当前页对进程是否可写，比如进程j如果运行在用户模式下，就拥有读VP0以及读写VP2的权限，但没有访问VP1的权限\n\n如果某条指令违反许可操作了某页，将会产生`短错误（segmentation fault）`异常\n\n### 地址翻译\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"《深入理解计算机系统》读书笔记——Chapter-8","published":1,"updated":"2021-05-31T03:06:33.201Z","_id":"ckf0h31it0031actsrlairofa","comments":1,"layout":"post","photos":[],"link":"","content":"<p>第九章：虚拟内存</p>\n<p>本章对虚拟内存的知识进行了讲解，虚拟内存是操作系统为进程访问内存数据提供的一层抽象，便于程序更方便地管理属于自己的内存数据<br><a id=\"more\"></a></p>\n<h4 id=\"为什么需要虚拟内存\"><a href=\"#为什么需要虚拟内存\" class=\"headerlink\" title=\"为什么需要虚拟内存\"></a>为什么需要虚拟内存</h4><p> 在以往的认知中，通常都以为程序使用的内存直接就是计算机硬件的那个内存，但如果所有运行的程序直接使用共享内存的话会出现一些问题：</p>\n<ul>\n<li>程序如果能直接访问内存不安全，比如一个进程操作了另一个进程申请的内存，则会发生不可预知的错误，操作系统并不希望一个用户应用程序拥有直接访问内存的权利</li>\n<li>系统中运行的程序太多的话，很容易就会把内存占满了，如果有新启动的程序则无法顺利的获得内存空间，这是需要避免的</li>\n</ul>\n<p>因此，操作系统使用<code>虚拟内存（Vitual Memory）</code>这一概念，对屏蔽了底层实际物理内存，抽象出一层来让用户访问，用户操作的只能是这个虚拟内存地址空间</p>\n<p>在程序看来，就好像自己拥有整个内存空间，而在操作系统的角度看，用户申请和使用哪块内存完全是操作系统虚拟化后的结果，对此，操作系统虚拟内存做了以下工作，来更好的服务于应用程序：</p>\n<ul>\n<li>虚拟内存管理的辖区<strong>不仅限于物理内存</strong>，而且还包括<strong>一部分磁盘空间</strong>，它把物理内存当作磁盘地址空间的一个大型缓存，应用程序的一些不活跃的内存数据会被转移到磁盘上进行存储，也不会存在用户新启动程序而没有足够的内存进行申请的情况，操作系统根据需要在磁盘和内存之间来回传送数据，而这个过程是对用户程序屏蔽的</li>\n<li>虚拟内存为每个进程提供了<strong>一致的地址空间</strong>，简化了应用程序管理内存的过程</li>\n<li>每个进程拥有自己<strong>单独隔离的虚拟地址空间</strong>，不会被其他进程影响</li>\n</ul>\n<h3 id=\"物理寻址和虚拟寻址\"><a href=\"#物理寻址和虚拟寻址\" class=\"headerlink\" title=\"物理寻址和虚拟寻址\"></a>物理寻址和虚拟寻址</h3><p>可以把物理内存看成一个很大的字节数组，每个字节都有一个唯一的数组索引，也就是字节的<code>物理地址</code>，早期计算机都使用物理地址来进行寻址，现代计算机在物理地址空间之上做了一层虚拟话，称之为虚拟内存，现在的程序都是使用<code>虚拟地址（Vitual Address）</code>来管理虚拟内存上存储的字节数据</p>\n<p><img src=\"http://img.mantian.site/201911071134_260.png\" alt></p>\n<p>CPU使用寻你地址发起发起虚拟寻址，需要通过CPU芯片上自带的<code>内存管理单元(MMU)</code>来将虚拟地址翻译为实际的物理地址，而这个地址映射关系存放在主内存中（称之为<code>页表（Page Table）</code>）</p>\n<h3 id=\"地址空间\"><a href=\"#地址空间\" class=\"headerlink\" title=\"地址空间\"></a>地址空间</h3><p>把物理内存比喻成字节数组，那这个数组索引的有序集合就叫<code>物理地址空间</code>，而相应的，虚拟内存地址对应的字节数组的索引有序集合就叫<code>虚拟地址空间</code>，每个进程都有自己对应的<code>虚拟地址空间</code></p>\n<p>系统中允许每个字节数据拥有不同的独立的地址，对应不同的地址空间，比如一个字节数据可以有一个对应物理地址空间的物理地址以及一个对应某个进程虚拟地址空间的虚拟内存地址</p>\n<h3 id=\"虚拟内存的页缓存\"><a href=\"#虚拟内存的页缓存\" class=\"headerlink\" title=\"虚拟内存的页缓存\"></a>虚拟内存的页缓存</h3><p>操作系统将虚拟内存以<code>虚拟页（Vitual Page）</code>的方式进行组织，每一页都是一个大小固定的数据块</p>\n<p>总体上来看，虚拟内存机制是把磁盘作为主要存储区域，而把物理内存作为缓存，相应的，在磁盘和物理内存中就以<code>物理页（Physical Page）</code>的方式来存储虚拟内存保存的页数据，因此一个进程的虚拟地址空间同一时间总会有三个不同的部分：</p>\n<ol>\n<li><code>未分配的虚拟内存</code>：这部分空间是还没有被程序使用的地址空间，从物理上来讲没有与任何一块数据相关联</li>\n<li><code>缓存的虚拟内存页</code>：这部分虚拟页保存在物理内存上</li>\n<li><code>未缓存的虚拟内存页</code>：这部分虚拟页保存在磁盘上</li>\n</ol>\n<p>下图就是描述虚拟内存是如何在磁盘和硬盘上进行组织的，每一格都代表一个虚拟页：</p>\n<p><img src=\"http://img.mantian.site/201911071352_505.png\" alt></p>\n<p>其中<code>未分配的</code>虚拟页不占有任何存储空间，<code>已缓存的</code>虚拟页存储在物理内存上，而剩下的<code>未缓存的</code>虚拟页仍旧保存在磁盘上</p>\n<h4 id=\"页表\"><a href=\"#页表\" class=\"headerlink\" title=\"页表\"></a>页表</h4><p>前文提到，CPU的MMU是根据<code>页表</code>将虚拟地址翻译为具体的物理地址，再根据物理地址寻找具体的数据，操作系统会为每一个进程维护一份与之配套的虚拟地址空间的<code>页表</code></p>\n<p>页表由多个<code>页表条目（Page Table Entry）</code>以及每个条目对应的<code>有效位</code>组成，其中<code>页表条目</code>简称<code>PTE</code>，条目中存储了某个虚拟页的物理地址，而有效位如果为1表示该PTE地址表示的物理内存的地址，为0则表示要么还未分配，要么保存于磁盘上</p>\n<h5 id=\"页命中\"><a href=\"#页命中\" class=\"headerlink\" title=\"页命中\"></a>页命中</h5><p>MMU如何根据页表来寻找虚拟页对应的具体地址？这就是页命中的过程</p>\n<p>页表和当前进程的虚拟内存地址空间总是一一对应的，每一个PTE都对应一个虚拟页（VP），如果想找到虚拟页VP2的具体物理地址，过程如下：</p>\n<p><img src=\"http://img.mantian.site/201911071445_849.png\" alt></p>\n<p>首先找到VP2地址所对应的页表PTE，发现当前有效位是1，表示VP2已经缓存在了物理内存上，则该PTE存储的地址就是VP2虚拟页所对应的物理页的具体地址</p>\n<h5 id=\"缺页交换\"><a href=\"#缺页交换\" class=\"headerlink\" title=\"缺页交换\"></a>缺页交换</h5><p>那如果当前PTE有效位为1呢？表示当前VP不在物理内存中，而存储在磁盘上，这就是通常所说的<code>缺页</code>，需要根据PTE存储的当前VP的磁盘地址去找到具体的页数据，然后将磁盘上的VP复制回物理内存中，最后修改PTE的有效位和存储的地址值，再交给MMU处理，此时MMU就能正常命中该VP了</p>\n<p>具体的缺页处理过程示例如下：</p>\n<ol>\n<li>MMU需要寻找VP3的具体地址，但有效位是0，触发缺页中断，交给缺页异常处理程序进行处理</li>\n</ol>\n<p><img src=\"http://img.mantian.site/201911071501_172.png\" alt></p>\n<ol start=\"2\">\n<li>缺页异常处理程序会选择一个牺牲页VP4，将VP4复制到磁盘并修改VP4对应的PTE，将有效位修改为0，并保存VP4的磁盘地址</li>\n<li>随后，异常处理程序将VP3复制到之前存放VP4的物理地址位置，并修改VP3的PTE的有效位和地址值，完成后如下：</li>\n</ol>\n<p><img src=\"http://img.mantian.site/201911071508_51.png\" alt></p>\n<ol start=\"4\">\n<li>处理完成后，异常处理程序将控制权交还给用户程序，MMU就能正常的命中VP3的物理内存地址了</li>\n</ol>\n<p>以上缺页处理的过程称为<strong>按需页面调度</strong></p>\n<p>那向系统新申请一个内存页是什么过程呢？系统会直接在当前虚拟内存对应的磁盘空间上新创建一块区域，并更新这块虚拟内存页对应的PTE，将有效位设置为0并保存对应的磁盘位置，待真正使用这块内存时才进行上述的页面调度过程将需要的虚拟页交换出来</p>\n<blockquote>\n<p><strong>局部性原理</strong>：</p>\n<p>虚拟内存的页面调度机制看上去性能会很差，毕竟缺页处理的开销很大，其实操作系统利用局部性原理可以将开销压缩到最小，因为在任意时刻应用程序都趋向于在一个较小的工作集（working set）上工作，这个工作集包含了程序使用频率最高的一部分虚拟页，经过一段初始开销后工作集中的虚拟页都被调度到了物理内存中，大部分时候都能命中</p>\n</blockquote>\n<h4 id=\"多进程的虚拟页管理\"><a href=\"#多进程的虚拟页管理\" class=\"headerlink\" title=\"多进程的虚拟页管理\"></a>多进程的虚拟页管理</h4><p>操作系统为每个进程单独管理自己的虚拟地址空间和页表，多个进程的不同的虚拟页面还可以映射到同一个共享的物理内存页面上</p>\n<p>虚拟地址机制对多进程的内存管理有显而易见的好处：</p>\n<ul>\n<li>简化程序内存管理：每个进程的虚拟地址空间都具有<strong>相同的内存格式</strong>，比如代码段和数据段等地址段的大小和起始位置都是相同的，不会与其他进程的内存管理产生冲突，并且链接器生成的可执行文件（包含指令的具体地址）也可以独立于物理内存实际的代码和数据位置，提高了可执行文件的移植性</li>\n<li>简化加载：操作系统加载文件时，加载器为代码和数据分配虚拟页，将对应页表PTE的有效位设置为0，此时加载器并没有加载实际的数据，待真正使用这部分数据时才从磁盘调用需要的数据页</li>\n<li>简化共享：有一部分系统调用代码保存于内核中一个共享的内存区域，并将所有进程虚拟地址空间中适当的虚拟页映射到这块共享的内存区域，这样就避免了每个虚拟内存必须得保存同样的内核代码</li>\n<li>简化内存分配：程序调用malloc等申请内存的系统调用时，系统会直接在虚拟内存空间上分配一系列连续的虚拟页给程序，而这部分虚拟页在实际物理内存上极有可能是分散的</li>\n</ul>\n<h4 id=\"内存访问许可\"><a href=\"#内存访问许可\" class=\"headerlink\" title=\"内存访问许可\"></a>内存访问许可</h4><p>虚拟内存作为程序到真实内存区域的访问媒介，自然就提供了一种保护机制，限制程序对某些内存的访问权限，比如可读或者可写，这些信息以<code>许可位</code>的形式保存在页表的PTE中：</p>\n<p><img src=\"http://img.mantian.site/201911071640_705.png\" alt></p>\n<p>如上，<code>SUP</code>表示进程是否必须运行在内核模式下才能访问该页，<code>READ</code>表示当前页对进程是否可读，<code>WRITE</code>表示当前页对进程是否可写，比如进程j如果运行在用户模式下，就拥有读VP0以及读写VP2的权限，但没有访问VP1的权限</p>\n<p>如果某条指令违反许可操作了某页，将会产生<code>短错误（segmentation fault）</code>异常</p>\n<h3 id=\"地址翻译\"><a href=\"#地址翻译\" class=\"headerlink\" title=\"地址翻译\"></a>地址翻译</h3>","site":{"data":{}},"excerpt":"<p>第九章：虚拟内存</p>\n<p>本章对虚拟内存的知识进行了讲解，虚拟内存是操作系统为进程访问内存数据提供的一层抽象，便于程序更方便地管理属于自己的内存数据<br>","more":"</p>\n<h4 id=\"为什么需要虚拟内存\"><a href=\"#为什么需要虚拟内存\" class=\"headerlink\" title=\"为什么需要虚拟内存\"></a>为什么需要虚拟内存</h4><p> 在以往的认知中，通常都以为程序使用的内存直接就是计算机硬件的那个内存，但如果所有运行的程序直接使用共享内存的话会出现一些问题：</p>\n<ul>\n<li>程序如果能直接访问内存不安全，比如一个进程操作了另一个进程申请的内存，则会发生不可预知的错误，操作系统并不希望一个用户应用程序拥有直接访问内存的权利</li>\n<li>系统中运行的程序太多的话，很容易就会把内存占满了，如果有新启动的程序则无法顺利的获得内存空间，这是需要避免的</li>\n</ul>\n<p>因此，操作系统使用<code>虚拟内存（Vitual Memory）</code>这一概念，对屏蔽了底层实际物理内存，抽象出一层来让用户访问，用户操作的只能是这个虚拟内存地址空间</p>\n<p>在程序看来，就好像自己拥有整个内存空间，而在操作系统的角度看，用户申请和使用哪块内存完全是操作系统虚拟化后的结果，对此，操作系统虚拟内存做了以下工作，来更好的服务于应用程序：</p>\n<ul>\n<li>虚拟内存管理的辖区<strong>不仅限于物理内存</strong>，而且还包括<strong>一部分磁盘空间</strong>，它把物理内存当作磁盘地址空间的一个大型缓存，应用程序的一些不活跃的内存数据会被转移到磁盘上进行存储，也不会存在用户新启动程序而没有足够的内存进行申请的情况，操作系统根据需要在磁盘和内存之间来回传送数据，而这个过程是对用户程序屏蔽的</li>\n<li>虚拟内存为每个进程提供了<strong>一致的地址空间</strong>，简化了应用程序管理内存的过程</li>\n<li>每个进程拥有自己<strong>单独隔离的虚拟地址空间</strong>，不会被其他进程影响</li>\n</ul>\n<h3 id=\"物理寻址和虚拟寻址\"><a href=\"#物理寻址和虚拟寻址\" class=\"headerlink\" title=\"物理寻址和虚拟寻址\"></a>物理寻址和虚拟寻址</h3><p>可以把物理内存看成一个很大的字节数组，每个字节都有一个唯一的数组索引，也就是字节的<code>物理地址</code>，早期计算机都使用物理地址来进行寻址，现代计算机在物理地址空间之上做了一层虚拟话，称之为虚拟内存，现在的程序都是使用<code>虚拟地址（Vitual Address）</code>来管理虚拟内存上存储的字节数据</p>\n<p><img src=\"http://img.mantian.site/201911071134_260.png\" alt></p>\n<p>CPU使用寻你地址发起发起虚拟寻址，需要通过CPU芯片上自带的<code>内存管理单元(MMU)</code>来将虚拟地址翻译为实际的物理地址，而这个地址映射关系存放在主内存中（称之为<code>页表（Page Table）</code>）</p>\n<h3 id=\"地址空间\"><a href=\"#地址空间\" class=\"headerlink\" title=\"地址空间\"></a>地址空间</h3><p>把物理内存比喻成字节数组，那这个数组索引的有序集合就叫<code>物理地址空间</code>，而相应的，虚拟内存地址对应的字节数组的索引有序集合就叫<code>虚拟地址空间</code>，每个进程都有自己对应的<code>虚拟地址空间</code></p>\n<p>系统中允许每个字节数据拥有不同的独立的地址，对应不同的地址空间，比如一个字节数据可以有一个对应物理地址空间的物理地址以及一个对应某个进程虚拟地址空间的虚拟内存地址</p>\n<h3 id=\"虚拟内存的页缓存\"><a href=\"#虚拟内存的页缓存\" class=\"headerlink\" title=\"虚拟内存的页缓存\"></a>虚拟内存的页缓存</h3><p>操作系统将虚拟内存以<code>虚拟页（Vitual Page）</code>的方式进行组织，每一页都是一个大小固定的数据块</p>\n<p>总体上来看，虚拟内存机制是把磁盘作为主要存储区域，而把物理内存作为缓存，相应的，在磁盘和物理内存中就以<code>物理页（Physical Page）</code>的方式来存储虚拟内存保存的页数据，因此一个进程的虚拟地址空间同一时间总会有三个不同的部分：</p>\n<ol>\n<li><code>未分配的虚拟内存</code>：这部分空间是还没有被程序使用的地址空间，从物理上来讲没有与任何一块数据相关联</li>\n<li><code>缓存的虚拟内存页</code>：这部分虚拟页保存在物理内存上</li>\n<li><code>未缓存的虚拟内存页</code>：这部分虚拟页保存在磁盘上</li>\n</ol>\n<p>下图就是描述虚拟内存是如何在磁盘和硬盘上进行组织的，每一格都代表一个虚拟页：</p>\n<p><img src=\"http://img.mantian.site/201911071352_505.png\" alt></p>\n<p>其中<code>未分配的</code>虚拟页不占有任何存储空间，<code>已缓存的</code>虚拟页存储在物理内存上，而剩下的<code>未缓存的</code>虚拟页仍旧保存在磁盘上</p>\n<h4 id=\"页表\"><a href=\"#页表\" class=\"headerlink\" title=\"页表\"></a>页表</h4><p>前文提到，CPU的MMU是根据<code>页表</code>将虚拟地址翻译为具体的物理地址，再根据物理地址寻找具体的数据，操作系统会为每一个进程维护一份与之配套的虚拟地址空间的<code>页表</code></p>\n<p>页表由多个<code>页表条目（Page Table Entry）</code>以及每个条目对应的<code>有效位</code>组成，其中<code>页表条目</code>简称<code>PTE</code>，条目中存储了某个虚拟页的物理地址，而有效位如果为1表示该PTE地址表示的物理内存的地址，为0则表示要么还未分配，要么保存于磁盘上</p>\n<h5 id=\"页命中\"><a href=\"#页命中\" class=\"headerlink\" title=\"页命中\"></a>页命中</h5><p>MMU如何根据页表来寻找虚拟页对应的具体地址？这就是页命中的过程</p>\n<p>页表和当前进程的虚拟内存地址空间总是一一对应的，每一个PTE都对应一个虚拟页（VP），如果想找到虚拟页VP2的具体物理地址，过程如下：</p>\n<p><img src=\"http://img.mantian.site/201911071445_849.png\" alt></p>\n<p>首先找到VP2地址所对应的页表PTE，发现当前有效位是1，表示VP2已经缓存在了物理内存上，则该PTE存储的地址就是VP2虚拟页所对应的物理页的具体地址</p>\n<h5 id=\"缺页交换\"><a href=\"#缺页交换\" class=\"headerlink\" title=\"缺页交换\"></a>缺页交换</h5><p>那如果当前PTE有效位为1呢？表示当前VP不在物理内存中，而存储在磁盘上，这就是通常所说的<code>缺页</code>，需要根据PTE存储的当前VP的磁盘地址去找到具体的页数据，然后将磁盘上的VP复制回物理内存中，最后修改PTE的有效位和存储的地址值，再交给MMU处理，此时MMU就能正常命中该VP了</p>\n<p>具体的缺页处理过程示例如下：</p>\n<ol>\n<li>MMU需要寻找VP3的具体地址，但有效位是0，触发缺页中断，交给缺页异常处理程序进行处理</li>\n</ol>\n<p><img src=\"http://img.mantian.site/201911071501_172.png\" alt></p>\n<ol start=\"2\">\n<li>缺页异常处理程序会选择一个牺牲页VP4，将VP4复制到磁盘并修改VP4对应的PTE，将有效位修改为0，并保存VP4的磁盘地址</li>\n<li>随后，异常处理程序将VP3复制到之前存放VP4的物理地址位置，并修改VP3的PTE的有效位和地址值，完成后如下：</li>\n</ol>\n<p><img src=\"http://img.mantian.site/201911071508_51.png\" alt></p>\n<ol start=\"4\">\n<li>处理完成后，异常处理程序将控制权交还给用户程序，MMU就能正常的命中VP3的物理内存地址了</li>\n</ol>\n<p>以上缺页处理的过程称为<strong>按需页面调度</strong></p>\n<p>那向系统新申请一个内存页是什么过程呢？系统会直接在当前虚拟内存对应的磁盘空间上新创建一块区域，并更新这块虚拟内存页对应的PTE，将有效位设置为0并保存对应的磁盘位置，待真正使用这块内存时才进行上述的页面调度过程将需要的虚拟页交换出来</p>\n<blockquote>\n<p><strong>局部性原理</strong>：</p>\n<p>虚拟内存的页面调度机制看上去性能会很差，毕竟缺页处理的开销很大，其实操作系统利用局部性原理可以将开销压缩到最小，因为在任意时刻应用程序都趋向于在一个较小的工作集（working set）上工作，这个工作集包含了程序使用频率最高的一部分虚拟页，经过一段初始开销后工作集中的虚拟页都被调度到了物理内存中，大部分时候都能命中</p>\n</blockquote>\n<h4 id=\"多进程的虚拟页管理\"><a href=\"#多进程的虚拟页管理\" class=\"headerlink\" title=\"多进程的虚拟页管理\"></a>多进程的虚拟页管理</h4><p>操作系统为每个进程单独管理自己的虚拟地址空间和页表，多个进程的不同的虚拟页面还可以映射到同一个共享的物理内存页面上</p>\n<p>虚拟地址机制对多进程的内存管理有显而易见的好处：</p>\n<ul>\n<li>简化程序内存管理：每个进程的虚拟地址空间都具有<strong>相同的内存格式</strong>，比如代码段和数据段等地址段的大小和起始位置都是相同的，不会与其他进程的内存管理产生冲突，并且链接器生成的可执行文件（包含指令的具体地址）也可以独立于物理内存实际的代码和数据位置，提高了可执行文件的移植性</li>\n<li>简化加载：操作系统加载文件时，加载器为代码和数据分配虚拟页，将对应页表PTE的有效位设置为0，此时加载器并没有加载实际的数据，待真正使用这部分数据时才从磁盘调用需要的数据页</li>\n<li>简化共享：有一部分系统调用代码保存于内核中一个共享的内存区域，并将所有进程虚拟地址空间中适当的虚拟页映射到这块共享的内存区域，这样就避免了每个虚拟内存必须得保存同样的内核代码</li>\n<li>简化内存分配：程序调用malloc等申请内存的系统调用时，系统会直接在虚拟内存空间上分配一系列连续的虚拟页给程序，而这部分虚拟页在实际物理内存上极有可能是分散的</li>\n</ul>\n<h4 id=\"内存访问许可\"><a href=\"#内存访问许可\" class=\"headerlink\" title=\"内存访问许可\"></a>内存访问许可</h4><p>虚拟内存作为程序到真实内存区域的访问媒介，自然就提供了一种保护机制，限制程序对某些内存的访问权限，比如可读或者可写，这些信息以<code>许可位</code>的形式保存在页表的PTE中：</p>\n<p><img src=\"http://img.mantian.site/201911071640_705.png\" alt></p>\n<p>如上，<code>SUP</code>表示进程是否必须运行在内核模式下才能访问该页，<code>READ</code>表示当前页对进程是否可读，<code>WRITE</code>表示当前页对进程是否可写，比如进程j如果运行在用户模式下，就拥有读VP0以及读写VP2的权限，但没有访问VP1的权限</p>\n<p>如果某条指令违反许可操作了某页，将会产生<code>短错误（segmentation fault）</code>异常</p>\n<h3 id=\"地址翻译\"><a href=\"#地址翻译\" class=\"headerlink\" title=\"地址翻译\"></a>地址翻译</h3>"},{"title":"《深入理解计算机系统》读书笔记——Chapter 12(1)","author":"天渊","date":"2019-12-15T04:47:00.000Z","_content":"何为并发？CPU处理指令时的逻辑控制流在时间上重叠就是`并发（Concurrency）`，计算机系统大量存在这种异步处理的情况，例如在进行耗时I/O操作时CPU会同时运行其他程序来提高CPU利用率，或者计算机响应人机交互时的异步事件，或者一个并发的web服务器可以同时处理多个client请求\n<!--more-->\n### 多进程并发编程\n\n像Apache或者Nginx这样的web服务器是基于多进程并发模型以支持大规模的网络请求\n\n多进程模型的web服务器在处理多个请求时大致过程如下：\n\n1. 主进程监听一个server socket描述符`3`，接受一个客户端请求，生成一个client socket连接描述符`4`\n2. 主进程fork一个子进程，该子进程拥有父进程描述符表的拷贝\n3. 子进程不需要监听描述符`3`，关闭这个描述符，使用描述符`4`与客户端通信\n4. 主进程不需要与客户端通信，关闭连接描述符`4`，继续监听描述符`3`\n\n在这个过程中，父进程关闭分配给子进程的描述符`4`这个操作至关重要，否则会内存泄漏\n\n按照以上过程，父进程持续不断地监听客户端请求并 fork子进程，多个子进程并发地为客户端服务\n\n> 进程的优劣：\n>\n> 父进程和子进程拥有各自独立的描述符表，共享文件表，由于是不同的进程因此拥有相互隔离的虚拟地址空间，这么做既有好处又有坏处，好处是不用担心父子进程相互覆盖对方的虚拟内存，但缺点在于不同的进程想要通信的话只能通过IPC进程间通信，开销较高\n\n### I/O多路复用并发编程\n\nI/O多路复用的优点在于同一个进程能够响应多个I/O事件，不至于因为处理某个连接的读或写阻塞了，而耽误对其他连接的处理\n\n传统的多路复用编程使用`select`函数，内核会在进程注册了select后将进程挂起，只有当一个或者多个连接产生了I/O事件后才将控制权返还给进程，此时进程就可以对这些就绪的I/O事件进程处理，这些事件既可以是read事件也可以write事件，还可以是connect事件，这种方式就是`并发事件驱动(event--driven)`\n\n`select`函数在检测到描述符集合中的某个描述符产生了新的状态，就会立即返回，用户需要遍历这个描述符集合中的每个描述符来判断哪个描述符产生了事件，并进行处理\n\n> select的方式需要用户自己轮询判断哪个描述符产生了事件，而且对最大描述符数有限制（默认是1024），因此后续在Linux平台上产生了更加好用epoll方式，epoll是真正的事件驱动模型，调用epoll后，内核会把具体哪个流产生了什么样的事件告诉给用户，极大地提高了性能\n\n#### I/O多路复用技术的优劣\n\n多路复用技术一个很明显的优点就是在单个进程中就能处理多个client的请求，并且多个I/O流可以共享进程上下文，使得共享数据变得更容易，并且不用开启多个进程处理请求使得资源利用率更高\n\n但多路复用技术在提高了性能的同时带来了编码的复杂度，并且如果当前进程在处理某个I/O流时耗时过长，会耽误对其他client请求的处理\n\n### 多线程并发编程\n\n现代操作系统中，一个进程可以包含多个`线程(thread)`，每个线程都有自己的上下文：线程ID，栈，栈指针，程序计数器等\n\n多个线程在进行工作时，操作系统同样会进行基于时间片的线程上下文切换，保证一个线程不会因为耗时任务而占用太多的CPU时间\n\n在C语言中，多线程是基于`Posix`标准的`pthread`进行编程，由于Java线程模型也是基于操作系统线程模型的，因此和C语言线程模型差别不大，在Java中的`new Thread()`创建的线程相当于当前线程调用`pthread_create()`函数生成子线程，在该子线程终止后需要主线程回收子线程的内存资源，主线程通过`pthread_join()`函数等待子线程运行结束并回收资源\n\n在`Posix`线程模型中还有一个分离线程的方式来生成一个新的线程`pthread_detach()`，这个新线程是不可join的，也不能被主线程杀死，不过优点就是该新线程的资源可以由操作系统回收","source":"_posts/《深入理解计算机系统》读书笔记——Chapter-12-1.md","raw":"title: 《深入理解计算机系统》读书笔记——Chapter 12(1)\nauthor: 天渊\ntags:\n  - csapp\ncategories:\n  - 读书笔记\ndate: 2019-12-15 12:47:00\n---\n何为并发？CPU处理指令时的逻辑控制流在时间上重叠就是`并发（Concurrency）`，计算机系统大量存在这种异步处理的情况，例如在进行耗时I/O操作时CPU会同时运行其他程序来提高CPU利用率，或者计算机响应人机交互时的异步事件，或者一个并发的web服务器可以同时处理多个client请求\n<!--more-->\n### 多进程并发编程\n\n像Apache或者Nginx这样的web服务器是基于多进程并发模型以支持大规模的网络请求\n\n多进程模型的web服务器在处理多个请求时大致过程如下：\n\n1. 主进程监听一个server socket描述符`3`，接受一个客户端请求，生成一个client socket连接描述符`4`\n2. 主进程fork一个子进程，该子进程拥有父进程描述符表的拷贝\n3. 子进程不需要监听描述符`3`，关闭这个描述符，使用描述符`4`与客户端通信\n4. 主进程不需要与客户端通信，关闭连接描述符`4`，继续监听描述符`3`\n\n在这个过程中，父进程关闭分配给子进程的描述符`4`这个操作至关重要，否则会内存泄漏\n\n按照以上过程，父进程持续不断地监听客户端请求并 fork子进程，多个子进程并发地为客户端服务\n\n> 进程的优劣：\n>\n> 父进程和子进程拥有各自独立的描述符表，共享文件表，由于是不同的进程因此拥有相互隔离的虚拟地址空间，这么做既有好处又有坏处，好处是不用担心父子进程相互覆盖对方的虚拟内存，但缺点在于不同的进程想要通信的话只能通过IPC进程间通信，开销较高\n\n### I/O多路复用并发编程\n\nI/O多路复用的优点在于同一个进程能够响应多个I/O事件，不至于因为处理某个连接的读或写阻塞了，而耽误对其他连接的处理\n\n传统的多路复用编程使用`select`函数，内核会在进程注册了select后将进程挂起，只有当一个或者多个连接产生了I/O事件后才将控制权返还给进程，此时进程就可以对这些就绪的I/O事件进程处理，这些事件既可以是read事件也可以write事件，还可以是connect事件，这种方式就是`并发事件驱动(event--driven)`\n\n`select`函数在检测到描述符集合中的某个描述符产生了新的状态，就会立即返回，用户需要遍历这个描述符集合中的每个描述符来判断哪个描述符产生了事件，并进行处理\n\n> select的方式需要用户自己轮询判断哪个描述符产生了事件，而且对最大描述符数有限制（默认是1024），因此后续在Linux平台上产生了更加好用epoll方式，epoll是真正的事件驱动模型，调用epoll后，内核会把具体哪个流产生了什么样的事件告诉给用户，极大地提高了性能\n\n#### I/O多路复用技术的优劣\n\n多路复用技术一个很明显的优点就是在单个进程中就能处理多个client的请求，并且多个I/O流可以共享进程上下文，使得共享数据变得更容易，并且不用开启多个进程处理请求使得资源利用率更高\n\n但多路复用技术在提高了性能的同时带来了编码的复杂度，并且如果当前进程在处理某个I/O流时耗时过长，会耽误对其他client请求的处理\n\n### 多线程并发编程\n\n现代操作系统中，一个进程可以包含多个`线程(thread)`，每个线程都有自己的上下文：线程ID，栈，栈指针，程序计数器等\n\n多个线程在进行工作时，操作系统同样会进行基于时间片的线程上下文切换，保证一个线程不会因为耗时任务而占用太多的CPU时间\n\n在C语言中，多线程是基于`Posix`标准的`pthread`进行编程，由于Java线程模型也是基于操作系统线程模型的，因此和C语言线程模型差别不大，在Java中的`new Thread()`创建的线程相当于当前线程调用`pthread_create()`函数生成子线程，在该子线程终止后需要主线程回收子线程的内存资源，主线程通过`pthread_join()`函数等待子线程运行结束并回收资源\n\n在`Posix`线程模型中还有一个分离线程的方式来生成一个新的线程`pthread_detach()`，这个新线程是不可join的，也不能被主线程杀死，不过优点就是该新线程的资源可以由操作系统回收","slug":"《深入理解计算机系统》读书笔记——Chapter-12-1","published":1,"updated":"2019-12-15T04:48:39.684Z","_id":"ckf0h31iu0034actsj11c3w2r","comments":1,"layout":"post","photos":[],"link":"","content":"<p>何为并发？CPU处理指令时的逻辑控制流在时间上重叠就是<code>并发（Concurrency）</code>，计算机系统大量存在这种异步处理的情况，例如在进行耗时I/O操作时CPU会同时运行其他程序来提高CPU利用率，或者计算机响应人机交互时的异步事件，或者一个并发的web服务器可以同时处理多个client请求<br><a id=\"more\"></a></p>\n<h3 id=\"多进程并发编程\"><a href=\"#多进程并发编程\" class=\"headerlink\" title=\"多进程并发编程\"></a>多进程并发编程</h3><p>像Apache或者Nginx这样的web服务器是基于多进程并发模型以支持大规模的网络请求</p>\n<p>多进程模型的web服务器在处理多个请求时大致过程如下：</p>\n<ol>\n<li>主进程监听一个server socket描述符<code>3</code>，接受一个客户端请求，生成一个client socket连接描述符<code>4</code></li>\n<li>主进程fork一个子进程，该子进程拥有父进程描述符表的拷贝</li>\n<li>子进程不需要监听描述符<code>3</code>，关闭这个描述符，使用描述符<code>4</code>与客户端通信</li>\n<li>主进程不需要与客户端通信，关闭连接描述符<code>4</code>，继续监听描述符<code>3</code></li>\n</ol>\n<p>在这个过程中，父进程关闭分配给子进程的描述符<code>4</code>这个操作至关重要，否则会内存泄漏</p>\n<p>按照以上过程，父进程持续不断地监听客户端请求并 fork子进程，多个子进程并发地为客户端服务</p>\n<blockquote>\n<p>进程的优劣：</p>\n<p>父进程和子进程拥有各自独立的描述符表，共享文件表，由于是不同的进程因此拥有相互隔离的虚拟地址空间，这么做既有好处又有坏处，好处是不用担心父子进程相互覆盖对方的虚拟内存，但缺点在于不同的进程想要通信的话只能通过IPC进程间通信，开销较高</p>\n</blockquote>\n<h3 id=\"I-O多路复用并发编程\"><a href=\"#I-O多路复用并发编程\" class=\"headerlink\" title=\"I/O多路复用并发编程\"></a>I/O多路复用并发编程</h3><p>I/O多路复用的优点在于同一个进程能够响应多个I/O事件，不至于因为处理某个连接的读或写阻塞了，而耽误对其他连接的处理</p>\n<p>传统的多路复用编程使用<code>select</code>函数，内核会在进程注册了select后将进程挂起，只有当一个或者多个连接产生了I/O事件后才将控制权返还给进程，此时进程就可以对这些就绪的I/O事件进程处理，这些事件既可以是read事件也可以write事件，还可以是connect事件，这种方式就是<code>并发事件驱动(event--driven)</code></p>\n<p><code>select</code>函数在检测到描述符集合中的某个描述符产生了新的状态，就会立即返回，用户需要遍历这个描述符集合中的每个描述符来判断哪个描述符产生了事件，并进行处理</p>\n<blockquote>\n<p>select的方式需要用户自己轮询判断哪个描述符产生了事件，而且对最大描述符数有限制（默认是1024），因此后续在Linux平台上产生了更加好用epoll方式，epoll是真正的事件驱动模型，调用epoll后，内核会把具体哪个流产生了什么样的事件告诉给用户，极大地提高了性能</p>\n</blockquote>\n<h4 id=\"I-O多路复用技术的优劣\"><a href=\"#I-O多路复用技术的优劣\" class=\"headerlink\" title=\"I/O多路复用技术的优劣\"></a>I/O多路复用技术的优劣</h4><p>多路复用技术一个很明显的优点就是在单个进程中就能处理多个client的请求，并且多个I/O流可以共享进程上下文，使得共享数据变得更容易，并且不用开启多个进程处理请求使得资源利用率更高</p>\n<p>但多路复用技术在提高了性能的同时带来了编码的复杂度，并且如果当前进程在处理某个I/O流时耗时过长，会耽误对其他client请求的处理</p>\n<h3 id=\"多线程并发编程\"><a href=\"#多线程并发编程\" class=\"headerlink\" title=\"多线程并发编程\"></a>多线程并发编程</h3><p>现代操作系统中，一个进程可以包含多个<code>线程(thread)</code>，每个线程都有自己的上下文：线程ID，栈，栈指针，程序计数器等</p>\n<p>多个线程在进行工作时，操作系统同样会进行基于时间片的线程上下文切换，保证一个线程不会因为耗时任务而占用太多的CPU时间</p>\n<p>在C语言中，多线程是基于<code>Posix</code>标准的<code>pthread</code>进行编程，由于Java线程模型也是基于操作系统线程模型的，因此和C语言线程模型差别不大，在Java中的<code>new Thread()</code>创建的线程相当于当前线程调用<code>pthread_create()</code>函数生成子线程，在该子线程终止后需要主线程回收子线程的内存资源，主线程通过<code>pthread_join()</code>函数等待子线程运行结束并回收资源</p>\n<p>在<code>Posix</code>线程模型中还有一个分离线程的方式来生成一个新的线程<code>pthread_detach()</code>，这个新线程是不可join的，也不能被主线程杀死，不过优点就是该新线程的资源可以由操作系统回收</p>\n","site":{"data":{}},"excerpt":"<p>何为并发？CPU处理指令时的逻辑控制流在时间上重叠就是<code>并发（Concurrency）</code>，计算机系统大量存在这种异步处理的情况，例如在进行耗时I/O操作时CPU会同时运行其他程序来提高CPU利用率，或者计算机响应人机交互时的异步事件，或者一个并发的web服务器可以同时处理多个client请求<br>","more":"</p>\n<h3 id=\"多进程并发编程\"><a href=\"#多进程并发编程\" class=\"headerlink\" title=\"多进程并发编程\"></a>多进程并发编程</h3><p>像Apache或者Nginx这样的web服务器是基于多进程并发模型以支持大规模的网络请求</p>\n<p>多进程模型的web服务器在处理多个请求时大致过程如下：</p>\n<ol>\n<li>主进程监听一个server socket描述符<code>3</code>，接受一个客户端请求，生成一个client socket连接描述符<code>4</code></li>\n<li>主进程fork一个子进程，该子进程拥有父进程描述符表的拷贝</li>\n<li>子进程不需要监听描述符<code>3</code>，关闭这个描述符，使用描述符<code>4</code>与客户端通信</li>\n<li>主进程不需要与客户端通信，关闭连接描述符<code>4</code>，继续监听描述符<code>3</code></li>\n</ol>\n<p>在这个过程中，父进程关闭分配给子进程的描述符<code>4</code>这个操作至关重要，否则会内存泄漏</p>\n<p>按照以上过程，父进程持续不断地监听客户端请求并 fork子进程，多个子进程并发地为客户端服务</p>\n<blockquote>\n<p>进程的优劣：</p>\n<p>父进程和子进程拥有各自独立的描述符表，共享文件表，由于是不同的进程因此拥有相互隔离的虚拟地址空间，这么做既有好处又有坏处，好处是不用担心父子进程相互覆盖对方的虚拟内存，但缺点在于不同的进程想要通信的话只能通过IPC进程间通信，开销较高</p>\n</blockquote>\n<h3 id=\"I-O多路复用并发编程\"><a href=\"#I-O多路复用并发编程\" class=\"headerlink\" title=\"I/O多路复用并发编程\"></a>I/O多路复用并发编程</h3><p>I/O多路复用的优点在于同一个进程能够响应多个I/O事件，不至于因为处理某个连接的读或写阻塞了，而耽误对其他连接的处理</p>\n<p>传统的多路复用编程使用<code>select</code>函数，内核会在进程注册了select后将进程挂起，只有当一个或者多个连接产生了I/O事件后才将控制权返还给进程，此时进程就可以对这些就绪的I/O事件进程处理，这些事件既可以是read事件也可以write事件，还可以是connect事件，这种方式就是<code>并发事件驱动(event--driven)</code></p>\n<p><code>select</code>函数在检测到描述符集合中的某个描述符产生了新的状态，就会立即返回，用户需要遍历这个描述符集合中的每个描述符来判断哪个描述符产生了事件，并进行处理</p>\n<blockquote>\n<p>select的方式需要用户自己轮询判断哪个描述符产生了事件，而且对最大描述符数有限制（默认是1024），因此后续在Linux平台上产生了更加好用epoll方式，epoll是真正的事件驱动模型，调用epoll后，内核会把具体哪个流产生了什么样的事件告诉给用户，极大地提高了性能</p>\n</blockquote>\n<h4 id=\"I-O多路复用技术的优劣\"><a href=\"#I-O多路复用技术的优劣\" class=\"headerlink\" title=\"I/O多路复用技术的优劣\"></a>I/O多路复用技术的优劣</h4><p>多路复用技术一个很明显的优点就是在单个进程中就能处理多个client的请求，并且多个I/O流可以共享进程上下文，使得共享数据变得更容易，并且不用开启多个进程处理请求使得资源利用率更高</p>\n<p>但多路复用技术在提高了性能的同时带来了编码的复杂度，并且如果当前进程在处理某个I/O流时耗时过长，会耽误对其他client请求的处理</p>\n<h3 id=\"多线程并发编程\"><a href=\"#多线程并发编程\" class=\"headerlink\" title=\"多线程并发编程\"></a>多线程并发编程</h3><p>现代操作系统中，一个进程可以包含多个<code>线程(thread)</code>，每个线程都有自己的上下文：线程ID，栈，栈指针，程序计数器等</p>\n<p>多个线程在进行工作时，操作系统同样会进行基于时间片的线程上下文切换，保证一个线程不会因为耗时任务而占用太多的CPU时间</p>\n<p>在C语言中，多线程是基于<code>Posix</code>标准的<code>pthread</code>进行编程，由于Java线程模型也是基于操作系统线程模型的，因此和C语言线程模型差别不大，在Java中的<code>new Thread()</code>创建的线程相当于当前线程调用<code>pthread_create()</code>函数生成子线程，在该子线程终止后需要主线程回收子线程的内存资源，主线程通过<code>pthread_join()</code>函数等待子线程运行结束并回收资源</p>\n<p>在<code>Posix</code>线程模型中还有一个分离线程的方式来生成一个新的线程<code>pthread_detach()</code>，这个新线程是不可join的，也不能被主线程杀死，不过优点就是该新线程的资源可以由操作系统回收</p>"},{"title":"自定义类加载器实践","author":"天渊","date":"2019-04-23T14:11:00.000Z","_content":"在进行java编程时，一般情况下不需要指定类加载器，jvm会根据需要加载的类自动选择合适的类加载器，不过在某些情况下就需要自定义类加载器实现对不同类别，不同来源或者不同版本的类分别进行加载，例如在tomcat中针对用户类库和tomcat自己的核心类库就实现了不同的类加载器\n\n<!-- more -->\n\n### 自定义ClassLoader\n\n#### 双亲委派\n\n实现自定义类加载器之前需要先了解`双亲委派`模式，jvm通过这个机制保证特定的类只能有特定的类加载器来加载\n\n每个类加载器都会指定一个父类加载器，收到加载任务后会提交给父类加载器进行加载，如果父类加载器加载不了则再交给当前类加载进行加载，目前默认的三种主要的类加载器如下：\n\n- `BootstrapClassLoader`：启动类加载器，复杂加载最为基础和重要的类，例如`$JAVA_HOME/jre/lib`目录下的类，以及虚拟机参数`Xbootclasspat`指定的类\n- `ExtClassLoader`：扩展类加载器，用于加载java类库中的扩展类库，即`$JAVA_HOME/jre/lib/ext`目录下的类，以及系统变量`java.ext.dirs`指定的类\n- `AppClassLoader`：应用类加载器，用于加载用户classpath下的所有类，用自己编写的类或者导入的第三方类库默认情况下都由应用类加载器进行加载\n\n在`ClassLoader`类（除BootstrapClassLoader外的所有类加载器均继承自这个类）中，`loadClass`方法的一部分源码如下：\n\n```java\nprotected Class<?> loadClass(String name, boolean resolve)\n    throws ClassNotFoundException {\n    synchronized (getClassLoadingLock(name)) {\n        // 检查这个类是不是已经被当前类加载器加载过了\n        Class<?> c = findLoadedClass(name);\n        if (c == null) {\n            long t0 = System.nanoTime();\n            try {\n                if (parent != null) {\n                    // 交给父加载器进行加载\n                    c = parent.loadClass(name, false);\n                } else {\n                    // 父加载器为空，则交给BootstrapClassLoader进行加载\n                    c = findBootstrapClassOrNull(name);\n                }\n            } catch (ClassNotFoundException e) {\n                // 父类加载器或者启动加载器都加载不了这个类\n            }\n            if (c == null) {               \n                long t1 = System.nanoTime();\n                // 调用findClass方法寻找需要加载的类\n                c = findClass(name);\n            }\n        }\n        // 如果需要解析，则对该类进行解析\n        if (resolve) {\n            resolveClass(c);\n        }\n        return c;\n    }\n}\n```\n\n可以看出，类加载器在拿到加载任务后，会交由父加载器进行加载，如果父加载器为null则直接交给启动类加载器进行加载（可以把启动类加载器看作所有加载器的父加载器），如果都加载不了，最后再由自己加载，调用`findClass`方法加载当前类，最后再判断是否需要解析\n\n在`ClassLoader`中默认的`findClass`方法默认抛出异常，需要子类自己去实现，如果要实现自己的类加载器就必须要重写`findClass`方法，如果要打破`双亲委派`模式（即加载类的时候不交给父加载器或者启动类加载器）的话，还需要额外重写`loadClass`方法\n\n##### 为何不能打破双亲委派模式\n\n在之前的例子中，自定义类加载器`SelfClassloader`没有重写`loadClass`方法，因此调用该方法加载类时会首先交给父加载器进行加载，由于父加载器为null，会交由`BootstrapClassLoader`进行加载\n\n在不打破双亲委派模式的情况下，用户无法自己额外伪造一个java核心类库中的类（例如`java.lang.String`）进行加载，因此保证了安全性\n\n##### 什么情况下需要打破双亲委派模式\n\n\n\n#### 重写findClass方法\n\n不打破双亲委派模式，将parent设置为null（此时父加载器为`BootstrapClassLoader`），创建自定义类加载器`SelfClassLoader`，重写`findClass`方法：\n\n```java\npublic class SelfClassLoader extends ClassLoader {\n\tprivate String root;\n    /**\n    * 指定这个类加载器可以加载的类的根路径\n    */\n\tpublic SelfClassLoader(String root) {\n\t\tsuper(null);\n\t\tthis.root = root;\n\t}\n\n\t@Override\n\tpublic Class<?> loadClass(String name) throws ClassNotFoundException {\n\t\treturn super.loadClass(name);\n\t}\n\n\t@Override\n\tprotected Class<?> findClass(String name) throws ClassNotFoundException {\n\t\tFile file;\n        // 将类名转换为path\n\t\tString path = root + name.replace('.', '/').concat(\".class\");\n\t\tfile = new File(path);\n\t\tif (!file.exists()) {\n\t\t\tthrow new ClassNotFoundException(name);\n\t\t}\n\t\tClass<?> clazz;\n\t\ttry {\n            // 读取字节码并调用defineClass方法加载类\n\t\t\tInputStream inputStream = new FileInputStream(file);\n\t\t\tbyte[] bytes = new byte[inputStream.available()];\n\t\t\tint result = inputStream.read(bytes);\n\t\t\tclazz = defineClass(null, bytes, 0, result);\n\t\t} catch (IOException e) {\n\t\t\tthrow new ClassNotFoundException(name, e);\n\t\t}\n\t\treturn clazz;\n\t}\n}\n```\n\n#### 加载指定类\n\n先创建一个类叫`People`，放到桌面的self_class文件夹中：\n\n```java\npublic class People {\n    public String name;\n    public int age;\n}\n```\n\n`SelfClassLoader`这个类加载器用于加载用户指定路径下的类，如下例子指定这个类加载器只能加载位于桌面self_class文件夹中的`.class`文件：\n\n```java\npublic static void main(String[] args) throws Exception {\n    // 指定根路径\n    SelfClassLoader selfClassLoader = new SelfClassLoader(\"C:\\\\Users\\\\admin\\\\Desktop\\\\self_class\\\\\");\n    // 加载该路径下的People这个类\n    Class<?> clazzCustomized = selfClassLoader.loadClass(\"People\");\n    Object instanceCustomized = clazzCustomized.newInstance();\n    Field field1 = clazzCustomized.getField(\"name\");\n    Field field2 = clazzCustomized.getField(\"age\");\n    field1.set(instanceCustomized, \"mike\");\n    field2.set(instanceCustomized, 18);\n    System.out.println(\"name is \" + field1.get(instanceCustomized));\n    System.out.println(\"age is \" + field2.get(instanceCustomized));\n}\n```\n\n#### 类隔离\n\n用自定义类加载器加载的类能够实现与系统默认类加载器（或者是其他的自定义类加载器）的隔离，现在来与系统默认类加载器加载的同一个类进行对比\n\n把People类拷贝一份放到项目classpath中：\n\n```java\n// 这个People类是AppClassLoader加载的\nClass<?> clazzDefault = Class.forName(\"People\");\nObject instanceDefault = clazzDefault.newInstance();\nSystem.out.println(clazzDefault.isInstance(instanceCustomized));\nSystem.out.println(clazzDefault.isInstance(instanceDefault));\nSystem.out.println(instanceCustomized instanceof People);\nSystem.out.println(instanceDefault instanceof People);\n```\n\n打印结果：\n\n> false\n\n> true\n\n> false\n\n> true\n\nclazzDefault由系统默认类加载器（也就是`AppClassLoader`）加载，与自定义类加载器加载的clazzCustomized很显然不是同一个类，这样就实现了不同来源类的隔离\n","source":"_posts/自定义类加载器实践.md","raw":"title: 自定义类加载器实践\nauthor: 天渊\ntags:\n  - java\n  - 类加载器\ncategories:\n  - 基础知识\ndate: 2019-04-23 22:11:00\n---\n在进行java编程时，一般情况下不需要指定类加载器，jvm会根据需要加载的类自动选择合适的类加载器，不过在某些情况下就需要自定义类加载器实现对不同类别，不同来源或者不同版本的类分别进行加载，例如在tomcat中针对用户类库和tomcat自己的核心类库就实现了不同的类加载器\n\n<!-- more -->\n\n### 自定义ClassLoader\n\n#### 双亲委派\n\n实现自定义类加载器之前需要先了解`双亲委派`模式，jvm通过这个机制保证特定的类只能有特定的类加载器来加载\n\n每个类加载器都会指定一个父类加载器，收到加载任务后会提交给父类加载器进行加载，如果父类加载器加载不了则再交给当前类加载进行加载，目前默认的三种主要的类加载器如下：\n\n- `BootstrapClassLoader`：启动类加载器，复杂加载最为基础和重要的类，例如`$JAVA_HOME/jre/lib`目录下的类，以及虚拟机参数`Xbootclasspat`指定的类\n- `ExtClassLoader`：扩展类加载器，用于加载java类库中的扩展类库，即`$JAVA_HOME/jre/lib/ext`目录下的类，以及系统变量`java.ext.dirs`指定的类\n- `AppClassLoader`：应用类加载器，用于加载用户classpath下的所有类，用自己编写的类或者导入的第三方类库默认情况下都由应用类加载器进行加载\n\n在`ClassLoader`类（除BootstrapClassLoader外的所有类加载器均继承自这个类）中，`loadClass`方法的一部分源码如下：\n\n```java\nprotected Class<?> loadClass(String name, boolean resolve)\n    throws ClassNotFoundException {\n    synchronized (getClassLoadingLock(name)) {\n        // 检查这个类是不是已经被当前类加载器加载过了\n        Class<?> c = findLoadedClass(name);\n        if (c == null) {\n            long t0 = System.nanoTime();\n            try {\n                if (parent != null) {\n                    // 交给父加载器进行加载\n                    c = parent.loadClass(name, false);\n                } else {\n                    // 父加载器为空，则交给BootstrapClassLoader进行加载\n                    c = findBootstrapClassOrNull(name);\n                }\n            } catch (ClassNotFoundException e) {\n                // 父类加载器或者启动加载器都加载不了这个类\n            }\n            if (c == null) {               \n                long t1 = System.nanoTime();\n                // 调用findClass方法寻找需要加载的类\n                c = findClass(name);\n            }\n        }\n        // 如果需要解析，则对该类进行解析\n        if (resolve) {\n            resolveClass(c);\n        }\n        return c;\n    }\n}\n```\n\n可以看出，类加载器在拿到加载任务后，会交由父加载器进行加载，如果父加载器为null则直接交给启动类加载器进行加载（可以把启动类加载器看作所有加载器的父加载器），如果都加载不了，最后再由自己加载，调用`findClass`方法加载当前类，最后再判断是否需要解析\n\n在`ClassLoader`中默认的`findClass`方法默认抛出异常，需要子类自己去实现，如果要实现自己的类加载器就必须要重写`findClass`方法，如果要打破`双亲委派`模式（即加载类的时候不交给父加载器或者启动类加载器）的话，还需要额外重写`loadClass`方法\n\n##### 为何不能打破双亲委派模式\n\n在之前的例子中，自定义类加载器`SelfClassloader`没有重写`loadClass`方法，因此调用该方法加载类时会首先交给父加载器进行加载，由于父加载器为null，会交由`BootstrapClassLoader`进行加载\n\n在不打破双亲委派模式的情况下，用户无法自己额外伪造一个java核心类库中的类（例如`java.lang.String`）进行加载，因此保证了安全性\n\n##### 什么情况下需要打破双亲委派模式\n\n\n\n#### 重写findClass方法\n\n不打破双亲委派模式，将parent设置为null（此时父加载器为`BootstrapClassLoader`），创建自定义类加载器`SelfClassLoader`，重写`findClass`方法：\n\n```java\npublic class SelfClassLoader extends ClassLoader {\n\tprivate String root;\n    /**\n    * 指定这个类加载器可以加载的类的根路径\n    */\n\tpublic SelfClassLoader(String root) {\n\t\tsuper(null);\n\t\tthis.root = root;\n\t}\n\n\t@Override\n\tpublic Class<?> loadClass(String name) throws ClassNotFoundException {\n\t\treturn super.loadClass(name);\n\t}\n\n\t@Override\n\tprotected Class<?> findClass(String name) throws ClassNotFoundException {\n\t\tFile file;\n        // 将类名转换为path\n\t\tString path = root + name.replace('.', '/').concat(\".class\");\n\t\tfile = new File(path);\n\t\tif (!file.exists()) {\n\t\t\tthrow new ClassNotFoundException(name);\n\t\t}\n\t\tClass<?> clazz;\n\t\ttry {\n            // 读取字节码并调用defineClass方法加载类\n\t\t\tInputStream inputStream = new FileInputStream(file);\n\t\t\tbyte[] bytes = new byte[inputStream.available()];\n\t\t\tint result = inputStream.read(bytes);\n\t\t\tclazz = defineClass(null, bytes, 0, result);\n\t\t} catch (IOException e) {\n\t\t\tthrow new ClassNotFoundException(name, e);\n\t\t}\n\t\treturn clazz;\n\t}\n}\n```\n\n#### 加载指定类\n\n先创建一个类叫`People`，放到桌面的self_class文件夹中：\n\n```java\npublic class People {\n    public String name;\n    public int age;\n}\n```\n\n`SelfClassLoader`这个类加载器用于加载用户指定路径下的类，如下例子指定这个类加载器只能加载位于桌面self_class文件夹中的`.class`文件：\n\n```java\npublic static void main(String[] args) throws Exception {\n    // 指定根路径\n    SelfClassLoader selfClassLoader = new SelfClassLoader(\"C:\\\\Users\\\\admin\\\\Desktop\\\\self_class\\\\\");\n    // 加载该路径下的People这个类\n    Class<?> clazzCustomized = selfClassLoader.loadClass(\"People\");\n    Object instanceCustomized = clazzCustomized.newInstance();\n    Field field1 = clazzCustomized.getField(\"name\");\n    Field field2 = clazzCustomized.getField(\"age\");\n    field1.set(instanceCustomized, \"mike\");\n    field2.set(instanceCustomized, 18);\n    System.out.println(\"name is \" + field1.get(instanceCustomized));\n    System.out.println(\"age is \" + field2.get(instanceCustomized));\n}\n```\n\n#### 类隔离\n\n用自定义类加载器加载的类能够实现与系统默认类加载器（或者是其他的自定义类加载器）的隔离，现在来与系统默认类加载器加载的同一个类进行对比\n\n把People类拷贝一份放到项目classpath中：\n\n```java\n// 这个People类是AppClassLoader加载的\nClass<?> clazzDefault = Class.forName(\"People\");\nObject instanceDefault = clazzDefault.newInstance();\nSystem.out.println(clazzDefault.isInstance(instanceCustomized));\nSystem.out.println(clazzDefault.isInstance(instanceDefault));\nSystem.out.println(instanceCustomized instanceof People);\nSystem.out.println(instanceDefault instanceof People);\n```\n\n打印结果：\n\n> false\n\n> true\n\n> false\n\n> true\n\nclazzDefault由系统默认类加载器（也就是`AppClassLoader`）加载，与自定义类加载器加载的clazzCustomized很显然不是同一个类，这样就实现了不同来源类的隔离\n","slug":"自定义类加载器实践","published":1,"updated":"2019-04-23T14:12:28.231Z","_id":"ckf0h31iw0038actstc2w30wf","comments":1,"layout":"post","photos":[],"link":"","content":"<p>在进行java编程时，一般情况下不需要指定类加载器，jvm会根据需要加载的类自动选择合适的类加载器，不过在某些情况下就需要自定义类加载器实现对不同类别，不同来源或者不同版本的类分别进行加载，例如在tomcat中针对用户类库和tomcat自己的核心类库就实现了不同的类加载器</p>\n<a id=\"more\"></a>\n<h3 id=\"自定义ClassLoader\"><a href=\"#自定义ClassLoader\" class=\"headerlink\" title=\"自定义ClassLoader\"></a>自定义ClassLoader</h3><h4 id=\"双亲委派\"><a href=\"#双亲委派\" class=\"headerlink\" title=\"双亲委派\"></a>双亲委派</h4><p>实现自定义类加载器之前需要先了解<code>双亲委派</code>模式，jvm通过这个机制保证特定的类只能有特定的类加载器来加载</p>\n<p>每个类加载器都会指定一个父类加载器，收到加载任务后会提交给父类加载器进行加载，如果父类加载器加载不了则再交给当前类加载进行加载，目前默认的三种主要的类加载器如下：</p>\n<ul>\n<li><code>BootstrapClassLoader</code>：启动类加载器，复杂加载最为基础和重要的类，例如<code>$JAVA_HOME/jre/lib</code>目录下的类，以及虚拟机参数<code>Xbootclasspat</code>指定的类</li>\n<li><code>ExtClassLoader</code>：扩展类加载器，用于加载java类库中的扩展类库，即<code>$JAVA_HOME/jre/lib/ext</code>目录下的类，以及系统变量<code>java.ext.dirs</code>指定的类</li>\n<li><code>AppClassLoader</code>：应用类加载器，用于加载用户classpath下的所有类，用自己编写的类或者导入的第三方类库默认情况下都由应用类加载器进行加载</li>\n</ul>\n<p>在<code>ClassLoader</code>类（除BootstrapClassLoader外的所有类加载器均继承自这个类）中，<code>loadClass</code>方法的一部分源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">protected</span> Class&lt;?&gt; loadClass(String name, <span class=\"keyword\">boolean</span> resolve)</span><br><span class=\"line\">    <span class=\"keyword\">throws</span> ClassNotFoundException &#123;</span><br><span class=\"line\">    <span class=\"keyword\">synchronized</span> (getClassLoadingLock(name)) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 检查这个类是不是已经被当前类加载器加载过了</span></span><br><span class=\"line\">        Class&lt;?&gt; c = findLoadedClass(name);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (c == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">long</span> t0 = System.nanoTime();</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (parent != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 交给父加载器进行加载</span></span><br><span class=\"line\">                    c = parent.loadClass(name, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 父加载器为空，则交给BootstrapClassLoader进行加载</span></span><br><span class=\"line\">                    c = findBootstrapClassOrNull(name);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (ClassNotFoundException e) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 父类加载器或者启动加载器都加载不了这个类</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (c == <span class=\"keyword\">null</span>) &#123;               </span><br><span class=\"line\">                <span class=\"keyword\">long</span> t1 = System.nanoTime();</span><br><span class=\"line\">                <span class=\"comment\">// 调用findClass方法寻找需要加载的类</span></span><br><span class=\"line\">                c = findClass(name);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 如果需要解析，则对该类进行解析</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (resolve) &#123;</span><br><span class=\"line\">            resolveClass(c);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> c;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以看出，类加载器在拿到加载任务后，会交由父加载器进行加载，如果父加载器为null则直接交给启动类加载器进行加载（可以把启动类加载器看作所有加载器的父加载器），如果都加载不了，最后再由自己加载，调用<code>findClass</code>方法加载当前类，最后再判断是否需要解析</p>\n<p>在<code>ClassLoader</code>中默认的<code>findClass</code>方法默认抛出异常，需要子类自己去实现，如果要实现自己的类加载器就必须要重写<code>findClass</code>方法，如果要打破<code>双亲委派</code>模式（即加载类的时候不交给父加载器或者启动类加载器）的话，还需要额外重写<code>loadClass</code>方法</p>\n<h5 id=\"为何不能打破双亲委派模式\"><a href=\"#为何不能打破双亲委派模式\" class=\"headerlink\" title=\"为何不能打破双亲委派模式\"></a>为何不能打破双亲委派模式</h5><p>在之前的例子中，自定义类加载器<code>SelfClassloader</code>没有重写<code>loadClass</code>方法，因此调用该方法加载类时会首先交给父加载器进行加载，由于父加载器为null，会交由<code>BootstrapClassLoader</code>进行加载</p>\n<p>在不打破双亲委派模式的情况下，用户无法自己额外伪造一个java核心类库中的类（例如<code>java.lang.String</code>）进行加载，因此保证了安全性</p>\n<h5 id=\"什么情况下需要打破双亲委派模式\"><a href=\"#什么情况下需要打破双亲委派模式\" class=\"headerlink\" title=\"什么情况下需要打破双亲委派模式\"></a>什么情况下需要打破双亲委派模式</h5><h4 id=\"重写findClass方法\"><a href=\"#重写findClass方法\" class=\"headerlink\" title=\"重写findClass方法\"></a>重写findClass方法</h4><p>不打破双亲委派模式，将parent设置为null（此时父加载器为<code>BootstrapClassLoader</code>），创建自定义类加载器<code>SelfClassLoader</code>，重写<code>findClass</code>方法：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SelfClassLoader</span> <span class=\"keyword\">extends</span> <span class=\"title\">ClassLoader</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">private</span> String root;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">    * 指定这个类加载器可以加载的类的根路径</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">SelfClassLoader</span><span class=\"params\">(String root)</span> </span>&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">super</span>(<span class=\"keyword\">null</span>);</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.root = root;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"keyword\">public</span> Class&lt;?&gt; loadClass(String name) <span class=\"keyword\">throws</span> ClassNotFoundException &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">super</span>.loadClass(name);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"keyword\">protected</span> Class&lt;?&gt; findClass(String name) <span class=\"keyword\">throws</span> ClassNotFoundException &#123;</span><br><span class=\"line\">\t\tFile file;</span><br><span class=\"line\">        <span class=\"comment\">// 将类名转换为path</span></span><br><span class=\"line\">\t\tString path = root + name.replace(<span class=\"string\">'.'</span>, <span class=\"string\">'/'</span>).concat(<span class=\"string\">\".class\"</span>);</span><br><span class=\"line\">\t\tfile = <span class=\"keyword\">new</span> File(path);</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (!file.exists()) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ClassNotFoundException(name);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tClass&lt;?&gt; clazz;</span><br><span class=\"line\">\t\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 读取字节码并调用defineClass方法加载类</span></span><br><span class=\"line\">\t\t\tInputStream inputStream = <span class=\"keyword\">new</span> FileInputStream(file);</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">byte</span>[] bytes = <span class=\"keyword\">new</span> <span class=\"keyword\">byte</span>[inputStream.available()];</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">int</span> result = inputStream.read(bytes);</span><br><span class=\"line\">\t\t\tclazz = defineClass(<span class=\"keyword\">null</span>, bytes, <span class=\"number\">0</span>, result);</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ClassNotFoundException(name, e);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> clazz;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"加载指定类\"><a href=\"#加载指定类\" class=\"headerlink\" title=\"加载指定类\"></a>加载指定类</h4><p>先创建一个类叫<code>People</code>，放到桌面的self_class文件夹中：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">People</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> String name;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">int</span> age;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>SelfClassLoader</code>这个类加载器用于加载用户指定路径下的类，如下例子指定这个类加载器只能加载位于桌面self_class文件夹中的<code>.class</code>文件：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 指定根路径</span></span><br><span class=\"line\">    SelfClassLoader selfClassLoader = <span class=\"keyword\">new</span> SelfClassLoader(<span class=\"string\">\"C:\\\\Users\\\\admin\\\\Desktop\\\\self_class\\\\\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">// 加载该路径下的People这个类</span></span><br><span class=\"line\">    Class&lt;?&gt; clazzCustomized = selfClassLoader.loadClass(<span class=\"string\">\"People\"</span>);</span><br><span class=\"line\">    Object instanceCustomized = clazzCustomized.newInstance();</span><br><span class=\"line\">    Field field1 = clazzCustomized.getField(<span class=\"string\">\"name\"</span>);</span><br><span class=\"line\">    Field field2 = clazzCustomized.getField(<span class=\"string\">\"age\"</span>);</span><br><span class=\"line\">    field1.set(instanceCustomized, <span class=\"string\">\"mike\"</span>);</span><br><span class=\"line\">    field2.set(instanceCustomized, <span class=\"number\">18</span>);</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"name is \"</span> + field1.get(instanceCustomized));</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"age is \"</span> + field2.get(instanceCustomized));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"类隔离\"><a href=\"#类隔离\" class=\"headerlink\" title=\"类隔离\"></a>类隔离</h4><p>用自定义类加载器加载的类能够实现与系统默认类加载器（或者是其他的自定义类加载器）的隔离，现在来与系统默认类加载器加载的同一个类进行对比</p>\n<p>把People类拷贝一份放到项目classpath中：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 这个People类是AppClassLoader加载的</span></span><br><span class=\"line\">Class&lt;?&gt; clazzDefault = Class.forName(<span class=\"string\">\"People\"</span>);</span><br><span class=\"line\">Object instanceDefault = clazzDefault.newInstance();</span><br><span class=\"line\">System.out.println(clazzDefault.isInstance(instanceCustomized));</span><br><span class=\"line\">System.out.println(clazzDefault.isInstance(instanceDefault));</span><br><span class=\"line\">System.out.println(instanceCustomized <span class=\"keyword\">instanceof</span> People);</span><br><span class=\"line\">System.out.println(instanceDefault <span class=\"keyword\">instanceof</span> People);</span><br></pre></td></tr></table></figure>\n<p>打印结果：</p>\n<blockquote>\n<p>false</p>\n</blockquote>\n<blockquote>\n<p>true</p>\n</blockquote>\n<blockquote>\n<p>false</p>\n</blockquote>\n<blockquote>\n<p>true</p>\n</blockquote>\n<p>clazzDefault由系统默认类加载器（也就是<code>AppClassLoader</code>）加载，与自定义类加载器加载的clazzCustomized很显然不是同一个类，这样就实现了不同来源类的隔离</p>\n","site":{"data":{}},"excerpt":"<p>在进行java编程时，一般情况下不需要指定类加载器，jvm会根据需要加载的类自动选择合适的类加载器，不过在某些情况下就需要自定义类加载器实现对不同类别，不同来源或者不同版本的类分别进行加载，例如在tomcat中针对用户类库和tomcat自己的核心类库就实现了不同的类加载器</p>","more":"<h3 id=\"自定义ClassLoader\"><a href=\"#自定义ClassLoader\" class=\"headerlink\" title=\"自定义ClassLoader\"></a>自定义ClassLoader</h3><h4 id=\"双亲委派\"><a href=\"#双亲委派\" class=\"headerlink\" title=\"双亲委派\"></a>双亲委派</h4><p>实现自定义类加载器之前需要先了解<code>双亲委派</code>模式，jvm通过这个机制保证特定的类只能有特定的类加载器来加载</p>\n<p>每个类加载器都会指定一个父类加载器，收到加载任务后会提交给父类加载器进行加载，如果父类加载器加载不了则再交给当前类加载进行加载，目前默认的三种主要的类加载器如下：</p>\n<ul>\n<li><code>BootstrapClassLoader</code>：启动类加载器，复杂加载最为基础和重要的类，例如<code>$JAVA_HOME/jre/lib</code>目录下的类，以及虚拟机参数<code>Xbootclasspat</code>指定的类</li>\n<li><code>ExtClassLoader</code>：扩展类加载器，用于加载java类库中的扩展类库，即<code>$JAVA_HOME/jre/lib/ext</code>目录下的类，以及系统变量<code>java.ext.dirs</code>指定的类</li>\n<li><code>AppClassLoader</code>：应用类加载器，用于加载用户classpath下的所有类，用自己编写的类或者导入的第三方类库默认情况下都由应用类加载器进行加载</li>\n</ul>\n<p>在<code>ClassLoader</code>类（除BootstrapClassLoader外的所有类加载器均继承自这个类）中，<code>loadClass</code>方法的一部分源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">protected</span> Class&lt;?&gt; loadClass(String name, <span class=\"keyword\">boolean</span> resolve)</span><br><span class=\"line\">    <span class=\"keyword\">throws</span> ClassNotFoundException &#123;</span><br><span class=\"line\">    <span class=\"keyword\">synchronized</span> (getClassLoadingLock(name)) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 检查这个类是不是已经被当前类加载器加载过了</span></span><br><span class=\"line\">        Class&lt;?&gt; c = findLoadedClass(name);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (c == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">long</span> t0 = System.nanoTime();</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (parent != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 交给父加载器进行加载</span></span><br><span class=\"line\">                    c = parent.loadClass(name, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 父加载器为空，则交给BootstrapClassLoader进行加载</span></span><br><span class=\"line\">                    c = findBootstrapClassOrNull(name);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (ClassNotFoundException e) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 父类加载器或者启动加载器都加载不了这个类</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (c == <span class=\"keyword\">null</span>) &#123;               </span><br><span class=\"line\">                <span class=\"keyword\">long</span> t1 = System.nanoTime();</span><br><span class=\"line\">                <span class=\"comment\">// 调用findClass方法寻找需要加载的类</span></span><br><span class=\"line\">                c = findClass(name);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 如果需要解析，则对该类进行解析</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (resolve) &#123;</span><br><span class=\"line\">            resolveClass(c);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> c;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以看出，类加载器在拿到加载任务后，会交由父加载器进行加载，如果父加载器为null则直接交给启动类加载器进行加载（可以把启动类加载器看作所有加载器的父加载器），如果都加载不了，最后再由自己加载，调用<code>findClass</code>方法加载当前类，最后再判断是否需要解析</p>\n<p>在<code>ClassLoader</code>中默认的<code>findClass</code>方法默认抛出异常，需要子类自己去实现，如果要实现自己的类加载器就必须要重写<code>findClass</code>方法，如果要打破<code>双亲委派</code>模式（即加载类的时候不交给父加载器或者启动类加载器）的话，还需要额外重写<code>loadClass</code>方法</p>\n<h5 id=\"为何不能打破双亲委派模式\"><a href=\"#为何不能打破双亲委派模式\" class=\"headerlink\" title=\"为何不能打破双亲委派模式\"></a>为何不能打破双亲委派模式</h5><p>在之前的例子中，自定义类加载器<code>SelfClassloader</code>没有重写<code>loadClass</code>方法，因此调用该方法加载类时会首先交给父加载器进行加载，由于父加载器为null，会交由<code>BootstrapClassLoader</code>进行加载</p>\n<p>在不打破双亲委派模式的情况下，用户无法自己额外伪造一个java核心类库中的类（例如<code>java.lang.String</code>）进行加载，因此保证了安全性</p>\n<h5 id=\"什么情况下需要打破双亲委派模式\"><a href=\"#什么情况下需要打破双亲委派模式\" class=\"headerlink\" title=\"什么情况下需要打破双亲委派模式\"></a>什么情况下需要打破双亲委派模式</h5><h4 id=\"重写findClass方法\"><a href=\"#重写findClass方法\" class=\"headerlink\" title=\"重写findClass方法\"></a>重写findClass方法</h4><p>不打破双亲委派模式，将parent设置为null（此时父加载器为<code>BootstrapClassLoader</code>），创建自定义类加载器<code>SelfClassLoader</code>，重写<code>findClass</code>方法：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SelfClassLoader</span> <span class=\"keyword\">extends</span> <span class=\"title\">ClassLoader</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">private</span> String root;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">    * 指定这个类加载器可以加载的类的根路径</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">SelfClassLoader</span><span class=\"params\">(String root)</span> </span>&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">super</span>(<span class=\"keyword\">null</span>);</span><br><span class=\"line\">\t\t<span class=\"keyword\">this</span>.root = root;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"keyword\">public</span> Class&lt;?&gt; loadClass(String name) <span class=\"keyword\">throws</span> ClassNotFoundException &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">super</span>.loadClass(name);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"keyword\">protected</span> Class&lt;?&gt; findClass(String name) <span class=\"keyword\">throws</span> ClassNotFoundException &#123;</span><br><span class=\"line\">\t\tFile file;</span><br><span class=\"line\">        <span class=\"comment\">// 将类名转换为path</span></span><br><span class=\"line\">\t\tString path = root + name.replace(<span class=\"string\">'.'</span>, <span class=\"string\">'/'</span>).concat(<span class=\"string\">\".class\"</span>);</span><br><span class=\"line\">\t\tfile = <span class=\"keyword\">new</span> File(path);</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (!file.exists()) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ClassNotFoundException(name);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tClass&lt;?&gt; clazz;</span><br><span class=\"line\">\t\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 读取字节码并调用defineClass方法加载类</span></span><br><span class=\"line\">\t\t\tInputStream inputStream = <span class=\"keyword\">new</span> FileInputStream(file);</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">byte</span>[] bytes = <span class=\"keyword\">new</span> <span class=\"keyword\">byte</span>[inputStream.available()];</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">int</span> result = inputStream.read(bytes);</span><br><span class=\"line\">\t\t\tclazz = defineClass(<span class=\"keyword\">null</span>, bytes, <span class=\"number\">0</span>, result);</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ClassNotFoundException(name, e);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> clazz;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"加载指定类\"><a href=\"#加载指定类\" class=\"headerlink\" title=\"加载指定类\"></a>加载指定类</h4><p>先创建一个类叫<code>People</code>，放到桌面的self_class文件夹中：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">People</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> String name;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">int</span> age;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>SelfClassLoader</code>这个类加载器用于加载用户指定路径下的类，如下例子指定这个类加载器只能加载位于桌面self_class文件夹中的<code>.class</code>文件：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 指定根路径</span></span><br><span class=\"line\">    SelfClassLoader selfClassLoader = <span class=\"keyword\">new</span> SelfClassLoader(<span class=\"string\">\"C:\\\\Users\\\\admin\\\\Desktop\\\\self_class\\\\\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">// 加载该路径下的People这个类</span></span><br><span class=\"line\">    Class&lt;?&gt; clazzCustomized = selfClassLoader.loadClass(<span class=\"string\">\"People\"</span>);</span><br><span class=\"line\">    Object instanceCustomized = clazzCustomized.newInstance();</span><br><span class=\"line\">    Field field1 = clazzCustomized.getField(<span class=\"string\">\"name\"</span>);</span><br><span class=\"line\">    Field field2 = clazzCustomized.getField(<span class=\"string\">\"age\"</span>);</span><br><span class=\"line\">    field1.set(instanceCustomized, <span class=\"string\">\"mike\"</span>);</span><br><span class=\"line\">    field2.set(instanceCustomized, <span class=\"number\">18</span>);</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"name is \"</span> + field1.get(instanceCustomized));</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"age is \"</span> + field2.get(instanceCustomized));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"类隔离\"><a href=\"#类隔离\" class=\"headerlink\" title=\"类隔离\"></a>类隔离</h4><p>用自定义类加载器加载的类能够实现与系统默认类加载器（或者是其他的自定义类加载器）的隔离，现在来与系统默认类加载器加载的同一个类进行对比</p>\n<p>把People类拷贝一份放到项目classpath中：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 这个People类是AppClassLoader加载的</span></span><br><span class=\"line\">Class&lt;?&gt; clazzDefault = Class.forName(<span class=\"string\">\"People\"</span>);</span><br><span class=\"line\">Object instanceDefault = clazzDefault.newInstance();</span><br><span class=\"line\">System.out.println(clazzDefault.isInstance(instanceCustomized));</span><br><span class=\"line\">System.out.println(clazzDefault.isInstance(instanceDefault));</span><br><span class=\"line\">System.out.println(instanceCustomized <span class=\"keyword\">instanceof</span> People);</span><br><span class=\"line\">System.out.println(instanceDefault <span class=\"keyword\">instanceof</span> People);</span><br></pre></td></tr></table></figure>\n<p>打印结果：</p>\n<blockquote>\n<p>false</p>\n</blockquote>\n<blockquote>\n<p>true</p>\n</blockquote>\n<blockquote>\n<p>false</p>\n</blockquote>\n<blockquote>\n<p>true</p>\n</blockquote>\n<p>clazzDefault由系统默认类加载器（也就是<code>AppClassLoader</code>）加载，与自定义类加载器加载的clazzCustomized很显然不是同一个类，这样就实现了不同来源类的隔离</p>"},{"title":"如何理解3PC协议","author":"天渊","date":"2019-03-28T14:33:00.000Z","_content":"3PC协议是在2PC协议的基础上发展而来，全称是`Three-Phase Commit`，即三阶段提交\n\n<!--more-->\n\n### 3PC整体流程\n\n3PC将2PC第二阶段提交协议的\"提交事务请求\"一分为二，总共划分为`CanCommit`，`PreCommit`和`DoCommit`三个阶段：\n\n\n![upload successful](\\blog\\images\\3pc-1.png)\n\n![upload successful](\\blog\\images\\3pc-2.png)\n\n![upload successful](\\blog\\images\\3pc-3.png)\n\n##### 阶段一：CanCommit\n\n1. 事务询问：协调者向参与者发送包含事务内容的`CanCommit`请求，询问是否可以执行事务提交\n2. 反馈询问响应：参与者如果认为其自身可以顺利执行事务，则反馈`Yes`响应并进入预备状态，否则反馈`No`状态\n\n##### 阶段二：PreCommit\n\n如果协调者从所有参与者获得的反馈都是`Yes`，则执行事务预提交：\n\n1. 发送预提交请求：协调者向参与者发出`PreCommit`请求并进入`Prepare`阶段\n2. 事务预提交：参与者收到协调者的`PreCommit`请求后，执行事务操作并记录undo和redo日志，\n3. 反馈事务执行响应：参与者向协调者反馈事务的预提交结果，`Yes`或者`No`\n\n如果阶段一有参与者反馈`No`或者与协调者通讯超时，协调者则会发起事务中断：\n\n1. 发送`abort`请求：协调者向参与者发起`abort`请求，中断事务\n2. 中断事务：参与者收到`abort`请求，执行中断事务操作\n3. 阶段二中，如果参与者等待协调者的任何请求超时均会执行中断事务操作\n\n##### 阶段三：DoCommit\n\n如果上一阶段协调者从所有参与者那里都获得`Yes`反馈，则执行事务最终提交：\n\n1. 发送提交请求：协调者进入`Commit`状态，向所有参与者发起`DoCommit`请求\n2. 事务提交：参与者收到`DoCommit`请求，会执行事务提交操作，最后释放事务资源\n3. 反馈提交结果：参与者反馈事务提交结果，协调者收到所有反馈结果后完成事务\n\n如果阶段二有参与者反馈`No`或者通讯超时，协调者则会发起事务中断：\n\n1. 发送`abort`请求：协调者向参与者发起`abort`请求，中断事务向\n2. 事务回滚：参与者收到`abort`请求后，会利用undo log执行`RollBack`操作，并在回滚完成后释放资源\n3. 反馈回滚结果：参与者反馈回滚结果，协调者收到所有回滚结果后中断整个事务\n4. 阶段三中，如果参与者等待协调者的任何请求超时均会直接执行事务提交操作\n\n#### 结论\n\n3PC相比于2PC，最大优点降低了参与者的阻塞范围，每个参与者不需要等待全局响应完成就能够自己做出判断（中断 or 提交），并且即使在协调者出现单点故障后仍然能够尽最大可能保障数据一致\n\n**3PC的缺点**：3PC虽然提高了效率，但并没有解决完全保障数据强一致性的问题，那就是在`PreCommit`后，如果协调者和某个参与者无法正常通信，该参与者仍然会执行提交，若另外有参与者提交失败，则会造成数据不一致\n\n保障分布式系统数据一致性最终还得靠`Paxos`算法","source":"_posts/如何理解3PC协议-1.md","raw":"title: 如何理解3PC协议\nauthor: 天渊\ntags:\n  - 分布式理论\ncategories: []\ndate: 2019-03-28 22:33:00\n---\n3PC协议是在2PC协议的基础上发展而来，全称是`Three-Phase Commit`，即三阶段提交\n\n<!--more-->\n\n### 3PC整体流程\n\n3PC将2PC第二阶段提交协议的\"提交事务请求\"一分为二，总共划分为`CanCommit`，`PreCommit`和`DoCommit`三个阶段：\n\n\n![upload successful](\\blog\\images\\3pc-1.png)\n\n![upload successful](\\blog\\images\\3pc-2.png)\n\n![upload successful](\\blog\\images\\3pc-3.png)\n\n##### 阶段一：CanCommit\n\n1. 事务询问：协调者向参与者发送包含事务内容的`CanCommit`请求，询问是否可以执行事务提交\n2. 反馈询问响应：参与者如果认为其自身可以顺利执行事务，则反馈`Yes`响应并进入预备状态，否则反馈`No`状态\n\n##### 阶段二：PreCommit\n\n如果协调者从所有参与者获得的反馈都是`Yes`，则执行事务预提交：\n\n1. 发送预提交请求：协调者向参与者发出`PreCommit`请求并进入`Prepare`阶段\n2. 事务预提交：参与者收到协调者的`PreCommit`请求后，执行事务操作并记录undo和redo日志，\n3. 反馈事务执行响应：参与者向协调者反馈事务的预提交结果，`Yes`或者`No`\n\n如果阶段一有参与者反馈`No`或者与协调者通讯超时，协调者则会发起事务中断：\n\n1. 发送`abort`请求：协调者向参与者发起`abort`请求，中断事务\n2. 中断事务：参与者收到`abort`请求，执行中断事务操作\n3. 阶段二中，如果参与者等待协调者的任何请求超时均会执行中断事务操作\n\n##### 阶段三：DoCommit\n\n如果上一阶段协调者从所有参与者那里都获得`Yes`反馈，则执行事务最终提交：\n\n1. 发送提交请求：协调者进入`Commit`状态，向所有参与者发起`DoCommit`请求\n2. 事务提交：参与者收到`DoCommit`请求，会执行事务提交操作，最后释放事务资源\n3. 反馈提交结果：参与者反馈事务提交结果，协调者收到所有反馈结果后完成事务\n\n如果阶段二有参与者反馈`No`或者通讯超时，协调者则会发起事务中断：\n\n1. 发送`abort`请求：协调者向参与者发起`abort`请求，中断事务向\n2. 事务回滚：参与者收到`abort`请求后，会利用undo log执行`RollBack`操作，并在回滚完成后释放资源\n3. 反馈回滚结果：参与者反馈回滚结果，协调者收到所有回滚结果后中断整个事务\n4. 阶段三中，如果参与者等待协调者的任何请求超时均会直接执行事务提交操作\n\n#### 结论\n\n3PC相比于2PC，最大优点降低了参与者的阻塞范围，每个参与者不需要等待全局响应完成就能够自己做出判断（中断 or 提交），并且即使在协调者出现单点故障后仍然能够尽最大可能保障数据一致\n\n**3PC的缺点**：3PC虽然提高了效率，但并没有解决完全保障数据强一致性的问题，那就是在`PreCommit`后，如果协调者和某个参与者无法正常通信，该参与者仍然会执行提交，若另外有参与者提交失败，则会造成数据不一致\n\n保障分布式系统数据一致性最终还得靠`Paxos`算法","slug":"如何理解3PC协议-1","published":1,"updated":"2019-03-28T14:50:22.624Z","_id":"ckf0h31ix003bactszhi82bcr","comments":1,"layout":"post","photos":[],"link":"","content":"<p>3PC协议是在2PC协议的基础上发展而来，全称是<code>Three-Phase Commit</code>，即三阶段提交</p>\n<a id=\"more\"></a>\n<h3 id=\"3PC整体流程\"><a href=\"#3PC整体流程\" class=\"headerlink\" title=\"3PC整体流程\"></a>3PC整体流程</h3><p>3PC将2PC第二阶段提交协议的”提交事务请求”一分为二，总共划分为<code>CanCommit</code>，<code>PreCommit</code>和<code>DoCommit</code>三个阶段：</p>\n<p><img src=\"\\blog\\images\\3pc-1.png\" alt=\"upload successful\"></p>\n<p><img src=\"\\blog\\images\\3pc-2.png\" alt=\"upload successful\"></p>\n<p><img src=\"\\blog\\images\\3pc-3.png\" alt=\"upload successful\"></p>\n<h5 id=\"阶段一：CanCommit\"><a href=\"#阶段一：CanCommit\" class=\"headerlink\" title=\"阶段一：CanCommit\"></a>阶段一：CanCommit</h5><ol>\n<li>事务询问：协调者向参与者发送包含事务内容的<code>CanCommit</code>请求，询问是否可以执行事务提交</li>\n<li>反馈询问响应：参与者如果认为其自身可以顺利执行事务，则反馈<code>Yes</code>响应并进入预备状态，否则反馈<code>No</code>状态</li>\n</ol>\n<h5 id=\"阶段二：PreCommit\"><a href=\"#阶段二：PreCommit\" class=\"headerlink\" title=\"阶段二：PreCommit\"></a>阶段二：PreCommit</h5><p>如果协调者从所有参与者获得的反馈都是<code>Yes</code>，则执行事务预提交：</p>\n<ol>\n<li>发送预提交请求：协调者向参与者发出<code>PreCommit</code>请求并进入<code>Prepare</code>阶段</li>\n<li>事务预提交：参与者收到协调者的<code>PreCommit</code>请求后，执行事务操作并记录undo和redo日志，</li>\n<li>反馈事务执行响应：参与者向协调者反馈事务的预提交结果，<code>Yes</code>或者<code>No</code></li>\n</ol>\n<p>如果阶段一有参与者反馈<code>No</code>或者与协调者通讯超时，协调者则会发起事务中断：</p>\n<ol>\n<li>发送<code>abort</code>请求：协调者向参与者发起<code>abort</code>请求，中断事务</li>\n<li>中断事务：参与者收到<code>abort</code>请求，执行中断事务操作</li>\n<li>阶段二中，如果参与者等待协调者的任何请求超时均会执行中断事务操作</li>\n</ol>\n<h5 id=\"阶段三：DoCommit\"><a href=\"#阶段三：DoCommit\" class=\"headerlink\" title=\"阶段三：DoCommit\"></a>阶段三：DoCommit</h5><p>如果上一阶段协调者从所有参与者那里都获得<code>Yes</code>反馈，则执行事务最终提交：</p>\n<ol>\n<li>发送提交请求：协调者进入<code>Commit</code>状态，向所有参与者发起<code>DoCommit</code>请求</li>\n<li>事务提交：参与者收到<code>DoCommit</code>请求，会执行事务提交操作，最后释放事务资源</li>\n<li>反馈提交结果：参与者反馈事务提交结果，协调者收到所有反馈结果后完成事务</li>\n</ol>\n<p>如果阶段二有参与者反馈<code>No</code>或者通讯超时，协调者则会发起事务中断：</p>\n<ol>\n<li>发送<code>abort</code>请求：协调者向参与者发起<code>abort</code>请求，中断事务向</li>\n<li>事务回滚：参与者收到<code>abort</code>请求后，会利用undo log执行<code>RollBack</code>操作，并在回滚完成后释放资源</li>\n<li>反馈回滚结果：参与者反馈回滚结果，协调者收到所有回滚结果后中断整个事务</li>\n<li>阶段三中，如果参与者等待协调者的任何请求超时均会直接执行事务提交操作</li>\n</ol>\n<h4 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h4><p>3PC相比于2PC，最大优点降低了参与者的阻塞范围，每个参与者不需要等待全局响应完成就能够自己做出判断（中断 or 提交），并且即使在协调者出现单点故障后仍然能够尽最大可能保障数据一致</p>\n<p><strong>3PC的缺点</strong>：3PC虽然提高了效率，但并没有解决完全保障数据强一致性的问题，那就是在<code>PreCommit</code>后，如果协调者和某个参与者无法正常通信，该参与者仍然会执行提交，若另外有参与者提交失败，则会造成数据不一致</p>\n<p>保障分布式系统数据一致性最终还得靠<code>Paxos</code>算法</p>\n","site":{"data":{}},"excerpt":"<p>3PC协议是在2PC协议的基础上发展而来，全称是<code>Three-Phase Commit</code>，即三阶段提交</p>","more":"<h3 id=\"3PC整体流程\"><a href=\"#3PC整体流程\" class=\"headerlink\" title=\"3PC整体流程\"></a>3PC整体流程</h3><p>3PC将2PC第二阶段提交协议的”提交事务请求”一分为二，总共划分为<code>CanCommit</code>，<code>PreCommit</code>和<code>DoCommit</code>三个阶段：</p>\n<p><img src=\"\\blog\\images\\3pc-1.png\" alt=\"upload successful\"></p>\n<p><img src=\"\\blog\\images\\3pc-2.png\" alt=\"upload successful\"></p>\n<p><img src=\"\\blog\\images\\3pc-3.png\" alt=\"upload successful\"></p>\n<h5 id=\"阶段一：CanCommit\"><a href=\"#阶段一：CanCommit\" class=\"headerlink\" title=\"阶段一：CanCommit\"></a>阶段一：CanCommit</h5><ol>\n<li>事务询问：协调者向参与者发送包含事务内容的<code>CanCommit</code>请求，询问是否可以执行事务提交</li>\n<li>反馈询问响应：参与者如果认为其自身可以顺利执行事务，则反馈<code>Yes</code>响应并进入预备状态，否则反馈<code>No</code>状态</li>\n</ol>\n<h5 id=\"阶段二：PreCommit\"><a href=\"#阶段二：PreCommit\" class=\"headerlink\" title=\"阶段二：PreCommit\"></a>阶段二：PreCommit</h5><p>如果协调者从所有参与者获得的反馈都是<code>Yes</code>，则执行事务预提交：</p>\n<ol>\n<li>发送预提交请求：协调者向参与者发出<code>PreCommit</code>请求并进入<code>Prepare</code>阶段</li>\n<li>事务预提交：参与者收到协调者的<code>PreCommit</code>请求后，执行事务操作并记录undo和redo日志，</li>\n<li>反馈事务执行响应：参与者向协调者反馈事务的预提交结果，<code>Yes</code>或者<code>No</code></li>\n</ol>\n<p>如果阶段一有参与者反馈<code>No</code>或者与协调者通讯超时，协调者则会发起事务中断：</p>\n<ol>\n<li>发送<code>abort</code>请求：协调者向参与者发起<code>abort</code>请求，中断事务</li>\n<li>中断事务：参与者收到<code>abort</code>请求，执行中断事务操作</li>\n<li>阶段二中，如果参与者等待协调者的任何请求超时均会执行中断事务操作</li>\n</ol>\n<h5 id=\"阶段三：DoCommit\"><a href=\"#阶段三：DoCommit\" class=\"headerlink\" title=\"阶段三：DoCommit\"></a>阶段三：DoCommit</h5><p>如果上一阶段协调者从所有参与者那里都获得<code>Yes</code>反馈，则执行事务最终提交：</p>\n<ol>\n<li>发送提交请求：协调者进入<code>Commit</code>状态，向所有参与者发起<code>DoCommit</code>请求</li>\n<li>事务提交：参与者收到<code>DoCommit</code>请求，会执行事务提交操作，最后释放事务资源</li>\n<li>反馈提交结果：参与者反馈事务提交结果，协调者收到所有反馈结果后完成事务</li>\n</ol>\n<p>如果阶段二有参与者反馈<code>No</code>或者通讯超时，协调者则会发起事务中断：</p>\n<ol>\n<li>发送<code>abort</code>请求：协调者向参与者发起<code>abort</code>请求，中断事务向</li>\n<li>事务回滚：参与者收到<code>abort</code>请求后，会利用undo log执行<code>RollBack</code>操作，并在回滚完成后释放资源</li>\n<li>反馈回滚结果：参与者反馈回滚结果，协调者收到所有回滚结果后中断整个事务</li>\n<li>阶段三中，如果参与者等待协调者的任何请求超时均会直接执行事务提交操作</li>\n</ol>\n<h4 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h4><p>3PC相比于2PC，最大优点降低了参与者的阻塞范围，每个参与者不需要等待全局响应完成就能够自己做出判断（中断 or 提交），并且即使在协调者出现单点故障后仍然能够尽最大可能保障数据一致</p>\n<p><strong>3PC的缺点</strong>：3PC虽然提高了效率，但并没有解决完全保障数据强一致性的问题，那就是在<code>PreCommit</code>后，如果协调者和某个参与者无法正常通信，该参与者仍然会执行提交，若另外有参与者提交失败，则会造成数据不一致</p>\n<p>保障分布式系统数据一致性最终还得靠<code>Paxos</code>算法</p>"},{"title":"对于Map-Reduce并行度的理解","author":"天渊","date":"2019-07-24T13:08:00.000Z","_content":"\nhadoop计算框架map-reduce有一个并行度的概念，每个job，对于输入文件A，需要对A进行切片（即`split`），再针对各个`split`单独启动独立的`mapTask`进行计算（hadoop 2.0后由yarn完成），切片完成后启动多个`mapTask`即为mr任务的并行度\n\n<!-- more -->\n\n### map-reduce的split方式\n\n默认情况下，文件的单个split大小（即`split-size`）通常与HDFS的`block-size`保持一致（即默认的128MB），该工作由`FileInputFormat`调用`getSplits()`方法来完成，通过读取文件metadata进行切分，生成对应的`FileSplit`对象，其中就包含了各个文件切片的offset和length等信息，再序列化到`job.splits`文件中：\n\n```java\n// InputFormat类中的方法，从JobContext中获取输入文件的信息\n// 根据输入文件信息生成切分信息\npublic abstract List<InputSplit> getSplits(JobContext context)\n```\n\n文件的切分信息保存在`FileSplit`对象中，主要保存的了文件在相应`FileSystem`上的path，切分开始位置和切分长度，以及主机信息和当前Split的具体位置：\n\n```java\npublic class FileSplit extends InputSplit implements Writable {\n  private Path file;\n  private long start;\n  private long length;\n  private String[] hosts;\n  private SplitLocationInfo[] hostInfos;\n    \n  ......\n}\n```\n\n### map-reduce任务提交过程\n\nmap-reduce在客户端完成切分工作后上传到服务器，针对每个`Split`单独启动mapTask，下面来看看在客户端提交job后是怎么进行split的：\n\n1. `job.submit()`后，初始化一个`JobSubmitter`对象进行job的提交工作\n\n2. `JobSubmitter`调用`submitJobInternal(job, cluster)`方法进行方法的提交，在进行一系列的初始化过程后，调用`writeSplits(job, submitJobDir)`方法进行切分\n\n3. `writeSplits`最终就会调用上面提到的`InputFormat`的`getSplits`方法\n\n4. 在`getSplits`方法中，首先计算split的最大和最小限制：\n\n   ```java\n   // 默认是1，可以通过mapreduce.input.fileinputformat.split.minsize属性进行设置\n   long minSize = Math.max(getFormatMinSplitSize(), getMinSplitSize(job));\n   // 默认是Long.MAX_VALUE，可以通过mapreduce.input.fileinputformat.split.maxsize属性来设置\n   long maxSize = getMaxSplitSize(job);\n   ```\n\n5. 在确认最大最小范围后，需要确定真正需要`splitSize`，使用`computeSplitSize`方法进行确认，可以看出通常情况下`splitSize`即为`blockSize`：\n\n   ```java\n   long splitSize = computeSplitSize(blockSize, minSize, maxSize);\n   //computeSplitSize方法：\n   protected long computeSplitSize(long blockSize, long minSize, long maxSize) {\n       // 在maxSize和blockSize中取小值，最后保证比minSize大\n       return Math.max(minSize, Math.min(maxSize, blockSize));\n   }\n   ```\n\n6. 对文件进行split，代码如下：\n\n   ```java\n   // 剩余还未split的数量\n   long bytesRemaining = length;\n   // 如果剩余数量多于1.1倍的splitSize，则持续进行split\n   while (((double) bytesRemaining)/splitSize > SPLIT_SLOP) {\n       // 获取当前offset所处的block\n       int blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);\n       // 生成split\n       splits.add(makeSplit(path, length-bytesRemaining, splitSize,\n                            blkLocations[blkIndex].getHosts(),\n                            blkLocations[blkIndex].getCachedHosts()));\n       // 更新剩余数量\n       bytesRemaining -= splitSize;\n   }\n   // 剩下的数量小于等于1.1倍的splitSize，直接把他们放到一个split里面去\n   if (bytesRemaining != 0) {\n       int blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);\n       splits.add(makeSplit(path, length-bytesRemaining, bytesRemaining,\n                            blkLocations[blkIndex].getHosts(),\n                            blkLocations[blkIndex].getCachedHosts()));\n   }\n   ```\n\n7. 完成split后，通过`JobSplitWriter`将splits信息保存到一个临时文件`job.splits`中：\n\n   ```java\n   private <T extends InputSplit>\n     int writeNewSplits(JobContext job, Path jobSubmitDir) throws IOException,\n         InterruptedException, ClassNotFoundException {\n       Configuration conf = job.getConfiguration();\n       InputFormat<?, ?> input =\n         ReflectionUtils.newInstance(job.getInputFormatClass(), conf);\n       // 获取splits      \n       List<InputSplit> splits = input.getSplits(job);\n       T[] array = (T[]) splits.toArray(new InputSplit[splits.size()]);\n       Arrays.sort(array, new SplitComparator());\n       // 将splits写到本地临时文件      \n       JobSplitWriter.createSplitFiles(jobSubmitDir, conf, \n           jobSubmitDir.getFileSystem(conf), array);\n       // 返回split的数量      \n       return array.length;\n     }\n   ```\n\n   其中`jobSubmitDir`是在提交阶段在本地创建的用于保存提交信息的临时文件夹，最后将split数目返回，即为需要启动的`mapTask`数目，也就是并行度\n\n8. 最后提交本次job，其中`submitClient`即为提交客户端，如果在yarn环境下是由`YARNRunner`这个类来完成：\n\n   ```java\n   status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());\n   ```\n\n至此整个提交过程完成，`yarn`会根据提交数据（包括split信息和job配置信息）再结合各计算节点的资源利用率，将job提交给各个计算节点启动多个`mapTask`进行计算\n\n关于任务提交后的流程就得研究`yarn`的运行机制了\n\n\n\n\n\n","source":"_posts/对于Map-Reduce并行度的理解.md","raw":"title: 对于Map-Reduce并行度的理解\nauthor: 天渊\ntags:\n  - map-reduce\ncategories:\n  - 大数据\ndate: 2019-07-24 21:08:00\n---\n\nhadoop计算框架map-reduce有一个并行度的概念，每个job，对于输入文件A，需要对A进行切片（即`split`），再针对各个`split`单独启动独立的`mapTask`进行计算（hadoop 2.0后由yarn完成），切片完成后启动多个`mapTask`即为mr任务的并行度\n\n<!-- more -->\n\n### map-reduce的split方式\n\n默认情况下，文件的单个split大小（即`split-size`）通常与HDFS的`block-size`保持一致（即默认的128MB），该工作由`FileInputFormat`调用`getSplits()`方法来完成，通过读取文件metadata进行切分，生成对应的`FileSplit`对象，其中就包含了各个文件切片的offset和length等信息，再序列化到`job.splits`文件中：\n\n```java\n// InputFormat类中的方法，从JobContext中获取输入文件的信息\n// 根据输入文件信息生成切分信息\npublic abstract List<InputSplit> getSplits(JobContext context)\n```\n\n文件的切分信息保存在`FileSplit`对象中，主要保存的了文件在相应`FileSystem`上的path，切分开始位置和切分长度，以及主机信息和当前Split的具体位置：\n\n```java\npublic class FileSplit extends InputSplit implements Writable {\n  private Path file;\n  private long start;\n  private long length;\n  private String[] hosts;\n  private SplitLocationInfo[] hostInfos;\n    \n  ......\n}\n```\n\n### map-reduce任务提交过程\n\nmap-reduce在客户端完成切分工作后上传到服务器，针对每个`Split`单独启动mapTask，下面来看看在客户端提交job后是怎么进行split的：\n\n1. `job.submit()`后，初始化一个`JobSubmitter`对象进行job的提交工作\n\n2. `JobSubmitter`调用`submitJobInternal(job, cluster)`方法进行方法的提交，在进行一系列的初始化过程后，调用`writeSplits(job, submitJobDir)`方法进行切分\n\n3. `writeSplits`最终就会调用上面提到的`InputFormat`的`getSplits`方法\n\n4. 在`getSplits`方法中，首先计算split的最大和最小限制：\n\n   ```java\n   // 默认是1，可以通过mapreduce.input.fileinputformat.split.minsize属性进行设置\n   long minSize = Math.max(getFormatMinSplitSize(), getMinSplitSize(job));\n   // 默认是Long.MAX_VALUE，可以通过mapreduce.input.fileinputformat.split.maxsize属性来设置\n   long maxSize = getMaxSplitSize(job);\n   ```\n\n5. 在确认最大最小范围后，需要确定真正需要`splitSize`，使用`computeSplitSize`方法进行确认，可以看出通常情况下`splitSize`即为`blockSize`：\n\n   ```java\n   long splitSize = computeSplitSize(blockSize, minSize, maxSize);\n   //computeSplitSize方法：\n   protected long computeSplitSize(long blockSize, long minSize, long maxSize) {\n       // 在maxSize和blockSize中取小值，最后保证比minSize大\n       return Math.max(minSize, Math.min(maxSize, blockSize));\n   }\n   ```\n\n6. 对文件进行split，代码如下：\n\n   ```java\n   // 剩余还未split的数量\n   long bytesRemaining = length;\n   // 如果剩余数量多于1.1倍的splitSize，则持续进行split\n   while (((double) bytesRemaining)/splitSize > SPLIT_SLOP) {\n       // 获取当前offset所处的block\n       int blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);\n       // 生成split\n       splits.add(makeSplit(path, length-bytesRemaining, splitSize,\n                            blkLocations[blkIndex].getHosts(),\n                            blkLocations[blkIndex].getCachedHosts()));\n       // 更新剩余数量\n       bytesRemaining -= splitSize;\n   }\n   // 剩下的数量小于等于1.1倍的splitSize，直接把他们放到一个split里面去\n   if (bytesRemaining != 0) {\n       int blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);\n       splits.add(makeSplit(path, length-bytesRemaining, bytesRemaining,\n                            blkLocations[blkIndex].getHosts(),\n                            blkLocations[blkIndex].getCachedHosts()));\n   }\n   ```\n\n7. 完成split后，通过`JobSplitWriter`将splits信息保存到一个临时文件`job.splits`中：\n\n   ```java\n   private <T extends InputSplit>\n     int writeNewSplits(JobContext job, Path jobSubmitDir) throws IOException,\n         InterruptedException, ClassNotFoundException {\n       Configuration conf = job.getConfiguration();\n       InputFormat<?, ?> input =\n         ReflectionUtils.newInstance(job.getInputFormatClass(), conf);\n       // 获取splits      \n       List<InputSplit> splits = input.getSplits(job);\n       T[] array = (T[]) splits.toArray(new InputSplit[splits.size()]);\n       Arrays.sort(array, new SplitComparator());\n       // 将splits写到本地临时文件      \n       JobSplitWriter.createSplitFiles(jobSubmitDir, conf, \n           jobSubmitDir.getFileSystem(conf), array);\n       // 返回split的数量      \n       return array.length;\n     }\n   ```\n\n   其中`jobSubmitDir`是在提交阶段在本地创建的用于保存提交信息的临时文件夹，最后将split数目返回，即为需要启动的`mapTask`数目，也就是并行度\n\n8. 最后提交本次job，其中`submitClient`即为提交客户端，如果在yarn环境下是由`YARNRunner`这个类来完成：\n\n   ```java\n   status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());\n   ```\n\n至此整个提交过程完成，`yarn`会根据提交数据（包括split信息和job配置信息）再结合各计算节点的资源利用率，将job提交给各个计算节点启动多个`mapTask`进行计算\n\n关于任务提交后的流程就得研究`yarn`的运行机制了\n\n\n\n\n\n","slug":"对于Map-Reduce并行度的理解","published":1,"updated":"2019-07-24T13:09:15.717Z","_id":"ckf0h31iy003factsn9e7a61k","comments":1,"layout":"post","photos":[],"link":"","content":"<p>hadoop计算框架map-reduce有一个并行度的概念，每个job，对于输入文件A，需要对A进行切片（即<code>split</code>），再针对各个<code>split</code>单独启动独立的<code>mapTask</code>进行计算（hadoop 2.0后由yarn完成），切片完成后启动多个<code>mapTask</code>即为mr任务的并行度</p>\n<a id=\"more\"></a>\n<h3 id=\"map-reduce的split方式\"><a href=\"#map-reduce的split方式\" class=\"headerlink\" title=\"map-reduce的split方式\"></a>map-reduce的split方式</h3><p>默认情况下，文件的单个split大小（即<code>split-size</code>）通常与HDFS的<code>block-size</code>保持一致（即默认的128MB），该工作由<code>FileInputFormat</code>调用<code>getSplits()</code>方法来完成，通过读取文件metadata进行切分，生成对应的<code>FileSplit</code>对象，其中就包含了各个文件切片的offset和length等信息，再序列化到<code>job.splits</code>文件中：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// InputFormat类中的方法，从JobContext中获取输入文件的信息</span></span><br><span class=\"line\"><span class=\"comment\">// 根据输入文件信息生成切分信息</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">abstract</span> List&lt;InputSplit&gt; <span class=\"title\">getSplits</span><span class=\"params\">(JobContext context)</span></span></span><br></pre></td></tr></table></figure>\n<p>文件的切分信息保存在<code>FileSplit</code>对象中，主要保存的了文件在相应<code>FileSystem</code>上的path，切分开始位置和切分长度，以及主机信息和当前Split的具体位置：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FileSplit</span> <span class=\"keyword\">extends</span> <span class=\"title\">InputSplit</span> <span class=\"keyword\">implements</span> <span class=\"title\">Writable</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> Path file;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> start;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> length;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> String[] hosts;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> SplitLocationInfo[] hostInfos;</span><br><span class=\"line\">    </span><br><span class=\"line\">  ......</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"map-reduce任务提交过程\"><a href=\"#map-reduce任务提交过程\" class=\"headerlink\" title=\"map-reduce任务提交过程\"></a>map-reduce任务提交过程</h3><p>map-reduce在客户端完成切分工作后上传到服务器，针对每个<code>Split</code>单独启动mapTask，下面来看看在客户端提交job后是怎么进行split的：</p>\n<ol>\n<li><p><code>job.submit()</code>后，初始化一个<code>JobSubmitter</code>对象进行job的提交工作</p>\n</li>\n<li><p><code>JobSubmitter</code>调用<code>submitJobInternal(job, cluster)</code>方法进行方法的提交，在进行一系列的初始化过程后，调用<code>writeSplits(job, submitJobDir)</code>方法进行切分</p>\n</li>\n<li><p><code>writeSplits</code>最终就会调用上面提到的<code>InputFormat</code>的<code>getSplits</code>方法</p>\n</li>\n<li><p>在<code>getSplits</code>方法中，首先计算split的最大和最小限制：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 默认是1，可以通过mapreduce.input.fileinputformat.split.minsize属性进行设置</span></span><br><span class=\"line\"><span class=\"keyword\">long</span> minSize = Math.max(getFormatMinSplitSize(), getMinSplitSize(job));</span><br><span class=\"line\"><span class=\"comment\">// 默认是Long.MAX_VALUE，可以通过mapreduce.input.fileinputformat.split.maxsize属性来设置</span></span><br><span class=\"line\"><span class=\"keyword\">long</span> maxSize = getMaxSplitSize(job);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>在确认最大最小范围后，需要确定真正需要<code>splitSize</code>，使用<code>computeSplitSize</code>方法进行确认，可以看出通常情况下<code>splitSize</code>即为<code>blockSize</code>：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">long</span> splitSize = computeSplitSize(blockSize, minSize, maxSize);</span><br><span class=\"line\"><span class=\"comment\">//computeSplitSize方法：</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">long</span> <span class=\"title\">computeSplitSize</span><span class=\"params\">(<span class=\"keyword\">long</span> blockSize, <span class=\"keyword\">long</span> minSize, <span class=\"keyword\">long</span> maxSize)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 在maxSize和blockSize中取小值，最后保证比minSize大</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> Math.max(minSize, Math.min(maxSize, blockSize));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>对文件进行split，代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 剩余还未split的数量</span></span><br><span class=\"line\"><span class=\"keyword\">long</span> bytesRemaining = length;</span><br><span class=\"line\"><span class=\"comment\">// 如果剩余数量多于1.1倍的splitSize，则持续进行split</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> (((<span class=\"keyword\">double</span>) bytesRemaining)/splitSize &gt; SPLIT_SLOP) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 获取当前offset所处的block</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);</span><br><span class=\"line\">    <span class=\"comment\">// 生成split</span></span><br><span class=\"line\">    splits.add(makeSplit(path, length-bytesRemaining, splitSize,</span><br><span class=\"line\">                         blkLocations[blkIndex].getHosts(),</span><br><span class=\"line\">                         blkLocations[blkIndex].getCachedHosts()));</span><br><span class=\"line\">    <span class=\"comment\">// 更新剩余数量</span></span><br><span class=\"line\">    bytesRemaining -= splitSize;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 剩下的数量小于等于1.1倍的splitSize，直接把他们放到一个split里面去</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (bytesRemaining != <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);</span><br><span class=\"line\">    splits.add(makeSplit(path, length-bytesRemaining, bytesRemaining,</span><br><span class=\"line\">                         blkLocations[blkIndex].getHosts(),</span><br><span class=\"line\">                         blkLocations[blkIndex].getCachedHosts()));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>完成split后，通过<code>JobSplitWriter</code>将splits信息保存到一个临时文件<code>job.splits</code>中：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> &lt;T extends InputSplit&gt;</span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">writeNewSplits</span><span class=\"params\">(JobContext job, Path jobSubmitDir)</span> <span class=\"keyword\">throws</span> IOException,</span></span><br><span class=\"line\"><span class=\"function\">      InterruptedException, ClassNotFoundException </span>&#123;</span><br><span class=\"line\">    Configuration conf = job.getConfiguration();</span><br><span class=\"line\">    InputFormat&lt;?, ?&gt; input =</span><br><span class=\"line\">      ReflectionUtils.newInstance(job.getInputFormatClass(), conf);</span><br><span class=\"line\">    <span class=\"comment\">// 获取splits      </span></span><br><span class=\"line\">    List&lt;InputSplit&gt; splits = input.getSplits(job);</span><br><span class=\"line\">    T[] array = (T[]) splits.toArray(<span class=\"keyword\">new</span> InputSplit[splits.size()]);</span><br><span class=\"line\">    Arrays.sort(array, <span class=\"keyword\">new</span> SplitComparator());</span><br><span class=\"line\">    <span class=\"comment\">// 将splits写到本地临时文件      </span></span><br><span class=\"line\">    JobSplitWriter.createSplitFiles(jobSubmitDir, conf, </span><br><span class=\"line\">        jobSubmitDir.getFileSystem(conf), array);</span><br><span class=\"line\">    <span class=\"comment\">// 返回split的数量      </span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> array.length;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n<p>其中<code>jobSubmitDir</code>是在提交阶段在本地创建的用于保存提交信息的临时文件夹，最后将split数目返回，即为需要启动的<code>mapTask</code>数目，也就是并行度</p>\n</li>\n<li><p>最后提交本次job，其中<code>submitClient</code>即为提交客户端，如果在yarn环境下是由<code>YARNRunner</code>这个类来完成：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>至此整个提交过程完成，<code>yarn</code>会根据提交数据（包括split信息和job配置信息）再结合各计算节点的资源利用率，将job提交给各个计算节点启动多个<code>mapTask</code>进行计算</p>\n<p>关于任务提交后的流程就得研究<code>yarn</code>的运行机制了</p>\n","site":{"data":{}},"excerpt":"<p>hadoop计算框架map-reduce有一个并行度的概念，每个job，对于输入文件A，需要对A进行切片（即<code>split</code>），再针对各个<code>split</code>单独启动独立的<code>mapTask</code>进行计算（hadoop 2.0后由yarn完成），切片完成后启动多个<code>mapTask</code>即为mr任务的并行度</p>","more":"<h3 id=\"map-reduce的split方式\"><a href=\"#map-reduce的split方式\" class=\"headerlink\" title=\"map-reduce的split方式\"></a>map-reduce的split方式</h3><p>默认情况下，文件的单个split大小（即<code>split-size</code>）通常与HDFS的<code>block-size</code>保持一致（即默认的128MB），该工作由<code>FileInputFormat</code>调用<code>getSplits()</code>方法来完成，通过读取文件metadata进行切分，生成对应的<code>FileSplit</code>对象，其中就包含了各个文件切片的offset和length等信息，再序列化到<code>job.splits</code>文件中：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// InputFormat类中的方法，从JobContext中获取输入文件的信息</span></span><br><span class=\"line\"><span class=\"comment\">// 根据输入文件信息生成切分信息</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">abstract</span> List&lt;InputSplit&gt; <span class=\"title\">getSplits</span><span class=\"params\">(JobContext context)</span></span></span><br></pre></td></tr></table></figure>\n<p>文件的切分信息保存在<code>FileSplit</code>对象中，主要保存的了文件在相应<code>FileSystem</code>上的path，切分开始位置和切分长度，以及主机信息和当前Split的具体位置：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FileSplit</span> <span class=\"keyword\">extends</span> <span class=\"title\">InputSplit</span> <span class=\"keyword\">implements</span> <span class=\"title\">Writable</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> Path file;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> start;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> length;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> String[] hosts;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> SplitLocationInfo[] hostInfos;</span><br><span class=\"line\">    </span><br><span class=\"line\">  ......</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"map-reduce任务提交过程\"><a href=\"#map-reduce任务提交过程\" class=\"headerlink\" title=\"map-reduce任务提交过程\"></a>map-reduce任务提交过程</h3><p>map-reduce在客户端完成切分工作后上传到服务器，针对每个<code>Split</code>单独启动mapTask，下面来看看在客户端提交job后是怎么进行split的：</p>\n<ol>\n<li><p><code>job.submit()</code>后，初始化一个<code>JobSubmitter</code>对象进行job的提交工作</p>\n</li>\n<li><p><code>JobSubmitter</code>调用<code>submitJobInternal(job, cluster)</code>方法进行方法的提交，在进行一系列的初始化过程后，调用<code>writeSplits(job, submitJobDir)</code>方法进行切分</p>\n</li>\n<li><p><code>writeSplits</code>最终就会调用上面提到的<code>InputFormat</code>的<code>getSplits</code>方法</p>\n</li>\n<li><p>在<code>getSplits</code>方法中，首先计算split的最大和最小限制：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 默认是1，可以通过mapreduce.input.fileinputformat.split.minsize属性进行设置</span></span><br><span class=\"line\"><span class=\"keyword\">long</span> minSize = Math.max(getFormatMinSplitSize(), getMinSplitSize(job));</span><br><span class=\"line\"><span class=\"comment\">// 默认是Long.MAX_VALUE，可以通过mapreduce.input.fileinputformat.split.maxsize属性来设置</span></span><br><span class=\"line\"><span class=\"keyword\">long</span> maxSize = getMaxSplitSize(job);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>在确认最大最小范围后，需要确定真正需要<code>splitSize</code>，使用<code>computeSplitSize</code>方法进行确认，可以看出通常情况下<code>splitSize</code>即为<code>blockSize</code>：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">long</span> splitSize = computeSplitSize(blockSize, minSize, maxSize);</span><br><span class=\"line\"><span class=\"comment\">//computeSplitSize方法：</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">long</span> <span class=\"title\">computeSplitSize</span><span class=\"params\">(<span class=\"keyword\">long</span> blockSize, <span class=\"keyword\">long</span> minSize, <span class=\"keyword\">long</span> maxSize)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 在maxSize和blockSize中取小值，最后保证比minSize大</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> Math.max(minSize, Math.min(maxSize, blockSize));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>对文件进行split，代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 剩余还未split的数量</span></span><br><span class=\"line\"><span class=\"keyword\">long</span> bytesRemaining = length;</span><br><span class=\"line\"><span class=\"comment\">// 如果剩余数量多于1.1倍的splitSize，则持续进行split</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> (((<span class=\"keyword\">double</span>) bytesRemaining)/splitSize &gt; SPLIT_SLOP) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 获取当前offset所处的block</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);</span><br><span class=\"line\">    <span class=\"comment\">// 生成split</span></span><br><span class=\"line\">    splits.add(makeSplit(path, length-bytesRemaining, splitSize,</span><br><span class=\"line\">                         blkLocations[blkIndex].getHosts(),</span><br><span class=\"line\">                         blkLocations[blkIndex].getCachedHosts()));</span><br><span class=\"line\">    <span class=\"comment\">// 更新剩余数量</span></span><br><span class=\"line\">    bytesRemaining -= splitSize;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 剩下的数量小于等于1.1倍的splitSize，直接把他们放到一个split里面去</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (bytesRemaining != <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);</span><br><span class=\"line\">    splits.add(makeSplit(path, length-bytesRemaining, bytesRemaining,</span><br><span class=\"line\">                         blkLocations[blkIndex].getHosts(),</span><br><span class=\"line\">                         blkLocations[blkIndex].getCachedHosts()));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>完成split后，通过<code>JobSplitWriter</code>将splits信息保存到一个临时文件<code>job.splits</code>中：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> &lt;T extends InputSplit&gt;</span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">writeNewSplits</span><span class=\"params\">(JobContext job, Path jobSubmitDir)</span> <span class=\"keyword\">throws</span> IOException,</span></span><br><span class=\"line\"><span class=\"function\">      InterruptedException, ClassNotFoundException </span>&#123;</span><br><span class=\"line\">    Configuration conf = job.getConfiguration();</span><br><span class=\"line\">    InputFormat&lt;?, ?&gt; input =</span><br><span class=\"line\">      ReflectionUtils.newInstance(job.getInputFormatClass(), conf);</span><br><span class=\"line\">    <span class=\"comment\">// 获取splits      </span></span><br><span class=\"line\">    List&lt;InputSplit&gt; splits = input.getSplits(job);</span><br><span class=\"line\">    T[] array = (T[]) splits.toArray(<span class=\"keyword\">new</span> InputSplit[splits.size()]);</span><br><span class=\"line\">    Arrays.sort(array, <span class=\"keyword\">new</span> SplitComparator());</span><br><span class=\"line\">    <span class=\"comment\">// 将splits写到本地临时文件      </span></span><br><span class=\"line\">    JobSplitWriter.createSplitFiles(jobSubmitDir, conf, </span><br><span class=\"line\">        jobSubmitDir.getFileSystem(conf), array);</span><br><span class=\"line\">    <span class=\"comment\">// 返回split的数量      </span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> array.length;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n<p>其中<code>jobSubmitDir</code>是在提交阶段在本地创建的用于保存提交信息的临时文件夹，最后将split数目返回，即为需要启动的<code>mapTask</code>数目，也就是并行度</p>\n</li>\n<li><p>最后提交本次job，其中<code>submitClient</code>即为提交客户端，如果在yarn环境下是由<code>YARNRunner</code>这个类来完成：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>至此整个提交过程完成，<code>yarn</code>会根据提交数据（包括split信息和job配置信息）再结合各计算节点的资源利用率，将job提交给各个计算节点启动多个<code>mapTask</code>进行计算</p>\n<p>关于任务提交后的流程就得研究<code>yarn</code>的运行机制了</p>"},{"title":"如何优雅地遍历并删除一个map中的元素","author":"","date":"2019-03-21T03:18:00.000Z","_content":"最近在实践基于netty造一个http服务器，需要实现`session`功能，需要有一个异步线程定期检查sessionMap中哪些session过期，过期的session需要删除，这个过程需要一边遍历Map一边删除元素，趁此机会探索一下如何优雅地实现这个功能\n\n<!--more-->\n\n## 单线程环境(HashMap)\n\n不考虑多线程的情况，单线程的情况下使用`HashMap`存储并遍历元素有以下方式：\n\n### 对Entry作foreach遍历\n\n对HashMap的Entry作foreach遍历，遍历时如果value为\"111\"则进行remove：\n\n```java\nfor (Map.Entry<String, Object> entry : hashMap.entrySet()) {\n    if (\"111\".equals(entry.getValue())) {\n        hashMap.remove(entry.getKey());\n    }\n}\n```\n\n显而易见这种情况会触发`ConcurrentModificationException`，因为foreach实际上是调用`EntrySet`的迭代器，也就是`HashMap`内部的实现：`EntryIterator`，在进行遍历时会调用这个迭代器的`next()`方法，最终调用的是`HashIterator`的`nextNode()`方法：\n\n```java\nfinal Node<K,V> nextNode() {\n    Node<K,V>[] t;\n    Node<K,V> e = next;\n    // 如果当前modCount与expectedModCount不匹配则抛异常\n    // hashmap的remove()方法会改变modCount，所以这个时候通过此方式遍历当然会报错了\n    if (modCount != expectedModCount)\n        throw new ConcurrentModificationException();\n\t// ...略\n    return e;\n}\n```\n\n`expectedModCount`即预期`modCount`，在初始化迭代器时一同初始化，如果通过迭代器进行遍历时改变了`modCount`就会出现经典的`ConcurrentModificationException`，这个异常在许多其他容器的遍历过程中都会存在，其用意就是让用户另外选择更为安全的遍历方式\n\n由于`hashMap.remove(entry.getKey())`这个操作会更新`modCount`，所以`ConcurrentModificationException`就免不了啦\n\n### 对Entry作foreach遍历（entrySet.forEach(lambda)方式）\n\n使用`EntrySet`自己实现的`forEach()`方法进行遍历，jdk8更新中与lambda表达式一起新加入的，看上去跟上一种方法差不多：\n\n```java\nhashMap.entrySet().forEach(entry -> {\n    if (\"111\".equals(entry.getValue())) {\n        hashMap.remove(entry.getKey());\n    }\n});\n```\n\n使用该方式遍历并删除元素，效果跟上一种一样，当然如预期一样抛出了`ConcurrentModificationException`异常，`EntrySet`自己的`forEach()`也是检测`modCount`在遍历时有没有改动：\n\n```java\npublic final void forEach(Consumer<? super Map.Entry<K,V>> action) {\n    Node<K,V>[] tab;\n    if (action == null)\n        throw new NullPointerException();\n    if (size > 0 && (tab = table) != null) {\n        int mc = modCount;\n        // 用for循环进行遍历，并执行lambda过程\n        for (int i = 0; i < tab.length; ++i) {\n            for (Node<K,V> e = tab[i]; e != null; e = e.next)\n                action.accept(e);\n        }\n        // 遍历完了看看modCount有没有改动，有改动就抛异常\n        if (modCount != mc)\n            throw new ConcurrentModificationException();\n    }\n}\n```\n\n这种实现方式倒是没有上一种曲折，不过没有达到我们的目的\n\n### 对HashMap作foreach遍历(hashMap.forEach(lambda)方式)\n\n这次直接调用`HashMap`自己的`foreach`方法:\n\n```java\nhashMap.forEach((key, value) -> {\n    if (\"111\".equals(value)) {\n        hashMap.remove(key);\n    }\n});\n```\n\n更简洁了，充分体验了lambda的好处，不过`ConcurrentModificationException`还是跑不了，继续探索吧\n\n### 显式的调用EntryIterator并EntryIterator.remove()\n\n翻翻`EntryIterator`的源码可以发现他的父类`HashIterator`实现了一个`remove()`方法，想到`List`的各个实现类都实现了自己的迭代器，以支持在遍历过程中对元素进行新增或者删除，举一反三可以想想现在这个`remove()`方法是不是可以达到我们的目的：\n\n```java\nHashMap<String, Object> hashMap = new HashMap<>();\nhashMap.put(\"hahah\", \"111\");\nhashMap.put(\"hehehe\", \"222\");\nhashMap.put(\"heiheihei\", \"333\");\nSystem.out.println(hashMap);\nIterator<Map.Entry<String, Object>> entryIterator = hashMap.entrySet().iterator();\n// 显示地执行迭代器的迭代方法\nwhile (entryIterator.hasNext()) {\n    Map.Entry<String, Object> next = entryIterator.next();\n    if (\"111\".equals(next.getValue())) {\n        // 使用HashIterator自己的remove，而不是HashMap的remove\n        entryIterator.remove();\n    }\n}\nSystem.out.println(hashMap);\n```\n\n结果如下，未曾抛出任何异常，说明这种方式是切实有效的：\n\n```java\n{hahah=111, heiheihei=333, hehehe=222}\n{heiheihei=333, hehehe=222}\n\nProcess finished with exit code 0\n```\n\n`HashIterator`的`remove()`为了支持遍历时删除，对`expectedModCount`做了一些手脚，源码如下：\n\n```java\npublic final void remove() {\n    Node<K,V> p = current;\n    if (p == null)\n        throw new IllegalStateException();\n    // 删除操作还未进行的时候发现modCount被修改了就抛异常\n    if (modCount != expectedModCount)\n        throw new ConcurrentModificationException();\n    current = null;\n    K key = p.key;\n    removeNode(hash(key), key, null, false, false);\n    // 删除操作完成，把expectedModCount修改为最新的modCount\n    expectedModCount = modCount;\n}\n```\n\n在调用完`removeNode`方法（这个过程会修改`modCount`）后，再把`expectedModCount`修改为`removeNode`，保证后续检查`expectedModCount`不会出问题\n\n> 为什么如此设计？\n>\n> 迭代过程中调用`HashIterator`自己的remove，删除当前迭代指针指向的元素，可以保证这个操作是不受外界影响的（比如其他线程的并发操作），hashMap.remove()就保证不了这个前提\n\n同理，`ListIterator`的设计思路也是基于相同的考虑\n\n### removeIf()\n\njdk8 引入了一个更为简练的方式：`removeIf`，是`Collection`的default方法，对元素进行遍历，满足条件就进行删除：\n\n```java\nhashMap.entrySet().removeIf(next -> \"111\".equals(next.getValue()));\n```\n\n进行该操作完全不需要考虑`ConcurrentModificationException`了，其内部也是调用的对应`Iterator`实现的`remove()`方法，原理跟上一种一致\n\n\n\n","source":"_posts/如何优雅地遍历并删除一个map中的元素.md","raw":"title: 如何优雅地遍历并删除一个map中的元素\ntags:\n  - Java\ncategories:\n  - 基础知识\nauthor: ''\ndate: 2019-03-21 11:18:00\n---\n最近在实践基于netty造一个http服务器，需要实现`session`功能，需要有一个异步线程定期检查sessionMap中哪些session过期，过期的session需要删除，这个过程需要一边遍历Map一边删除元素，趁此机会探索一下如何优雅地实现这个功能\n\n<!--more-->\n\n## 单线程环境(HashMap)\n\n不考虑多线程的情况，单线程的情况下使用`HashMap`存储并遍历元素有以下方式：\n\n### 对Entry作foreach遍历\n\n对HashMap的Entry作foreach遍历，遍历时如果value为\"111\"则进行remove：\n\n```java\nfor (Map.Entry<String, Object> entry : hashMap.entrySet()) {\n    if (\"111\".equals(entry.getValue())) {\n        hashMap.remove(entry.getKey());\n    }\n}\n```\n\n显而易见这种情况会触发`ConcurrentModificationException`，因为foreach实际上是调用`EntrySet`的迭代器，也就是`HashMap`内部的实现：`EntryIterator`，在进行遍历时会调用这个迭代器的`next()`方法，最终调用的是`HashIterator`的`nextNode()`方法：\n\n```java\nfinal Node<K,V> nextNode() {\n    Node<K,V>[] t;\n    Node<K,V> e = next;\n    // 如果当前modCount与expectedModCount不匹配则抛异常\n    // hashmap的remove()方法会改变modCount，所以这个时候通过此方式遍历当然会报错了\n    if (modCount != expectedModCount)\n        throw new ConcurrentModificationException();\n\t// ...略\n    return e;\n}\n```\n\n`expectedModCount`即预期`modCount`，在初始化迭代器时一同初始化，如果通过迭代器进行遍历时改变了`modCount`就会出现经典的`ConcurrentModificationException`，这个异常在许多其他容器的遍历过程中都会存在，其用意就是让用户另外选择更为安全的遍历方式\n\n由于`hashMap.remove(entry.getKey())`这个操作会更新`modCount`，所以`ConcurrentModificationException`就免不了啦\n\n### 对Entry作foreach遍历（entrySet.forEach(lambda)方式）\n\n使用`EntrySet`自己实现的`forEach()`方法进行遍历，jdk8更新中与lambda表达式一起新加入的，看上去跟上一种方法差不多：\n\n```java\nhashMap.entrySet().forEach(entry -> {\n    if (\"111\".equals(entry.getValue())) {\n        hashMap.remove(entry.getKey());\n    }\n});\n```\n\n使用该方式遍历并删除元素，效果跟上一种一样，当然如预期一样抛出了`ConcurrentModificationException`异常，`EntrySet`自己的`forEach()`也是检测`modCount`在遍历时有没有改动：\n\n```java\npublic final void forEach(Consumer<? super Map.Entry<K,V>> action) {\n    Node<K,V>[] tab;\n    if (action == null)\n        throw new NullPointerException();\n    if (size > 0 && (tab = table) != null) {\n        int mc = modCount;\n        // 用for循环进行遍历，并执行lambda过程\n        for (int i = 0; i < tab.length; ++i) {\n            for (Node<K,V> e = tab[i]; e != null; e = e.next)\n                action.accept(e);\n        }\n        // 遍历完了看看modCount有没有改动，有改动就抛异常\n        if (modCount != mc)\n            throw new ConcurrentModificationException();\n    }\n}\n```\n\n这种实现方式倒是没有上一种曲折，不过没有达到我们的目的\n\n### 对HashMap作foreach遍历(hashMap.forEach(lambda)方式)\n\n这次直接调用`HashMap`自己的`foreach`方法:\n\n```java\nhashMap.forEach((key, value) -> {\n    if (\"111\".equals(value)) {\n        hashMap.remove(key);\n    }\n});\n```\n\n更简洁了，充分体验了lambda的好处，不过`ConcurrentModificationException`还是跑不了，继续探索吧\n\n### 显式的调用EntryIterator并EntryIterator.remove()\n\n翻翻`EntryIterator`的源码可以发现他的父类`HashIterator`实现了一个`remove()`方法，想到`List`的各个实现类都实现了自己的迭代器，以支持在遍历过程中对元素进行新增或者删除，举一反三可以想想现在这个`remove()`方法是不是可以达到我们的目的：\n\n```java\nHashMap<String, Object> hashMap = new HashMap<>();\nhashMap.put(\"hahah\", \"111\");\nhashMap.put(\"hehehe\", \"222\");\nhashMap.put(\"heiheihei\", \"333\");\nSystem.out.println(hashMap);\nIterator<Map.Entry<String, Object>> entryIterator = hashMap.entrySet().iterator();\n// 显示地执行迭代器的迭代方法\nwhile (entryIterator.hasNext()) {\n    Map.Entry<String, Object> next = entryIterator.next();\n    if (\"111\".equals(next.getValue())) {\n        // 使用HashIterator自己的remove，而不是HashMap的remove\n        entryIterator.remove();\n    }\n}\nSystem.out.println(hashMap);\n```\n\n结果如下，未曾抛出任何异常，说明这种方式是切实有效的：\n\n```java\n{hahah=111, heiheihei=333, hehehe=222}\n{heiheihei=333, hehehe=222}\n\nProcess finished with exit code 0\n```\n\n`HashIterator`的`remove()`为了支持遍历时删除，对`expectedModCount`做了一些手脚，源码如下：\n\n```java\npublic final void remove() {\n    Node<K,V> p = current;\n    if (p == null)\n        throw new IllegalStateException();\n    // 删除操作还未进行的时候发现modCount被修改了就抛异常\n    if (modCount != expectedModCount)\n        throw new ConcurrentModificationException();\n    current = null;\n    K key = p.key;\n    removeNode(hash(key), key, null, false, false);\n    // 删除操作完成，把expectedModCount修改为最新的modCount\n    expectedModCount = modCount;\n}\n```\n\n在调用完`removeNode`方法（这个过程会修改`modCount`）后，再把`expectedModCount`修改为`removeNode`，保证后续检查`expectedModCount`不会出问题\n\n> 为什么如此设计？\n>\n> 迭代过程中调用`HashIterator`自己的remove，删除当前迭代指针指向的元素，可以保证这个操作是不受外界影响的（比如其他线程的并发操作），hashMap.remove()就保证不了这个前提\n\n同理，`ListIterator`的设计思路也是基于相同的考虑\n\n### removeIf()\n\njdk8 引入了一个更为简练的方式：`removeIf`，是`Collection`的default方法，对元素进行遍历，满足条件就进行删除：\n\n```java\nhashMap.entrySet().removeIf(next -> \"111\".equals(next.getValue()));\n```\n\n进行该操作完全不需要考虑`ConcurrentModificationException`了，其内部也是调用的对应`Iterator`实现的`remove()`方法，原理跟上一种一致\n\n\n\n","slug":"如何优雅地遍历并删除一个map中的元素","published":1,"updated":"2019-03-20T16:32:02.935Z","_id":"ckf0h31j0003iacts9w1ngeww","comments":1,"layout":"post","photos":[],"link":"","content":"<p>最近在实践基于netty造一个http服务器，需要实现<code>session</code>功能，需要有一个异步线程定期检查sessionMap中哪些session过期，过期的session需要删除，这个过程需要一边遍历Map一边删除元素，趁此机会探索一下如何优雅地实现这个功能</p>\n<a id=\"more\"></a>\n<h2 id=\"单线程环境-HashMap\"><a href=\"#单线程环境-HashMap\" class=\"headerlink\" title=\"单线程环境(HashMap)\"></a>单线程环境(HashMap)</h2><p>不考虑多线程的情况，单线程的情况下使用<code>HashMap</code>存储并遍历元素有以下方式：</p>\n<h3 id=\"对Entry作foreach遍历\"><a href=\"#对Entry作foreach遍历\" class=\"headerlink\" title=\"对Entry作foreach遍历\"></a>对Entry作foreach遍历</h3><p>对HashMap的Entry作foreach遍历，遍历时如果value为”111”则进行remove：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> (Map.Entry&lt;String, Object&gt; entry : hashMap.entrySet()) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"string\">\"111\"</span>.equals(entry.getValue())) &#123;</span><br><span class=\"line\">        hashMap.remove(entry.getKey());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>显而易见这种情况会触发<code>ConcurrentModificationException</code>，因为foreach实际上是调用<code>EntrySet</code>的迭代器，也就是<code>HashMap</code>内部的实现：<code>EntryIterator</code>，在进行遍历时会调用这个迭代器的<code>next()</code>方法，最终调用的是<code>HashIterator</code>的<code>nextNode()</code>方法：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> Node&lt;K,V&gt; <span class=\"title\">nextNode</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    Node&lt;K,V&gt;[] t;</span><br><span class=\"line\">    Node&lt;K,V&gt; e = next;</span><br><span class=\"line\">    <span class=\"comment\">// 如果当前modCount与expectedModCount不匹配则抛异常</span></span><br><span class=\"line\">    <span class=\"comment\">// hashmap的remove()方法会改变modCount，所以这个时候通过此方式遍历当然会报错了</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (modCount != expectedModCount)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ConcurrentModificationException();</span><br><span class=\"line\">\t<span class=\"comment\">// ...略</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> e;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>expectedModCount</code>即预期<code>modCount</code>，在初始化迭代器时一同初始化，如果通过迭代器进行遍历时改变了<code>modCount</code>就会出现经典的<code>ConcurrentModificationException</code>，这个异常在许多其他容器的遍历过程中都会存在，其用意就是让用户另外选择更为安全的遍历方式</p>\n<p>由于<code>hashMap.remove(entry.getKey())</code>这个操作会更新<code>modCount</code>，所以<code>ConcurrentModificationException</code>就免不了啦</p>\n<h3 id=\"对Entry作foreach遍历（entrySet-forEach-lambda-方式）\"><a href=\"#对Entry作foreach遍历（entrySet-forEach-lambda-方式）\" class=\"headerlink\" title=\"对Entry作foreach遍历（entrySet.forEach(lambda)方式）\"></a>对Entry作foreach遍历（entrySet.forEach(lambda)方式）</h3><p>使用<code>EntrySet</code>自己实现的<code>forEach()</code>方法进行遍历，jdk8更新中与lambda表达式一起新加入的，看上去跟上一种方法差不多：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hashMap.entrySet().forEach(entry -&gt; &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"string\">\"111\"</span>.equals(entry.getValue())) &#123;</span><br><span class=\"line\">        hashMap.remove(entry.getKey());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>使用该方式遍历并删除元素，效果跟上一种一样，当然如预期一样抛出了<code>ConcurrentModificationException</code>异常，<code>EntrySet</code>自己的<code>forEach()</code>也是检测<code>modCount</code>在遍历时有没有改动：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">forEach</span><span class=\"params\">(Consumer&lt;? <span class=\"keyword\">super</span> Map.Entry&lt;K,V&gt;&gt; action)</span> </span>&#123;</span><br><span class=\"line\">    Node&lt;K,V&gt;[] tab;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (action == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> NullPointerException();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (size &gt; <span class=\"number\">0</span> &amp;&amp; (tab = table) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> mc = modCount;</span><br><span class=\"line\">        <span class=\"comment\">// 用for循环进行遍历，并执行lambda过程</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; tab.length; ++i) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (Node&lt;K,V&gt; e = tab[i]; e != <span class=\"keyword\">null</span>; e = e.next)</span><br><span class=\"line\">                action.accept(e);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 遍历完了看看modCount有没有改动，有改动就抛异常</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (modCount != mc)</span><br><span class=\"line\">            <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ConcurrentModificationException();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这种实现方式倒是没有上一种曲折，不过没有达到我们的目的</p>\n<h3 id=\"对HashMap作foreach遍历-hashMap-forEach-lambda-方式\"><a href=\"#对HashMap作foreach遍历-hashMap-forEach-lambda-方式\" class=\"headerlink\" title=\"对HashMap作foreach遍历(hashMap.forEach(lambda)方式)\"></a>对HashMap作foreach遍历(hashMap.forEach(lambda)方式)</h3><p>这次直接调用<code>HashMap</code>自己的<code>foreach</code>方法:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hashMap.forEach((key, value) -&gt; &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"string\">\"111\"</span>.equals(value)) &#123;</span><br><span class=\"line\">        hashMap.remove(key);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>更简洁了，充分体验了lambda的好处，不过<code>ConcurrentModificationException</code>还是跑不了，继续探索吧</p>\n<h3 id=\"显式的调用EntryIterator并EntryIterator-remove\"><a href=\"#显式的调用EntryIterator并EntryIterator-remove\" class=\"headerlink\" title=\"显式的调用EntryIterator并EntryIterator.remove()\"></a>显式的调用EntryIterator并EntryIterator.remove()</h3><p>翻翻<code>EntryIterator</code>的源码可以发现他的父类<code>HashIterator</code>实现了一个<code>remove()</code>方法，想到<code>List</code>的各个实现类都实现了自己的迭代器，以支持在遍历过程中对元素进行新增或者删除，举一反三可以想想现在这个<code>remove()</code>方法是不是可以达到我们的目的：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">HashMap&lt;String, Object&gt; hashMap = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">hashMap.put(<span class=\"string\">\"hahah\"</span>, <span class=\"string\">\"111\"</span>);</span><br><span class=\"line\">hashMap.put(<span class=\"string\">\"hehehe\"</span>, <span class=\"string\">\"222\"</span>);</span><br><span class=\"line\">hashMap.put(<span class=\"string\">\"heiheihei\"</span>, <span class=\"string\">\"333\"</span>);</span><br><span class=\"line\">System.out.println(hashMap);</span><br><span class=\"line\">Iterator&lt;Map.Entry&lt;String, Object&gt;&gt; entryIterator = hashMap.entrySet().iterator();</span><br><span class=\"line\"><span class=\"comment\">// 显示地执行迭代器的迭代方法</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> (entryIterator.hasNext()) &#123;</span><br><span class=\"line\">    Map.Entry&lt;String, Object&gt; next = entryIterator.next();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"string\">\"111\"</span>.equals(next.getValue())) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 使用HashIterator自己的remove，而不是HashMap的remove</span></span><br><span class=\"line\">        entryIterator.remove();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">System.out.println(hashMap);</span><br></pre></td></tr></table></figure>\n<p>结果如下，未曾抛出任何异常，说明这种方式是切实有效的：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;hahah=<span class=\"number\">111</span>, heiheihei=<span class=\"number\">333</span>, hehehe=<span class=\"number\">222</span>&#125;</span><br><span class=\"line\">&#123;heiheihei=<span class=\"number\">333</span>, hehehe=<span class=\"number\">222</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">Process finished with exit code <span class=\"number\">0</span></span><br></pre></td></tr></table></figure>\n<p><code>HashIterator</code>的<code>remove()</code>为了支持遍历时删除，对<code>expectedModCount</code>做了一些手脚，源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">remove</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    Node&lt;K,V&gt; p = current;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalStateException();</span><br><span class=\"line\">    <span class=\"comment\">// 删除操作还未进行的时候发现modCount被修改了就抛异常</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (modCount != expectedModCount)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ConcurrentModificationException();</span><br><span class=\"line\">    current = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    K key = p.key;</span><br><span class=\"line\">    removeNode(hash(key), key, <span class=\"keyword\">null</span>, <span class=\"keyword\">false</span>, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">    <span class=\"comment\">// 删除操作完成，把expectedModCount修改为最新的modCount</span></span><br><span class=\"line\">    expectedModCount = modCount;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在调用完<code>removeNode</code>方法（这个过程会修改<code>modCount</code>）后，再把<code>expectedModCount</code>修改为<code>removeNode</code>，保证后续检查<code>expectedModCount</code>不会出问题</p>\n<blockquote>\n<p>为什么如此设计？</p>\n<p>迭代过程中调用<code>HashIterator</code>自己的remove，删除当前迭代指针指向的元素，可以保证这个操作是不受外界影响的（比如其他线程的并发操作），hashMap.remove()就保证不了这个前提</p>\n</blockquote>\n<p>同理，<code>ListIterator</code>的设计思路也是基于相同的考虑</p>\n<h3 id=\"removeIf\"><a href=\"#removeIf\" class=\"headerlink\" title=\"removeIf()\"></a>removeIf()</h3><p>jdk8 引入了一个更为简练的方式：<code>removeIf</code>，是<code>Collection</code>的default方法，对元素进行遍历，满足条件就进行删除：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hashMap.entrySet().removeIf(next -&gt; <span class=\"string\">\"111\"</span>.equals(next.getValue()));</span><br></pre></td></tr></table></figure>\n<p>进行该操作完全不需要考虑<code>ConcurrentModificationException</code>了，其内部也是调用的对应<code>Iterator</code>实现的<code>remove()</code>方法，原理跟上一种一致</p>\n","site":{"data":{}},"excerpt":"<p>最近在实践基于netty造一个http服务器，需要实现<code>session</code>功能，需要有一个异步线程定期检查sessionMap中哪些session过期，过期的session需要删除，这个过程需要一边遍历Map一边删除元素，趁此机会探索一下如何优雅地实现这个功能</p>","more":"<h2 id=\"单线程环境-HashMap\"><a href=\"#单线程环境-HashMap\" class=\"headerlink\" title=\"单线程环境(HashMap)\"></a>单线程环境(HashMap)</h2><p>不考虑多线程的情况，单线程的情况下使用<code>HashMap</code>存储并遍历元素有以下方式：</p>\n<h3 id=\"对Entry作foreach遍历\"><a href=\"#对Entry作foreach遍历\" class=\"headerlink\" title=\"对Entry作foreach遍历\"></a>对Entry作foreach遍历</h3><p>对HashMap的Entry作foreach遍历，遍历时如果value为”111”则进行remove：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> (Map.Entry&lt;String, Object&gt; entry : hashMap.entrySet()) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"string\">\"111\"</span>.equals(entry.getValue())) &#123;</span><br><span class=\"line\">        hashMap.remove(entry.getKey());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>显而易见这种情况会触发<code>ConcurrentModificationException</code>，因为foreach实际上是调用<code>EntrySet</code>的迭代器，也就是<code>HashMap</code>内部的实现：<code>EntryIterator</code>，在进行遍历时会调用这个迭代器的<code>next()</code>方法，最终调用的是<code>HashIterator</code>的<code>nextNode()</code>方法：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> Node&lt;K,V&gt; <span class=\"title\">nextNode</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    Node&lt;K,V&gt;[] t;</span><br><span class=\"line\">    Node&lt;K,V&gt; e = next;</span><br><span class=\"line\">    <span class=\"comment\">// 如果当前modCount与expectedModCount不匹配则抛异常</span></span><br><span class=\"line\">    <span class=\"comment\">// hashmap的remove()方法会改变modCount，所以这个时候通过此方式遍历当然会报错了</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (modCount != expectedModCount)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ConcurrentModificationException();</span><br><span class=\"line\">\t<span class=\"comment\">// ...略</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> e;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>expectedModCount</code>即预期<code>modCount</code>，在初始化迭代器时一同初始化，如果通过迭代器进行遍历时改变了<code>modCount</code>就会出现经典的<code>ConcurrentModificationException</code>，这个异常在许多其他容器的遍历过程中都会存在，其用意就是让用户另外选择更为安全的遍历方式</p>\n<p>由于<code>hashMap.remove(entry.getKey())</code>这个操作会更新<code>modCount</code>，所以<code>ConcurrentModificationException</code>就免不了啦</p>\n<h3 id=\"对Entry作foreach遍历（entrySet-forEach-lambda-方式）\"><a href=\"#对Entry作foreach遍历（entrySet-forEach-lambda-方式）\" class=\"headerlink\" title=\"对Entry作foreach遍历（entrySet.forEach(lambda)方式）\"></a>对Entry作foreach遍历（entrySet.forEach(lambda)方式）</h3><p>使用<code>EntrySet</code>自己实现的<code>forEach()</code>方法进行遍历，jdk8更新中与lambda表达式一起新加入的，看上去跟上一种方法差不多：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hashMap.entrySet().forEach(entry -&gt; &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"string\">\"111\"</span>.equals(entry.getValue())) &#123;</span><br><span class=\"line\">        hashMap.remove(entry.getKey());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>使用该方式遍历并删除元素，效果跟上一种一样，当然如预期一样抛出了<code>ConcurrentModificationException</code>异常，<code>EntrySet</code>自己的<code>forEach()</code>也是检测<code>modCount</code>在遍历时有没有改动：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">forEach</span><span class=\"params\">(Consumer&lt;? <span class=\"keyword\">super</span> Map.Entry&lt;K,V&gt;&gt; action)</span> </span>&#123;</span><br><span class=\"line\">    Node&lt;K,V&gt;[] tab;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (action == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> NullPointerException();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (size &gt; <span class=\"number\">0</span> &amp;&amp; (tab = table) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> mc = modCount;</span><br><span class=\"line\">        <span class=\"comment\">// 用for循环进行遍历，并执行lambda过程</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; tab.length; ++i) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (Node&lt;K,V&gt; e = tab[i]; e != <span class=\"keyword\">null</span>; e = e.next)</span><br><span class=\"line\">                action.accept(e);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 遍历完了看看modCount有没有改动，有改动就抛异常</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (modCount != mc)</span><br><span class=\"line\">            <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ConcurrentModificationException();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这种实现方式倒是没有上一种曲折，不过没有达到我们的目的</p>\n<h3 id=\"对HashMap作foreach遍历-hashMap-forEach-lambda-方式\"><a href=\"#对HashMap作foreach遍历-hashMap-forEach-lambda-方式\" class=\"headerlink\" title=\"对HashMap作foreach遍历(hashMap.forEach(lambda)方式)\"></a>对HashMap作foreach遍历(hashMap.forEach(lambda)方式)</h3><p>这次直接调用<code>HashMap</code>自己的<code>foreach</code>方法:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hashMap.forEach((key, value) -&gt; &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"string\">\"111\"</span>.equals(value)) &#123;</span><br><span class=\"line\">        hashMap.remove(key);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>更简洁了，充分体验了lambda的好处，不过<code>ConcurrentModificationException</code>还是跑不了，继续探索吧</p>\n<h3 id=\"显式的调用EntryIterator并EntryIterator-remove\"><a href=\"#显式的调用EntryIterator并EntryIterator-remove\" class=\"headerlink\" title=\"显式的调用EntryIterator并EntryIterator.remove()\"></a>显式的调用EntryIterator并EntryIterator.remove()</h3><p>翻翻<code>EntryIterator</code>的源码可以发现他的父类<code>HashIterator</code>实现了一个<code>remove()</code>方法，想到<code>List</code>的各个实现类都实现了自己的迭代器，以支持在遍历过程中对元素进行新增或者删除，举一反三可以想想现在这个<code>remove()</code>方法是不是可以达到我们的目的：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">HashMap&lt;String, Object&gt; hashMap = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">hashMap.put(<span class=\"string\">\"hahah\"</span>, <span class=\"string\">\"111\"</span>);</span><br><span class=\"line\">hashMap.put(<span class=\"string\">\"hehehe\"</span>, <span class=\"string\">\"222\"</span>);</span><br><span class=\"line\">hashMap.put(<span class=\"string\">\"heiheihei\"</span>, <span class=\"string\">\"333\"</span>);</span><br><span class=\"line\">System.out.println(hashMap);</span><br><span class=\"line\">Iterator&lt;Map.Entry&lt;String, Object&gt;&gt; entryIterator = hashMap.entrySet().iterator();</span><br><span class=\"line\"><span class=\"comment\">// 显示地执行迭代器的迭代方法</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> (entryIterator.hasNext()) &#123;</span><br><span class=\"line\">    Map.Entry&lt;String, Object&gt; next = entryIterator.next();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"string\">\"111\"</span>.equals(next.getValue())) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 使用HashIterator自己的remove，而不是HashMap的remove</span></span><br><span class=\"line\">        entryIterator.remove();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">System.out.println(hashMap);</span><br></pre></td></tr></table></figure>\n<p>结果如下，未曾抛出任何异常，说明这种方式是切实有效的：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;hahah=<span class=\"number\">111</span>, heiheihei=<span class=\"number\">333</span>, hehehe=<span class=\"number\">222</span>&#125;</span><br><span class=\"line\">&#123;heiheihei=<span class=\"number\">333</span>, hehehe=<span class=\"number\">222</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">Process finished with exit code <span class=\"number\">0</span></span><br></pre></td></tr></table></figure>\n<p><code>HashIterator</code>的<code>remove()</code>为了支持遍历时删除，对<code>expectedModCount</code>做了一些手脚，源码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">remove</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    Node&lt;K,V&gt; p = current;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalStateException();</span><br><span class=\"line\">    <span class=\"comment\">// 删除操作还未进行的时候发现modCount被修改了就抛异常</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (modCount != expectedModCount)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ConcurrentModificationException();</span><br><span class=\"line\">    current = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    K key = p.key;</span><br><span class=\"line\">    removeNode(hash(key), key, <span class=\"keyword\">null</span>, <span class=\"keyword\">false</span>, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">    <span class=\"comment\">// 删除操作完成，把expectedModCount修改为最新的modCount</span></span><br><span class=\"line\">    expectedModCount = modCount;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在调用完<code>removeNode</code>方法（这个过程会修改<code>modCount</code>）后，再把<code>expectedModCount</code>修改为<code>removeNode</code>，保证后续检查<code>expectedModCount</code>不会出问题</p>\n<blockquote>\n<p>为什么如此设计？</p>\n<p>迭代过程中调用<code>HashIterator</code>自己的remove，删除当前迭代指针指向的元素，可以保证这个操作是不受外界影响的（比如其他线程的并发操作），hashMap.remove()就保证不了这个前提</p>\n</blockquote>\n<p>同理，<code>ListIterator</code>的设计思路也是基于相同的考虑</p>\n<h3 id=\"removeIf\"><a href=\"#removeIf\" class=\"headerlink\" title=\"removeIf()\"></a>removeIf()</h3><p>jdk8 引入了一个更为简练的方式：<code>removeIf</code>，是<code>Collection</code>的default方法，对元素进行遍历，满足条件就进行删除：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hashMap.entrySet().removeIf(next -&gt; <span class=\"string\">\"111\"</span>.equals(next.getValue()));</span><br></pre></td></tr></table></figure>\n<p>进行该操作完全不需要考虑<code>ConcurrentModificationException</code>了，其内部也是调用的对应<code>Iterator</code>实现的<code>remove()</code>方法，原理跟上一种一致</p>"},{"title":"gossip协议初探——原理及应用","author":"天渊","date":"2020-09-13T03:48:00.000Z","_content":"### 什么是gossip协议\n`Gossip Protocol`，字面理解也就是`绯闻协议`，还有个名字叫做`Epidimic Protocol(流行性协议)`，这个协议基于`最终一致性(BASE)`以及`去中心化`的设计思想，被广泛运用于各个分布式系统中，用于分布式节点之间进行信息交换和数据同步，具有`低负载`，`高可靠`和`可扩展性`等特点，其比较著名的设计实现包括redis-cluster，Cassandra数据库，KV存储中间件Consul，以及一些区块链项目也使用了`Gossip Protocol`来实现信息交互\n<!--more-->\n\n#### Gossip协议的理论基础\n`Gossip Protocol`最早是在1987年发表在ACM上的论文 《Epidemic Algorithms for Replicated Database Maintenance》中被提出，其理论基础来源于流行病学的数学模型，这种场景的一个最大特点就是组成的网络的节点都是去中心化的对等节点，在信息同步过程中不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，实现最终一致性协议\n\n### Gossip协议主要概念\n`Gossip Protocol`是利用一种随机的方式将信息散播到整个集群网络中，就像流言蜚语或者流行病毒的传播过程，通过`一传十，十传百`，在没有中心调度节点的情况下，短时间内自动将消息同步到集群中的每个节点：\n\n![gossip-protocol](http://img.mantian.site/Snipaste_2020-09-13_11-49-46.png)\n\n如图所述，集群中每个节点随机选择通讯对象并向其发送信息，以达到共识信息在整个集群进行同步的目的\n\n#### Gossip协议的特点\n\n`Gossip Protocol`有以下几个优势：\n\n1. **扩展性**：集群网络允许任意个节点，新加入的节点的状态最终会与其他节点一致\n2. **容错**：集群中任何节点失效都不会影响集群消息的传播\n3. **去中心化**：集群中任何节点的地位都是对等的，只要网络是连通的，任意一个节点就可以把消息散播到全网\n4. **一致性收敛**：系统状态的不一致可以在很快的时间内收敛到一致，消息传播速度能够达到 `logN`\n\n相应的，Gossip协议又有以下缺点：\n\n1. **消息延迟**：集群消息需要经过多个轮次才能让整个集群状态达到一致，因此使用 Gossip 协议会造成不可避免的消息延迟，不适合用在对实时性要求较高的场景\n2. **消息冗余**：由于在某些Gossip实现中，集群节点需要定期随机选择周围节点发送消息，收到消息的节点也会重复该步骤，因此就不可避免的存在消息重复发送给同一节点的情况，造成了消息的冗余\n\n### Gossip协议实现形式\n\n`Gossip Protocol`实现形式大致分为两种：`Anti-Entropy`，`Rumor-Mongering`\n\n#### Anti-Entropy\n\n`Anti-Entropy`，即`反熵`，顾名思义，熵代表混乱，那么反熵就是在混乱中寻求一致，因此Gossip协议的反熵实现其主要目的就是想要集群状态尽快达到一致：\n\n1. 反熵模式下，一个节点会定期把**所有的数据**都跟其他节点共享，以便消除节点之间数据的任何不一致，它可以保证最终完全的一致，这种方式集群收敛速度很快\n2. 反熵模式下，消息会**不断反复的交换**，消息数量是无限制的，对系统来说是非常巨大的开销\n\n#### Rumor-Mongering\n\n`Rumor-Mongering`，即`谣言传播`，顾名思义只有当有**新的“谣言”产生时**才需要进行信息交互，因此在这种模式下消息只包含最新信息，消息体积更小，消息可以发送得更频繁，但相比于`Anti-Entropy`模式，由于`Rumor-Mongering`模式规定一个消息在某个时间后会被标记为过期不再传播，因此这种情况下集群状态有可能会产生不一致\n\n### Gossip协议的信息交互\n\n`Gossip Protocol`根据信息交互方式又可以分为`Push-based`，`Pull-based`以及`Pull-Push-based`三种实现：\n\n#### Push-based\n基于推模式的`Gossip Protocol`，其大致实现主要有以下几个步骤：\n1. 网络中的某个节点随机的选择其他N个节点作为传输对象。\n2. 该节点向其选中的N个节点传输相应的信息\n3. 接收到信息的节点重复完成相同的工作\n\n#### Pull-based\n基于拉模式，大致实现有以下几个步骤：\n1. 某个节点随机选择N个节点询问有没有最新的信息\n2. 这N个节点在收到询问后向其回复是否有最新信息\n\n#### Pull-Push-based\n\n除了这两种模式，`Gossip Protocol`还有基于这两种模式的混合模式`Pull-Push-based`：\n\n1. 源节点随机选择N个节点作为目标节点，询问其有没有最新的信息\n2. 目标节点将本地比源节点新的数据推送给源节点，源节点则更新本地\n3. 源节点再将本地比目标节点新的数据推送给目标节点，目标节点则更新本地\n\n相比之下`Push-based`网络通信消耗最低，而`Pull-Push-based`虽然通信消耗最高，但集群交互收敛性更强，理论上一次通信就可以使两个节点的状态完全一致\n\n![convergence time](http://img.mantian.site/Snipaste_2020-09-13_11-52-08.png\t)\n\n上图反映了三种通信模式下集群状态的收敛程度，可以看到，`Pull-Push-based`的收敛性是最强的\n\n#### 对网络可靠性要求较低\n`Gossip Protocol`原则上并不对网络的质量做出任何要求，因此很多`Gossip Protocol`都基于`UDP`协议进行实现","source":"_posts/gossip协议初探——原理及应用.md","raw":"title: gossip协议初探——原理及应用\nauthor: 天渊\ntags:\n  - gossip\ncategories: []\ndate: 2020-09-13 11:48:00\n---\n### 什么是gossip协议\n`Gossip Protocol`，字面理解也就是`绯闻协议`，还有个名字叫做`Epidimic Protocol(流行性协议)`，这个协议基于`最终一致性(BASE)`以及`去中心化`的设计思想，被广泛运用于各个分布式系统中，用于分布式节点之间进行信息交换和数据同步，具有`低负载`，`高可靠`和`可扩展性`等特点，其比较著名的设计实现包括redis-cluster，Cassandra数据库，KV存储中间件Consul，以及一些区块链项目也使用了`Gossip Protocol`来实现信息交互\n<!--more-->\n\n#### Gossip协议的理论基础\n`Gossip Protocol`最早是在1987年发表在ACM上的论文 《Epidemic Algorithms for Replicated Database Maintenance》中被提出，其理论基础来源于流行病学的数学模型，这种场景的一个最大特点就是组成的网络的节点都是去中心化的对等节点，在信息同步过程中不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，实现最终一致性协议\n\n### Gossip协议主要概念\n`Gossip Protocol`是利用一种随机的方式将信息散播到整个集群网络中，就像流言蜚语或者流行病毒的传播过程，通过`一传十，十传百`，在没有中心调度节点的情况下，短时间内自动将消息同步到集群中的每个节点：\n\n![gossip-protocol](http://img.mantian.site/Snipaste_2020-09-13_11-49-46.png)\n\n如图所述，集群中每个节点随机选择通讯对象并向其发送信息，以达到共识信息在整个集群进行同步的目的\n\n#### Gossip协议的特点\n\n`Gossip Protocol`有以下几个优势：\n\n1. **扩展性**：集群网络允许任意个节点，新加入的节点的状态最终会与其他节点一致\n2. **容错**：集群中任何节点失效都不会影响集群消息的传播\n3. **去中心化**：集群中任何节点的地位都是对等的，只要网络是连通的，任意一个节点就可以把消息散播到全网\n4. **一致性收敛**：系统状态的不一致可以在很快的时间内收敛到一致，消息传播速度能够达到 `logN`\n\n相应的，Gossip协议又有以下缺点：\n\n1. **消息延迟**：集群消息需要经过多个轮次才能让整个集群状态达到一致，因此使用 Gossip 协议会造成不可避免的消息延迟，不适合用在对实时性要求较高的场景\n2. **消息冗余**：由于在某些Gossip实现中，集群节点需要定期随机选择周围节点发送消息，收到消息的节点也会重复该步骤，因此就不可避免的存在消息重复发送给同一节点的情况，造成了消息的冗余\n\n### Gossip协议实现形式\n\n`Gossip Protocol`实现形式大致分为两种：`Anti-Entropy`，`Rumor-Mongering`\n\n#### Anti-Entropy\n\n`Anti-Entropy`，即`反熵`，顾名思义，熵代表混乱，那么反熵就是在混乱中寻求一致，因此Gossip协议的反熵实现其主要目的就是想要集群状态尽快达到一致：\n\n1. 反熵模式下，一个节点会定期把**所有的数据**都跟其他节点共享，以便消除节点之间数据的任何不一致，它可以保证最终完全的一致，这种方式集群收敛速度很快\n2. 反熵模式下，消息会**不断反复的交换**，消息数量是无限制的，对系统来说是非常巨大的开销\n\n#### Rumor-Mongering\n\n`Rumor-Mongering`，即`谣言传播`，顾名思义只有当有**新的“谣言”产生时**才需要进行信息交互，因此在这种模式下消息只包含最新信息，消息体积更小，消息可以发送得更频繁，但相比于`Anti-Entropy`模式，由于`Rumor-Mongering`模式规定一个消息在某个时间后会被标记为过期不再传播，因此这种情况下集群状态有可能会产生不一致\n\n### Gossip协议的信息交互\n\n`Gossip Protocol`根据信息交互方式又可以分为`Push-based`，`Pull-based`以及`Pull-Push-based`三种实现：\n\n#### Push-based\n基于推模式的`Gossip Protocol`，其大致实现主要有以下几个步骤：\n1. 网络中的某个节点随机的选择其他N个节点作为传输对象。\n2. 该节点向其选中的N个节点传输相应的信息\n3. 接收到信息的节点重复完成相同的工作\n\n#### Pull-based\n基于拉模式，大致实现有以下几个步骤：\n1. 某个节点随机选择N个节点询问有没有最新的信息\n2. 这N个节点在收到询问后向其回复是否有最新信息\n\n#### Pull-Push-based\n\n除了这两种模式，`Gossip Protocol`还有基于这两种模式的混合模式`Pull-Push-based`：\n\n1. 源节点随机选择N个节点作为目标节点，询问其有没有最新的信息\n2. 目标节点将本地比源节点新的数据推送给源节点，源节点则更新本地\n3. 源节点再将本地比目标节点新的数据推送给目标节点，目标节点则更新本地\n\n相比之下`Push-based`网络通信消耗最低，而`Pull-Push-based`虽然通信消耗最高，但集群交互收敛性更强，理论上一次通信就可以使两个节点的状态完全一致\n\n![convergence time](http://img.mantian.site/Snipaste_2020-09-13_11-52-08.png\t)\n\n上图反映了三种通信模式下集群状态的收敛程度，可以看到，`Pull-Push-based`的收敛性是最强的\n\n#### 对网络可靠性要求较低\n`Gossip Protocol`原则上并不对网络的质量做出任何要求，因此很多`Gossip Protocol`都基于`UDP`协议进行实现","slug":"gossip协议初探——原理及应用","published":1,"updated":"2020-09-13T03:53:31.078Z","_id":"ckf0k6v6z000014tsjo0qtkit","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"什么是gossip协议\"><a href=\"#什么是gossip协议\" class=\"headerlink\" title=\"什么是gossip协议\"></a>什么是gossip协议</h3><p><code>Gossip Protocol</code>，字面理解也就是<code>绯闻协议</code>，还有个名字叫做<code>Epidimic Protocol(流行性协议)</code>，这个协议基于<code>最终一致性(BASE)</code>以及<code>去中心化</code>的设计思想，被广泛运用于各个分布式系统中，用于分布式节点之间进行信息交换和数据同步，具有<code>低负载</code>，<code>高可靠</code>和<code>可扩展性</code>等特点，其比较著名的设计实现包括redis-cluster，Cassandra数据库，KV存储中间件Consul，以及一些区块链项目也使用了<code>Gossip Protocol</code>来实现信息交互<br><a id=\"more\"></a></p>\n<h4 id=\"Gossip协议的理论基础\"><a href=\"#Gossip协议的理论基础\" class=\"headerlink\" title=\"Gossip协议的理论基础\"></a>Gossip协议的理论基础</h4><p><code>Gossip Protocol</code>最早是在1987年发表在ACM上的论文 《Epidemic Algorithms for Replicated Database Maintenance》中被提出，其理论基础来源于流行病学的数学模型，这种场景的一个最大特点就是组成的网络的节点都是去中心化的对等节点，在信息同步过程中不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，实现最终一致性协议</p>\n<h3 id=\"Gossip协议主要概念\"><a href=\"#Gossip协议主要概念\" class=\"headerlink\" title=\"Gossip协议主要概念\"></a>Gossip协议主要概念</h3><p><code>Gossip Protocol</code>是利用一种随机的方式将信息散播到整个集群网络中，就像流言蜚语或者流行病毒的传播过程，通过<code>一传十，十传百</code>，在没有中心调度节点的情况下，短时间内自动将消息同步到集群中的每个节点：</p>\n<p><img src=\"http://img.mantian.site/Snipaste_2020-09-13_11-49-46.png\" alt=\"gossip-protocol\"></p>\n<p>如图所述，集群中每个节点随机选择通讯对象并向其发送信息，以达到共识信息在整个集群进行同步的目的</p>\n<h4 id=\"Gossip协议的特点\"><a href=\"#Gossip协议的特点\" class=\"headerlink\" title=\"Gossip协议的特点\"></a>Gossip协议的特点</h4><p><code>Gossip Protocol</code>有以下几个优势：</p>\n<ol>\n<li><strong>扩展性</strong>：集群网络允许任意个节点，新加入的节点的状态最终会与其他节点一致</li>\n<li><strong>容错</strong>：集群中任何节点失效都不会影响集群消息的传播</li>\n<li><strong>去中心化</strong>：集群中任何节点的地位都是对等的，只要网络是连通的，任意一个节点就可以把消息散播到全网</li>\n<li><strong>一致性收敛</strong>：系统状态的不一致可以在很快的时间内收敛到一致，消息传播速度能够达到 <code>logN</code></li>\n</ol>\n<p>相应的，Gossip协议又有以下缺点：</p>\n<ol>\n<li><strong>消息延迟</strong>：集群消息需要经过多个轮次才能让整个集群状态达到一致，因此使用 Gossip 协议会造成不可避免的消息延迟，不适合用在对实时性要求较高的场景</li>\n<li><strong>消息冗余</strong>：由于在某些Gossip实现中，集群节点需要定期随机选择周围节点发送消息，收到消息的节点也会重复该步骤，因此就不可避免的存在消息重复发送给同一节点的情况，造成了消息的冗余</li>\n</ol>\n<h3 id=\"Gossip协议实现形式\"><a href=\"#Gossip协议实现形式\" class=\"headerlink\" title=\"Gossip协议实现形式\"></a>Gossip协议实现形式</h3><p><code>Gossip Protocol</code>实现形式大致分为两种：<code>Anti-Entropy</code>，<code>Rumor-Mongering</code></p>\n<h4 id=\"Anti-Entropy\"><a href=\"#Anti-Entropy\" class=\"headerlink\" title=\"Anti-Entropy\"></a>Anti-Entropy</h4><p><code>Anti-Entropy</code>，即<code>反熵</code>，顾名思义，熵代表混乱，那么反熵就是在混乱中寻求一致，因此Gossip协议的反熵实现其主要目的就是想要集群状态尽快达到一致：</p>\n<ol>\n<li>反熵模式下，一个节点会定期把<strong>所有的数据</strong>都跟其他节点共享，以便消除节点之间数据的任何不一致，它可以保证最终完全的一致，这种方式集群收敛速度很快</li>\n<li>反熵模式下，消息会<strong>不断反复的交换</strong>，消息数量是无限制的，对系统来说是非常巨大的开销</li>\n</ol>\n<h4 id=\"Rumor-Mongering\"><a href=\"#Rumor-Mongering\" class=\"headerlink\" title=\"Rumor-Mongering\"></a>Rumor-Mongering</h4><p><code>Rumor-Mongering</code>，即<code>谣言传播</code>，顾名思义只有当有<strong>新的“谣言”产生时</strong>才需要进行信息交互，因此在这种模式下消息只包含最新信息，消息体积更小，消息可以发送得更频繁，但相比于<code>Anti-Entropy</code>模式，由于<code>Rumor-Mongering</code>模式规定一个消息在某个时间后会被标记为过期不再传播，因此这种情况下集群状态有可能会产生不一致</p>\n<h3 id=\"Gossip协议的信息交互\"><a href=\"#Gossip协议的信息交互\" class=\"headerlink\" title=\"Gossip协议的信息交互\"></a>Gossip协议的信息交互</h3><p><code>Gossip Protocol</code>根据信息交互方式又可以分为<code>Push-based</code>，<code>Pull-based</code>以及<code>Pull-Push-based</code>三种实现：</p>\n<h4 id=\"Push-based\"><a href=\"#Push-based\" class=\"headerlink\" title=\"Push-based\"></a>Push-based</h4><p>基于推模式的<code>Gossip Protocol</code>，其大致实现主要有以下几个步骤：</p>\n<ol>\n<li>网络中的某个节点随机的选择其他N个节点作为传输对象。</li>\n<li>该节点向其选中的N个节点传输相应的信息</li>\n<li>接收到信息的节点重复完成相同的工作</li>\n</ol>\n<h4 id=\"Pull-based\"><a href=\"#Pull-based\" class=\"headerlink\" title=\"Pull-based\"></a>Pull-based</h4><p>基于拉模式，大致实现有以下几个步骤：</p>\n<ol>\n<li>某个节点随机选择N个节点询问有没有最新的信息</li>\n<li>这N个节点在收到询问后向其回复是否有最新信息</li>\n</ol>\n<h4 id=\"Pull-Push-based\"><a href=\"#Pull-Push-based\" class=\"headerlink\" title=\"Pull-Push-based\"></a>Pull-Push-based</h4><p>除了这两种模式，<code>Gossip Protocol</code>还有基于这两种模式的混合模式<code>Pull-Push-based</code>：</p>\n<ol>\n<li>源节点随机选择N个节点作为目标节点，询问其有没有最新的信息</li>\n<li>目标节点将本地比源节点新的数据推送给源节点，源节点则更新本地</li>\n<li>源节点再将本地比目标节点新的数据推送给目标节点，目标节点则更新本地</li>\n</ol>\n<p>相比之下<code>Push-based</code>网络通信消耗最低，而<code>Pull-Push-based</code>虽然通信消耗最高，但集群交互收敛性更强，理论上一次通信就可以使两个节点的状态完全一致</p>\n<p><img src=\"http://img.mantian.site/Snipaste_2020-09-13_11-52-08.png\" alt=\"convergence time\"></p>\n<p>上图反映了三种通信模式下集群状态的收敛程度，可以看到，<code>Pull-Push-based</code>的收敛性是最强的</p>\n<h4 id=\"对网络可靠性要求较低\"><a href=\"#对网络可靠性要求较低\" class=\"headerlink\" title=\"对网络可靠性要求较低\"></a>对网络可靠性要求较低</h4><p><code>Gossip Protocol</code>原则上并不对网络的质量做出任何要求，因此很多<code>Gossip Protocol</code>都基于<code>UDP</code>协议进行实现</p>\n","site":{"data":{}},"excerpt":"<h3 id=\"什么是gossip协议\"><a href=\"#什么是gossip协议\" class=\"headerlink\" title=\"什么是gossip协议\"></a>什么是gossip协议</h3><p><code>Gossip Protocol</code>，字面理解也就是<code>绯闻协议</code>，还有个名字叫做<code>Epidimic Protocol(流行性协议)</code>，这个协议基于<code>最终一致性(BASE)</code>以及<code>去中心化</code>的设计思想，被广泛运用于各个分布式系统中，用于分布式节点之间进行信息交换和数据同步，具有<code>低负载</code>，<code>高可靠</code>和<code>可扩展性</code>等特点，其比较著名的设计实现包括redis-cluster，Cassandra数据库，KV存储中间件Consul，以及一些区块链项目也使用了<code>Gossip Protocol</code>来实现信息交互<br>","more":"</p>\n<h4 id=\"Gossip协议的理论基础\"><a href=\"#Gossip协议的理论基础\" class=\"headerlink\" title=\"Gossip协议的理论基础\"></a>Gossip协议的理论基础</h4><p><code>Gossip Protocol</code>最早是在1987年发表在ACM上的论文 《Epidemic Algorithms for Replicated Database Maintenance》中被提出，其理论基础来源于流行病学的数学模型，这种场景的一个最大特点就是组成的网络的节点都是去中心化的对等节点，在信息同步过程中不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，实现最终一致性协议</p>\n<h3 id=\"Gossip协议主要概念\"><a href=\"#Gossip协议主要概念\" class=\"headerlink\" title=\"Gossip协议主要概念\"></a>Gossip协议主要概念</h3><p><code>Gossip Protocol</code>是利用一种随机的方式将信息散播到整个集群网络中，就像流言蜚语或者流行病毒的传播过程，通过<code>一传十，十传百</code>，在没有中心调度节点的情况下，短时间内自动将消息同步到集群中的每个节点：</p>\n<p><img src=\"http://img.mantian.site/Snipaste_2020-09-13_11-49-46.png\" alt=\"gossip-protocol\"></p>\n<p>如图所述，集群中每个节点随机选择通讯对象并向其发送信息，以达到共识信息在整个集群进行同步的目的</p>\n<h4 id=\"Gossip协议的特点\"><a href=\"#Gossip协议的特点\" class=\"headerlink\" title=\"Gossip协议的特点\"></a>Gossip协议的特点</h4><p><code>Gossip Protocol</code>有以下几个优势：</p>\n<ol>\n<li><strong>扩展性</strong>：集群网络允许任意个节点，新加入的节点的状态最终会与其他节点一致</li>\n<li><strong>容错</strong>：集群中任何节点失效都不会影响集群消息的传播</li>\n<li><strong>去中心化</strong>：集群中任何节点的地位都是对等的，只要网络是连通的，任意一个节点就可以把消息散播到全网</li>\n<li><strong>一致性收敛</strong>：系统状态的不一致可以在很快的时间内收敛到一致，消息传播速度能够达到 <code>logN</code></li>\n</ol>\n<p>相应的，Gossip协议又有以下缺点：</p>\n<ol>\n<li><strong>消息延迟</strong>：集群消息需要经过多个轮次才能让整个集群状态达到一致，因此使用 Gossip 协议会造成不可避免的消息延迟，不适合用在对实时性要求较高的场景</li>\n<li><strong>消息冗余</strong>：由于在某些Gossip实现中，集群节点需要定期随机选择周围节点发送消息，收到消息的节点也会重复该步骤，因此就不可避免的存在消息重复发送给同一节点的情况，造成了消息的冗余</li>\n</ol>\n<h3 id=\"Gossip协议实现形式\"><a href=\"#Gossip协议实现形式\" class=\"headerlink\" title=\"Gossip协议实现形式\"></a>Gossip协议实现形式</h3><p><code>Gossip Protocol</code>实现形式大致分为两种：<code>Anti-Entropy</code>，<code>Rumor-Mongering</code></p>\n<h4 id=\"Anti-Entropy\"><a href=\"#Anti-Entropy\" class=\"headerlink\" title=\"Anti-Entropy\"></a>Anti-Entropy</h4><p><code>Anti-Entropy</code>，即<code>反熵</code>，顾名思义，熵代表混乱，那么反熵就是在混乱中寻求一致，因此Gossip协议的反熵实现其主要目的就是想要集群状态尽快达到一致：</p>\n<ol>\n<li>反熵模式下，一个节点会定期把<strong>所有的数据</strong>都跟其他节点共享，以便消除节点之间数据的任何不一致，它可以保证最终完全的一致，这种方式集群收敛速度很快</li>\n<li>反熵模式下，消息会<strong>不断反复的交换</strong>，消息数量是无限制的，对系统来说是非常巨大的开销</li>\n</ol>\n<h4 id=\"Rumor-Mongering\"><a href=\"#Rumor-Mongering\" class=\"headerlink\" title=\"Rumor-Mongering\"></a>Rumor-Mongering</h4><p><code>Rumor-Mongering</code>，即<code>谣言传播</code>，顾名思义只有当有<strong>新的“谣言”产生时</strong>才需要进行信息交互，因此在这种模式下消息只包含最新信息，消息体积更小，消息可以发送得更频繁，但相比于<code>Anti-Entropy</code>模式，由于<code>Rumor-Mongering</code>模式规定一个消息在某个时间后会被标记为过期不再传播，因此这种情况下集群状态有可能会产生不一致</p>\n<h3 id=\"Gossip协议的信息交互\"><a href=\"#Gossip协议的信息交互\" class=\"headerlink\" title=\"Gossip协议的信息交互\"></a>Gossip协议的信息交互</h3><p><code>Gossip Protocol</code>根据信息交互方式又可以分为<code>Push-based</code>，<code>Pull-based</code>以及<code>Pull-Push-based</code>三种实现：</p>\n<h4 id=\"Push-based\"><a href=\"#Push-based\" class=\"headerlink\" title=\"Push-based\"></a>Push-based</h4><p>基于推模式的<code>Gossip Protocol</code>，其大致实现主要有以下几个步骤：</p>\n<ol>\n<li>网络中的某个节点随机的选择其他N个节点作为传输对象。</li>\n<li>该节点向其选中的N个节点传输相应的信息</li>\n<li>接收到信息的节点重复完成相同的工作</li>\n</ol>\n<h4 id=\"Pull-based\"><a href=\"#Pull-based\" class=\"headerlink\" title=\"Pull-based\"></a>Pull-based</h4><p>基于拉模式，大致实现有以下几个步骤：</p>\n<ol>\n<li>某个节点随机选择N个节点询问有没有最新的信息</li>\n<li>这N个节点在收到询问后向其回复是否有最新信息</li>\n</ol>\n<h4 id=\"Pull-Push-based\"><a href=\"#Pull-Push-based\" class=\"headerlink\" title=\"Pull-Push-based\"></a>Pull-Push-based</h4><p>除了这两种模式，<code>Gossip Protocol</code>还有基于这两种模式的混合模式<code>Pull-Push-based</code>：</p>\n<ol>\n<li>源节点随机选择N个节点作为目标节点，询问其有没有最新的信息</li>\n<li>目标节点将本地比源节点新的数据推送给源节点，源节点则更新本地</li>\n<li>源节点再将本地比目标节点新的数据推送给目标节点，目标节点则更新本地</li>\n</ol>\n<p>相比之下<code>Push-based</code>网络通信消耗最低，而<code>Pull-Push-based</code>虽然通信消耗最高，但集群交互收敛性更强，理论上一次通信就可以使两个节点的状态完全一致</p>\n<p><img src=\"http://img.mantian.site/Snipaste_2020-09-13_11-52-08.png\" alt=\"convergence time\"></p>\n<p>上图反映了三种通信模式下集群状态的收敛程度，可以看到，<code>Pull-Push-based</code>的收敛性是最强的</p>\n<h4 id=\"对网络可靠性要求较低\"><a href=\"#对网络可靠性要求较低\" class=\"headerlink\" title=\"对网络可靠性要求较低\"></a>对网络可靠性要求较低</h4><p><code>Gossip Protocol</code>原则上并不对网络的质量做出任何要求，因此很多<code>Gossip Protocol</code>都基于<code>UDP</code>协议进行实现</p>"}],"PostAsset":[],"PostCategory":[{"post_id":"ckf0h31h30008actsy095kgil","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31hh000factst7sax8tc"},{"post_id":"ckf0h31gq0003actsgatgxf6i","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31hk000jactsd21wxk6b"},{"post_id":"ckf0h31he000dacts9v395nsa","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31hl000macts7dldmbs4"},{"post_id":"ckf0h31gs0004actsh716zpqb","category_id":"ckf0h31hd000aactsyqk11vun","_id":"ckf0h31ho000qactsq4a03omp"},{"post_id":"ckf0h31hg000eactsyvzid657","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31hp000tactsrc9w53p2"},{"post_id":"ckf0h31h00007actsizyxplq6","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31hr000xacts0szvsymf"},{"post_id":"ckf0h31hl000lactsvd1z8o9x","category_id":"ckf0h31hd000aactsyqk11vun","_id":"ckf0h31ht0010actstfflpgu6"},{"post_id":"ckf0h31hb0009acts5vnz2noq","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31hu0013actsuc22byyb"},{"post_id":"ckf0h31ho000sactsltrfk8ha","category_id":"ckf0h31hd000aactsyqk11vun","_id":"ckf0h31hw0016actsdul7two8"},{"post_id":"ckf0h31hn000pactsuk76qwb8","category_id":"ckf0h31hq000vactsp7tmvqhx","_id":"ckf0h31hy0018actsk6r29ps6"},{"post_id":"ckf0h31ht0012actscz3mdswv","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31i0001bactsyuzp7p9z"},{"post_id":"ckf0h31hv0015actsd5thluzv","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31i1001dactsijc0b9bk"},{"post_id":"ckf0h31hx0017acts2mugr2el","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31i3001gactsp87gpzb1"},{"post_id":"ckf0h31hz001aactsoftdfe39","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31i4001jactsy1dc6n7y"},{"post_id":"ckf0h31i2001facts2ii4yuo7","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31i9001oactss64nspka"},{"post_id":"ckf0h31i5001mactshveq7puh","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31ic001uactsk79kh8y4"},{"post_id":"ckf0h31i7001nactszwim85fl","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31id001xactsbwnbyyvy"},{"post_id":"ckf0h31ia001ractstfu7y476","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31ie0021actsplcsjgug"},{"post_id":"ckf0h31ib001tactsalfr2k6g","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31if0024actsudr29iqj"},{"post_id":"ckf0h31ie0020actsihar3mbt","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31ii002aacts4fe5n1gr"},{"post_id":"ckf0h31if0023acts9218e886","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31ik002eactsaevmmidg"},{"post_id":"ckf0h31ig0027acts2tmqrw0p","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31il002hactsj0pru52f"},{"post_id":"ckf0h31ih0029actsqs9b36iy","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31in002lactsk1aqbrpx"},{"post_id":"ckf0h31ij002dacts45uhowzm","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31ip002oactsmmocgkjx"},{"post_id":"ckf0h31il002gactsbb10unf8","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31iq002ractsc634hq3n"},{"post_id":"ckf0h31im002kactsb9em4q8c","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31ir002vactsob1zyz29"},{"post_id":"ckf0h31io002nactsjc5c0mg6","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31is002yactset7vx9f5"},{"post_id":"ckf0h31ip002qactsroel4k7o","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31iu0032actsif0pzdyn"},{"post_id":"ckf0h31ir002uactsn5q1e13v","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31iv0035actsex2utrme"},{"post_id":"ckf0h31is002xactsub83f5ja","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31iw0039actsrknbo8y8"},{"post_id":"ckf0h31it0031actsrlairofa","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31iy003cactsadt0q6pr"},{"post_id":"ckf0h31iu0034actsj11c3w2r","category_id":"ckf0h31hm000nactsv9uk46sp","_id":"ckf0h31iz003gactsy03vjpkp"},{"post_id":"ckf0h31iw0038actstc2w30wf","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31j1003jacts82t9jpu7"},{"post_id":"ckf0h31iy003factsn9e7a61k","category_id":"ckf0h31hd000aactsyqk11vun","_id":"ckf0h31j3003nacts87dr09sm"},{"post_id":"ckf0h31j0003iacts9w1ngeww","category_id":"ckf0h31gt0005acts6b4gt8s1","_id":"ckf0h31j3003pactsqdl44lbx"}],"PostTag":[{"post_id":"ckf0h31gq0003actsgatgxf6i","tag_id":"ckf0h31gz0006actsnhvz4gow","_id":"ckf0h31he000cactsc1rvsbdu"},{"post_id":"ckf0h31gs0004actsh716zpqb","tag_id":"ckf0h31hd000bactsmtzjja8h","_id":"ckf0h31hk000kacts4t9tqklt"},{"post_id":"ckf0h31h00007actsizyxplq6","tag_id":"ckf0h31gz0006actsnhvz4gow","_id":"ckf0h31ho000racts5fosxppj"},{"post_id":"ckf0h31h30008actsy095kgil","tag_id":"ckf0h31hm000oactsfa4n5oc0","_id":"ckf0h31hr000yactsnja1sz1m"},{"post_id":"ckf0h31hb0009acts5vnz2noq","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31hv0014actswoivjwu8"},{"post_id":"ckf0h31he000dacts9v395nsa","tag_id":"ckf0h31ht0011actsjgenantz","_id":"ckf0h31i3001hactslnqyt7da"},{"post_id":"ckf0h31he000dacts9v395nsa","tag_id":"ckf0h31hy0019actsrl1cjejs","_id":"ckf0h31i4001kacts22kxawi0"},{"post_id":"ckf0h31i5001mactshveq7puh","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31i9001pacts5rogx65y"},{"post_id":"ckf0h31hg000eactsyvzid657","tag_id":"ckf0h31i1001eactskqm45aj4","_id":"ckf0h31ib001sactsw53e2ipv"},{"post_id":"ckf0h31hg000eactsyvzid657","tag_id":"ckf0h31i5001lactsyuiyijm3","_id":"ckf0h31ic001vacts5yp1waf7"},{"post_id":"ckf0h31ia001ractstfu7y476","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31ie001zactsg9cyw7fo"},{"post_id":"ckf0h31ib001tactsalfr2k6g","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31if0022actscyqzrp44"},{"post_id":"ckf0h31ie0020actsihar3mbt","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31ig0026acts5owz1n47"},{"post_id":"ckf0h31if0023acts9218e886","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31ih0028actss537yq4p"},{"post_id":"ckf0h31ig0027acts2tmqrw0p","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31ij002cacts94053wkg"},{"post_id":"ckf0h31hj000iactsgpio04r0","tag_id":"ckf0h31ia001qactsr5w1625g","_id":"ckf0h31ik002factst6feo42z"},{"post_id":"ckf0h31hj000iactsgpio04r0","tag_id":"ckf0h31id001yactsivcwobfe","_id":"ckf0h31im002iacts5nmpuiim"},{"post_id":"ckf0h31hj000iactsgpio04r0","tag_id":"ckf0h31ig0025actsltln1oso","_id":"ckf0h31io002mactsq3k7r6vg"},{"post_id":"ckf0h31ih0029actsqs9b36iy","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31ip002pactsmok1qaw5"},{"post_id":"ckf0h31ij002dacts45uhowzm","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31iq002tactst6xqx8ps"},{"post_id":"ckf0h31il002gactsbb10unf8","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31is002wacts714waokv"},{"post_id":"ckf0h31im002kactsb9em4q8c","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31it0030actsp1ylql0i"},{"post_id":"ckf0h31io002nactsjc5c0mg6","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31iu0033actsfnqzesh9"},{"post_id":"ckf0h31hl000lactsvd1z8o9x","tag_id":"ckf0h31ii002bactsgvf34tio","_id":"ckf0h31iw0037acts52r38v43"},{"post_id":"ckf0h31hl000lactsvd1z8o9x","tag_id":"ckf0h31im002jactst6lad4rd","_id":"ckf0h31ix003aactsub34a91t"},{"post_id":"ckf0h31ip002qactsroel4k7o","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31iy003dactsgz0espst"},{"post_id":"ckf0h31ir002uactsn5q1e13v","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31j0003hactsquhwwjmb"},{"post_id":"ckf0h31hn000pactsuk76qwb8","tag_id":"ckf0h31iq002sactspasm0n7t","_id":"ckf0h31j1003kactsnphgf3bd"},{"post_id":"ckf0h31it0031actsrlairofa","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31j3003mactsekd137nr"},{"post_id":"ckf0h31iu0034actsj11c3w2r","tag_id":"ckf0h31hp000uacts47zs64n2","_id":"ckf0h31j3003oactsfa204crh"},{"post_id":"ckf0h31ho000sactsltrfk8ha","tag_id":"ckf0h31it002zactstvgt2sv6","_id":"ckf0h31j4003ractsrznv313t"},{"post_id":"ckf0h31ho000sactsltrfk8ha","tag_id":"ckf0h31iv0036acts0fg97pkd","_id":"ckf0h31j4003sacts51fthxz9"},{"post_id":"ckf0h31hq000wactsg4mimn5q","tag_id":"ckf0h31iy003eactsc95nzfr9","_id":"ckf0h31j4003uactsoka57c81"},{"post_id":"ckf0h31hs000zacts3ghkmnjt","tag_id":"ckf0h31iy003eactsc95nzfr9","_id":"ckf0h31j4003vacts4bi66gow"},{"post_id":"ckf0h31ht0012actscz3mdswv","tag_id":"ckf0h31j3003qactszw1jwat3","_id":"ckf0h31j5003yactstedwvme0"},{"post_id":"ckf0h31ht0012actscz3mdswv","tag_id":"ckf0h31j4003tactshh2arobr","_id":"ckf0h31j5003zactskzrh182g"},{"post_id":"ckf0h31ht0012actscz3mdswv","tag_id":"ckf0h31j4003wacts46cfip22","_id":"ckf0h31j60041acts1kii41oo"},{"post_id":"ckf0h31hv0015actsd5thluzv","tag_id":"ckf0h31ht0011actsjgenantz","_id":"ckf0h31j60042actszp39mjo1"},{"post_id":"ckf0h31hv0015actsd5thluzv","tag_id":"ckf0h31j5003xactssl4cg5y9","_id":"ckf0h31j70044actsctn1c1px"},{"post_id":"ckf0h31hx0017acts2mugr2el","tag_id":"ckf0h31ht0011actsjgenantz","_id":"ckf0h31j70045actsn7vlyivm"},{"post_id":"ckf0h31hx0017acts2mugr2el","tag_id":"ckf0h31j5003xactssl4cg5y9","_id":"ckf0h31j80047acts6xcwpb6w"},{"post_id":"ckf0h31hz001aactsoftdfe39","tag_id":"ckf0h31j4003tactshh2arobr","_id":"ckf0h31j9004aactsd0j5wd7s"},{"post_id":"ckf0h31hz001aactsoftdfe39","tag_id":"ckf0h31j4003wacts46cfip22","_id":"ckf0h31j9004bactsw5d40560"},{"post_id":"ckf0h31hz001aactsoftdfe39","tag_id":"ckf0h31j3003qactszw1jwat3","_id":"ckf0h31ja004dactsjgrzdgx3"},{"post_id":"ckf0h31i0001cactsl4r3hlvk","tag_id":"ckf0h31j90049actsvpt9g66w","_id":"ckf0h31ja004eactse0x4kw41"},{"post_id":"ckf0h31i2001facts2ii4yuo7","tag_id":"ckf0h31ht0011actsjgenantz","_id":"ckf0h31jb004gactsdhcqcr7s"},{"post_id":"ckf0h31i2001facts2ii4yuo7","tag_id":"ckf0h31j5003xactssl4cg5y9","_id":"ckf0h31jb004hactsuk2zila6"},{"post_id":"ckf0h31i3001iactsg5hfi9re","tag_id":"ckf0h31ht0011actsjgenantz","_id":"ckf0h31jc004jactshtr0s08p"},{"post_id":"ckf0h31i3001iactsg5hfi9re","tag_id":"ckf0h31j5003xactssl4cg5y9","_id":"ckf0h31jc004kacts2ha5pe7b"},{"post_id":"ckf0h31i7001nactszwim85fl","tag_id":"ckf0h31jb004iactstlb7mses","_id":"ckf0h31jd004nactsasf8bo35"},{"post_id":"ckf0h31i7001nactszwim85fl","tag_id":"ckf0h31j3003qactszw1jwat3","_id":"ckf0h31jd004oactsykbbxgpe"},{"post_id":"ckf0h31is002xactsub83f5ja","tag_id":"ckf0h31jd004mactsaqzxnseu","_id":"ckf0h31jf004sacts08ni742c"},{"post_id":"ckf0h31is002xactsub83f5ja","tag_id":"ckf0h31jd004pacts0vhqm9dx","_id":"ckf0h31jf004tactsnay5as8q"},{"post_id":"ckf0h31is002xactsub83f5ja","tag_id":"ckf0h31j3003qactszw1jwat3","_id":"ckf0h31jf004vactsaaoc81jj"},{"post_id":"ckf0h31iw0038actstc2w30wf","tag_id":"ckf0h31jf004ractsil57gewg","_id":"ckf0h31jg004xactsk2m1giti"},{"post_id":"ckf0h31iw0038actstc2w30wf","tag_id":"ckf0h31jf004uacts3xaauaeg","_id":"ckf0h31jg004yactso5vh9bwf"},{"post_id":"ckf0h31ix003bactszhi82bcr","tag_id":"ckf0h31jg004wactsfycri8lm","_id":"ckf0h31jh0050actsnm326ef2"},{"post_id":"ckf0h31iy003factsn9e7a61k","tag_id":"ckf0h31jg004zactspgcjv9e8","_id":"ckf0h31jh0052actsx435hva4"},{"post_id":"ckf0h31j0003iacts9w1ngeww","tag_id":"ckf0h31j3003qactszw1jwat3","_id":"ckf0h31ji0053actsmk1cqef7"},{"post_id":"ckf0k6v6z000014tsjo0qtkit","tag_id":"ckf0k7gso000114tsi59ijkap","_id":"ckf0k7gsp000214ts2bgjqv9v"}],"Tag":[{"name":"netty","_id":"ckf0h31gz0006actsnhvz4gow"},{"name":"nifi","_id":"ckf0h31hd000bactsmtzjja8h"},{"name":"Nginx","_id":"ckf0h31hm000oactsfa4n5oc0"},{"name":"csapp","_id":"ckf0h31hp000uacts47zs64n2"},{"name":"Kafka","_id":"ckf0h31ht0011actsjgenantz"},{"name":"reactor","_id":"ckf0h31hy0019actsrl1cjejs"},{"name":"TCP","_id":"ckf0h31i1001eactskqm45aj4"},{"name":"计算机网络","_id":"ckf0h31i5001lactsyuiyijm3"},{"name":"k8s","_id":"ckf0h31ia001qactsr5w1625g"},{"name":"devops","_id":"ckf0h31id001yactsivcwobfe"},{"name":"云原生","_id":"ckf0h31ig0025actsltln1oso"},{"name":"Hadoop","_id":"ckf0h31ii002bactsgvf34tio"},{"name":"Yarn","_id":"ckf0h31im002jactst6lad4rd"},{"name":"vim","_id":"ckf0h31iq002sactspasm0n7t"},{"name":"yarn","_id":"ckf0h31it002zactstvgt2sv6"},{"name":"hadoop","_id":"ckf0h31iv0036acts0fg97pkd"},{"name":"elasticsearch","_id":"ckf0h31iy003eactsc95nzfr9"},{"name":"Java","_id":"ckf0h31j3003qactszw1jwat3"},{"name":"多线程","_id":"ckf0h31j4003tactshh2arobr"},{"name":"Java并发包","_id":"ckf0h31j4003wacts46cfip22"},{"name":"大数据","_id":"ckf0h31j5003xactssl4cg5y9"},{"name":"mongodb","_id":"ckf0h31j90049actsvpt9g66w"},{"name":"Netty","_id":"ckf0h31jb004iactstlb7mses"},{"name":"spring","_id":"ckf0h31jd004mactsaqzxnseu"},{"name":"RestTemplate","_id":"ckf0h31jd004pacts0vhqm9dx"},{"name":"java","_id":"ckf0h31jf004ractsil57gewg"},{"name":"类加载器","_id":"ckf0h31jf004uacts3xaauaeg"},{"name":"分布式理论","_id":"ckf0h31jg004wactsfycri8lm"},{"name":"map-reduce","_id":"ckf0h31jg004zactspgcjv9e8"},{"name":"gossip","_id":"ckf0k7gso000114tsi59ijkap"}]}}